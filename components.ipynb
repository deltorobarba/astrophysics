{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "components.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deltorobarba/machinelearning/blob/master/components.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjNmcYpFuFTY",
        "colab_type": "text"
      },
      "source": [
        "# **Components of Neural Networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzvQMv1ycXK3",
        "colab_type": "text"
      },
      "source": [
        "**Following components of neural networks will be covered**\n",
        "\n",
        "> Activation Function\n",
        "\n",
        "> Regularization\n",
        "\n",
        "> Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhp10G3Muto0",
        "colab_type": "text"
      },
      "source": [
        "**Import Libraries and Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXcjmIMCt4Tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install livelossplot --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYViK39mt7Nj",
        "colab_type": "code",
        "outputId": "cc9fb05e-3517-4df1-f0b7-5921ff241f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "from livelossplot import PlotLossesKeras\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yact1eGKt9bi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdkRafdD1VVv",
        "colab_type": "text"
      },
      "source": [
        "# **Activation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-TDYxwO2upN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvaAFp7B2uuD",
        "colab_type": "text"
      },
      "source": [
        "**Overview**\n",
        "\n",
        "![Activation Function](https://raw.githubusercontent.com/deltorobarba/repo/master/activation.png)\n",
        "\n",
        "* The activation function is the non-linear function that we apply over the output data coming out of a particular layer of neurons before it propagates as the input to the next layer.\n",
        "* Activation functions reside within neurons and transform input values into acceptable and useful range. They can introduce non-linearity to a network.\n",
        "* There are various kinds of activation functions and it has been found, empirically, that some of them works better for large datasets or particular problems than the others. \n",
        "* Neural networks extract hidden pattern from a dataset by observing given examples of known answers. Evidently, it does so by comparing its predictions to the ground truth (labeled images for example) and turning the parameters of the model. The difference between the prediction and the ground truth is called the ‘classification error’.\n",
        "* Parameters of a DL model consists of a set of weights connecting neurons across layers and bias terms which add to those layers. So, the ultimate goal is to set those weights to specific values which reduces the overall classification error. This is a minimization operation, and consequently, an optimization technique is needed.\n",
        "* The overall representation structure of a deep learning model is a highly complex nonlinear function and therefore, the optimizer is responsible for minimizing the error produced by the evaluation of this complex function. Therefore, standard optimization like linear programming does not work for DL models and innovative nonlinear optimization must be used.\n",
        "* These two components – **activation functions** and **nonlinear optimizers** – are at the core of every deep learning architecture. However, there is considerable variety in the specifics of these components.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OmRYTee202F",
        "colab_type": "text"
      },
      "source": [
        "**Necessary Characteristics of Activation Function**\n",
        "\n",
        "Activation functions must be:\n",
        "\n",
        "1. Non-constant (obvious)\n",
        "2. Bounded\n",
        "3. Monotonically increasing\n",
        "4. Continuous\n",
        "\n",
        "These are the conditions under which the universal approximation theorem holds. The universal approximation theorem proves that, under the above conditions, any continuous function of N-variables defined on a compact subset of R^N can be approximated by a three- layer (input, hidden layer, output) neural network with that activation function.\n",
        "\n",
        "The universal approximation theorem is certainly one of the most rigorous tenets of neural networks.\n",
        "\n",
        "Of course, if the prediction problem at hand does not deal with continuous variables or cannot be approximated by a problem that does, then the above is no longer valid and the choice of activation functions becomes more of a customized problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-JlaXJ02212",
        "colab_type": "text"
      },
      "source": [
        "**Selection Criteria**\n",
        "\n",
        "Activation layers are a type of hyperparameter, and you’ll need to experiment with all of them in order to find which works best for you. You can narrow your search by referring to prior work in the field for your particular problem. For example, it has already been shown that tanh activations work better for image classification while leaky ReLUs work better for temporal sequences such as video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7T1Bci91kmz",
        "colab_type": "text"
      },
      "source": [
        "## **Run an Example**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFrNnVE92J71",
        "colab_type": "text"
      },
      "source": [
        "* activation function als Dense parameter. Activation layer als eigener layer.\n",
        "* keras.activation = functions\n",
        "* keras.layers = layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGIWgiCP2aGY",
        "colab_type": "text"
      },
      "source": [
        "**Select one activation function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTZIRw192O0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = tf.keras.activations.tanh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj5LzCvQ2O3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = tf.keras.activations.sigmoid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_Q3vYut2Srq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = tf.keras.layers.ReLU(max_value=None,\n",
        "                                 negative_slope=0,\n",
        "                                 threshold=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDP-0vAo2UGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = tf.keras.layers.LeakyReLU(alpha=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y8gZYsc2ViG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = tf.keras.layers.Softmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7Wg-sTB1tsL",
        "colab_type": "text"
      },
      "source": [
        "**Alternatively Add Default Settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8rkBI0g1r-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = 'relu'\n",
        "# activation = 'linear'\n",
        "# activation = 'sigmoid'\n",
        "# activation = 'tanh'\n",
        "# activation = 'softmax'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70kka3Qj1mVJ",
        "colab_type": "text"
      },
      "source": [
        "**Define Model and Run**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vGUsNGZ1o2B",
        "colab_type": "code",
        "outputId": "a0d6b6da-e588-457d-a5b7-b826b3ef44c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(tf.keras.layers.Dense(512, activation=activation))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.fit(x=x_train, \n",
        "          y=y_train, \n",
        "          epochs=5, \n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5111 - accuracy: 0.8163 - val_loss: 0.4467 - val_accuracy: 0.8383\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4154 - accuracy: 0.8492 - val_loss: 0.4153 - val_accuracy: 0.8480\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3837 - accuracy: 0.8606 - val_loss: 0.4132 - val_accuracy: 0.8506\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3672 - accuracy: 0.8646 - val_loss: 0.3801 - val_accuracy: 0.8684\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3487 - accuracy: 0.8710 - val_loss: 0.3630 - val_accuracy: 0.8670\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f475041fcf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsP-maXp4TL8",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **Regularization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr-q4oEusOUa",
        "colab_type": "text"
      },
      "source": [
        "![Regularization Types](https://raw.githubusercontent.com/deltorobarba/repo/master/vectornorm.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5O1QrOXswPf",
        "colab_type": "text"
      },
      "source": [
        "Source: ['Getting started with Regression'](https://medium.com/@savannahar68/getting-started-with-regression-a39aca03b75f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75X3Z2teJNs-",
        "colab_type": "text"
      },
      "source": [
        "**Theoretical Foundation** \n",
        "\n",
        "Modify cost function J by adding 'preference' to certain parameter values:\n",
        "\n",
        "$J(\\underline{\\theta})=\\frac{1}{2}\\left(\\underline{y}-\\underline{\\theta} \\underline{X}^{T}\\right) \\cdot\\left(\\underline{y}-\\underline{\\theta} \\underline{X}^{T}\\right)^{T}+\\alpha \\theta \\theta^{T}$\n",
        "\n",
        "New solution (derive the same way) - problem is now well-posed for any degree:\n",
        "\n",
        "$\\underline{\\theta}=\\underline{y} \\underline{X}\\left(\\underline{X}^{T} \\underline{X}+\\alpha I\\right)^{-1}$\n",
        "\n",
        "* Shrinks parameters towards zero\n",
        "* Alpha large: we prefer small theta to small MSE\n",
        "* Regularization term is independent of the data: paying more attention reduces variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNJBr4ZHljUM",
        "colab_type": "text"
      },
      "source": [
        "**Lambda Value (λ)**\n",
        "\n",
        "* Lambda is a regularization hyperparameter\n",
        "* Reasonable values of lambda range between 0 and 0.1\n",
        "* L2 weight regularization with very small regularization hyperparameters such as (e.g. 0.0005 or 5 x 10^−4) may be a good starting point\n",
        "* Learn more: [Google Course: Regularization for Simplicity: Lambda](https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/lambda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlN8ilZEqQj7",
        "colab_type": "text"
      },
      "source": [
        "## **L1 Regularization**\n",
        "\n",
        "<p>\n",
        "$\\sum_{i=1}^{n}\\left|u_{i}\\right|=\\sum_{i=1}^{n}\\left|y_{i}-b_{0}-b_{1} x_{i}\\right|$\n",
        "</p><br>\n",
        "\n",
        "* **Synonyms**: Lasso, Manhatten distance, least absolute deviations (LAD method), least absolute errors (LAE)\n",
        "* **Fun Fact**: L1 Regularization is analytical equivalent to Laplacean prior\n",
        "* **Summary**: Sum of the absolute weights. Gives sparse solutions, since it does not take all features. Lasso shrinks the less important feature’s coefficient to zero thus, removing some feature altogether. So, this works well for feature selection in case we have a huge number of features.\n",
        "* **Advantages**: less influenced by outliers (robust). Can shrink some coefficients to zero while lambda increases, performing variable selection. generates sparse feature vectors (Sparse: only very few entries in a matrix or vector is non-zero. L1-norm has property of producing many coefficients with zero values or very small values with few large coefficients). Sparse is sometimes good eg. in high dimensional classification problems. sparsity properties: calculation more computationally efficient.\n",
        "* **Disadvantages**: L1 regularization doesn’t easily work with all forms of training. gives a solution with more large residuals, and a lot of zeros in the solution.\n",
        "* **Use Cases**: if only a subset of features are correlated with the label, as in lasso model some coefficient can be shrunken to zero. very useful when you want to understand exactly which features are contributing to a decision. if you can ignore the ouliers in your dataset or you need them to be there. use L1 when constraints on feature extraction: easily avoid computing a lot of computationally expensive features  at the cost of some of the accuracy, since the L1-norm will give us a solution which has the weights for a large set of features set to zero (real-time detection or tracking of an object/face/material using a set of diverse handcrafted features with a large margin classifier like an SVM in a sliding window fashion - you'd probably want feature computation to be as fast as possible in this case).\n",
        "* **Bayesian**: L1 usually corresponds to setting a Laplacean prior: Some of the coefficients will shrink to zero: similar effect would be achieved in Bayesian linear regression using a Laplacian prior (strongly peaked at zero) on each of the beta coefficients.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHWJgeJqB4gy",
        "colab_type": "text"
      },
      "source": [
        "**Add L1 (Lasso) Penalty Term to Cost Function**\n",
        "\n",
        "$\\sum_{i=1}^{n}\\left(Y_{i}-\\sum_{j=1}^{p} X_{i j} \\beta_{j}\\right)^{2}+\\lambda \\sum_{j=1}^{p}\\left|\\beta_{j}\\right|$\n",
        "\n",
        "* Lasso Regression (Least Absolute Shrinkage and Selection Operator) adds “absolute value of magnitude” of coefficient as penalty term to the loss function.\n",
        "* If lambda is zero then we will get back OLS whereas very large value will make coefficients zero hence it will under-fit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZuDNlbKlWu4",
        "colab_type": "text"
      },
      "source": [
        "## **L2 Regularization**\n",
        "\n",
        "<p>\n",
        "$\\sum_{i=1}^{n} u_{i}^{2}=\\sum_{i=1}^{n}\\left(y_{i}-b_{0}-b_{1} x_{i}\\right)^{2}$\n",
        "</p><br>\n",
        "\n",
        "* **Synonyms**: Weight Decay, Ridge Regression, KQ-Methode, kleinste Quadrate, [Tikhonov regularization](https://en.m.wikipedia.org/wiki/Tikhonov_regularization), Euclidean distance, least squares error (LSE)\n",
        "* **Fun Fact**: L2 Regularization is analytically equivalent to Gaussian prior\n",
        "* **Summary**: Sum of the squared weights. Is the most common type of regularization, also called simply “weight decay,” with values often on a logarithmic scale between 0 and 0.1, such as 0.1, 0.001, 0.0001, etc.\n",
        "* **Advantages**: Shrinks all the coefficient by the same proportions, but eliminates none. Leads to small distributed weights in neural networks. The L2 regularization heavily penalizes \"peaky\" weight vectors and prefers diffuse weight vectors. Empirically performs better than L1. The fit for L2 will be more precise than L1. Works with all forms of training. Smoother: fewer large residual values along with fewer very small residuals as well. L2-norm has analytical solution - allows the L2-norm solutions to be calculated computationally efficiently.\n",
        "* **Disadvantages**: Sensitive to outliers, since L2 wants all errors to be tiny and heavily penalizes anyone who doesn't obey. Computation heavy compared to the L1 norm. Doesn’t give you implicit feature selection.\n",
        "* **Use Cases**: Use ridge if all the features are correlated with the label, as the coefficients are never zero in ridge. \n",
        "* **Bayesian**: L2 similarly corresponds to Gaussian prior. As one moves away from zero, the probability for such a coefficient grows progressively smaller. The square loss penalty can be seen as putting a Gaussian prior on your weights.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYzCd1FUBnjV",
        "colab_type": "text"
      },
      "source": [
        "**Add L2 (Ridge) Penalty Term to Cost Function**\n",
        "\n",
        "$\\sum_{i=1}^{n}\\left(y_{i}-\\sum_{j=1}^{p} x_{i j} \\beta_{j}\\right)^{2}+\\lambda \\sum_{j=1}^{p} \\beta_{j}^{2}$\n",
        "\n",
        "* Ridge regression adds “squared magnitude” of coefficient as penalty term to the loss function.\n",
        "* If lambda is zero then you can imagine we get back OLS. However, if lambda is very large then it will add too much weight and it will lead to under-fitting. Having said that it’s important how lambda is chosen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ8UW9XnleoV",
        "colab_type": "text"
      },
      "source": [
        "## **Elastic Net**\n",
        "\n",
        "* Method that linearly combines the L1 and L2 penalties of the lasso and ridge methods, at the \"only\" cost of introducing another hyperparameter to tune (see Hastie's paper on stanford.edu).\n",
        "* Overcome limitations of L1: in the \"large p, small n\" case (high-dimensional data with few examples), the LASSO selects at most n variables before it saturates. Also if there is a group of highly correlated variables, then the LASSO tends to select one variable from a group and ignore the others.\n",
        "* Solution in elastic net: add quadratic part to penalty (L2). quadratic penalty term makes the loss function strictly convex, and it therefore has a unique minimum.\n",
        "* Naive version of elastic net method finds an estimator in a two-stage procedure : first for each fixed λ2 it finds the ridge regression coefficients, and then does a LASSO type shrinkage. This kind of estimation incurs a double amount of shrinkage, which leads to increased bias and poor predictions. To improve the prediction performance, the authors rescale the coefficients of the naive version of elastic net by multiplying the estimated coefficients by (1+λ2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4foOVciWvULS",
        "colab_type": "text"
      },
      "source": [
        "**Special: Analytical Equivalence**\n",
        "\n",
        "Why is L2 Regularization is analytically equivalent to Gaussian prior?\n",
        "\n",
        "\n",
        "https://stats.stackexchange.com/questions/163388/why-is-the-l2-regularization-equivalent-to-gaussian-prior/163450#163450\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knt6wCob4xfj",
        "colab_type": "text"
      },
      "source": [
        "**Weight Regularization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvnac8AA41ac",
        "colab_type": "text"
      },
      "source": [
        "* Weight regularization was borrowed from penalized regression models in statistics. Neural networks learn a set of weights that best map inputs to outputs. \n",
        "* A network with large network weights can be a sign of an unstable network where small changes in the input can lead to large changes in the output. This can be a sign that the network has overfit the training dataset and will likely perform poorly when making predictions on new data. \n",
        "* A solution to this problem is to update the learning algorithm to encourage the network to keep the weights small. This is called weight regularization and it can be used as a general technique to reduce overfitting of the training dataset and improve the generalization of the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H4crpOcoMlSe"
      },
      "source": [
        "## **Run an Example**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6gKj7gjwQtw",
        "colab_type": "text"
      },
      "source": [
        "**Kernel Regularizer**\n",
        "\n",
        "*Regularizer function applied to the kernel weights matrix.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRsFyXXiwXYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernel_regularizer=tf.keras.regularizers.l1(l=0.0005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKn6U3WTwVRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernel_regularizer=tf.keras.regularizers.l2(l=0.0005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yVhv_57wbN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernel_regularizer=None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFJSTvHowfzn",
        "colab_type": "text"
      },
      "source": [
        "**Bias Regularizer**\n",
        "\n",
        "*Regularizer function applied to the bias vector*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7QXjYfzwsgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bias_regularizer=tf.keras.regularizers.l1(l=0.0005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHyBz0fwwvU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bias_regularizer=tf.keras.regularizers.l2(l=0.0005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NrlNShswyvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bias_regularizer=None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDXotzf7wk4o",
        "colab_type": "text"
      },
      "source": [
        "**Activity Regularizer**\n",
        "\n",
        "*Regularizer function applied to the output of the layer (its \"activation\")*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO2jgyv5w30S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activity_regularizer=tf.keras.regularizers.l1(l=0.0005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXWwwJ5vw8HA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activity_regularizer=tf.keras.regularizers.l2(l=0.0005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFwslg_Bw_9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activity_regularizer=None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfVxKUnwXK8Z",
        "colab_type": "text"
      },
      "source": [
        "**Define Model & Run**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDEv6ZETl129",
        "colab_type": "code",
        "outputId": "bb7974ae-da65-489a-fa8e-1200136fdc7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu', \n",
        "                                kernel_regularizer=kernel_regularizer, \n",
        "                                bias_regularizer=bias_regularizer, \n",
        "                                activity_regularizer=activity_regularizer))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.fit(x=x_train, \n",
        "          y=y_train, \n",
        "          epochs=5, \n",
        "          validation_data=(x_test, y_test), \n",
        "#          callbacks=[PlotLossesKeras()]\n",
        "          )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 1.4673 - accuracy: 0.7791 - val_loss: 0.9737 - val_accuracy: 0.7863\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.8910 - accuracy: 0.8081 - val_loss: 0.8340 - val_accuracy: 0.8255\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.8322 - accuracy: 0.8158 - val_loss: 0.7904 - val_accuracy: 0.8317\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.8076 - accuracy: 0.8211 - val_loss: 0.7757 - val_accuracy: 0.8313\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7898 - accuracy: 0.8237 - val_loss: 0.7681 - val_accuracy: 0.8314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9af7584048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD664G5zyGZY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **Optimizer**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdUXshnDyLAv",
        "colab_type": "text"
      },
      "source": [
        "* why optimizer\n",
        "* what is it doing\n",
        "\n",
        "https://medium.com/explorations-in-language-and-learning/a-short-note-on-gradient-descent-optimization-algorithms-335546c5a896\n",
        "\n",
        "\n",
        "An overview of gradient descent optimization algorithms\n",
        "\n",
        "https://arxiv.org/pdf/1609.04747.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiYYgAxtyPm1",
        "colab_type": "text"
      },
      "source": [
        "## **SGD**\n",
        "\n",
        "(Stochastic Gradient Descent)\n",
        "\n",
        "* [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) documentation\n",
        "* Nesterov algorithm based on [this paper](http://jmlr.org/proceedings/papers/v28/sutskever13.pdf)\n",
        "\n",
        "**Characteristics**\n",
        "* SGD is a stochastic approximation of the gradient descent optimization and iterative method for minimizing an objective function that is written as a sum of differentiable functions. All other optimizers are called „adaptive“, because they have momentum.\n",
        "* A compromise between computing the true gradient and the gradient at a single example is to compute the gradient against more than one training example (called a \"mini-batch\") at each step. This can perform significantly better than \"true\" stochastic gradient descent described, because the code can make use of vectorization libraries rather than computing each step separately. It may also result in smoother convergence, as the gradient computed at each step uses more training examples.\n",
        "* The convergence of stochastic gradient descent has been analyzed using the theories of convex minimization and of stochastic approximation. Briefly, when the learning rates decrease with an appropriate rate, and subject to relatively mild assumptions, stochastic gradient descent converges almost surely to a global minimum when the objective function is convex or pseudoconvex, and otherwise converges almost surely to a local minimum.[3][4] This is in fact a consequence of the Robbins-Siegmund theorem.\n",
        "* SGD suffers from 2 problems: (i) being hesitant at steep slopes, and (ii) having same learning rate for all parameters.\n",
        "\n",
        "**Formula**\n",
        "\n",
        "$\\theta=\\theta-\\eta \\cdot \\nabla_{\\theta} J\\left(\\theta ; x^{(i)} ; y^{(i)}\\right)$\n",
        "\n",
        "* Stochastic gradient descent (SGD) in contrast performs a parameter update for each training example $x^{(i)}$ and label $y^{(i)}$\n",
        "* Batch gradient descent performs redundant computations for large datasets, as it recomputes gradients for similar examples before each parameter update. SGD does away with this redundancy by performing one update at a time. It is therefore usually much faster and can also be used to learn online. \n",
        "* SGD performs frequent updates with a high variance that cause the objective function to fluctuate heavily.\n",
        "\n",
        "**SGD Optimizer Components**\n",
        "\n",
        "* **learning_rate**: float hyperparameter >= 0. Learning rate.\n",
        "* **momentum**: float hyperparameter >= 0 that accelerates SGD in the relevant direction and dampens oscillations.\n",
        "* **nesterov**: boolean. Whether to apply Nesterov momentum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuzwCEO5ymdG",
        "colab_type": "text"
      },
      "source": [
        "**// Extension: SGD with Momentum**\n",
        "\n",
        "**Characteristics**\n",
        "* The update vector consists of another term which has the previous update vector (weighted by γ). This helps it to move faster downhill — like a ball.\n",
        "* The momentum term γ is usually set to 0.9 or a similar value.\n",
        "\n",
        "**Formula**\n",
        "\n",
        "$\\begin{aligned}\n",
        "v_{t} &=\\gamma v_{t-1}+\\eta \\nabla_{\\theta} J(\\theta) \\\\\n",
        "\\theta &=\\theta-v_{t}\n",
        "\\end{aligned}$\n",
        "\n",
        "![Momentum](https://raw.githubusercontent.com/deltorobarba/repo/master/momentum.png)\n",
        "\n",
        "Source: [An overview of gradient descent optimization\n",
        "algorithms](https://arxiv.org/pdf/1609.04747.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jFRBEACysQz",
        "colab_type": "text"
      },
      "source": [
        "**//SGD with NAG (Nesterov Accelerated Gradient)**\n",
        "\n",
        "**Characteristics**\n",
        "* In Momentum optimizer, the ball may go past the minima due to too much momentum, so we want to have a look-ahead term. \n",
        "* In NAG, we take gradient of future position instead of current position.\n",
        "\n",
        "**Formula**\n",
        "\n",
        "$\\begin{aligned}\n",
        "v_{t} &=\\gamma v_{t-1}+\\eta \\nabla_{\\theta} J\\left(\\theta-\\gamma v_{t-1}\\right) \\\\\n",
        "\\theta &=\\theta-v_{t}\n",
        "\\end{aligned}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGCzl1U5zDh9",
        "colab_type": "text"
      },
      "source": [
        "## **Adam** \n",
        "\n",
        "(Adaptive Moment Estimation)\n",
        "\n",
        "* [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) documentation\n",
        "* Algorithm based on the paper ['Adam: A Method for Stochastic Optimization' by Kingma et al., 2014,](https://arxiv.org/abs/1412.6980)\n",
        "\n",
        "**Characteristics**\n",
        "* The theory is that Adam already handles learning rate optimization ([Check paper](http://arxiv.org/pdf/1412.6980v8.pdf)) : \"We propose Adam, a method for efficient stochastic optimization that only requires first-order gradients with little memory requirement. The method computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients; the name Adam is derived from adaptive moment estimation.\"\n",
        "* Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments. The method is computationally efficient, has little memory requirement, invariant to diagonal rescaling of gradients, and is well suited for problems that are large in terms of data/parameters.\n",
        "* Adam can be looked at as a combination of RMSprop and Stochastic Gradient Descent with momentum. It uses the squared gradients to scale the learning rate like RMSprop and it takes advantage of momentum by using moving average of the gradient instead of gradient itself like SGD with momentum.\n",
        "\n",
        "**Formula**\n",
        "\n",
        "$\\theta_{t+1}=\\theta_{t}-\\frac{\\eta}{\\sqrt{\\hat{v}_{t}+\\epsilon}} \\hat{m}_{t}$\n",
        "\n",
        "* Adam combines RMSProp with Momentum. So, in addition to using the decaying average of past squared gradients for parameter-specific learning rate, it uses a decaying average of past gradients in place of the current gradient (similar to Momentum).\n",
        "* The ^ terms are actually bias-corrected averages to ensure that the values are not biased towards 0.\n",
        "\n",
        "**Adam Optimizer Components**\n",
        "\n",
        "* **learning_rate**: A Tensor or a floating point value. The learning rate.\n",
        "* **beta_1**: A float value or a constant float tensor. The exponential decay rate for the 1st moment estimates.\n",
        "* **beta_2**: A float value or a constant float tensor. The exponential decay rate for the 2nd moment estimates.\n",
        "* **epsilon**: A small constant for numerical stability. This epsilon is \"epsilon hat\" in the Kingma and Ba paper (in the formula just before Section 2.1), not the epsilon in Algorithm 1 of the paper.\n",
        "* **amsgrad**: boolean. Whether to apply AMSGrad variant of this algorithm from the paper \"On the Convergence of Adam and beyond\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bw8dnhILzJmw",
        "colab_type": "text"
      },
      "source": [
        "**// Extension: Nadam (Nesterov Adaptive Moment Estimation)**\n",
        "\n",
        "* [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Nadam) documentation\n",
        "* Algorithm based on the paper ['Incorporating Nesterov Momentum into Adam' by Dozat, T., 2015](http://cs229.stanford.edu/proj2015/054_report.pdf)\n",
        "\n",
        "**Characteristics**\n",
        "* Nadam is Adam with Nesterov momentum\n",
        "\n",
        "**Nadam Optimizer Components**\n",
        "* learning_rate: A Tensor or a floating point value. The learning rate.\n",
        "* beta_1: A float value or a constant float tensor. The exponential decay rate for the 1st moment estimates.\n",
        "* beta_2: A float value or a constant float tensor. The exponential decay rate for the 2nd moment estimates.\n",
        "* epsilon: A small constant for numerical stability. This epsilon is \"epsilon hat\" in the Kingma and Ba paper (in the formula just before Section 2.1), not the epsilon in Algorithm 1 of the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkMe7DNkzPyB",
        "colab_type": "text"
      },
      "source": [
        "## **RMSprop**\n",
        "\n",
        "* [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop) documentation\n",
        "* RMSprop is an unpublished optimization algorithm designed for neural networks, first proposed by Geoff Hinton in lecture 6 of the online course “Neural Networks for Machine Learning”\n",
        "\n",
        "**Characteristics**\n",
        "* RMSPro: works well in non-stationary settings. RMSProp with momentum is the method most closely related to Adam. Main differences: RMSProp rescales gradient and then applies momentum, Adam first applies momentum (moving average) and then rescales. RMSProp lacks bias correction, often leading to large stepsizes in early stages of run (especially when β2 is close to 1)\n",
        "* maintain a moving (discounted) average of the square of gradients\n",
        "divide gradient by the root of this average\n",
        "* This implementation of RMSprop uses plain momentum, not Nesterov momentum.\n",
        "* The centered version additionally maintains a moving average of the gradients, and uses that average to estimate the variance\n",
        "\n",
        "**Formula**\n",
        "\n",
        "$E\\left[g^{2}\\right]_{t}=\\gamma E\\left[g^{2}\\right]_{t-1}+(1-\\gamma) g_{t}^{2}$\n",
        "\n",
        "* In Adagrad, since we keep adding all gradients, gradients become vanishingly small after some time. So in RMSProp, the idea is to add them in a decaying fashion as shown in the formula. \n",
        "* Now replace G_t in the denominator of Adagrad equation by this new term. Due to this, the gradients are no more vanishing.\n",
        "\n",
        "**RMSprop Optimizer Components**\n",
        "* **learning_rate**: A Tensor or a floating point value. The learning rate.\n",
        "* **rho**: Discounting factor for the history/coming gradient\n",
        "* **momentum**: A scalar tensor.\n",
        "* **epsilon**: Small value to avoid zero denominator.\n",
        "* **centered**: If True, gradients are normalized by the estimated variance of the gradient; if False, by the uncentered second moment. Setting this to True may help with training, but is slightly more expensive in terms of computation and memory. Defaults to False."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpE6lCXZzWO6",
        "colab_type": "text"
      },
      "source": [
        "## **Adagrad**\n",
        "\n",
        "**Characteristics**\n",
        "* Instead of a common learning rate for all parameters, we want to have separate learning rate for each. So Adagrad keeps sum of squares of parameter-wise gradients and modifies individual learning rates using this. As a result, parameters occuring more often have smaller gradients.\n",
        "* works well with sparse gradients\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP4NxP_FzaAZ",
        "colab_type": "text"
      },
      "source": [
        "## **FTRL** \n",
        "\n",
        "(Follow The (Proximally) Regularized Leader)\n",
        "\n",
        "* Algorithm based on [this paper](https://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf)\n",
        "* [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Ftrl) documentation\n",
        "\n",
        "**Characteristics**\n",
        "* kkk\n",
        "\n",
        "**Ftrl Optimizer Components**\n",
        "\n",
        "* learning_rate: A float value or a constant float Tensor.\n",
        "learning_rate_power: A float value, must be less or equal to zero. Controls how the learning rate decreases during training. Use zero for a fixed learning rate.\n",
        "* initial_accumulator_value: The starting value for accumulators. Only zero or positive values are allowed.\n",
        "* l1_regularization_strength: A float value, must be greater than or equal to zero.\n",
        "* l2_regularization_strength: A float value, must be greater than or equal to zero.\n",
        "* l2_shrinkage_regularization_strength: A float value, must be greater than or equal to zero. This differs from L2 above in that the L2 above is a stabilization penalty, whereas this L2 shrinkage is a magnitude penalty. The FTRL formulation can be written as: w_{t+1} = argminw(\\hat{g}{1:t}w + L1||w||_1 + L2||w||_2^2), where \\hat{g} = g + (2L2_shrinkagew), and g is the gradient of the loss function w.r.t. the weights w. Specifically, in the absence of L1 regularization, it is equivalent to the following update rule: w_{t+1} = w_t - lr_t / (1 + 2L2lr_t) * g_t - 2L2_shrinkagelr_t / (1 + 2L2lr_t) * w_t where lr_t is the learning rate at t. When input is sparse shrinkage will only happen on the active weights.\\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_dXdznmzvmq",
        "colab_type": "text"
      },
      "source": [
        "## **Which Optimizer to use?**\n",
        "\n",
        "* So, which optimizer should you now use? If your input data is sparse, then you likely achieve the best results using one of the adaptive learning-rate methods. An additional benefit is that you won't need to tune the learning rate but likely achieve the best results with the default value.\n",
        "* In summary, RMSprop is an extension of Adagrad that deals with its radically diminishing learning rates. It is identical to Adadelta, except that Adadelta uses the RMS of parameter updates in the numinator update rule. Adam, finally, adds bias-correction and momentum to RMSprop. Insofar, RMSprop, Adadelta, and Adam are very similar algorithms that do well in similar circumstances. Kingma et al. [15] show that its bias-correction helps Adam slightly outperform RMSprop towards the end of optimization as gradients become sparser. Insofar, Adam might be the best overall choice.\n",
        "* Interestingly, many recent papers use vanilla SGD without momentum and a simple learning rate annealing schedule. As has been shown, SGD usually achieves to find a minimum, but it might take significantly longer than with some of the optimizers, is much more reliant on a robust initialization and annealing schedule, and may get stuck in saddle points rather than local minima. Consequently, if you care about fast convergence and train a deep or complex neural network, you should choose one of the adaptive learning rate methods.\n",
        "\n",
        "**Comparison**\n",
        "\n",
        "* Few days ago, an interesting paper titled The Marginal Value of Adaptive Gradient Methods in Machine Learning (https://arxiv.org/abs/1705.08292) from UC Berkeley came out. In this paper, the authors compare adaptive optimizer (Adam, RMSprop and AdaGrad) with SGD, observing that SGD has better generalization than adaptive optimizers.\n",
        "* “We observe that the solutions found by adaptive methods generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.”\n",
        "* I was astounded by their finding since I never used SGD before and consider it as an outdated optimizer with slower convergence than Adam or RMSprop. Am I totally wrong from the very beginning?\n",
        "\n",
        "![Optimizer](https://raw.githubusercontent.com/deltorobarba/repo/master/optimizer_4.png)\n",
        "\n",
        "https://medium.com/vitalify-asia/whats-up-with-deep-learning-optimizers-since-adam-5c1d862b9db0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWmp1AeF0Evr",
        "colab_type": "text"
      },
      "source": [
        "## **Run an Example**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfj2razi0UAN",
        "colab_type": "text"
      },
      "source": [
        "**Select one optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl2-00iD0SLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, \n",
        "                                    momentum=0.9, \n",
        "                                    nesterov=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2nkJu4w0cic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, \n",
        "                                     beta_1=0.9, \n",
        "                                     beta_2=0.999, \n",
        "                                     epsilon=1e-07, \n",
        "                                     amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAJgbbL30krX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01, \n",
        "                                      beta_1=0.9, \n",
        "                                      beta_2=0.999, \n",
        "                                      epsilon=1e-07)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVuuLCpY0o7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001, \n",
        "                                        rho=0.9, \n",
        "                                        momentum=0.0, \n",
        "                                        epsilon=1e-07, \n",
        "                                        centered=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nhuO0l90sJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Ftrl(learning_rate=0.001, \n",
        "                                     learning_rate_power=-0.5, \n",
        "                                     initial_accumulator_value=0.1, \n",
        "                                     l1_regularization_strength=0.0, \n",
        "                                     l2_regularization_strength=0.0, \n",
        "                                     name='Ftrl', \n",
        "                                     l2_shrinkage_regularization_strength=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZpqyQZ-02oq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adadelta(learning_rate=0.001, \n",
        "                                        rho=0.9, \n",
        "                                        epsilon=1e-07)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q97hoOtn06WL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.001, \n",
        "                                        initial_accumulator_value=0.1,\n",
        "                                        epsilon=1e-07)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj0HVDFZ098t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adamax(learning_rate=0.01, \n",
        "                                     beta_1=0.9, \n",
        "                                     beta_2=0.999, \n",
        "                                     epsilon=1e-07)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYBDzBo41JWW",
        "colab_type": "text"
      },
      "source": [
        "**Define Model & Run**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jJRS5C_0IGe",
        "colab_type": "code",
        "outputId": "ecd4548a-6a34-4a9c-bac2-d655123c2b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer=optimizer, \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.fit(x=x_train, \n",
        "          y=y_train, \n",
        "          epochs=5, \n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6443 - accuracy: 0.7715 - val_loss: 0.5088 - val_accuracy: 0.8255\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5688 - accuracy: 0.7973 - val_loss: 0.5217 - val_accuracy: 0.8290\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5371 - accuracy: 0.8085 - val_loss: 0.4776 - val_accuracy: 0.8353\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5292 - accuracy: 0.8123 - val_loss: 0.4905 - val_accuracy: 0.8304\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5235 - accuracy: 0.8153 - val_loss: 0.4869 - val_accuracy: 0.8368\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9af749d9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}