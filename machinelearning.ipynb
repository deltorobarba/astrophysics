{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "86rBYa_u4urx",
        "JgPN5UHup5lH",
        "CBU1tb4vs16v",
        "WikX85R-r4I2",
        "bkXljK6xhBPG",
        "Cqusdv76O-Bx",
        "0MXqdUuKJZ37",
        "PFZKZOdMPBfF",
        "0IdZ1gStv7HP",
        "3cyZhA5TuEuW",
        "l_kkJp3mtIyD",
        "qoluFPb7O8Vv",
        "JC96LcJUvxwY",
        "w4FmSc4QvQsY",
        "ON5x3x5CPe7d",
        "jK7vTB6GIQpe",
        "QaGfSVYXp_gy",
        "Y7EMAgb2PJDH",
        "6Z0vHScrO3Nw",
        "ut_14zjENSyM",
        "QFiC9iq1uchk",
        "KcuadzY1rHe3",
        "hrYb8_OIPhhO",
        "r2-fNN88Cb7S",
        "NxI60357-N2l",
        "J4ZBVKqKqAbk",
        "vOqtFAy5GKtG",
        "OnneO2AhgoGY",
        "uM9V1BBQGHTy",
        "crQgUFkRk-XB",
        "6uUn645o-PmN",
        "EkdQBmsWyXyQ",
        "NpX_msD1vmi-",
        "-bgPYHGr1kCz",
        "EV6x8bY7pvDP",
        "WnAvpRxbPSwU",
        "1Amg0O9YxNcY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deltorobarba/sciences/blob/master/machinelearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"blue\">**Machine Learning**"
      ],
      "metadata": {
        "id": "xEVSiuftty-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1000.png)"
      ],
      "metadata": {
        "id": "YiqcrmGetjeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [Attention in Transformers](https://youtu.be/eMlx5fFNoYc?si=C7mPpdqouDtZpDN5)"
      ],
      "metadata": {
        "id": "RXwcRdnpNXKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formal Aspects of Language Modeling\n",
        "Ryan Cotterell, Anej Svete, Clara Meister, Tianyu Liu and Li Du\n",
        "Thursday 9th November, 2023"
      ],
      "metadata": {
        "id": "OmZK-lF9zgGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Foundation Model*"
      ],
      "metadata": {
        "id": "86rBYa_u4urx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A foundation model development cheatsheet, from foundation model developers.\n",
        "\n",
        "The folks over at EleutherAI, in collaboration with MIT, AI2, HuggingFace, Stanford, Princeton, and more, have released the foundation model development cheatsheet, a quick-start guide to familiarize new developers with useful tools and resources for developing new open models.\n",
        "\n",
        "You can use it to easily find, for example, pre-training data sources, tools and frameworks for data preparation, model training, model evaluation, and more.\n",
        "\n",
        "This is a great initiative aligned with EleutherAI's mission to lower barriers to entry of research and development of foundation models.\n",
        "\n",
        "Cheat sheet (interactive): https://fmcheatsheet.org/\n",
        "Github repo: https://lnkd.in/dSDkbY-K\n",
        "Paper: https://lnkd.in/d5DRns4i\n",
        "Blog: https://lnkd.in/dg4drU_3"
      ],
      "metadata": {
        "id": "E433hvia4xsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Finetune LLMs*"
      ],
      "metadata": {
        "id": "JgPN5UHup5lH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mixer of Experts(MOE) — Modern architecture for divide and concur learning\n",
        "\n",
        "https://medium.com/@sthanikamsanthosh1994/the-mixer-of-experts-moe-modern-architecture-for-divide-and-concur-learning-dbe10ffa8436"
      ],
      "metadata": {
        "id": "dgUkkXpDvYie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Overview*"
      ],
      "metadata": {
        "id": "CBU1tb4vs16v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1704.png)"
      ],
      "metadata": {
        "id": "2WTi1ggcqbc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Finetuning LLMs*\n",
        "\n",
        "* Supervised\n",
        "* RLHF\n",
        "* Distillation\n",
        "* deprecated: Parameter-Efficient Fine-Tuning using PEFT: https://arxiv.org/abs/2312.12148\n",
        "* pending (?): Lora and QLora\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2023/08/fine-tuning-large-language-models/\n",
        "\n",
        "https://www.deeplearning.ai/short-courses/finetuning-large-language-models/"
      ],
      "metadata": {
        "id": "XEjwjS3Lsp2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Parameter efficient Turning (PEFT)*"
      ],
      "metadata": {
        "id": "WikX85R-r4I2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-text-models-supervised"
      ],
      "metadata": {
        "id": "TqEuagbhr7fP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* This is a good primer go/parameter-efficient-tuning-primer\n",
        "* what I didn't get very well is why the candidate related int-8 with LoRA tuning\n",
        "* for hosting on CPU\n",
        "* I think the candidate mixed-up things\n",
        "* LoRA tuning is to do fine-tuning efficiently by just changing some of the weights inside the model. The amount of weights to change is decided by its rank, currently in Vertex we only offer rank 1, but this is hidden. OpenAI offers a way larger rank, and it's more powerful\n",
        "* there's QLoRA as well for quantized models.\n",
        "* What actually reduces memory is quantization, and there you can go to int-8 and host it inCPU if the model permits it\n",
        "* In fact, gemini-pro and bison@002 are quantized\n",
        "* obviously as these are bigs the quantization still requires a good amount of TPUs 😀\n"
      ],
      "metadata": {
        "id": "rE0R1YjchIO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### $\\hookrightarrow$ *Prompt Engineering (incl. Chain-of-Thoughts - CoT)*"
      ],
      "metadata": {
        "id": "bkXljK6xhBPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://ploomber.io/blog/prompt-engineering-techniques/"
      ],
      "metadata": {
        "id": "gQtUYa9whALK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/2401.14423 Prompt Design and Engineering: Introduction and Advanced Methods"
      ],
      "metadata": {
        "id": "caVuz9hgGMIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Engineering: Längere \"Chain of Thoughts\" verbessern die Leistung von Sprachmodellen\n",
        "\n",
        "https://the-decoder.de/prompt-engineering-laengere-chain-of-thoughts-verbessern-die-leistung-von-sprachmodellen/"
      ],
      "metadata": {
        "id": "LPk_jDKukQNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### $\\hookrightarrow$ *Low-Rank Adaptation (Lora and qLora)*"
      ],
      "metadata": {
        "id": "Cqusdv76O-Bx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just wrote a new article on \"Improving LoRA: Implementing Weight-Decomposed Low-Rank Adaptation (DoRA) from Scratch\": https://magazine.sebastianraschka.com/p/lora-and-dora-from-scratch\n"
      ],
      "metadata": {
        "id": "wBbEKuA9zESS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "qLora and Lora to move from floating to integers in models (can damage a bit performance but still acceptable), but we can use then CPUs to train some of these models instead of only GPUs.\n",
        "\n",
        "can one use qLora and Lora to move from floating to integers in LLM models in order to use CPUs to train LLMs instead of only GPUs.\n",
        "\n",
        "Yes, qLora and Lora are techniques that can potentially enable the use of CPUs for training large language models (LLMs) by moving from floating-point to integer representations. Here's a breakdown of how this works and the considerations involved:\n",
        "\n",
        "**Traditional LLM Training and GPUs**\n",
        "\n",
        "* **Floating-point precision:** LLMs are typically trained using floating-point numbers (e.g., float32) because they offer a wide dynamic range necessary to represent the subtle gradients and relationships between parameters during the learning process.\n",
        "* **GPU advantage:** GPUs are highly optimized for parallel computations involving floating-point numbers. This makes them significantly faster than CPUs for traditional LLM training.\n",
        "\n",
        "**qLora and Lora for CPU Training**\n",
        "\n",
        "* **Quantization:** qLora (quantized Lora) is a method for reducing the precision of LLM parameters. Instead of storing them as full 32-bit floating-point numbers, it's possible to represent them using lower-precision integers (e.g., 8-bit integers). This drastically reduces memory footprint and computational cost.\n",
        "* **Lora:** Lora (Low-Rank Adaptation) is a technique that decomposes weight matrices in LLMs into smaller, more manageable components. This decomposition can then be exploited during quantization for efficiency.\n",
        "* **CPU efficiency:**  By reducing the memory and computational requirements through quantization, it becomes feasible to train, or at least perform inference of, LLMs on CPUs, which are more generally available and cost-effective than GPUs in many scenarios.\n",
        "\n",
        "**Challenges and Considerations**\n",
        "\n",
        "* **Accuracy trade-off:** Quantization generally leads to a slight loss in model accuracy compared to full-precision floating-point representations. The goal is to find the right balance between quantization level and acceptable performance.\n",
        "* **Optimization:** Techniques like qLora and Lora are relatively new, and ongoing research is focused on making them more efficient and minimizing the accuracy loss.\n",
        "* **Deployment:**  If you aim to deploy a quantized LLM on CPUs,  you'll likely need specialized software and hardware support to ensure optimal performance.\n",
        "\n",
        "**In Conclusion**\n",
        "\n",
        "qLora and Lora offer a promising path towards making LLM training and inference more accessible by potentially allowing the use of CPUs. However, it's essential to be aware of the potential accuracy trade-offs and the fact that this field is still under active development.\n",
        "\n",
        "**Let me know if you'd like more details on any specific aspect or have another related question!**\n"
      ],
      "metadata": {
        "id": "1kQP9sfnhvO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Lora*\n",
        "\n",
        "\"𝗟𝗼𝗥𝗔, which stands for Low-Rank Adaptation, is a popular technique to finetune #llms more efficiently. Instead of adjusting all the parameters of a deep neural network, LoRA focuses on updating only a small set of low-rank matrices.\"\n",
        "\n",
        "https://lightning.ai/lightning-ai/studios/code-lora-from-scratch?utm_source=tldrai\n",
        "\n",
        "  * LoRA: Low-Rank Adaptation of Large Language Models\n",
        "  * Edward J. Hu*, Yelong Shen*, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen\n",
        "  * Paper: https://arxiv.org/abs/2106.09685\n",
        "  * Video explainer: https://www.youtube.com/watch?v=DhRoTONcyZE\n",
        "  * https://github.com/microsoft/LoRA"
      ],
      "metadata": {
        "id": "n3TCWKhJZvRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### $\\hookrightarrow$ *Dora*"
      ],
      "metadata": {
        "id": "0MXqdUuKJZ37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While everyone is talking about Sora, there's a potential successor to LoRA (low-rank adaptation) called DoRA. Here's a closer look at the \"DoRA: Weight-Decomposed Low-Rank Adaptation\" paper: https://arxiv.org/abs/2402.09353\n",
        "LoRA is probably the most widely used parameter-efficient finetuning method for LLMs and vision transformers, and DoRA can be seen as an improvement or extension of LoRA that is built on top of it.\n",
        "\n",
        "A brief LoRA recap: Assuming we have pretrained model weights W, LoRA uses low-rank matrices to approximate weight changes ΔW. I.e., in regular finetuning we have W' = W + ΔW, and in LoRA, we approximate ΔW with BA.\n",
        "\n",
        "Now, the DoRA method first decomposes the pretrained weight matrix into a magnitude vector (m) and a directional matrix (V). Then, it takes the directional matrix V and applies standard LoRA to it, i.e., W' = m (V + ΔV)/norm = m (W + BA)/norm.\n",
        "\n",
        "The motivation for developing this method is based on analyzing and comparing the LoRA and full finetuning learning patterns. They found that LoRA either increases or decreases magnitude and direction updates proportionally but seems to lack the capability of making only subtle directional changes as found in full finetuning. Hence, the researchers propose the decoupling of magnitude and directional components. In other words, their DoRA method aims to apply LoRA only to the directional component (while also allowing the magnitude component to be trained separably.)\n",
        "\n",
        "Note that introducing the magnitude vector m in DoRA adds 0.01% more parameters than standard LoRA. However, across both LLM and vision transformer benchmarks, they found that DoRA even outperforms LoRA if the DoRA rank is halved, i.e., when DoRA only uses half the parameters of regular LoRA.\n",
        "\n",
        "Overall, I am actually quite impressed by the results and need to toy with this method in practice. It should not be too big of a lift to upgrade a LoRA implementation to DoRA."
      ],
      "metadata": {
        "id": "Z4vmfiEHJdKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### $\\hookrightarrow$ (?) *Proxy-tuning*"
      ],
      "metadata": {
        "id": "PFZKZOdMPBfF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Proxy-tuning*\n",
        "\n",
        "Proxy-tuning is a way to adapt LLMs without changing the model's weights. This is especially attractive if a given LLM is too resource-intensive to train or if a user doesn't have access to the LLM's weights.\n",
        "Following up on the proxy-tuning paper discussion from last week, I implemented it in code and gave it a try. It actually works!\n",
        "\n",
        "In a nutshell, it works like this:\n",
        "\n",
        "1. Select a base LLM (e.g., an untuned 7B Llama 2 model) smaller and cheaper than the target LLM (e.g., a 10x larger, untuned 70B Llama 2 model).\n",
        "\n",
        "2. Finetune this smaller base LLM to obtain a small finetuned LLM (e.g., instruction-finetune a 7B Llama 2 model to get a finetuned 7B model).\n",
        "\n",
        "3. Compute the output difference between the base model (step 1) and the tuned model (step 2).\n",
        "\n",
        "4. Add this difference in outputs to the target LLM's outputs.\n",
        "\n",
        "5. Normalize the modified outputs from step 4, and then generate the answer.\n",
        "\n",
        "I tried the following query:\n",
        "\n",
        "\"If I have 5 apples and eat 2, but then find 3 more on my way home, how many do I have?\"\n",
        "\n",
        "The proxy-tuned model was indeed able to answer correctly, whereas the base models failed: \"You start with 5 apples and eat 2, so you have 5 - 2 = 3 apples left. Then, you find 3 more apples on your way home, so you have 3 + 3 = 6 apples in total.\"\n",
        "\n",
        "Using the same approach, it was also possible to give Llama 2 13B coding abilities via CodeLlama 7B.\n",
        "\n",
        "More details and code in my write-up and associated code Studio:\n",
        "\n",
        "https://lightning.ai/lightning-ai/studios/improve-llms-with-proxy-tuning?view=public"
      ],
      "metadata": {
        "id": "RJJgo0tk_4aQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While proxy-tuning and prompting have connections and some potential overlap, they are not precisely the same approach. Here's a breakdown of the differences and where they might intersect:\n",
        "\n",
        "**Proxy-Tuning**\n",
        "\n",
        "* **Core Focus:** Parameter-efficient fine-tuning of large language models (LLMs). The goal is to adapt a pre-trained LLM to a new task without fully fine-tuning its vast number of parameters.\n",
        "* **Mechanism:** Introduces a small set of learnable \"proxy\" parameters. These might be:\n",
        "    * Additional vectors that learn relationships between input embeddings.\n",
        "    * Small adapter modules placed between layers of the LLM.\n",
        "* **Advantage:** Reduces computational cost and memory footprint of fine-tuning compared to training the entire LLM.\n",
        "\n",
        "**Prompting**\n",
        "\n",
        "* **Core Focus:** Eliciting a desired response or behavior from an LLM by carefully crafting the input text.  Prompts include instructions, examples, or textual structures that guide the model's generation.\n",
        "* **Mechanism:** No internal model parameters are directly modified.  Prompts guide the LLM to use its pre-existing knowledge and abilities to complete the task.\n",
        "* **Advantage:** Highly flexible and can be applied to a wide range of tasks without fine-tuning.\n",
        "\n",
        "**Connections and Overlaps**\n",
        "\n",
        "* **Semantic Tuning:**  Proxy-tuning could be employed with  prompts that have rich semantic representations. This fine-tuning could refine the proxy parameters to better  align with complex queries or instructions provided in the prompts.\n",
        "* **Prompt Design as Lightweight Fine-tuning:** Sometimes,  prompting involves finding prompts that essentially 'trick' the LLM into performing a task it  wasn't explicitly trained for.  This fine-grained task adaptation through crafting prompts can have a similar spirit to proxy-tuning, in the sense that both aim to modify how the LLM behaves without major internal changes.\n",
        "\n",
        "**In Summary**\n",
        "\n",
        "Proxy-tuning and prompting are distinct but complementary techniques. Proxy-tuning focuses on efficient internal parameter modification of LLMs. Prompting focuses on steering model output through clever input design.  There could be interesting potential in the use of these two approaches together."
      ],
      "metadata": {
        "id": "Ej7C082gtwyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Adapter Tuning*"
      ],
      "metadata": {
        "id": "0IdZ1gStv7HP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-models"
      ],
      "metadata": {
        "id": "1etW7dnRGOp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://services.google.com/fh/files/misc/adaptation_of_foundation_models_whitepaper_google_cloud.pdf"
      ],
      "metadata": {
        "id": "6QyPscgUGCu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://magazine.sebastianraschka.com/p/finetuning-llms-with-adapters"
      ],
      "metadata": {
        "id": "_-8jp5b6FbOJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/2106.03164 On the Effectiveness of Adapter-based Tuning for Pretrained Language Model Adaptation"
      ],
      "metadata": {
        "id": "i5vNXkQPF0d3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a breakdown of Adapter Tuning, its advantages, and how it works:\n",
        "\n",
        "**What is Adapter Tuning?**\n",
        "\n",
        "Adapter tuning is a technique used to fine-tune large language models (LLMs) for new tasks more efficiently. Here's the core idea:\n",
        "\n",
        "* **Pre-trained Models:** Large language models have been trained on vast amounts of text data, giving them a deep understanding of language patterns.\n",
        "* **Bottleneck:** Fine-tuning these massive models to a specific task (like question answering or translation) often means updating millions or billions of parameters, which is computationally expensive and time-consuming.\n",
        "* **Adapters to the Rescue:** Adapter tuning introduces compact \"adapter\" modules (small sets of new neural network layers) within the pre-trained model's architecture.  Instead of updating the entire model, only the parameters within these adapters are trained for the new task.\n",
        "\n",
        "**Advantages of Adapter Tuning**\n",
        "\n",
        "* **Efficiency:** Adapter tuning greatly reduces the number of parameters needing updates, making fine-tuning significantly faster and less computationally demanding.\n",
        "* **Preserving Knowledge:** By freezing most of the original model's weights, adapter tuning preserves the language knowledge the model has acquired during pre-training.\n",
        "* **Multi-Task Learning:** A single pre-trained model can have multiple adapters, each trained for a different task. This allows the model to switch between tasks easily without needing to retrain the entire model.\n",
        "\n",
        "**How Adapter Tuning Works**\n",
        "\n",
        "1. **Pre-trained Model:** Start with a large, pre-trained language model.\n",
        "2. **Insert Adapters:** Add small adapter modules (new layers) between existing layers of the pre-trained model.\n",
        "3. **Freeze the Original Model:** Keep the weights of the pre-trained model frozen.\n",
        "4. **Train the Adapters:** Train only the parameters of the newly added adapters on the data for the specific task at hand.\n",
        "\n",
        "**In Summary**\n",
        "\n",
        "Adapter tuning is a clever way to fine-tune large language models. It saves time and computing resources, maintains the model's core knowledge, and facilitates efficient multi-task capabilities.\n",
        "\n",
        "**Let me know if you'd like a more technical explanation or examples of how adapter tuning is used!**\n"
      ],
      "metadata": {
        "id": "dfCkiw8zwImy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *ASPIRE*"
      ],
      "metadata": {
        "id": "3cyZhA5TuEuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://blog.research.google/2024/01/introducing-aspire-for-selective.html"
      ],
      "metadata": {
        "id": "DPpnWeV-uGA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes! \"Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs\" (ASPIRE) is primarily a framework for finetuning LLMs. Here's why:\n",
        "\n",
        "**Focus of ASPIRE:**\n",
        "\n",
        "* **Selective Prediction:**  ASPIRE aims to teach LLMs to evaluate their own output and decide whether to provide an answer or abstain (\"I don't know\"). This aligns with finetuning goals of improving model behavior rather than directly changing its architecture.\n",
        "* **Self-Evaluation:** The framework trains the LLM on target-task data to learn to assess its own predictions, rather than relying on external retrieval mechanisms.\n",
        "\n",
        "**How ASPIRE Finetunes LLMs:**\n",
        "\n",
        "ASPIRE involves finetuning a pre-trained LLM on a portion of question-answering datasets like CoQA. During finetuning, the model learns to output both an answer and a selection score. The selection score indicates the model's confidence in its answer.  This approach directly modifies the LLM's output behavior, aligning with finetuning.\n",
        "\n",
        "**Difference from RAG:**\n",
        "\n",
        "RAG (Retrieval-Augmented Generation) frameworks enhance LLMs by teaching them to retrieve relevant information from external sources during answer generation.  ASPIRE, in contrast, focuses on internal self-assessment.\n",
        "\n",
        "**ASPIRE vs. RLHF:**\n",
        "\n",
        "While both ASPIRE and RLHF (Reinforcement Learning from Human Feedback) aim to improve the quality and reliability of LLM responses, they differ in approach:\n",
        "\n",
        "* **RLHF:** Uses human feedback to directly reward desirable responses and penalize undesirable ones.\n",
        "* **ASPIRE:** Focuses on the LLM learning to evaluate itself based on data.\n",
        "\n",
        "**In conclusion, ASPIRE falls firmly within the domain of finetuning LLMs by teaching them the crucial skill of selective prediction.**\n"
      ],
      "metadata": {
        "id": "0qZ6IWEiuO_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*RHLF*"
      ],
      "metadata": {
        "id": "l_kkJp3mtIyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/blog/products/ai-machine-learning/rlhf-on-google-cloud?hl=en\n",
        "\n",
        "https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-text-models-rlhf"
      ],
      "metadata": {
        "id": "iXpqxCF4lcDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RLHF stands for \"Reinforcement Learning from Human Feedback\"**\n",
        "\n",
        "* is a crucial technique for improving the performance and alignment of these models. It involves a combination of methods that leverage human feedback to refine and guide the learning process of the model.\n",
        "\n",
        "* Here's how RLHF is applied to LLMs:\n",
        "\n",
        "1. **Supervised Fine-Tuning (SFT)**: Initially, the language model is trained on a large dataset of text from the internet. This phase is purely supervised learning, where the model learns to predict the next word in a sequence. However, this dataset might not perfectly represent desirable outputs, as it contains a wide range of materials, including low-quality or harmful content.\n",
        "\n",
        "2. **Reward Modeling**: After the initial training, human reviewers assess the outputs of the model, providing feedback on its responses. This feedback could be in the form of rankings, ratings, or direct corrections. This human feedback is then used to create a reward model. The reward model essentially predicts how a human would rate a given output, serving as a proxy for human judgment.\n",
        "\n",
        "3. **Proximal Policy Optimization (PPO)**: With the reward model in place, the LLM is further trained using reinforcement learning, specifically a method called Proximal Policy Optimization. In this phase, the model learns to generate outputs that are more likely to receive higher ratings from the reward model. This step is crucial for aligning the model's outputs with human values and preferences.\n",
        "\n",
        "4. **Iterative Refinement**: The process can be iterative, with further rounds of human feedback and model refinement. This ongoing interaction helps in continuously improving the quality and relevance of the model's responses, ensuring they align well with ethical guidelines, factual accuracy, and user expectations.\n",
        "\n",
        "Applying RLHF to LLMs is important for several reasons:\n",
        "\n",
        "- **Alignment with Human Values**: It helps ensure that the model's outputs are aligned with human ethical standards and societal norms.\n",
        "- **Reduction of Harmful Outputs**: By training the model with human feedback, it's possible to reduce the likelihood of generating unsafe, biased, or otherwise undesirable content.\n",
        "- **Enhanced Relevance and Utility**: Feedback-driven training can make the model more useful and relevant to users by focusing on generating high-quality, contextually appropriate responses.\n",
        "\n",
        "This approach represents a significant advancement in the development of more responsible and effective AI language models."
      ],
      "metadata": {
        "id": "iXz7p2YntKQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Direct Preference Optimization (DPO)*"
      ],
      "metadata": {
        "id": "qoluFPb7O8Vv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Direct Preference Optimization (DPO)**\n",
        "\n",
        "Interesting article from Andrew Ng about a new research paper that proposes DPO (direct preference optimization) over RLHF. A promise is that you won‘t need to deal with a separately represented reward function -- you just need the LLM transformer -- and you can train the LLM directly and more efficiently to optimize the same objective as RLHF. Enjoy the read 🤓🙌\n",
        "\n",
        "https://www.deeplearning.ai/the-batch/issue-231/\n",
        "\n",
        "https://browse.arxiv.org/html/2305.18290v2\n",
        "\n",
        "https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023\n",
        "\n",
        "and here his thoughts more ind details in case you dont want to read the paper: https://magazine.sebastianraschka.com/p/llm-training-rlhf-and-its-alternatives\n",
        "\n",
        "\n",
        "Direct Preference Optimization (DPO) is pretty amazing. Surely, it can't be this straightforward to replace the whole reinforcement learning on human feedback (RLHF) phase?\n",
        "1. Treat a foundational (or instruction tuned) LLM\n",
        "as the reference LLM\n",
        "1.    Generate pairs of outputs to prompts and have humans choose which one they like (human feedback)\n",
        "2.    Add a linear layer to the LLM so that it outputs a scalar value, and tune this new model with a new loss function (compute log-ratio of scalar outputs of the reference LLM and the one being tuned, multiply by a divergence parameter ... -- very cool math insight here, but end-of-the-day this is just a new training loss function called dpo_loss or something that Keras and Pytorch will ship with)\n",
        "3.    Drop the last linear layer, and you have a fine tuned LLM on human feedback\n",
        "Amazing stuff. RLHF was the most dicey part of LLM training and the one that needed the most art vs science. Expect a lot of convergence between LLMs trained on the same data\n",
        "\n",
        "---\n",
        "\n",
        "Direct Preference Optimization (DPO) in the context of machine learning, and specifically for large language models (LLMs) like GPT-3 or GPT-4, is an approach that focuses on optimizing the model's outputs based directly on human preferences. This method is a part of the broader framework of Reinforcement Learning from Human Feedback (RLHF). Here's a closer look at how DPO works and its significance:\n",
        "\n",
        "1. **Collecting Human Preferences**: The first step in DPO involves gathering data on human preferences. This is typically done by presenting human reviewers with pairs of outputs generated by the model in response to the same prompt or query. The reviewers are then asked to indicate which of the two responses they prefer.\n",
        "\n",
        "2. **Training a Preference Model**: The collected preference data is used to train a preference model. This model learns to predict the likelihood of one output being preferred over another by humans. Essentially, it aims to understand and quantify what makes one response more favorable or acceptable than another.\n",
        "\n",
        "3. **Optimizing the Language Model**: Once the preference model is trained, it is used to guide the training of the language model. The language model is optimized to generate outputs that are more likely to align with the preferences indicated by humans. This optimization can be done using various techniques, including reinforcement learning algorithms.\n",
        "\n",
        "4. **Iterative Process**: Like other RLHF techniques, DPO is often iterative. The model's outputs can be continuously evaluated and compared by human reviewers, and the preference model can be updated based on new data. This leads to ongoing improvements in the language model's alignment with human preferences.\n",
        "\n",
        "The significance of DPO lies in its focus on aligning the model's outputs with what humans explicitly prefer. This is particularly important for applications where the quality of an output is subjective and can vary based on context and the specific needs or values of the user.\n",
        "\n",
        "For example, in a conversational AI, different users might have different preferences for the style, tone, and type of responses they find engaging or helpful. DPO allows the model to be tuned to these preferences, potentially leading to more personalized and satisfactory interactions.\n",
        "\n",
        "Overall, Direct Preference Optimization represents a powerful method for increasing the alignment of AI systems with human values, preferences, and expectations, thereby enhancing their usefulness, safety, and acceptance in various applications."
      ],
      "metadata": {
        "id": "5VEtMTUkQz3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Distillation*"
      ],
      "metadata": {
        "id": "JC96LcJUvxwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vertex-ai/docs/generative-ai/models/distill-text-models"
      ],
      "metadata": {
        "id": "d5qpyD1AHvFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-models"
      ],
      "metadata": {
        "id": "v6w_qgUoGs4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-models#tune-distill"
      ],
      "metadata": {
        "id": "DstE8mSrGp7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning and distillation - Distillation is a good option if you have a large model that you want to make smaller without degrading its ability to do what you want. The process of distilling a model creates a new, smaller trained model that costs less to use and has lower latency than the original model"
      ],
      "metadata": {
        "id": "M66NW8rjGlAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/pdf/1503.02531.pdf Distilling the Knowledge in a Neural Network"
      ],
      "metadata": {
        "id": "zvawWRmev2O1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://blog.research.google/2024/02/intervening-on-early-readouts-for.html?m=1"
      ],
      "metadata": {
        "id": "3jWTvDr-v0EX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Self-instruct*"
      ],
      "metadata": {
        "id": "w4FmSc4QvQsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Context - Consider a LLM use-case where we only have access to a handful of HQ few-shot examples that are not sufficient for a full fine-tuning (or even LoRA). Then, is it possible to use an LLM to generate similar examples that can then be used for fine-tuning the model?\n",
        "\n",
        "Concerns\n",
        "1) Model bias - using a model to generate examples and then fine-tuning it based on those sounds like a classic case of introducing bias.\n",
        "\n",
        "2) Role of fine-tuning - If the model is capable of generating the additional examples, then is fine-tuning even necessary? it seems like the model is already able to generalize to the use-case quite well.\n",
        "\n",
        "https://arxiv.org/pdf/2212.10560.pdf\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Yes, this approach is quite effective for training.\n",
        "\n",
        "(1).  Yes, you need to ensure you aren't entrenching existing idiosyncrasies.  Typically this is done in one of three ways: (a) Human review+annotation of machine-generated examples or (b) spending more compute time at inference to generate+filter/select only the best examples for the next round of training, and discarding the low-quality generations.\n",
        "\n",
        "(2).  Generally, given enough time and temperature, all models are capable of generating anything (monkies on a typewriter).  The goal of additional training is always and exclusively to improve the quality of the results in a pass@1 fashion.  If you sample from pass@100, use additional compute to rank the results, and select the top 1% of generations for additional training, then you are increasingly biasing the model toward the highest quality results (which is the purpose of training).  It is true the model is already \"able to generalize to the use-case quite well if given enough compute\", but training is all about paying at training time in order to increase the ROI at inference time.\n",
        "\n",
        "---\n",
        "This sounds like go/datasynth. You can start with a few high quality examples and use LLMs to generate a synthetic dataset for fine-tuning. They also provide tools to mitigate bias you mentioned in #1 (e.g. diversity scores, topic visualizations, etc).  \n"
      ],
      "metadata": {
        "id": "Knw1fQeYvUUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self-instruct is a fascinating technique in the realm of large language models (LLMs) that straddles the line between fine-tuning and augmentation. Here's what it entails:\n",
        "\n",
        "**Core Idea**\n",
        "\n",
        "Self-instruct aims to improve an LLM's ability to follow instructions and perform tasks by having it generate its own training data. Essentially, the LLM acts as both teacher and student.\n",
        "\n",
        "**The Process**\n",
        "\n",
        "1. **Task Generation:** The LLM is given a few initial examples of tasks and desired solutions. It then attempts to generate new, similar tasks itself.\n",
        "2. **Solution Generation:** The LLM also tries to provide solutions or completions to the tasks it has created.\n",
        "3. **Filtering:** Human experts or automated quality checks filter out poorly generated tasks and solutions.\n",
        "4. **Instruction Fine-tuning:** The remaining high-quality, self-generated data is used to fine-tune the LLM using instruction-following techniques.\n",
        "\n",
        "**Why It's Both Fine-tuning and Augmentation**\n",
        "\n",
        "* **Fine-tuning:**  Self-instruct directly modifies the LLM's parameters based on the data it generates, just like other fine-tuning processes. This refines its ability to execute instructions.\n",
        "* **Augmentation:** The main difference is that self-instruct augments the existing training process by creating a novel and customized dataset that caters specifically to the desired task format.\n",
        "\n",
        "**Benefits**\n",
        "\n",
        "* **Addresses Dataset Limitations:** Human-written instruction datasets are often limited in scale and diversity. Self-instruct expands these training resources.\n",
        "* **Reduces Expert Effort:** Creating large datasets manually is time-consuming. Self-instruct lessens the burden on human annotators.\n",
        "* **Iterative Improvement:** As the LLM becomes better at following instructions, its self-generated training data also improves, creating a positive feedback loop.\n",
        "\n",
        "**Example**\n",
        "\n",
        "Imagine you want the LLM to summarize articles.\n",
        "\n",
        "* **Initial Input:**  A few articles with provided human-written summaries.\n",
        "* **Self-Instruct:** The LLM generates new articles and creates summaries for them. These are filtered for quality.\n",
        "* **Fine-tuning:**  The LLM is fine-tuned on the self-generated dataset to improve its summarization skills.\n",
        "\n",
        "**Let me know if you'd like to delve into the technical details of self-instruct methods or want to explore practical applications!**\n"
      ],
      "metadata": {
        "id": "uXbRtyYZvWES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Token*"
      ],
      "metadata": {
        "id": "ON5x3x5CPe7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Token*\n",
        "\n",
        "* basic unit of text representation.\n",
        "* sequences of characters that are treated as individual elements in the LLM's internal representation of the input text.\n",
        "* used to build up more complex language structures, such as words, phrases, and sentences.\n",
        "* Tokenization is the process of breaking down a piece of text into tokens. This can be done using various methods, such as word-level tokenization, character-level tokenization, or subword tokenization. The choice of tokenization method depends on the specific task and the characteristics of the input text.\n",
        "* LLMs use tokens to extract features from the input text and to generate output text. For example, when generating text, the LLM will consider the surrounding tokens to determine the most likely next word or phrase. Tokens also play a role in LLM performance evaluation. Evaluation metrics such as accuracy and F1 score are often calculated based on the similarity between predicted and ground truth tokens.\n",
        "  * Text-to-text translation: When translating a sentence from one language to another, the LLM breaks down the input sentence into tokens and then uses these tokens to generate the corresponding tokens in the target language.\n",
        "  * Text summarization: When summarizing a document, the LLM identifies the most important tokens in the document and then uses these tokens to generate a concise summary.\n",
        "  * Question answering: When answering a question about a text, the LLM extracts the relevant tokens from the text and uses these tokens to identify the answer to the question."
      ],
      "metadata": {
        "id": "C2x7aHgiWuOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I get better results with no training. See how, at https://mltblog.com/42l51rJ\n",
        "Eventually, I will add training: user based (self-tuning) rather than based on algorithms. Of course, fully automated and transparent to the user.\n"
      ],
      "metadata": {
        "id": "A0wqPksljzJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *SLM (Small Language Model)*"
      ],
      "metadata": {
        "id": "jK7vTB6GIQpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://the-decoder.de/microsoft-prognostiziert-drei-grosse-ki-trends-fuer-2024/\n",
        "\n"
      ],
      "metadata": {
        "id": "5YNYNHmIH-7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Microsoft investiert in diesen Bereich, hat bereits die SLMs Phi und Orca vorgestellt und soll seine eigenen Abteilungen auf effizientere KI-Modelle ausgerichtet haben."
      ],
      "metadata": {
        "id": "6iMpdYbDID5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://the-decoder.de/microsofts-mini-llm-phi-2-ist-jetzt-open-source-und-angeblich-besser-als-google-gemini-nano/"
      ],
      "metadata": {
        "id": "KBKBgFLeIJZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://the-decoder.de/microsofts-orca-2-ist-ein-kleines-ki-modell-mit-verbesserter-denkfaehigkeit/"
      ],
      "metadata": {
        "id": "C_vrvQL9IMrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://the-decoder.de/generative-ki-ist-teuer-und-microsoft-will-die-kosten-senken/"
      ],
      "metadata": {
        "id": "EPit7Ws7IPr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[How to Build an LLM from Scratch | An Overview](https://www.youtube.com/watch?v=ZLbVdvOoTKM&list=WL&index=8&t=480s)"
      ],
      "metadata": {
        "id": "UdSIcDIUu6uH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Augment LLMs*"
      ],
      "metadata": {
        "id": "QaGfSVYXp_gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Grounding*"
      ],
      "metadata": {
        "id": "Y7EMAgb2PJDH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grounding**: Out-of-the-box grounding against structured and unstructured data\n"
      ],
      "metadata": {
        "id": "wK-YLsg4sTJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Grounding*\n",
        "\n",
        "https://cloud.google.com/vertex-ai/docs/generative-ai/grounding/overview\n",
        "\n",
        "Grounding in large language models (LLMs) refers to the process of connecting their responses to real-world entities and concepts. This is crucial for ensuring that LLMs generate accurate, relevant, and meaningful outputs. LLMs are trained on massive datasets of text and code, but this knowledge is often abstract and lacks specific context. Grounding allows LLMs to access and incorporate external information to make their responses more grounded in reality.\n",
        "\n",
        "There are several different approaches to grounding LLMs, but they typically involve some combination of the following techniques:\n",
        "\n",
        "* **Knowledge base access:** LLMs can be connected to knowledge bases, such as Wikidata or Google Search, to access information about real-world entities and concepts. This information can be used to refine and improve their responses.\n",
        "* **Data retrieval:** LLMs can be used to retrieve relevant data from external sources, such as databases or web pages. This data can then be used to ground their responses in real-world context.\n",
        "* **Physical interaction:** In some cases, LLMs can be directly connected to the real world through sensors and actuators. This allows them to interact with their environment and gather information directly.\n",
        "\n",
        "Grounding is an essential part of developing reliable and useful LLMs. By grounding their responses in real-world knowledge, LLMs can be more accurate, relevant, and informative. This makes them more suitable for a wider range of applications, such as question answering, summarization, and natural language generation.\n",
        "\n",
        "Here are some of the benefits of grounding LLMs:\n",
        "\n",
        "* **Improved accuracy:** Grounding can help to reduce the number of factual errors in LLM responses.\n",
        "* **Increased relevance:** Grounding can help to ensure that LLM responses are relevant to the context in which they are generated.\n",
        "* **Enhanced creativity:** Grounding can help LLMs to generate more creative and interesting text formats.\n",
        "* **Expanded capabilities:** Grounding can allow LLMs to perform tasks that require more knowledge of the real world, such as answering questions about physical entities or events.\n",
        "\n",
        "Overall, grounding is a powerful technique for improving the performance and usefulness of large language models. As LLMs continue to develop, grounding is likely to play an even more important role in their development and application."
      ],
      "metadata": {
        "id": "HcdUr67tZ6JW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Retrieval-Augmented Generation (RAG)*"
      ],
      "metadata": {
        "id": "6Z0vHScrO3Nw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/blog/products/ai-machine-learning/rags-powered-by-google-search-technology-part-1?hl=en"
      ],
      "metadata": {
        "id": "Mnmh9oFDYQjU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Long tokens vs RAG**\n",
        "\n",
        "https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024\n",
        "\n",
        "https://youtu.be/wa0MT8OwHuk?si=4DeetM9gi9yI1i-T\n",
        "\n",
        "the demo is using a movie. That explains why the 1.5 version landed on the Multimodal part of Studio. Will that context window not apply to the text-only endpoint?\n",
        "\n",
        "Good thing I didn't invest too much time learning about chunking strategies with RAG 😅\n",
        "\n",
        "Apparently Deepmind tested 10M token successfully in research\n",
        "\n",
        "I think chunking will still make sense for RAG use cases, especially if you care about latency or have significantly more than 1M tokens. But it's great to see that there are lots of improvements on the input token limit."
      ],
      "metadata": {
        "id": "wyDsltggM6_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1710.png)"
      ],
      "metadata": {
        "id": "x6b56-TiMMHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.linkedin.com/posts/alexwang2911_genai-llm-technology-activity-7164438306871603200--mgt/?utm_source=share&utm_medium=member_ios"
      ],
      "metadata": {
        "id": "Onb9kYmoIzDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/blog/products/ai-machine-learning/rags-powered-by-google-search-technology-part-1?hl=en"
      ],
      "metadata": {
        "id": "mdFXP_TgVQA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/blog/products/ai-machine-learning/rags-powered-by-google-search-technology-part-2?hl=en"
      ],
      "metadata": {
        "id": "UkJKK25Xlvbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/blog/products/ai-machine-learning/context-aware-code-generation-rag-and-vertex-ai-codey-apis?hl=en"
      ],
      "metadata": {
        "id": "HYCk0zmUl4Ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have a question about chatbot and RAG. Is there any good/easy approach which we can add RAG layer between data source and conversation AI app? The challenge is today we show great demo in Playbooks with cleaned data but in the reality, customers usually have more complicated/messy data source (source data against each others), so the first step of doing data retrieval is critical.  Say customer is ok to use our DFCX/Playbooks but they need to add extra RAG layer. Any experience ?\n"
      ],
      "metadata": {
        "id": "iorG22NB44ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrieval Augmented Generation (RAG)**: Fully managed vector database for high-scale, low latency vector search\n",
        "\n",
        "[What is Retrieval-Augmented Generation (RAG)?](https://www.youtube.com/watch?v=T-D1OfcDW1M&list=WL&index=9&t=23s)\n"
      ],
      "metadata": {
        "id": "YTf3gJSGsUsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG stands for **Retrieval-Augmented Generation** in the context of Large Language Models (LLMs). Here's a breakdown of what it is and why it's important:\n",
        "\n",
        "**How LLMs Typically Work**\n",
        "\n",
        "* Traditional LLMs are trained on massive amounts of text data. They learn to predict the next word in a sequence based on patterns they've seen during training.\n",
        "* This makes them great at generating text, translating languages, etc.\n",
        "* **Limitation:** LLMs can't easily access and incorporate new knowledge or information that wasn't part of their original training data.\n",
        "\n",
        "**How RAG Solves This**\n",
        "\n",
        "RAG combines the power of LLMs with traditional information retrieval systems:\n",
        "\n",
        "1. **Retrieval:** When you ask a question, RAG first searches through a knowledge base (like Wikipedia, internal company documents, news articles, etc.) to find relevant passages of text.\n",
        "2. **Augmentation:** This relevant text is appended to your original question, creating a richer, more informative prompt.\n",
        "3. **Generation:** The LLM uses this combined information (original question + retrieved knowledge) to generate a more comprehensive and accurate answer.\n",
        "\n",
        "**Benefits of RAG**\n",
        "\n",
        "* **Up-to-date Information:** RAG models aren't stuck with the knowledge they were trained on. They can access and integrate fresh information on demand.\n",
        "* **Factual Grounding:** Answers generated by RAG models can be linked back to the knowledge sources they are based on, providing sources or citations.\n",
        "* **Domain-Specific Adaptation:** A RAG model can be customized to work well in specific fields (legal, medical, etc.) by using a knowledge base tailored to that domain.\n",
        "* **Improved Accuracy:** RAG models often significantly outperform traditional LLMs on tasks that require external knowledge\n",
        "\n",
        "**In summary:**  RAG is a technique that allows LLMs to go beyond their internal training data, access external knowledge, and provide more informed, accurate, and trustworthy responses.\n"
      ],
      "metadata": {
        "id": "m0FaHYgS1ygi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Prompting and RAG*\n",
        "\n",
        "Prompting and RAG are equivalent to feature engineering (data augmentation to be exact) in the traditional ML paradigm, while finetuning is equivalent to model training. So, all three are needed for the best result.\n",
        "* rag is more like a key point selection based on features. That's more like an attention mechanism rather than feature engineering.\n",
        "* When you do RAG, you use the user's original input to find relevant pieces of external information and add them to the input you send to the model. This is by definition feature engineering.\n"
      ],
      "metadata": {
        "id": "tq-iqkJhyA1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrieval-Augmented Generation (RAG)**\n",
        "\n",
        "Retrieval-Augmented Generation (RAG) is a framework for improving the accuracy and reliability of large language models (LLMs) by incorporating external knowledge bases during the generation process. It combines the strengths of two approaches: dense retrieval and sequence-to-sequence modeling.\n",
        "\n",
        "**Dense retrieval** is used to identify relevant documents from a knowledge base that are related to the query or prompt provided to the LLM. This ensures that the LLM has access to the most up-to-date and accurate information before generating its response.\n",
        "\n",
        "**Sequence-to-sequence modeling** is used to generate the final output text, taking into account the retrieved documents and the original query. This allows the LLM to incorporate factual information from the knowledge base into its response while maintaining its natural language fluency and coherence.\n",
        "\n",
        "RAG has been shown to improve the performance of LLMs on a variety of tasks, including question answering, summarization, and translation. It has also been found to be more robust to errors in the knowledge base than traditional LLM approaches.\n",
        "\n",
        "**Benefits of RAG:**\n",
        "\n",
        "* **Improved accuracy:** RAG can help to prevent LLMs from generating incorrect or misleading information by providing them with access to a broader range of information.\n",
        "\n",
        "* **Reduced factual errors:** RAG can reduce the number of factual errors in LLM responses by incorporating information from a knowledge base.\n",
        "\n",
        "* **Improved coherence:** RAG can help to improve the coherence of LLM responses by ensuring that they are consistent with the information in the knowledge base.\n",
        "\n",
        "**Drawbacks of RAG:**\n",
        "\n",
        "* **Increased computational complexity:** RAG is more computationally complex than traditional LLM approaches, as it requires both dense retrieval and sequence-to-sequence modeling.\n",
        "\n",
        "* **Dependency on knowledge base:** RAG is dependent on the quality of the knowledge base that is used. If the knowledge base is inaccurate or incomplete, RAG's performance will suffer.\n",
        "\n",
        "Despite these drawbacks, RAG is a promising approach for improving the accuracy and reliability of LLMs. As knowledge bases continue to improve, RAG is likely to become an even more valuable tool for natural language processing."
      ],
      "metadata": {
        "id": "2L0kvygNz4MO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### $\\hookrightarrow$ *LangChain*"
      ],
      "metadata": {
        "id": "ut_14zjENSyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/blog/products/databases/build-rag-applications-with-langchain-and-google-cloud"
      ],
      "metadata": {
        "id": "JTmQ6pFyNQqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### $\\hookrightarrow$ *LLamaindex*"
      ],
      "metadata": {
        "id": "QFiC9iq1uchk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLamaindex**\n",
        "\n",
        "Video: [Llamaindex webinar](https://youtu.be/aoLtTIYAafY?si=r2iEJC_bqTsPRlnf)\n",
        "\n",
        "LlamaIndex is a powerful data framework designed to streamline the development of applications powered by Large Language Models (LLMs). Here's a breakdown of what it is and why it's important:\n",
        "\n",
        "**Key Functions**\n",
        "\n",
        "* **Data Ingestion & Management:**\n",
        "    * **Diverse Formats:** Handles structured, semi-structured, and unstructured data sources (documents, PDFs, APIs, SQL databases, etc.).\n",
        "    * **Organization:** Structures data in ways LLMs can easily understand and access.\n",
        "* **Indexing:** Creates efficient indices (like a virtual library) of your data, allowing quick retrieval of relevant information.\n",
        "* **Query Interface:** Provides a user-friendly way to interact with your data using prompts or questions. The responses are augmented with knowledge retrieved from your indexed data.\n",
        "\n",
        "**Why It Matters (Benefits)**\n",
        "\n",
        "* **Retrieval-Augmented Generation (RAG):** LlamaIndex is core to implementing RAG, a method where LLMs first consult an external knowledge base before generating a text response. This leads to more informed, grounded, and less likely to hallucinate answers.\n",
        "* **Custom Applications:** It simplifies building a range of LLM-driven applications:\n",
        "    * Question-answering systems over specific information (company docs, product manuals, etc.).\n",
        "    * Sophisticated chatbots or conversational AI.\n",
        "    * Intelligent tools that interact with your personal data.\n",
        "* **Flexibility:** Offers both high-level APIs for easy use and low-level APIs for finer control.\n",
        "\n",
        "**How it Works (Simplified)**\n",
        "\n",
        "1. **Import & Structure:** You import data into LlamaIndex, where it's organized.\n",
        "2. **Indexing:**  LlamaIndex creates efficient indices to speed up search within your data.\n",
        "3. **Query:** You give the system a question or prompt.\n",
        "4. **Retrieval:** LlamaIndex uses vector search techniques to find relevant bits of information in your data.\n",
        "5. **Augmented Generation:** The LLM takes your question AND the retrieved knowledge to generate a comprehensive response.\n",
        "\n",
        "**In Summary**\n",
        "\n",
        "LlamaIndex offers a powerful framework for harnessing the capabilities of LLMs with your own diverse data. It simplifies the process of building LLM-based applications that rely on external knowledge sources."
      ],
      "metadata": {
        "id": "f-MDnUAvuPmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Extensions*"
      ],
      "metadata": {
        "id": "KcuadzY1rHe3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extensions**: Integrate easily real-time data and real-world actions, e.g. Ingest internal codebases and automatically lookup evolving security threats in real time\n"
      ],
      "metadata": {
        "id": "YPwk16g1rKKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Function Calling*"
      ],
      "metadata": {
        "id": "hrYb8_OIPhhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function Calling**: enables LLMs to interact with external tools, databases, and APIs or code snippets that perform specific tasks (e.g., weather lookup, math calculations, sending emails) to improve model responses"
      ],
      "metadata": {
        "id": "6h-cCeTcsX-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Function Calling*\n",
        "\n",
        "https://codelabs.developers.google.com/codelabs/gemini-function-calling#0\n"
      ],
      "metadata": {
        "id": "KhkJHDb7j29X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a breakdown of the differences between function calling and extensions in the context of LLMs:\n",
        "\n",
        "**Function Calling**\n",
        "\n",
        "* **Focus:** Executing specific, well-defined tasks or retrieving information from external sources.\n",
        "* **Nature:** Dynamic and on-demand. Functions are called in response to specific prompts and instructions.\n",
        "* **Scope:** Actions are usually limited to external tools and APIs the LLM is connected to.\n",
        "* **Example:** A function to look up the current temperature in a specific city.\n",
        "\n",
        "**Extensions**\n",
        "\n",
        "* **Focus:** Expanding the core capabilities of the LLM with new features or knowledge domains.\n",
        "* **Nature:** More persistent. Extensions are installed or integrated into the model.\n",
        "* **Scope:** Can fundamentally change how the LLM processes information and generates responses.\n",
        "* **Example:** An extension designed for summarizing scientific papers, allowing the LLM to better understand and answer questions about complex research.\n",
        "\n",
        "**Key Differences Table**\n",
        "\n",
        "| Feature            | Function Calling                                    | Extensions                                                   |\n",
        "|--------------------|-----------------------------------------------------|--------------------------------------------------------------|\n",
        "| Purpose            | Perform external actions, retrieve real-world data  | Expand the LLM's capabilities and knowledge                   |\n",
        "| Nature             | Dynamic, task-specific                              | Persistent, integrated into the LLM                           |\n",
        "| Scope              | Focused on external tools the LLM can access       | Can affect the LLM's internal processing and understanding    |\n",
        "| Implementation     | LLM generates code to call external functions      | Often require installing code or packages within the LLM's environment |\n",
        "\n",
        "**In Summary**\n",
        "\n",
        "* **Function calling** is about letting the LLM interact with the outside world to get things done.\n",
        "* **Extensions** are about making the LLM itself smarter or more capable by adding new skills or knowledge.\n",
        "\n",
        "**Let me know if you'd like more clarification or examples!**\n"
      ],
      "metadata": {
        "id": "cJbYYtJO11zH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Special: Vector Retrieval / Vector Search*"
      ],
      "metadata": {
        "id": "r2-fNN88Cb7S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vector Retrieval / Vector Search both refer to the core process of finding similar items within a large dataset of vectors generated by an LLM. Here's how it works:\n",
        "\n",
        "1. Embedding Generation: The LLM takes a query (e.g., a piece of text or an image) and creates a vector representation of it.\n",
        "2. Vector Database: The LLM has a pre-computed database of vectors representing items like text passages, images, or code snippets.\n",
        "3. Similarity Calculation: The LLM calculates the similarity (often using cosine similarity) between the query vector and all the vectors in the database.\n",
        "4. Retrieval: The vectors with the highest similarity scores (closest distance to the query vector) are retrieved. These returned items are considered the most relevant matches to the original query.\n",
        "\n",
        "Applications - Vector retrieval (a.k.a. vector search) is a powerful tool used across various LLM-based applications:\n",
        "\n",
        "* Semantic Search: Searching for information based on meaning rather than just keywords.\n",
        "* Recommendation Systems: Recommending products, content, etc. based on a user's preferences and similarity between items.\n",
        "* Question Answering: Finding relevant passages in a large corpus of text to answer a question.\n",
        "* Image Search: Searching for images similar to a query image."
      ],
      "metadata": {
        "id": "wbIfqyYxr7at"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a breakdown of ANN and MMR in the context of information retrieval using LLMs:\n",
        "\n",
        "**ANN (Approximate Nearest Neighbor)**\n",
        "\n",
        "* **Purpose:**  ANN algorithms are designed to find items (\"neighbors\") in a dataset that are most similar to a given query, even in very high-dimensional spaces. In LLM retrieval, the query would be the user's input, and the items in the dataset are potential text passages containing relevant information.\n",
        "\n",
        "* **Role in LLM Retrieval:**\n",
        "    * **Efficiency:**  ANN is crucial for LLM-based retrieval because naively comparing a query to every piece of text in a large database would be extremely computationally expensive. ANN makes this process tremendously faster.\n",
        "    * **Understanding Similarity:** ANN focuses on finding passages that are semantically similar to the user's query, even if they don't contain exact keyword matches. This aligns well with LLMs' ability to understand nuanced meaning.\n",
        "\n",
        "* **Types of ANN:** Several ANN algorithms exist (e.g., HNSW, FAISS), each with trade-offs in accuracy, speed, and memory usage.\n",
        "\n",
        "**MMR (Maximal Marginal Relevance)**\n",
        "\n",
        "* **Purpose:** MMR is a ranking algorithm used to ensure diversity and avoid redundancy in search results. In LLM retrieval, it works after ANN has identified potential relevant passages.\n",
        "\n",
        "* **Role in LLM Retrieval:**\n",
        "    * **Diversification of Results:** MMR aims to prevent the top results from all being too similar to each other. Instead, it promotes including passages that, while relevant, also cover different aspects or perspectives related to the query.\n",
        "    * **Improving User Experience:** This diversification helps the LLM provide a more comprehensive and informative set of responses to the user, reducing the likelihood of receiving repetitive information.\n",
        "\n",
        "**How ANN and MMR Work Together**\n",
        "\n",
        "1. **User Query:** The user enters a query or question.\n",
        "2. **ANN Retrieval:** Using the ANN algorithm, a set of potentially relevant passages is efficiently retrieved from a large text corpus.\n",
        "3. **MMR Ranking:** MMR analyzes the retrieved passages and reranks them, prioritizing both relevance to the query and diversity within the results.\n",
        "4. **Return to LLM:** The top-ranked passages may be fed back into the LLM for further processing, allowing the LLM to generate a more informed and helpful response.\n",
        "\n",
        "**Let me know if you'd like more details on the technical aspects of specific ANN algorithms or how MMR calculates diversity!**\n"
      ],
      "metadata": {
        "id": "weryLPVwuvxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your favorite cloud data warehouse now supports vector search and vector indexes, see https://lnkd.in/g3ztYWWy. How cool is that? BigQuery vector search lets you find semantically similar items in a table using by comparing the distance of  vector embeddings. Find similar customers, articles, products, locations. This is super useful for integrating LLMs with your data and validating LLM output. The best thing is that you don't need another product to do it."
      ],
      "metadata": {
        "id": "lVvlo-1MCdjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " are announcing the Public Preview of BigQuery Vector Search. This functionality, also commonly referred to as approximate nearest-neighbor search, is key to empowering numerous new data and AI use cases such as semantic search, similarity detection, and retrieval-augmented generation (RAG) with a large language model (LLM).\n",
        "\n",
        "Vector search is often performed on high-dimensional numeric vectors, a.k.a. embeddings, which incorporate a semantic representation for an entity and can be generated from numerous sources, including text, image, or video. BigQuery vector search relies on an index to optimize the lookups and distance computations required to identify closely matching embeddings.\n",
        "\n",
        "Our framework supports multiple Vector Index types, with the first implemented type (IVF) combining (a) an optimized [BQML](https://cloud.google.com/bigquery/docs/bqml-introduction) KMeans clustering model with (b) an inverted row locator, which is automatically updated as the underlying table data mutates (similar to [BigSearch](https://cloud.google.com/bigquery/docs/search-index)). It works with BigQuery’s embedding-generation capabilities, notably via LLM-based or pre-trained models. Yet the generic interface allows users to use embeddings generated via other means as well.\n",
        "\n",
        "New optimizations, features, index types, and the GA launch are expected in Q2/Q3 2024.\n",
        "\n",
        "Public Launch Material\n",
        "* Launch blog: https://cloud.google.com/blog/products/data-analytics/introducing-new-vector-search-capabilities-in-bigquery?hl=en\n",
        "* Public documentation: https://cloud.google.com/bigquery/docs/vector-search-intro\n",
        "* Tutorial 1 for using with existing embeddings: https://cloud.google.com/bigquery/docs/vector-search\n",
        "* Tutorial 2 for combining with embedding generation and RAG: https://cloud.google.com/bigquery/docs/vector-index-text-search-tutorial\n",
        "* LangChain integration: https://python.langchain.com/docs/integrations/vectorstores/bigquery_vector_search\n",
        "\n",
        "What does the introduced syntax and usage look like?\n",
        "1. Create Vector Index\n",
        "CREATE OR REPLACE VECTOR INDEX <my_index> ON <my_table>(embedding_col)\n",
        "OPTIONS (distance_type=\"COSINE\", index_type=\"IVF\");\n",
        "2. Vector SearchSELECT <columns> FROM VECTOR_SEARCH (TABLE <my_table>, 'embedding_col', (SELECT embedding_col FROM <test_table> WHERE <>));\n",
        "\n",
        "3. (Optional) Monitor Indexing Progress AnytimeSELECT table_name, index_name, coverage_percentage, unindexed_row_count\n",
        "FROM `<myproject.mydataset>.INFORMATION_SCHEMA.VECTOR_INDEXES` WHERE index_status = 'ACTIVE';\n",
        "4. Example RAG query, combining embedding generation, vector search, and LLM text generation:SELECT ml_generate_text_llm_result AS generated, prompt\n",
        "FROM ML.GENERATE_TEXT(\n",
        "   MODEL `<LLM_text_generation_model>`,\n",
        "   (SELECT CONCAT('Propose some project ideas to improve user password security using the context below: ', STRING_AGG(FORMAT(\"patent title: %s, patent abstract: %s\", base.title, base.abstract), ',\\n')) AS prompt, FROM VECTOR_SEARCH(\n",
        "         TABLE `<patents_my_embeddings_table>`, 'text_embedding',\n",
        "         (SELECT text_embedding, content AS query\n",
        "           FROM ML.GENERATE_TEXT_EMBEDDING(\n",
        "               MODEL `<LLM_embedding_model>`,\n",
        "               (SELECT 'improving password security' AS content))), top_k => 5)\n",
        "   ), STRUCT(0.4 AS temperature, 300 AS max_output_tokens, 0.5 AS top_p, 5 AS top_k, TRUE AS flatten_json_output));\n"
      ],
      "metadata": {
        "id": "LHnqM83Capic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Vector Retrieval*\n",
        "\n",
        "https://arxiv.org/abs/2401.09350: Foundations of Vector Retrieval"
      ],
      "metadata": {
        "id": "nRhWlzbKrZ5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Special: Knowledge Graph*"
      ],
      "metadata": {
        "id": "NxI60357-N2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://neo4j.com/labs/genai-ecosystem/"
      ],
      "metadata": {
        "id": "-QrtL9Cs-QXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Evaluate LLMs*"
      ],
      "metadata": {
        "id": "J4ZBVKqKqAbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evaluation*\n",
        "\n",
        "**Automatic Side-by-Side (AutoSxS)**\n",
        "\n",
        "https://cloud.google.com/vertex-ai/docs/generative-ai/models/side-by-side-eval\n",
        "\n",
        "**Metrics-based evaluation**\n",
        "\n",
        "https://cloud.google.com/vertex-ai/docs/generative-ai/models/evaluate-models\n",
        "\n",
        "**Vertex AI Model Evaluation**\n",
        "\n",
        "Vertex AI Model Evaluation provides a comprehensive framework for evaluating LLMs across a wide range of tasks, including natural language understanding (NLU), natural language generation (NLG), and question answering. It allows you to define custom evaluation metrics and compare performance over time.\n",
        "\n"
      ],
      "metadata": {
        "id": "d2RwjKyMVbg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*MLOps*"
      ],
      "metadata": {
        "id": "vOqtFAy5GKtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's for example a reference architecture for an infrastructure to run a retrieval-augmented generation (RAG) application using Vertex AI. Obviously not the only way to do it, but a good way to do it.\n",
        "\n",
        "This architecture includes three components:\n",
        "- Data ingestion subsystem\n",
        "- Serving subsystem\n",
        "- Quality evaluation subsystem\n",
        "\n",
        "https://cloud.google.com/architecture/rag-capable-gen-ai-app-using-vertex-ai?hl=de"
      ],
      "metadata": {
        "id": "m46jcaVOtJMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vertex-ai/docs/general/deployment?hl=de\n",
        "\n",
        "https://blog.ml6.eu/vertex-pipelines-vertex-ai-vs-ai-platform-6c2f799d6e2e?gi=5a1dbe25d735"
      ],
      "metadata": {
        "id": "mdsVo5zvjjd_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excited to share that a new tutorial on Ray on Vertex AI is now available! 🔥\n",
        "\n",
        "This tutorial will take you through the process of distributing PyTorch model training using Ray on Vertex AI and deploying it to Vertex AI Endpoint.\n",
        "\n",
        "To learn more, you can find the notebook link on GitHub 👇 . And if you have any ideas for more Ray on Vertex AI content you'd like to see, let me know.\n",
        "\n",
        "Get started with PyTorch on Ray on Vertex AI\n",
        "https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/ray_on_vertex_ai/get_started_with_pytorch_rov.ipynb"
      ],
      "metadata": {
        "id": "J5QrNO-MIfPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/google-cloud/machine-learning-pipeline-development-on-google-cloud-5cba36819058"
      ],
      "metadata": {
        "id": "Fq4EBdvhFC13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning"
      ],
      "metadata": {
        "id": "8MmOgfMSHSYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vertex-ai/docs/start/introduction-mlops"
      ],
      "metadata": {
        "id": "It97BIplHWWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Programming*"
      ],
      "metadata": {
        "id": "OnneO2AhgoGY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Distributed Training*"
      ],
      "metadata": {
        "id": "uM9V1BBQGHTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=NbID_AqdZXM"
      ],
      "metadata": {
        "id": "i4DIXwcbHFVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=S1tN9a4Proc"
      ],
      "metadata": {
        "id": "ZJ7hEebdHDXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/guide/distributed_training"
      ],
      "metadata": {
        "id": "tiCklVoxGoFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/guide/keras/distributed_training"
      ],
      "metadata": {
        "id": "BmRIRKb9G3yA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/tutorials/distribute/keras"
      ],
      "metadata": {
        "id": "VA8BRTjDHArx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Libraries*"
      ],
      "metadata": {
        "id": "crQgUFkRk-XB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Qualtran**\n",
        "\n",
        "https://github.com/quantumlib/Qualtran/blob/main/qualtran/surface_code/magic_state_factory.py\n",
        "\n",
        "https://github.com/quantumlib/Qualtran/tree/main/qualtran"
      ],
      "metadata": {
        "id": "K-VJ5ea6lArD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QuTip**\n",
        "\n",
        "https://qutip.org/qutip-tutorials/#visualizations\n",
        "\n",
        "https://nbviewer.org/urls/qutip.org/qutip-tutorials/tutorials-v4/visualization/bloch_sphere_with_colorbar.ipynb"
      ],
      "metadata": {
        "id": "lCeP13HblFCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QubiC**\n",
        "\n",
        "An open source FPGA-based control and measurement system for superconducting quantum information processors, https://arxiv.org/pdf/2101.00071.pdf"
      ],
      "metadata": {
        "id": "UVy4V3ayu4Hc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Speichersichere Programmiersprachen*"
      ],
      "metadata": {
        "id": "6uUn645o-PmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://m.winfuture.de/news/141447\n",
        "\n",
        "* Konkret hat das White House Office of the National Cyber Director (ONCD) einen Bericht (PDF) veröffentlicht (via Infoworld), in dem man Entwicklern nahelegt, \"speichersichere Programmiersprachen\" zu verwenden - und dazu zählen C und C++ eben nicht. Laut ONCD können IT-Unternehmen mit der Einführung speichersicherer Programmiersprachen verhindern, \"dass ganze Klassen von Schwachstellen in das digitale Ökosystem eindringen\".\n",
        "\n",
        "* Der Begriff bezieht sich auf Fehler und Schwachstellen bzw. deren Schutz, die den Speicherzugriff betreffen, dazu zählen **Buffer Overflows, Out-of-Bound-Reads und Memory Leaks**. Mit dieser Meinung ist das Weiße Haus auch nicht alleine, da auch Microsoft und Google in Studien festgestellt haben, dass rund 70 Prozent aller Schwachstellen auf das Konto von Speicherproblemen zurückgehen.\n",
        "\n",
        "* [Laut der National Security Agency (NSA)](https://m.winfuture.de/news/132951) werden folgende Programmiersprachen als \"Memory-Safe\" bzw. sicher eingestuft:\n",
        "Rust\n",
        "Go\n",
        "C#\n",
        "Java\n",
        "Swift\n",
        "JavaScript\n",
        "Ruby"
      ],
      "metadata": {
        "id": "xUdNWhEP-ShT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *JAX*"
      ],
      "metadata": {
        "id": "EkdQBmsWyXyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://jax.readthedocs.io/en/latest/jax-101/index.html"
      ],
      "metadata": {
        "id": "TyH5oxOchjqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://jax.readthedocs.io/en/latest/notebooks/quickstart.html"
      ],
      "metadata": {
        "id": "MNTTlgnLyXBm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html"
      ],
      "metadata": {
        "id": "sKF2rI6NhaHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Linux*"
      ],
      "metadata": {
        "id": "NpX_msD1vmi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.digitalocean.com/community/tutorials/linux-commands"
      ],
      "metadata": {
        "id": "D1N-de6GwqUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ls - The most frequently used command in Linux to list directories\n",
        "* pwd - Print working directory command in Linux\n",
        "* cd - Linux command to navigate through directories\n",
        "* mkdir - Command used to create directories in Linux\n",
        "* mv - Move or rename files in Linux\n",
        "* cp - Similar usage as mv but for copying files in Linux\n",
        "* rm - Delete files or directories\n",
        "* touch - Create blank/empty files\n",
        "* ln - Create symbolic links (shortcuts) to other files\n",
        "* cat - Display file contents on the terminal\n",
        "* clear - Clear the terminal display\n",
        "* echo - Print any text that follows the command\n",
        "* less - Linux command to display paged outputs in the terminal\n",
        "* man - Access manual pages for all Linux commands\n",
        "* uname - Linux command to get basic information about the OS\n",
        "* whoami - Get the active username\n",
        "* tar - Command to extract and compress files in Linux\n",
        "* grep - Search for a string within an output\n",
        "* head - Return the specified number of lines from the top\n",
        "* ail - Return the specified number of lines from the bottom\n",
        "* diff - Find the difference between two files\n",
        "* cmp - Allows you to check if two files are identical\n",
        "* comm - Combines the functionality of diff and cmp\n",
        "* sort - Linux command to sort the content of a file while outputting\n",
        "* export - Export environment variables in Linux\n",
        "* zip - Zip files in Linux\n",
        "* unzip - Unzip files in Linux\n",
        "* ssh - Secure Shell command in Linux\n",
        "* service - Linux command to start and stop services\n",
        "* ps - Display active processes\n",
        "* kill and killall - Kill active processes by process ID or name\n",
        "* df - Display disk filesystem information\n",
        "* mount - Mount file systems in Linux\n",
        "* chmod - Command to change file permissions\n",
        "* chown - Command for granting ownership of files or folders\n",
        "* ifconfig - Display network interfaces and IP addresses\n",
        "* traceroute - Trace all the network hops to reach the destination\n",
        "* wget - Direct download files from the internet\n",
        "* ufw - Firewall command\n",
        "* iptables - Base firewall for all other firewall utilities to interface with\n",
        "* apt, pacman, yum, rpm - Package managers depending on the distro\n",
        "* sudo - Command to escalate privileges in Linux\n",
        "* cal - View a command-line calendar\n",
        "* alias - Create custom shortcuts for your regularly used commands\n",
        "* dd - Majorly used for creating bootable USB sticks\n",
        "* whereis - Locate the binary, source, and manual pages for a command\n",
        "* whatis - Find what a command is used for\n",
        "* top - View active processes live with their system usage\n",
        "* useradd and usermod - Add new user or change existing users data\n",
        "* passwd - Create or update passwords for existing users"
      ],
      "metadata": {
        "id": "uO0J0iBAwjsG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Python*"
      ],
      "metadata": {
        "id": "-bgPYHGr1kCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For (Loop)**"
      ],
      "metadata": {
        "id": "bHxVacZSzNRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute n^3\n",
        "\n",
        "example_list = [1,4,9]\n",
        "cube_list = []\n",
        "\n",
        "for value in example_list:\n",
        "    cube_list.append(value**3)\n",
        "\n",
        "print(cube_list)"
      ],
      "metadata": {
        "id": "HEOrl3Il0Y-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3068cf41-07be-4f60-968d-ffca9b658a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 64, 729]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Range**\n",
        "\n",
        "https://www.freecodecamp.org/news/python-for-loop-for-i-in-range-example/"
      ],
      "metadata": {
        "id": "axn8EIN20d2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(6):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9JzPC-Xzf8L",
        "outputId": "dd541f76-1c0c-4c6e-e316-0fe38a849606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,6,2): # Start, Stop, Steps\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T76OMRBtzjHJ",
        "outputId": "5b5fdd74-eb6c-4466-ed24-6bdec39359e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "2\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Now outsource one value to get generic function:*"
      ],
      "metadata": {
        "id": "y1phzBwszy2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_function(x):\n",
        "  for i in range(0,x,2): # Start, Stop, Steps\n",
        "    print(i)\n",
        "\n",
        "x = 10\n",
        "my_function(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMM3qKJyOFqF",
        "outputId": "802138dc-c551-4c3d-e85e-483749ee6862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "2\n",
            "4\n",
            "6\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**While** (Loop)\n",
        "\n",
        "* while = as long as: *While Loop (simplest loop): is given a condition, and executes the loop until the condition is false. (If the condition is false, it does nothing.)*\n",
        "\n",
        "* https://www.w3schools.com/python/python_while_loops.asp\n"
      ],
      "metadata": {
        "id": "D3C3Frwh0FU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Berechne den Restwert in der Modulurechnung\n",
        "\n",
        "# Setup Variables\n",
        "modulus = 51 # moduland\n",
        "modulo = 7\n",
        "\n",
        "# Compute Modulus\n",
        "while modulus > modulo:\n",
        "    modulus = modulus - modulo\n",
        "\n",
        "# Show Restwert\n",
        "print(modulus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vhM4pD40A0K",
        "outputId": "e519a1bd-437f-49d1-f054-60564d4186f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Break**\n",
        "\n",
        "*Break escapes the current loop, and moves on after it. This is mostly used for searching for particular values - iterating until something happens.*"
      ],
      "metadata": {
        "id": "IYhDJ4SI0tBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "  if i==5:\n",
        "    break\n",
        "print(i)"
      ],
      "metadata": {
        "id": "65DXNSnQ0n0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Else** (Rekursion)\n",
        "\n",
        "*It is a better pattern than while loops for high intensity computing because of your easy ability to set an upper limit for loop length. But if the calculation fails, you need a way to determine it: fortunately, for supports an else clause which triggers if and only if the loop exists without hitting a break statement.*"
      ],
      "metadata": {
        "id": "HFsqRuLw053E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 101\n",
        "\n",
        "for i in range(100):\n",
        "  if i==n:\n",
        "    break\n",
        "else:\n",
        "  print(\"Unable to find\" + str(n))\n",
        "\n",
        "print(i)"
      ],
      "metadata": {
        "id": "PSva2CdA09cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Continue**\n",
        "\n",
        "*Break only breaks out of the closest loop. There is no way to easily break out of a higher loop just using break. Continue works similarly, but instead of escaping the loop, it starts the next iteration immediately. This is great for discarding cases, and is a common task in the algorithm:*"
      ],
      "metadata": {
        "id": "49wpgaI61FV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  if i==5:\n",
        "    continue\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "L03w27k71Gov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7fd5a1f-52be-480a-d4e9-13cf6d27189a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# != means not equal\n",
        "# i%3 means\n",
        "# Restwerte berechnen in Modulo hiermit: 51%7\n",
        "# \\leq means ≤, so less than or equal to ..\n",
        "\n",
        "for i in range(10):\n",
        "  if i%3 != i%2:\n",
        "    continue\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "od2pk8MN1VGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Print and Return**\n",
        "\n",
        "* Return keeps value\n",
        "\n",
        "* [More about print statement](https://realpython.com/python-print/#printing-in-a-nutshell)"
      ],
      "metadata": {
        "id": "NjmO1Y-0zJyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Flow Control: Conditionals**"
      ],
      "metadata": {
        "id": "tJqcIKCr3Dss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=3\n",
        "if x>10:\n",
        "    print(\"x is big.\")\n",
        "if x<= 10:\n",
        "    print(\"x is small.\")"
      ],
      "metadata": {
        "id": "wGXplj2U3Eh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=3\n",
        "if x>10:\n",
        "    print(\"x is big.\")\n",
        "elif x>0:\n",
        "    print(\"x is small.\")\n",
        "else:\n",
        "    print(\"x is not positive.\")"
      ],
      "metadata": {
        "id": "TwrTdspJ3IqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yield**\n",
        "\n",
        "* Generators: like yield: https://www.python-kurs.eu/generatoren.php\n",
        "\n",
        "* there is one reason we must bring them up; you cannot create tuples with a comprehension directly; they instead create a generator.\n",
        "\n",
        "* You can think of generators as single-use lists. This makes them considerably faster, and with a lower memory footprint, in many use cases. We have already talked about a few generators - in Python 3, range is a generator.\n",
        "\n",
        "* These can be used as arguments without the enclosing. For example, you could construct a string containing the integers with:"
      ],
      "metadata": {
        "id": "aOjvMkgg3iWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fibonacci(n):\n",
        "    \"\"\"Ein Fibonacci-Zahlen-Generator\"\"\"\n",
        "    a, b, counter = 0, 1, 0\n",
        "    while True:\n",
        "        if (counter > n): return\n",
        "        yield a\n",
        "        a, b = b, a + b\n",
        "        counter += 1\n",
        "f = fibonacci(5)\n",
        "for x in f:\n",
        "  print x,\n",
        "print"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "Sz47xQO936wm",
        "outputId": "21a1c7b8-a0ef-416d-d51c-4c5a910d3614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-fb5705716190>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    print x\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(x)?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def firstn(g, n):\n",
        "\tfor i in range(n):\n",
        "\t\tyield g.next()\n",
        "\n",
        "\n",
        "firstn(5, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUCdS4iv5iXL",
        "outputId": "8f79513d-6a67-47cf-8473-516cc3d7c2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object firstn at 0x7f162b6846d0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.python-kurs.eu/generatoren.php"
      ],
      "metadata": {
        "id": "3-kxvfnn5TZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Enumerate** (Aufzählen)\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Enumeration\n",
        "\n",
        "* https://realpython.com/python-enumerate/"
      ],
      "metadata": {
        "id": "oaYQE4Q23jMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "values = [\"a\", \"b\", \"c\"]\n",
        "for count, value in enumerate(values):\n",
        "  print(count, value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5FfJ9pf4hzk",
        "outputId": "7db098ae-d0c5-4de9-c8dc-822c59db9384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 a\n",
            "1 b\n",
            "2 c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Miscellaneous**"
      ],
      "metadata": {
        "id": "hkDgUCb546zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 10\n",
        "a += 5\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpKfGQeX46UN",
        "outputId": "2298cd82-0f47-4b44-a6cf-afa98c889f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Functions in Maths & Physics I (Def)**"
      ],
      "metadata": {
        "id": "fLMArogly99J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.w3schools.com/python/python_functions.asp\n",
        "\n",
        "http://www-personal.umich.edu/~mejn/computational-physics/"
      ],
      "metadata": {
        "id": "w_B7I77I6aKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_function(x):\n",
        "  return x + 2\n",
        "\n",
        "my_function(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdyUIe0tK7O8",
        "outputId": "b4df5afd-c957-4444-ffe2-4cb99a548dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_function(x):\n",
        "  for i in range(1,x):\n",
        "    print(i**2)\n",
        "\n",
        "my_function(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUCfTgihCl9v",
        "outputId": "ea876fcd-2cca-4912-c05d-eee817785753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "4\n",
            "9\n",
            "16\n",
            "25\n",
            "36\n",
            "49\n",
            "64\n",
            "81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def isqrt(n):\n",
        "  return int(math.sqrt(n))\n",
        "\n",
        "n = 100\n",
        "isqrt(n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjS5fc4C2UMM",
        "outputId": "c78c2f48-21f9-43ce-c03d-b6acda0c8392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_function(n):\n",
        "  if n = (1):\n",
        "    return 1,\n",
        "  else:\n",
        "    return alg2d(n-1) + n\n",
        "\n",
        "alg2d(3)"
      ],
      "metadata": {
        "id": "ZkLNDfQ99hSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_function(x):\n",
        "  return 5 * x\n",
        "\n",
        "print(my_function(3))\n",
        "print(my_function(5))\n",
        "print(my_function(9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgVKnVjc7o4u",
        "outputId": "6b9b66cc-90c4-40b5-eb37-b31084f93ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "25\n",
            "45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def selectionsort(seq):\n",
        "  for i in range(len(seq) - 1):\n",
        "    k = i\n",
        "    for j in range(i, len(seq)):\n",
        "      if seq[j] < seq[k]:\n",
        "        k = j\n",
        "    seq[i], seq[k] = seq[k], seq[i]\n",
        "\n",
        "result = selectionsort([1, 3, 5, 2, 4])\n",
        "result"
      ],
      "metadata": {
        "id": "qs_2cqJU8Ifu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def function(input):\n",
        "  for i in range(len(input) + 1):\n",
        "\n",
        "function([1, 2, 4])"
      ],
      "metadata": {
        "id": "BCUcl2Yf7vwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the Fibonacci numbers up to 1000\n",
        "f1,f2 = 1,1\n",
        "while f2<1000:\n",
        "    print(f2)\n",
        "    f1,f2 = f2,f1+f2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqI9EP3s68wt",
        "outputId": "24c3f412-b883-49c1-f4f7-6a77bcd51f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "5\n",
            "8\n",
            "13\n",
            "21\n",
            "34\n",
            "55\n",
            "89\n",
            "144\n",
            "233\n",
            "377\n",
            "610\n",
            "987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the wavelengths of hydrogen lines\n",
        "R = 1.097e-2\n",
        "for m in range(1,4):\n",
        "    print(\"Series for m =\",m)\n",
        "    for n in range(m+1,m+6):\n",
        "        invlambda = R*(1/m**2-1/n**2)\n",
        "        print(\"  \",1/invlambda,\"nm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA7mkKRZ8fcy",
        "outputId": "589eb076-750b-48c0-f174-875a916d72c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series for m = 1\n",
            "   121.5436037678517 nm\n",
            "   102.55241567912488 nm\n",
            "   97.23488301428137 nm\n",
            "   94.95594044363415 nm\n",
            "   93.76220862091418 nm\n",
            "Series for m = 2\n",
            "   656.3354603463993 nm\n",
            "   486.1744150714068 nm\n",
            "   434.084299170899 nm\n",
            "   410.2096627164995 nm\n",
            "   397.04243897498225 nm\n",
            "Series for m = 3\n",
            "   1875.2441724182836 nm\n",
            "   1281.9051959890612 nm\n",
            "   1093.8924339106654 nm\n",
            "   1005.013673655424 nm\n",
            "   954.6697605038536 nm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the internal energy of a quantum simple harmonic oscillator at temperature T\n",
        "from math import exp\n",
        "\n",
        "terms = 1000\n",
        "beta = 1/100\n",
        "S = 0.0\n",
        "Z = 0.0\n",
        "for n in range(terms):\n",
        "    E = n + 0.5\n",
        "    weight = exp(-beta*E)\n",
        "    S += weight*E\n",
        "    Z += weight\n",
        "\n",
        "print(S/Z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr3JAICQ7I80",
        "outputId": "835890b7-3433-4fee-e584-8bd48e8d10ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99.95543134093475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_5():\n",
        "  for i in range(100):\n",
        "    for j in range(20):\n",
        "      if i == 5:\n",
        "        return i\n",
        "  print(\"Couldn't find 5.\")"
      ],
      "metadata": {
        "id": "7p_dm_Bi1iOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def natural_language(message):\n",
        "    print(message)\n",
        "\n",
        "message = \"Hello World\"\n",
        "natural_language(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDLQQt7E2IeL",
        "outputId": "1cdaf4c1-bc75-4bbd-e1ff-a68eac58c8f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Functions in Maths & Physics II (Class)**"
      ],
      "metadata": {
        "id": "xEP2z9S719Ep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Video: Methoden in Klassen](https://www.youtube.com/watch?v=58IjjwHs_4A)"
      ],
      "metadata": {
        "id": "aBZdbhCcFgF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tweet:\n",
        "  def __init__(self):\n",
        "    print('Hi')\n",
        "\n",
        "result = Tweet()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq8z1hDi18sH",
        "outputId": "a5330983-f9ae-4e1f-9e6d-45e9a5ed0b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class and function / self is referring to the instances below\n",
        "class Tweet:\n",
        "  def __init__(self, message):\n",
        "    self.x = message\n",
        "\n",
        "# Define messages (instances)\n",
        "a = Tweet('Hello 42')\n",
        "b = Tweet('Hello 88')\n",
        "\n",
        "# Call messages\n",
        "print('a is ' + a.x)\n",
        "print('b is ' + b.x)"
      ],
      "metadata": {
        "id": "mZqS96oX2gLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class and function\n",
        "class Tweet:\n",
        "  def __init__(self, message):\n",
        "    self.message = message\n",
        "  def print_tweet(self):\n",
        "    print(self.message)\n",
        "\n",
        "# Define messages (objects?)\n",
        "c = Tweet('Hello 100')\n",
        "\n",
        "# Call messages\n",
        "c.print_tweet()"
      ],
      "metadata": {
        "id": "5PpAf4es2hmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Car():\n",
        "\n",
        "    # init method or constructor\n",
        "    # (these are not functions, because functions have no self and also within class they are called methods)\n",
        "    def __init__(self, model, color):\n",
        "        self.model = model\n",
        "        self.color = color\n",
        "\n",
        "    def show(self):\n",
        "        print(\"Model is\", self.model )\n",
        "        print(\"color is\", self.color )\n",
        "\n",
        "# both objects have different self which\n",
        "# contain their attributes\n",
        "audi = Car(\"audi a4\", \"blue\")\n",
        "ferrari = Car(\"ferrari 488\", \"green\")\n",
        "\n",
        "audi.show()     # same output as car.show(audi)\n",
        "ferrari.show()  # same output as car.show(ferrari)\n",
        "\n",
        "# Behind the scene, in every instance method\n",
        "# call, python sends the instances also with\n",
        "# that method call like car.show(audi)"
      ],
      "metadata": {
        "id": "y0r0UEgi2kB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "self parameter: https://www.youtube.com/watch?v=CLoK-_qNTnU\n",
        "\n",
        "klassen und objekte: https://www.youtube.com/watch?v=XxCZrT7Z3G4\n",
        "\n",
        "methoden: https://www.youtube.com/watch?v=58IjjwHs_4A"
      ],
      "metadata": {
        "id": "cSeBZR6g2mU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization of Functions**"
      ],
      "metadata": {
        "id": "DSkCPO-97ZAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://scriptverse.academy/tutorials/python-matplotlib-plot-function.html"
      ],
      "metadata": {
        "id": "y1ALPQD18XwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize':(10, 6), \"lines.linewidth\": 1.0})\n",
        "\n",
        "# 100 linearly spaced numbers\n",
        "x = np.linspace(0,10,10)\n",
        "\n",
        "# the function\n",
        "y = x**2\n",
        "\n",
        "# setting the axes at the centre\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.xaxis.set_ticks_position('bottom')\n",
        "ax.yaxis.set_ticks_position('left')\n",
        "\n",
        "# plot the function\n",
        "#plt.plot(x,y, 'g')\n",
        "plt.plot(x,y, 'b', label='y=sin(x)')\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cbiVzNHZDJmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize':(10, 6), \"lines.linewidth\": 1.0})\n",
        "\n",
        "\n",
        "# 100 linearly spaced numbers\n",
        "x = np.linspace(0,1,100)\n",
        "x = np.linspace(-np.pi,np.pi,100)\n",
        "\n",
        "# the function\n",
        "y = x**20\n",
        "y = np.sin(x)\n",
        "\n",
        "# setting the axes at the centre\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.xaxis.set_ticks_position('bottom')\n",
        "ax.yaxis.set_ticks_position('left')\n",
        "\n",
        "# plot the function\n",
        "#plt.plot(x,y, 'g')\n",
        "plt.plot(x,y, 'b', label='y=sin(x)')\n",
        "plt.plot(x,2*y, 'c', label='y=2sin(x)')\n",
        "plt.plot(x,3*y, 'r', label='y=3sin(x)')\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "8JuGtYMGPwpx",
        "outputId": "abc363b7-cec6-4d43-df48-94aa3acdb440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 100 linearly spaced numbers\n",
        "x = np.linspace(-5,5,100)\n",
        "\n",
        "# the function, which is y = x^3 here\n",
        "y = x**2\n",
        "y = np.exp(x)\n",
        "\n",
        "# setting the axes at the centre\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.spines['left'].set_position('center')\n",
        "ax.spines['bottom'].set_position('center')\n",
        "ax.spines['right'].set_color('none')\n",
        "ax.spines['top'].set_color('none')\n",
        "ax.xaxis.set_ticks_position('bottom')\n",
        "ax.yaxis.set_ticks_position('left')\n",
        "\n",
        "# plot the function\n",
        "plt.plot(x,y, 'g')\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "Rt99Vbv1OmFX",
        "outputId": "7394fe92-6469-4dd6-b58b-b53bd63b0009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vFQCvRyaxKAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Google*"
      ],
      "metadata": {
        "id": "EV6x8bY7pvDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Three Decades of Activations: A Comprehensive Survey of 400 Activation Functions for Neural Networks offers the most extensive overview of activation functions to date. It aims to streamline the selection process for researchers and practitioners, reducing redundancy and the unintentional rediscovery of functions.\n",
        "\n",
        "https://arxiv.org/abs/2402.09092\n",
        "\n",
        "\n",
        "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n",
        "\n",
        "https://arxiv.org/abs/2306.08302"
      ],
      "metadata": {
        "id": "JKXH9meQFzR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Google Products*"
      ],
      "metadata": {
        "id": "WnAvpRxbPSwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vertex AI! 🎉\n",
        "\n",
        "🔎 You can now query an index from the Vector Search console, making it even easier to validate your retrievals.\n",
        "\n",
        "🌻 New models have been added to the Model Garden, including Stable Diffusion XL LCM, LLaVA 1.5, PyTorch-ZipNeRF, WizardLM, and more.\n",
        "\n",
        "🎥 Multimodal Embeddings video support went GA, giving you the possibility to extend your AI applications.\n",
        "\n",
        "✨ Vertex AI Gemini 1.0 Pro and Gemini 1.0 Pro Vision multimodal language models also went GA!\n",
        "\n",
        "Overview of multimodal models\n",
        "https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/overview\n",
        "\n",
        "Multimodal video embeddings\n",
        "https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-multimodal-embeddings#vid-img-txt-request\n",
        "\n",
        "Vertex AI Vector search\n",
        "https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index"
      ],
      "metadata": {
        "id": "J_TrPlyPP6Um"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview\n",
        "\n",
        "https://www.linkedin.com/in/deltorobarba/recent-activity/reactions/\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1699.jpeg)"
      ],
      "metadata": {
        "id": "ImUnO-bDTkNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "book: Official Google Cloud Certified Professional Machine Learning Engineer Study Guide, https://www.amazon.com/dp/1119944465?ref_=cm_sw_r_mwn_dp_QEQREW6ES28470H5333A&language=en-US"
      ],
      "metadata": {
        "id": "ehkWx65LkI5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.linkedin.com/pulse/use-mistral-llms-locally-your-computer-lm-studio-windows-molina-ldmje"
      ],
      "metadata": {
        "id": "tkRhOULDj_Xz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.linkedin.com/pulse/gemini-look-my-food-give-me-new-ideas-filipe-gracio-phd-tl4be"
      ],
      "metadata": {
        "id": "EiWGjWMykCYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Lumiere*\n",
        "\n",
        "The first generative video goodness of 2024 is in: Lumiere. A text-to-video, image-to-video, and stylized video generation model from Google Research.\n",
        "\n",
        "Lumiere demonstrates state-of-the-art video generation results with a new model design that facilitates a wide range of content creation tasks such as video editing, video in-painting, and stylized generation.\n",
        "\n",
        "While existing video models first synthesize distant keyframes then apply temporal super-resolution to make videos look temporally consistent, Lumiere generates the entire temporal duration of the video at once, through a single pass in the model. This makes the videos look more realistic.\n",
        "\n",
        "Paper: https://lnkd.in/dvcWNCtp\n",
        "Video: https://lnkd.in/deQHkxFj"
      ],
      "metadata": {
        "id": "3fNy3RrnyTa3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Appendix: Models*"
      ],
      "metadata": {
        "id": "1Amg0O9YxNcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Differentiable Programming and Probabilistic Programming*\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1701.jpg)\n",
        "\n",
        "https://www.lokad.com/blog/2024/1/29/probabilistic-exponential-smoothing-for-explainable-ai-in-supply-chain/"
      ],
      "metadata": {
        "id": "or8sN-Vzjadz"
      }
    }
  ]
}