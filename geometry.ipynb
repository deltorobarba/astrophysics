{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "geometry.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Gdr6F1zuU4MG",
        "VwBNw0I30_GX",
        "9AR9PIXysIa4",
        "pd2IsJ_CSCS6",
        "bcxaUB6UFfh8",
        "KYzlWwuA8hXl",
        "ttEWWgIVr9Sl",
        "kyduGf4kNe-b",
        "TH8b8Mbvy_Fe",
        "zFD0yRkvYGE2",
        "uTlqgkPgcyej",
        "3HEOBISTrpoC",
        "ArSX-a3HWv_P",
        "dolnoE19IyYG",
        "VQdL1yhzPGzI",
        "SHwK1ZsvrPIY",
        "PhQKZZ-1M-GE",
        "zLvbjOH0rbDs",
        "4NB7LHkmNm_3",
        "kjZH2A2rUEuE",
        "BytRtSdcUHyV",
        "7_ny37AvMYht",
        "f7N9Drp8MaU_",
        "v9B0-W5pOH1j",
        "q5b2Y8K9go3V",
        "B0FfxBbbwDc_",
        "bOySjqTlor8_",
        "8IPAiZ28NJWe",
        "Ql9Z6ZU4N6yl",
        "aXHFSYKFo8Lk",
        "Ke4QbSguzrVQ",
        "-fuJkBd4yOg1",
        "7WGGOihv4kO6",
        "xA0pXc2eO8EQ",
        "YR05LFbobsrI",
        "7k4R8JsxwlZ_",
        "LNgeGnbhm91L",
        "MfDD1ch-Fm94",
        "vqpFJcC27fAX",
        "3fr1laSwL3_0",
        "OQisesrD4aTm",
        "qa-kd0Yp4eKI",
        "3SR7NUJt4vwu",
        "qPn5K0s4_de-",
        "Un7FkOhvAakA",
        "tRahASq3iF1r",
        "hePBaTYIVEVe",
        "TJWHwObPnF4h",
        "qV9zDahD-li_",
        "USxCwRx3_1pK",
        "71BYhuzC572k",
        "5jLrbXE_VdYz",
        "XhQ9Bdz6srjf",
        "VYVA-IStucoJ",
        "j1DyadwjGbxH",
        "mo90zO_QTANO",
        "MS95OLOyzWfc",
        "Uu2tISKaWYgS",
        "Ke7HSuNXXf01",
        "dlQLeAV2kmMd",
        "jjroy83AivLA",
        "GhDVtEXnAQXx",
        "ktuQa-nIDOqo",
        "2hATTShqPvAS",
        "HHymNPa47OYB",
        "I6buU0Nz5-Ik",
        "_WbQkWdCA0rW",
        "YntIti2fNbT1",
        "5K27Uu3jNoqI",
        "Vwd9ycMPnGaj",
        "e9kuqV7wnL0t",
        "ZmDhjARH8C1l",
        "tN0JHv-YFbJK",
        "fbty_KKPgF9o",
        "kRa8wC482caL",
        "56qtcwg5IAo2",
        "Adud22GGIRQb",
        "zYNetSMmIhcB",
        "-spr-G2USI37",
        "HYEN7gQIyVkn",
        "n0DbmdY474cs",
        "qhj2ieePzubb",
        "Y0fWrfCiRpNV",
        "toPWFrsBORvV",
        "8FMTtABgb7i6"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deltorobarba/machinelearning/blob/master/geometry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjNmcYpFuFTY"
      },
      "source": [
        "# **Differential Geometry**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYViK39mt7Nj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0168c965-db78-461b-ba19-50df85a9e604"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgLz8uc1s9dv"
      },
      "source": [
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/geometry_header.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gdr6F1zuU4MG"
      },
      "source": [
        "## **Variationsrechnung**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDN-b9pzHAJa"
      },
      "source": [
        "https://youtu.be/KpLno70oYHE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2JDEFznHDO0"
      },
      "source": [
        "https://youtu.be/VCHFCXgYdvY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwBNw0I30_GX"
      },
      "source": [
        "#### **Geometrie**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BanCpbeJFnk"
      },
      "source": [
        "http://www.joergresag.privat.t-online.de/mybk2htm/chap514.htm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McmF7fYT2r0T"
      },
      "source": [
        "In jeder Geometrie interessiert man sich für diejenigen **Transformationen, die bestimmte Eigenschaften nicht zerstören** (also ihre **Automorphismen**): Zum Beispiel ändern weder eine Parallelverschiebung noch eine Drehung oder Spiegelung in einer zweidimensionalen euklidischen Geometrie die Abstände von Punkten. Umgekehrt ist jede Transformation, die die Abstände von Punkten nicht ändert, eine Zusammensetzung von Parallelverschiebungen, Drehungen und Spiegelungen. Man sagt, dass diese Abbildungen die **Transformationsgruppe** bilden, die zu einer ebenen euklidischen Geometrie gehört, und dass der Abstand zweier Punkte eine euklidische **Invariante** darstellt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPQWDbEsAWLu"
      },
      "source": [
        "**Typen an Geometrien**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyjRNIMUEkBd"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Analytische_Geometrie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1THvVVC01Mll"
      },
      "source": [
        "* [Projektive Geometrie](https://de.wikipedia.org/wiki/Projektive_Geometrie) und [Affine Geometrie](https://de.wikipedia.org/wiki/Affine_Geometrie): Solche Geometrien bestehen meist aus Punkten und Geraden, und die Axiome betreffen Verbindungsgeraden von Punkten und die Schnittpunkte von Geraden. Affine und projektive Geometrien kommen meist in Paaren: Das Hinzufügen von Fernelementen macht eine affine Geometrie zu einer projektiven, und das Entfernen einer Geraden bzw. einer Ebene mit ihren Punkten macht aus einer zwei- bzw. dreidimensionalen projektiven Geometrie eine affine. In wichtigen Fällen können die Punkte auf einer Geraden in der affinen Geometrie so angeordnet werden, dass sich Halbgeraden und Strecken definieren lassen. In diesen Fällen nennt man die affine Geometrie und ihren projektiven Abschluss 'angeordnet'.\n",
        "\n",
        "  * [Projektiver_Raum](https://de.wikipedia.org/wiki/Projektiver_Raum)\n",
        "\n",
        "  * [Affiner_Raum](https://de.wikipedia.org/wiki/Affiner_Raum)\n",
        "\n",
        "* [Euklidische Geometrie](https://de.wikipedia.org/wiki/Euklidische_Geometrie): Darunter versteht man üblicherweise die aus den Axiomen und Postulaten Euklids abgeleitete Geometrie. Weil der seit Euklid überlieferte Aufbau der Theorie noch Lücken enthielt, hat David Hilbert in seinen Grundlagen der Geometrie (1899 und viele weitere Auflagen) ein Axiomensystem aufgestellt, aus dem er die euklidische Geometrie bis auf Isomorphie eindeutig aufbauen konnte. Danach kann diese eindeutig beschrieben werden als der dreidimensionale reelle Vektorraum, in dem die Punkte durch die Vektoren dargestellt werden und die Geraden durch die Nebenklassen der eindimensionalen Unterräume. Strecken, Senkrechtstehen, Winkel usw. werden wie in der seit Descartes üblichen analytischen Geometrie erklärt.\n",
        "\n",
        "  * [Euklidischer_Raum](https://de.wikipedia.org/wiki/Euklidischer_Raum)\n",
        "\n",
        "* [Nichteuklidische Geometrie](https://de.wikipedia.org/wiki/Nichteuklidische_Geometrie): Geometrien, deren Eigenschaften in vielem analog zur euklidischen Geometrie sind, in denen jedoch das Parallelenpostulat (auch Parallelenaxiom genannt) nicht gilt. Man unterscheidet elliptische und hyperbolische Geometrien.\n",
        "\n",
        "* [Absolute Geometrie](https://de.wikipedia.org/wiki/Absolute_Geometrie): ist der gemeinsame Unterbau der euklidischen und der nichteuklidischen Geometrien, d. h. die Menge aller Sätze, die ohne das Parallelenpostulat bewiesen werden.\n",
        "\n",
        "* [Synthetische Geometrie](https://de.wikipedia.org/wiki/Synthetische_Geometrie) führt den klassischen Ansatz der „reinen“ Geometrie fort, indem anstelle algebraischer Objekte (Koordinaten, Morphismen …) abstrakte geometrische Objekte (Punkte, Geraden) und deren Beziehungen (Schnitt, Parallelität, Orthogonalität …) zugrunde gelegt werden. Die Inzidenzstruktur gehört hier heute zu den allgemeinsten Ansätzen. Beispiele von nicht linearen Inzidenzstrukturen sind die Benz-Ebenen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZRNJ0B33HV8"
      },
      "source": [
        "**Grundlegende Sätze**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqXe2grs3Kdu"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Satz_des_Pythagoras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvqZh0FU3Mm6"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Kosinussatz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfcGUBLe3OvI"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Trigonometrischer_Pythagoras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_bf6Uds3b8S"
      },
      "source": [
        "Zusatzlich siehe auch [Zentralprojektion](https://de.wikipedia.org/wiki/Zentralprojektion) und [Zykloide](https://de.wikipedia.org/wiki/Zykloide)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDJq4saXMmeT"
      },
      "source": [
        "**Differentialgeometrie**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czHKt9s9Mlc0"
      },
      "source": [
        "Die [Differentialgeometrie](https://de.wikipedia.org/wiki/Differentialgeometrie) stellt die Synthese von Analysis und Geometrie dar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AR9PIXysIa4"
      },
      "source": [
        "#### **Gegenstand der Variationsrechnung**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_on0MZCUMWI"
      },
      "source": [
        "**Variation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9ULU9gH-F0N"
      },
      "source": [
        "![cc](https://upload.wikimedia.org/wikipedia/commons/1/10/Total_variation.gif)\n",
        "\n",
        "*As the green ball travels on the graph of the given function, the length of the path travelled by that ball's projection on the y-axis, shown as a red ball, is the total variation of the function.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkItUc9NUPLf"
      },
      "source": [
        "* the [total variation](https://en.wikipedia.org/wiki/Total_variation) identifies several slightly different concepts, related to the (local or global) structure of the codomain of a function or a measure. For a real-valued continuous function f, defined on an interval [a, b] ⊂ ℝ, its total variation on the interval of definition is a measure of the one-dimensional [arclength](https://en.wikipedia.org/wiki/Arc_length) of the curve with parametric equation x ↦ f(x), for x ∈ [a, b].\n",
        "\n",
        "* In der Variationsrechnung und der Theorie der stochastischen Prozesse ist die [Variation](https://de.wikipedia.org/wiki/Variation_(Mathematik)) (auch totale Variation genannt) einer Funktion **ein Maß für das lokale Schwingungsverhalten der Funktion**. \n",
        "\n",
        "* Bei den stochastischen Prozessen ist die Variation von besonderer Bedeutung, da sie die Klasse der zeitstetigen Prozesse in zwei fundamental verschiedene Unterklassen unterteilt: jene mit endlicher und solche mit unendlicher Variation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_X2Fv7rUuny"
      },
      "source": [
        "Die [erste Variation](https://de.wikipedia.org/wiki/Erste_Variation) ist eine verallgemeinerte Richtungsableitung eines Funktionals. Ihre Eigenschaften sind in der angewandten Mathematik und der theoretischen Physik relevant. Die erste Variation spielt eine zentrale Rolle in der Variationsrechnung und wird in der analytischen Mechanik genutzt. Ein verwandtes Konzept ist die Funktionalableitung."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRSLhtGHUz6-"
      },
      "source": [
        "In der Analysis ist eine Funktion von [beschränkter Variation](https://de.wikipedia.org/wiki/Beschränkte_Variation) (beschränkter Schwankung), wenn ihre totale Variation (totale Schwankung) endlich ist, sie also in gewisser Weise nicht beliebig stark oszilliert. Diese Begriffe hängen eng mit der Stetigkeit und der Integrierbarkeit von Funktionen zusammen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTt3OLla2IRt"
      },
      "source": [
        "**Variational Principle**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjqXlKua2Mj8"
      },
      "source": [
        "* a [variational principle](https://en.wikipedia.org/wiki/Variational_principle) is one that enables a problem to be solved using calculus of variations, which concerns finding such functions which optimize the values of quantities that depend upon those functions. \n",
        "\n",
        "* For example, the problem of determining the shape of a hanging chain suspended at both ends—a catenary—can be solved using variational calculus, and in this case, the variational principle is the following: The solution is a function that minimizes the gravitational potential energy of the chain.\n",
        "\n",
        "* Any physical law which can be expressed as a variational principle describes a **self-adjoint operator.** These expressions are also called Hermitian. Such an expression describes an invariant under a Hermitian transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBVibsq7UgT9"
      },
      "source": [
        "**Variationsrechnung**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXIblPI6_-oP"
      },
      "source": [
        "\n",
        "\n",
        "* **Find [stationary points](https://internal.ncl.ac.uk/ask/numeracy-maths-statistics/core-mathematics/calculus/stationary-points.html) (=derivative is zero, local minima or maxima) of a functional, like an integral I[f] (=here for example the path lenghts, or time spent travelling) is minimal between two points a and b.**\n",
        "\n",
        "  * A stationary point of a function $f(x)$ is a point where the derivative of $f(x)$ is equal to 0 . \n",
        "  * These points are called \"stationary\" because at these points the function is neither increasing nor decreasing. \n",
        "  * Graphically, this corresponds to points on the graph of $f(x)$ where the tangent to the curve is a horizontal line.\n",
        " * The stationary points of a function $y=f(x)$ are the solutions to $\n",
        "\\frac{d y}{d x}=0 $. This repeats in mathematical notation the definition given above: \"points where the gradient of the function is zero\".\n",
        "\n",
        "* **The integral is a functional (=function of functions), its stationary point is a fix point / minima of a functional (not function). Solve (usually differential) equations for stationary function f(x) (via calculus of variations)**\n",
        "\n",
        "* from regular calculus to calculus of variations: find stationary functions, not only stationary points, a function becomes a functional.\n",
        "\n",
        "* **Typical problem in variational calculus: find minimal path between points A and B, not necessarily a linear one (in physics for examples check Brachistochrone !)**. \n",
        "\n",
        "* Also consider that velocity depending on position changes the minimum paths or time to travel (later in vector analysis relevant for Kurvenintegral)\n",
        "\n",
        "In general, Calculus of variations seeks to find y = f(x) such that this integral:\n",
        "\n",
        "> $I[f]=\\int_{x_{1}}^{x_{2}} F\\left(x, y, \\frac{d y}{d x}\\right) d x$\n",
        "\n",
        "is stationary (ps: $\\frac{d y}{d x}$ = $y'$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWS6r7zeXBiF"
      },
      "source": [
        "https://www.youtube.com/watch?v=6HeQc7CSkZs&list=PLdgVBOaXkb9CD8igcUr9Fmn5WXLpE8ZE_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtfLe2I18pBF"
      },
      "source": [
        "https://www.youtube.com/playlist?list=PLdgVBOaXkb9CD8igcUr9Fmn5WXLpE8ZE_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-YucyzLNVXX"
      },
      "source": [
        "1. Die [Variationsrechnung](https://de.wikipedia.org/wiki/Variationsrechnung) ist eine **Erweiterung der Funktionalanalysis und beschaeftigt sich mit <u>nichtlinearen Funktionalen</u>** (in der Funktionalanalysis sind es linear Funktionale)\n",
        "\n",
        "2. The [calculus of variations](https://en.m.wikipedia.org/wiki/Calculus_of_variations) is a field that **uses variations, which are small changes in functions and functionals, to find maxima and minima of functionals**: mappings from a set of functions to the real numbers. Functionals are often expressed as definite integrals involving functions and their derivatives. <u>**Functions that maximize or minimize functionals may be found using the Euler–Lagrange equation of the calculus of variations.**</u>\n",
        "\n",
        "* In calculus of variations we are **NOT concerned with finding fix points of functions (like local maxima in a function), but rather fix points of functionals.**\n",
        "\n",
        "\n",
        "* dann führt eine Variation der Wirkung: https://de.m.wikipedia.org/wiki/Feldtheorie_(Physik)#Formalismus\n",
        "\n",
        "* Beispiel: https://de.wikipedia.org/wiki/Fluiddynamik\n",
        "\n",
        "* Martin: formulier problem in variationelle formulierung (dann bist du in sobolove räume), und dann Eigenschaften von Testfunktionen ausnutzen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sKOpLJ5il05"
      },
      "source": [
        "**Variation der Elemente**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWojWs7Px8DZ"
      },
      "source": [
        "* die [Variation der Elemente](https://de.wikipedia.org/wiki/Variation_der_Elemente) ist eine im 19. Jahrhundert entwickelte Methode zur genauen Bahnbestimmung von Himmelskörpern. Sie dient bis heute zur Modellierung von [Bahnstörungen](https://de.wikipedia.org/wiki/Bahnstörung)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eloiR80j3LKg"
      },
      "source": [
        "**Brachistochrone & Tautochronie**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Caqyohtk9JPX"
      },
      "source": [
        "https://www.youtube.com/watch?v=zYOAUG8PxyM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpbYH6ya6lV_"
      },
      "source": [
        "* Brachistochrone: Path between 2 points $A$ and $B$ which minimizes the time taken by a particle falling from $A$ to $B$ under the influence of gravity.\n",
        "\n",
        "* Time = distance / speed. Goal: Mix of minimize distance and maximize speed\n",
        "\n",
        "* Johann I Bernoulli hat sich mit dem **Problem des schnellsten Falles** beschäftigt. Im Jahre 1696 fand er schließlich die Lösung in der **Brachistochrone**. Heute sieht man dies oft als die **Geburtsstunde der Variationsrechnung**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWNCf_416SQR"
      },
      "source": [
        "[**Brachistochrone Curve**](https://en.wikipedia.org/wiki/Brachistochrone_curve) (in rot): Der Körper gleitet auf einer solchen Bahn schneller zum Ziel als auf jeder anderen Bahn, beispielsweise auf einer geradlinigen, obwohl diese kürzer ist.\n",
        "\n",
        "\n",
        "![vv](https://upload.wikimedia.org/wikipedia/commons/6/63/Brachistochrone.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMvO3MMS6JFg"
      },
      "source": [
        "**Tautochronie** der Brachistochrone – von jedem Startpunkt auf der Kurve erreichen die Kugeln das „Ziel“ gleichzeitig.\n",
        "\n",
        "![ff](https://upload.wikimedia.org/wikipedia/commons/b/bd/Tautochrone_curve.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnIIOyg7sUWT"
      },
      "source": [
        "**Gâteaux-Differential**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO6d-DQEsTA4"
      },
      "source": [
        "* [Gâteaux-Differential](https://de.wikipedia.org/wiki/Gâteaux-Differential) ist eine **Verallgemeinerung des gewöhnlichen Differentiationsbegriffes** dar, indem es die Richtungsableitung auch in unendlichdimensionalen Räumen definiert."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd2IsJ_CSCS6"
      },
      "source": [
        "#### **Principle of Stationary Action & Hamilton'sches Prinzip**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1_LTPqfTDH4"
      },
      "source": [
        "![ff](https://raw.githubusercontent.com/deltorobarba/repo/master/lagrange_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5BT3mKBTKRs"
      },
      "source": [
        "![ff](https://raw.githubusercontent.com/deltorobarba/repo/master/lagrange_02.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RWhECg9U_Oh"
      },
      "source": [
        "* Total energy = kinetic energy - potential energy.\n",
        "\n",
        "* Kinetic - potential energy = Lagrangian $L$\n",
        "\n",
        "* Kinetic energy depends on velocity of a particle (detonated with a dot over x,y,z), potential energy depends on position of a particle x,y,z. Hence the Lagrangian of a particle depends on all of the positions and all of their time derivatives. \n",
        "\n",
        "* **Use and solve the three Lagrangian equations in order to determine the equation of motion of a particle (and Lagrange equations are equivalent to Newton's second law)**\n",
        "\n",
        "* And they can easily applied to other coordinate systems than cartesian (i.e cylindric, or spherical)\n",
        "\n",
        "* Also: **Lagrange equations are very similar to Euler-Lagrange Equations!**\n",
        "\n",
        "* Because the three Lagrange equations very strongly resemble the Euler-Lagrange-equation, there must be some functional that's being made stationary by Lagrange equations\n",
        "\n",
        "* **$S$ is the action integral (= a functional!)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-nJvdQFOk7w"
      },
      "source": [
        "[The Principle of Stationary Action](https://www.youtube.com/watch?v=M05ixbSOY80): If a particle/system $P$ travels from one point to another in the time interval $\\left[t_{1}, t_{2}\\right]$, the path the particle traverses is such that this function:\n",
        "\n",
        "> $\n",
        "S=\\int_{t_{1}}^{t_{2}} \\mathcal{L} \\text { dt}$\n",
        "\n",
        "is stationary. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-B68-upYzGV"
      },
      "source": [
        "$L$ is the Lagrangian of the particle: $L=E_{u}-U$. \n",
        "\n",
        "Need to solve Lagrange equations to make $S$ stationary:\n",
        "\n",
        "$\\frac{\\partial L}{\\partial q_{1}}=\\frac{d}{d t}\\left(\\frac{\\partial L}{\\partial \\dot{q}_{1}}\\right), \\frac{\\partial L}{\\partial q_{2}}=\\frac{d}{d t}\\left(\\frac{\\partial L}{\\partial \\dot{q}_{2}}\\right), \\frac{\\partial L}{\\partial q_{3}}=\\frac{d}{d t}\\left(\\frac{\\partial L}{\\partial \\dot{q}_{3}}\\right) \\quad \\begin{array}{c}\\\\ \\end{array}$\n",
        "\n",
        "We can use a general coordinate system:\n",
        "$\\\\ {\\left[q_{1}(t), q_{2}(t), q_{3}(t)\\right]}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUccaxMqCONs"
      },
      "source": [
        "**Hamilton'sches Prinzip (Wirkungsfunktional)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YUSTnxUCj_B"
      },
      "source": [
        "> Das [Hamilton'sche Prinzip](https://de.wikipedia.org/wiki/Hamiltonsches_Prinzip) zeichnet tatsachlich durchlaufene Bahnen dadurch aus, **dass bei ihnen die Wirkung (=Funktional) S[q] (verglichen mit anderen Bahnen) ein Minimum annimmt (minimal variation ??)**.\n",
        "\n",
        "* Das Hamiltonsche Prinzip der Theoretischen Mechanik ist ein **Extremalprinzip**. Physikalische Felder und Teilchen nehmen danach für eine bestimmte Größe einen extremalen (d. h. größten oder kleinsten) Wert an. Diese Bewertung nennt man Wirkung, mathematisch ist die Wirkung ein Funktional, daher auch die Bezeichnung **Wirkungsfunktional**.\n",
        "\n",
        "* Die Wirkung erweist sich in vielen Fällen nicht als minimal, sondern nur als **„stationär“** (d. h. extremal). Deshalb wird das Prinzip von manchen Lehrbuchautoren auch das Prinzip der **stationären Wirkung** genannt. Manche Autoren nennen das Hamiltonsche Prinzip auch **'Prinzip der kleinsten Wirkung'**, was jedoch – wie oben ausgeführt – nicht präzise ist.\n",
        "\n",
        "* Hamilton's principle states that the true evolution of a physical system is a solution of the functional equation:\n",
        "\n",
        "> $\\frac{\\delta \\mathcal{S}}{\\delta \\mathbf{q}(t)}=0$\n",
        "\n",
        "* That is, the system takes a path in configuration space for which the action is stationary, with fixed boundary conditions at the beginning and the end of the path."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcfFakZPDSlA"
      },
      "source": [
        "![ff](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Least_action_principle.svg/500px-Least_action_principle.svg.png)\n",
        "\n",
        "*As the system evolves, q traces a path through configuration space (only some are shown). The path taken by the system (red) has a stationary action (δS = 0) under small changes in the configuration of the system (δq).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rTSTqyoGEgM"
      },
      "source": [
        "Richard Feynman zeigte in den 1940ern, dass sich das Hamiltonsche Prinzip in der Quantenfeldtheorie gerade dadurch ergibt, dass alle möglichen Pfade (auch die nicht zielgerichteten) zulässig sind und aufintegriert werden. Dabei überlagern sich Pfade mit extremaler Wirkung konstruktiv und davon abweichende destruktiv, so dass die Natur schließlich zielgerichtet erscheint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcxaUB6UFfh8"
      },
      "source": [
        "#### **Langrange Formalismus (Lagrange Equation)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juoWoVAzFb7x"
      },
      "source": [
        "Eingeführte Formulierung der klassischen Mechanik, in der die Dynamik eines Systems durch **eine einzige skalare Funktion, die Lagrange-Funktion**, beschrieben wird. Der Formalismus ist (im Gegensatz zu der newtonschen Mechanik, die a priori nur in Inertialsystemen gilt) auch in beschleunigten Bezugssystemen gültig. Der Lagrange-Formalismus ist invariant gegen Koordinatentransformationen.\n",
        "\n",
        "Der [Langrange Formalismus](https://de.wikipedia.org/wiki/Lagrange-Formalismus) ist eine mögliche (von vielen!) Formulierung der klassischen Mechanik. Hier wird die Dynamik eines Systems durch die Langrange-Funktion L(${\\boldsymbol{q}}$, $\\dot{\\boldsymbol{q}}$, $t$) beschrieben:\n",
        "\n",
        "* ${\\boldsymbol{q}}$ = (q1, q2, ..., qw) - allgemeine Koordinaten im Raum\n",
        "* $\\dot{\\boldsymbol{q}}$ = (d / dt) q ... ($\\dot{\\boldsymbol{q}}$1, $\\dot{\\boldsymbol{q}}$2.. $\\dot{\\boldsymbol{q}}$n) - Vektor der Wirkung (allgemeine Geschwindigkeiten)\n",
        "* $t$ - Zeit (Die explizite Zeitabhängige berücksichtigt externe, zeitabhängige Faktoren (z.B. Magnet-Felder etc). Wird auf Null gesetzt, denn bei einem Wechsel in die mikroskopische Theorie verschwindet die Zeit)\n",
        "\n",
        "> $L_{x}(q, \\dot{q}, t)$ wird zu: $L_{x}(q, \\dot{q})$ = $T$<sub>kin</sub> - $V$<sub>pot</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh3-XC92HP_o"
      },
      "source": [
        "https://www.youtube.com/watch?v=V8CR4GVg5Io&t=301s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj_FQa3ZHR25"
      },
      "source": [
        "https://www.youtube.com/watch?v=EceVJJGAFFI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6yxA1-8Glkp"
      },
      "source": [
        "**Fluiddynamik**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJNcqO0LGdAR"
      },
      "source": [
        "Im Allgemeinen wird die Bewegung eines Fluids durch die Navier-Stokes-Gleichungen beschrieben. Im Falle kleiner Viskosität und damit hoher Reynolds-Zahl können Reibungseffekte vernachlässigt werden und als Bewegungsgleichung des Fluids gilt in guter Näherung die Euler-Gleichung:\n",
        "\n",
        "> formel hier\n",
        "\n",
        "Diese setzt die Geschwindigkeitsänderung des Fluids an einem Ort mit dem in der Umgebung herrschenden Druck \n",
        "p\n",
        "p in Verbindung. Häufig wird die Euler-Gleichung für die Berechnung bewegter Gase verwendet, während bei der Berechnung bewegter Flüssigkeiten meist die Navier-Stokes-Gleichungen verwendet werden.\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Fluiddynamik"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYzlWwuA8hXl"
      },
      "source": [
        "#### **Euler–Lagrange Equation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSDm60df1uY6"
      },
      "source": [
        "The Euler–Lagrange equation is an equation satisfied by a function q of a real argument t, which is a stationary point of the functional:\n",
        "\n",
        "> $S(\\boldsymbol{q})=\\int_{a}^{b} L(t, \\boldsymbol{q}(t), \\dot{\\boldsymbol{q}}(t)) \\mathrm{d} t$\n",
        "\n",
        "* ${\\boldsymbol{q}}$ - Koordinaten im Raum\n",
        "* $\\dot{\\boldsymbol{q}}$ - Vektor der Wirkung\n",
        "* t - Zeit (wird auf Null gesetzt, den bei einem Wechsel in die mikroskopische Theorie verschwindet die Zeit)\n",
        "\n",
        "The Euler–Lagrange equation, then, is given by\n",
        "\n",
        "> $L_{x}(t, q(t), \\dot{q}(t))-\\frac{\\mathrm{d}}{\\mathrm{d} t} L_{v}(t, q(t), \\dot{q}(t))=0$\n",
        "\n",
        "* partial derivative of one dimension, then second dimension and then time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YgD5e1WCrQG"
      },
      "source": [
        "Youtube: [Derivation of the Euler-Lagrange Equation](https://www.youtube.com/watch?v=sFqp2lCEvwM&list=PLdgVBOaXkb9CD8igcUr9Fmn5WXLpE8ZE_&index=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2qfbPen7OHY"
      },
      "source": [
        "https://www.youtube.com/watch?v=V0wx0JBEgZc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8e1OmDf8qdS"
      },
      "source": [
        "* the [Euler equation](https://en.m.wikipedia.org/wiki/Euler–Lagrange_equation) is a **second-order partial differential** equation whose **solutions are the functions for which a given functional is stationary**.\n",
        "\n",
        "* Because **a differentiable functional is stationary at its local extrema**, the Euler–Lagrange equation is useful for solving optimization problems in which, given some functional, one seeks the function minimizing or maximizing it. \n",
        "\n",
        "* This is analogous to [Fermat's theorem](https://en.m.wikipedia.org/wiki/Fermat%27s_theorem_(stationary_points)) in calculus, stating that at any point where a differentiable function attains a local extremum its derivative is zero.\n",
        "\n",
        "* In Lagrangian mechanics, according to [Hamilton's principle](https://en.m.wikipedia.org/wiki/Hamilton%27s_principle) of stationary action, the evolution of a physical system is described by the solutions to the Euler equation for the action of the system. In this context Euler equations are usually called Lagrange equations. In classical mechanics, it is equivalent to Newton's laws of motion, but it has the advantage that it takes the same form in any system of generalized coordinates, and it is better suited to generalizations.\n",
        "\n",
        "  * Hamilton's principle is William Rowan Hamilton's formulation of the [principle of stationary action](https://en.m.wikipedia.org/wiki/Principle_of_least_action) (also called: 'Principle of least action'). It states that the **dynamics of a physical system are determined by a variational problem for a functional based on a single function**, the Lagrangian, which may contain all physical information concerning the system and the forces acting on it. The variational problem is equivalent to and allows for the derivation of the differential equations of motion of the physical system\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hvq9Ze9vgJ-T"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Variationsrechnung#Euler-Lagrange-Gleichung;_Variationsableitung;_weitere_notwendige_bzw._hinreichende_Bedingungen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttEWWgIVr9Sl"
      },
      "source": [
        "#### **Fundamentallemma & -satz**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3b7M8Nygvq7"
      },
      "source": [
        "**Fundamentallemma der Variationsrechnung**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FRcJghJgyjL"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Fundamentallemma_der_Variationsrechnung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULsopNsIg5dZ"
      },
      "source": [
        "**Fundamentalsatz der Variationsrechnung**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwkRUt1ihCd_"
      },
      "source": [
        "* Fundamental Theorem of the Calculus of Variations - [Fundamentalsatz der Variationsrechnung](https://de.wikipedia.org/wiki/Fundamentalsatz_der_Variationsrechnung)\n",
        "\n",
        "* eng verwandt mit dem [weierstraßschen Satz vom Minimum](https://de.wikipedia.org/wiki/Satz_vom_Minimum_und_Maximum)\n",
        "\n",
        "* Er behandelt die in der Variationsrechnung zentrale Frage, unter welchen Bedingungen reellwertige Funktionale ein Minimum annehmen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyduGf4kNe-b"
      },
      "source": [
        "## **Vektoranalysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH8b8Mbvy_Fe"
      },
      "source": [
        "#### **Grundbegriffe**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxw_I_chlfSU"
      },
      "source": [
        "https://youtube.com/playlist?list=PLBh2i93oe2quqhn4TZjMnBM2v7lG5QhDD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r66BzwvTX8Ue"
      },
      "source": [
        "* Die [Vektoranalysis](https://de.m.wikipedia.org/wiki/Vektoranalysis) ist ein **Teilgebiet der Tensoranalysis**, beschäftigt sich hauptsächlich mit **Vektorfeldern in zwei oder mehr Dimensionen** \n",
        "\n",
        "* Die Vektoranalysis **verallgemeinert die Differential- und der Integralrechnung** (z.B. werden Verzerrungen auf Oberflachen bei der Integration berucksichtigt, oder Stroemungen bei Wegen)\n",
        "\n",
        "* Betrachtet werden **Vektorfelder**, die jedem Punkt des Raumes einen Vektor zuordnen, und **Skalarfelder**, die jedem Punkt des Raumes einen Skalar zuordnen.\n",
        "\n",
        "*  Die Temperatur eines Swimmingpools ist ein Skalarfeld: Jedem Punkt wird der Skalarwert seiner Temperatur zugeordnet. Die Wasserbewegung entspricht dagegen einem Vektorfeld, da jedem Punkt ein Geschwindigkeitsvektor zugeordnet wird, der Betrag und Richtung hat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwHPxe488bdG"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Polarkoordinaten#Vektoranalysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib8wN8Qsy42W"
      },
      "source": [
        "* **Kurven** in $\\mathbb{R}^{2}$ oder $\\mathbb{R}^{3}$: Wege bzw. **parametrisierte** Kurven in $\\mathbb{R}^{n}$ sind **stetige** Abbildungen $\\gamma$ [a, b] -> $\\mathbb{R}^{n}$\n",
        "\n",
        "* **Reguläre Wege** bzw. Kurven: **stetig + differenzierbar** und Norm der Ableitung ist die Summe der Komponenten: $\\|\\dot{\\gamma}(t)\\|^{2}=\\left|\\dot{\\gamma}_{1}(t)\\right|^{2}+\\left|\\dot{\\gamma}_{2}(t)\\right|^{2}+\\left|\\dot{\\gamma}_{3}(t)\\right|^{2} \\neq 0$ fur alle t $\\in$ [a,b]. Bedeutet auch: es gibt uberall einen Tangentialvektor.\n",
        "\n",
        "* **Bogenlänge** (Länge der Kurve / [Arc Length](https://en.wikipedia.org/wiki/Arc_length)): Integration der Geschwindigkeitsvektoren in der Norm: $L[\\gamma]=\\int_{a}^{b}\\|\\dot{\\gamma}(t)\\| d t$\n",
        "\n",
        "* **Tangentialvektor**: Ableitung / Geschwindigkeitsvektor an einem Punkt, der in eine Richtung zeigt, der tangential zur Kurve zeigt. Den Vektor normiert man (dividiert durch Norm): $T_{\\gamma}(t):=\\frac{\\dot{\\gamma}(t)}{\\|\\dot{\\gamma}(t)\\|}$\n",
        "\n",
        "* **Normalenvektor**: nur definiert in einer Ebene, also in R2. Sollte senkrecht auf der Kurve / senkrecht auf dem Tangentialvektor stehen (man muss also diesen Punkt $\\dot{\\gamma}(t)=\\left(\\begin{array}{l}\\dot{\\gamma}_{1}(t) \\\\ \\dot{\\gamma}_{2}(t)\\end{array}\\right)$ um 90 Grad drehen, damit er senkrech steht): $N_{\\gamma}(t):=\\frac{1}{\\|\\dot{\\gamma}(t)\\|}\\left(\\begin{array}{c}-\\dot{\\gamma}_{2}(t) \\\\ \\dot{\\gamma}_{2}(t)\\end{array}\\right)$. \n",
        "\n",
        "* **Die Norm im Normalenvektor (Jacobi-Determinante) gibt zB die Kruemmung / Verzerrung einer Flaeche an, die bei der Integration beruecksichtigt werden muss.**\n",
        "\n",
        "* Eine [**vektorielle Größe**](https://de.wikipedia.org/wiki/Vektorielle_Größe) oder gerichtete Größe ist eine physikalische Größe, die – im Gegensatz zu den skalaren Größen – einen Richtungscharakter hat. \n",
        "  * Typische vektorielle Größen sind die kinematischen Größen Geschwindigkeit und Beschleunigung, die dynamischen Größen Impuls und Kraft bzw. Drehimpuls und Drehmoment sowie die Feldstärken der elektrischen und magnetischen Felder der Elektrodynamik. \n",
        "  * Vektorielle Größen werden sowohl zeichnerisch als auch rechnerisch wie geometrische Vektoren behandelt, wobei einige Besonderheiten zu beachten sind."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_ZoCkWyJeNH"
      },
      "source": [
        "**Beispielaufgabe in der Vektoranalysis**\n",
        "\n",
        "* Betrachten Sie die folgende parametrisierte Kurve: $\n",
        "\\gamma:[0, \\infty) \\rightarrow \\mathbb{R}^{2}, \\quad \\gamma(t)=\\left(\\begin{array}{c}\n",
        "t \\cos (t) \\\\\n",
        "t \\sin (t)\n",
        "\\end{array}\\right)\n",
        "$\n",
        "\n",
        "  * (a) Skizzieren Sie die Kurve, d. h. das Bild der Abbildung.\n",
        "\n",
        "  * (b) Handelt es sich um einen regulären Weg?\n",
        "\n",
        "  * (c) Geben Sie Tangenteneinheitsvektor und Normaleneinheitsvektor für jeden Punkt an."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFD0yRkvYGE2"
      },
      "source": [
        "#### **Felder (Skalar, Vektor, Gradient)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Aolz28MRggQ"
      },
      "source": [
        "**Skalarfeld**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbKijNH7RjtR"
      },
      "source": [
        "* In der mehrdimensionalen Analysis, der Vektorrechnung und der Differentialgeometrie ist ein [skalares Feld (kurz Skalarfeld)](https://de.wikipedia.org/wiki/Skalarfeld) $\\varphi$ **eine Funktion, die jedem Punkt eines Raumes eine reelle Zahl (Skalar) zuordnet**, z. B. eine Temperatur, Luftdruck.\n",
        "\n",
        "* Wichtige Operationen im Zusammenhang mit Skalarfeldern sind: \n",
        "\n",
        "  * **[Gradient](https://de.wikipedia.org/wiki/Gradient_(Mathematik)) eines Skalarfeldes, der ein Vektorfeld ist**.\n",
        "\n",
        "  * [Richtungsableitung](https://de.wikipedia.org/wiki/Richtungsableitung) eines Skalarfeldes: die Richtungsableitung einer von mehreren Variablen abhängigen Funktion ist die **momentane Änderungsrate dieser Funktion in einer durch einen Vektor vorgegebenen Richtung**. (Eine Verallgemeinerung der Richtungsableitung auf unendlichdimensionale Räume ist das [Gâteaux-Differential](https://de.m.wikipedia.org/wiki/G%C3%A2teaux-Differential).)\n",
        "  * Ein Skalarfeld ist das einfachste [Tensorfeld](https://de.m.wikipedia.org/wiki/Tensorfeld).\n",
        "\n",
        "* Skalarfelder sind von großer Bedeutung in der Feldbeschreibung der Physik und in der mehrdimensionalen Vektoranalysis.\n",
        "\n",
        "* Man unterscheidet dabei zwischen **reellwertigen** Skalarfeldern $\\varphi\\colon M\\to \\mathbb {R}$ und **komplexwertigen** Skalarfeldern $\\displaystyle \\varphi \\colon M\\to \\mathbb {C} $.\n",
        "\n",
        "* Man spricht von einem **stationären Skalarfeld**, wenn die Funktionswerte nur vom Ort abhängen. Hängen sie auch von der Zeit ab, handelt es sich um ein **instationäres Skalarfeld**.\n",
        "\n",
        "* Beispiele für Skalarfelder in der Physik sind der Luftdruck, die Temperatur, Dichte oder allgemein **Potentiale (= Skalarpotentiale)**.\n",
        "\n",
        "* Im Gegensatz zum Skalarfeld ordnet ein Vektorfeld jedem Punkt einen Vektor zu. Ein Skalarfeld ist das einfachste Tensorfeld"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLeX-skuQC_8"
      },
      "source": [
        "**Vektorfeld**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3O9MS9VNgPz"
      },
      "source": [
        "**Der Gradient eines Skalarfeldes ist ein Vektorfeld (zB: Skalar ist die Temperatur in einem Pool, und Temperaturveranderung uber Zeit ist die erste Ableitung dessen und dann ein Vektorfeld), und die zweite Ableitung ist die Beschleunigung der Temperaturveranderung.**\n",
        "\n",
        "* In der mehrdimensionalen Analysis und der Differentialgeometrie ist ein [Vektorfeld](https://de.m.wikipedia.org/wiki/Vektorfeld) eine Funktion, die jedem Punkt eines Raumes einen Vektor zuordnet.\n",
        "\n",
        "* Eine Abbildung $V: D \\rightarrow \\mathbb{R}^{n}, D \\subseteq \\mathbb{R}^{n}$ mit n = 1,2,3..\n",
        "\n",
        "* Die Temperatur eines Swimmingpools ist ein Skalarfeld: Jedem Punkt wird der Skalarwert seiner Temperatur zugeordnet. Die Wasserbewegung entspricht dagegen einem Vektorfeld, da jedem Punkt ein Geschwindigkeitsvektor zugeordnet wird, der Betrag und Richtung hat.\n",
        "\n",
        "* Meist sind Vektorfelder stetig differenzierbar = Komponenten sind stetig differenzierbar, zB Vektor $v1$ mit (x,y,z) und ihren drei Ableitungen als Komponente des Vektorfeldes $V$\n",
        "\n",
        "* Das duale Konzept zu einem Vektorfeld ist eine Funktion, die jedem Punkt eine [Linearform](https://de.m.wikipedia.org/wiki/Linearform), [zB [stetige lineare Funktionale](https://de.m.wikipedia.org/wiki/Funktional#Stetige_lineare_Funktionale)] zuordnet, eine solche Abbildung wird [pfaffsche Form](https://de.m.wikipedia.org/wiki/Pfaffsche_Form) (One-Form) genannt. (Pfaffsche Formen sind die natürlichen Integranden für Wegintegrale.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HITrObGEbo2I"
      },
      "source": [
        "*Beispiele von Vektorfeldern*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilI3SG0Pb4xw"
      },
      "source": [
        "**Gradientenfeld**: Ist $f: \\Omega \\rightarrow \\mathbb{R}$ eine differenzierbare Funktion auf einer offenen Menge $\\Omega \\subset \\mathbb{R}^{n},$ so wird das Gradientenfeld grad $f: \\Omega \\rightarrow \\mathbb{R}^{n}$ von $f$ definiert durch die Zuordnung\n",
        "\n",
        ">$\n",
        "x \\mapsto \\operatorname{grad} f(x)=\\left(\\frac{\\partial f}{\\partial x_{1}}(x), \\ldots, \\frac{\\partial f}{\\partial x_{n}}(x)\\right)\n",
        "$\n",
        "\n",
        "Oft schreibt man es mit dem Nabla-Symbol: grad $f=\\nabla f$. **Ist ein Vektorfeld $v$ das Gradientenfeld einer Funktion $f$ (=Skalarfeld ist abgeleitet nach Ort), das heißt $v=\\nabla f,$ so bezeichnet man $f$ als Potential**. Man sagt auch $v$ besitzt ein Potential. Beispiele von Gradientenfeldern sind das von einer Punktquelle nach allen Seiten\n",
        "gleichmäßig fließende Feld einer Strömung und das elektrische Feld um eine Punktladung."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1djFC2M4cKnO"
      },
      "source": [
        "**Zentralfelder**: Sei $I$ ein Intervall, welches die Null enthält, und $K(I)=\\left\\{x \\in \\mathbb{R}^{n}:\\|x\\| \\in I\\right\\} \\subset \\mathbb{R}^{n}$ eine Kugelschale. Zentralfelder auf der Kugelschale sind definiert durch $v(x)=a(\\|x\\|) \\cdot x$ mit $a: I \\rightarrow \\mathbb{R}$. In $\\mathbb{R}^{3} \\backslash\\{0\\}$ ist das **Gravitationsfeld** $v(x)=-\\frac{x}{\\|x\\|^{3}}$ ein solches Zentralfeld.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWyWoFmfcM22"
      },
      "source": [
        "Weitere Beispiele sind im $\\mathbb{R}^{3}$ die mathematisch diffizileren sogenannten **\"Wirbelfelder\"**. Sie lassen sich als Rotation eines Vektorpotentials A beschreiben, nach der Formel $\\mathbf{v}(\\mathbf{r})=\\operatorname{rot} \\mathbf{A}(\\mathbf{s} . \\mathbf{u}) .$\n",
        "Prägnantes Beispiel eines Wirbelfeldes ist das in Kreislinien um den\n",
        "Ausfluss einer , Badewanne\" herumwirbelnde Strömungsfeld, oder das Magnetfeld um einen stromdurchflossenen Draht."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56sZZ-KLKsX_"
      },
      "source": [
        "*Konservatives bzw. wirbelfreies Vektorfeld*\n",
        "\n",
        "* In Physik sind conservative forces jene, wo es keine Friktion, Air resistance etc. gibt\n",
        "\n",
        "* Vektorfelder, die Gradienten eines Skalarfelds sind, werden in Anlehnung an den Begriff des „konservativen Kraftfelds“ oft auch als konservative Vektorfelder bezeichnet (siehe Eigenschaften unten unter Gradientenfeld)\n",
        "\n",
        "* Als [wirbelfrei bzw. konservativ](https://de.wikipedia.org/wiki/Wirbelfreies_Vektorfeld) wird in der Physik und Potentialtheorie ein Vektorfeld $\\vec{X}(\\vec{r})$ bezeichnet, in dem das **Kurvenintegral** $\n",
        "\\oint_{S} \\vec{X}(\\vec{r}) \\cdot \\mathrm{d} \\vec{s}=0$ für beliebige in sich geschlossene Randkurven $S$ stets den Wert null liefert. \n",
        "\n",
        "* Deutet man $\\vec{X}(\\vec{r})$ als Kraftfeld, so ist das Kurvenintegral die gesamte längs der Randkurve $S$ gegen die Kraft $\\vec{X}(\\vec{r})$ verrichtete Arbeit.\n",
        "\n",
        "* Wirbelfrei sind z. B. das ruhende elektrische Feld in der Elektrostatik und das Gravitationsfeld, aber auch Felder wie das Geschwindigkeitsfeld einer Potentialströmung.\n",
        "\n",
        "> Ist $\\vec{X}(\\vec{r})$ wirbelfrei, dann gilt: $\\operatorname{rot} \\vec{X}(\\vec{r})=\\overrightarrow{0}$\n",
        "d. h. die Rotation des Vektorfeldes ist gleich null. \n",
        "\n",
        "* Ist der Definitionsbereich einfach **zusammenhängend, so gilt auch die Umkehrung**.\n",
        "\n",
        "> Wirbelfreie Vektorfelder lassen sich stets als **Gradient eines zugrundeliegenden skalaren Felds** $\\Phi(\\vec{r})$ formulieren (siehe Gradientenfeld): $\n",
        "\\vec{X}(\\vec{r})=\\operatorname{grad} \\Phi(\\vec{r})=\\vec{\\nabla} \\Phi(\\vec{r})\n",
        "$\n",
        "\n",
        "* Daraus folgt, dass für das skalare Feld $\\Phi$ gilt: \n",
        "$\\operatorname{rot}(\\operatorname{grad} \\Phi(\\vec{r}))=\\overrightarrow{0}$ (**siehe auch unten auch Gradientfeld & Skalarpotenzial**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLH2-gTPd43O"
      },
      "source": [
        "*Quellenfreie und wirbelfreie Vektorfelder; Zerlegungssatz*\n",
        "\n",
        "Ein mindestens **zweimal stetig differenzierbares Vektorfeld** $\\mathbf{v}(\\mathbf{r})$ im $\\mathbb{R}^{3}$ heißt quellenfrei (beziehungsweise wirbelfrel), wenn seine **Quellendichte (Divergenz) beziehungsweise Wirbeldichte (Rotation) dort überall Null ist**. Unter der weiteren\n",
        "Voraussetzung, dass die Komponenten von $\\mathbf{v}$ im Unendlichen hinreichend rasch verschwinden, gilt der sogenannte Zerlegungssatz: Jedes Vektorfeld $\\mathbf{v}(\\mathbf{r})$ ist\n",
        "eindeutig durch seine Quellen bzw. Wirbel bestimmt, und zwar gilt die folgende\n",
        "Zerlegung in einen wirbelfreien beziehungsweise quellenfreien Anteil:\n",
        "\n",
        "> $\n",
        "\\mathbf{v}(\\mathbf{r}) \\equiv-\\operatorname{grad}_{\\mathbf{r}} \\int_{\\mathbb{R}^{3}} d^{3} \\mathbf{r}^{\\prime} \\frac{\\operatorname{div}^{\\prime} \\mathbf{v}\\left(\\mathbf{r}^{\\prime}\\right)}{4 \\pi\\left|\\mathbf{r}-\\mathbf{r}^{\\prime}\\right|}+\\operatorname{rot}_{\\mathbf{r}} \\int_{\\mathbb{R}^{3}} d^{3} \\mathbf{r}^{\\prime} \\frac{\\operatorname{rot}^{\\prime} \\mathbf{v}\\left(\\mathbf{r}^{\\prime}\\right)}{4 \\pi\\left|\\mathbf{r}-\\mathbf{r}^{\\prime}\\right|}\n",
        "$\n",
        "\n",
        "Dies entspricht der Zerlegung eines statischen elektromagnetischen Feldes in den elektrischen beziehungsweise magnetischen Anteil (siehe Elektrodynamik). Es sind also genau die Gradientenfelder (d. h. die , elektrischen Feldkomponenten\") wirbelfrei bzw. genau die Wirbelfelder (d. h. die ,magnetischen Feldkomponenten\") quellenfrei. Dabei sind grad $\\phi(\\mathbf{r}):=\\nabla \\phi,$ div $\\mathbf{v}:=\\nabla \\cdot \\mathbf{v}$ und rot $\\mathbf{v}:=\\nabla \\times \\mathbf{v}$ die bekannten, mit dem Nabla-Operator $(\\nabla)$ der Vektoranalysis\n",
        "gebildeten Operationen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T3n7jhWXtHv"
      },
      "source": [
        "**Gradientenfeld**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6-0Gw75XzxE"
      },
      "source": [
        "* Ein [Gradientenfeld](https://de.wikipedia.org/wiki/Gradientenfeld) **ist ein Vektorfeld, das aus einem Skalarfeld durch Differentiation nach dem Ort abgeleitet wurde**, bzw. – kürzer formuliert – der Gradient des Skalarfelds (= **ein Skalarfeld, das nach dem Ort abgeleitet wird, ist ein Gradientenfeld**, mit Skalarpotenzial inkl. angegeben).\n",
        "\n",
        "* Zur besseren Abgrenzung zwischen dem Gradienten als mathematischem Operator und dem Resultat seiner Anwendung bezeichnen manche Autoren die Vektoren, aus denen sich Gradientenfelder zusammensetzen, auch als Gradientvektoren, andere dagegen mit Blick auf die Potentiale, aus denen sie sich herleiten, als Potentialvektoren.\n",
        "\n",
        "* Analog verwendet die überwiegende Zahl der Autoren den Begriff Potentialfeld nicht für das skalare Feld des Potentials selbst, sondern das sich aus ihm ableitende Gradientenfeld\n",
        "\n",
        "> Ein Vektorfeld $\\vec{F}: \\vec{r} \\mapsto \\vec{F}(\\vec{r})$ heißt Gradientenfeld, wenn es ein Skalarfeld $\\Phi: \\vec{r} \\mapsto \\Phi(\\vec{r})$ gibt, so dass\n",
        "$\n",
        "\\vec{F}(\\vec{r})=\\vec{\\nabla} \\Phi(\\vec{r})\n",
        "$\n",
        "\n",
        "*  Dabei nennt man $\\Phi$  das zu $F$ gehörige **Skalarpotential** oder einfach kurz das „Potential“ des Gradientenfelds \n",
        "${\\vec {F}}$. (*Der Begriff darf jedoch nicht mit dem physikalischen Begriff des „Potentials“ verwechselt werden, mit dem die Fähigkeit eines konservativen Kraftfelds bezeichnet wird, einen dem Feld ausgesetzten Körper eine Arbeit verrichten zu lassen.*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a1CyVnAX8Xu"
      },
      "source": [
        "**Vektorfelder, die Gradienten eines Skalarfelds sind**, werden in Anlehnung an den Begriff des „konservativen Kraftfelds“ oft auch als **konservative Vektorfelder** bezeichnet - ihnen allen gemeinsam sind dabei die folgenden drei einander äquivalenten Eigenschaften:\n",
        "\n",
        "1. **Wegunabhängigkeit des Kurvenintegrals**: Der Wert des Kurvenintegrals entlang einer beliebigen Kurve $S$ innerhalb des Feldes ist nur von ihrem Anfangs- und Endpunkt abhängig, nicht dagegen von ihrer Länge.\n",
        "\n",
        "2. **Verschwinden des Ringintegrals für beliebige Randkurven** $S$ :\n",
        "$\n",
        "\\oint_{S} \\operatorname{grad} \\Phi(\\vec{r}) \\mathrm{d} \\vec{r}=\\oint_{S} \\vec{F}(\\vec{r}) \\mathrm{d} \\vec{r}=0\n",
        "$\n",
        "\n",
        "3. **Generelle Rotationsfreiheit bzw. Wirbelfreiheit** des Feldes:\n",
        "$\\operatorname{rot}(\\operatorname{grad} \\Phi(\\vec{r}))=\\operatorname{rot} \\vec{F}(\\vec{r})=\\vec{\\nabla} \\times \\vec{F}(\\vec{r})=\\overrightarrow{0}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTlqgkPgcyej"
      },
      "source": [
        "#### **Potentiale (Skalar, Vektor)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUy8UbeIYqx1"
      },
      "source": [
        "**Skalarpotential**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NleEXk9Z_pB"
      },
      "source": [
        "Das [Skalarpotential](https://de.wikipedia.org/wiki/Skalarpotential), oft einfach auch nur Potential genannt, ist in der Mathematik ein - im Unterschied zum Vektorpotential - skalares Feld $\\Phi(\\vec{r})$, dessen Gradient gemäß folgender Formel\n",
        "\n",
        "> $\n",
        "\\vec{F}(\\vec{r})=\\operatorname{grad} \\Phi(\\vec{r})=\\vec{\\nabla} \\Phi(\\vec{r})\n",
        "$\n",
        "\n",
        "ein als \"Gradientenfeld\" genanntes Vektorfeld $\\vec{F}(\\vec{r})$ liefert. \n",
        "\n",
        "Kurz: **Die erste Ableitung des Skalarpotentials (= ein Skalarfeld) ergibt das Gradientenfeld (= ein spezielles Vektorfeld).**\n",
        "\n",
        "* Ist $\\vec{F}(\\vec{r})$ ein **konservatives** Kraftfeld, in dem die Kraft $\\vec{F}$ dem Prinzip des kleinsten Zwanges folgend stets der Richtung des maximalen Anstiegs des Potentials $\\Phi$ entgegengerichtet ist, gilt alternativ die Definition\n",
        "$\n",
        "\\vec{F}(\\vec{r})=-\\operatorname{grad} \\Phi(\\vec{r})=-\\vec{\\nabla} \\Phi(\\vec{r})\n",
        "$\n",
        "\n",
        "* Skalarpotentiale bilden u. a. die mathematische Grundlage der Untersuchung konservativer Kraftfelder wie des elektrischen und des Gravitationsfelds, aber auch von wirbelfreien sogenannten Potentialströmungen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scez_eQlbpPg"
      },
      "source": [
        "**Ein Skalarfeld $\\Phi: \\vec{r} \\mapsto \\Phi(\\vec{r})$ ist genau dann ein Skalarpotential**, wenn es in einem einfach zusammenhängenden Gebiet\n",
        "\n",
        "1. zweimal stetig differenzierbar ist, das heißt keine , Sprünge\", Stufen oder andere\n",
        "Unstetigkeitsstellen enthält;\n",
        "\n",
        "2. zu ihm ein Vektorfeld $\\vec{F}: \\vec{r} \\mapsto \\vec{F}(\\vec{r})$ existiert, so dass gilt:\n",
        "$\\vec{F}(\\vec{r})=\\operatorname{grad} \\Phi(\\vec{r})=\\vec{\\nabla} \\Phi(\\vec{r})$\n",
        "\n",
        "$\\vec{F}$ wird daher oft auch das zugehörige Gradientenfeld genannt, das als Gradient des Skalarpotentials $\\Phi$ seinerseits stets folgende Bedingungen erfüllt:\n",
        "\n",
        "1. **Wegunabhängigkeit des Kurvenintegrals**: Der Wert des Kurvenintegrals entlang einer beliebigen Kurve S innerhalb des Feldes ist nur von ihrem Anfangs- und Endpunkt abhängig, nicht dagegen von ihrer Länge.\n",
        "\n",
        "2. **Verschwinden des geschlossenen Kurvenintegrals für beliebige Randkurven S**:\n",
        "$\\oint_{S} \\operatorname{grad} \\Phi(\\vec{r}) \\mathrm{d} \\vec{r}=\\oint_{S} \\vec{F}(\\vec{r}) \\mathrm{d} \\vec{r}=0$\n",
        "\n",
        "3. **Generelle Rotationsfreiheit bzw. Wirbelfreiheit des Feldes**:\n",
        "$\\operatorname{rot}(\\operatorname{grad} \\Phi(\\vec{r}))=\\operatorname{rot} \\vec{F}(\\vec{r})=\\vec{\\nabla} \\times \\vec{F}(\\vec{r})=\\overrightarrow{0}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msznOfm3bCGA"
      },
      "source": [
        "![cc](https://upload.wikimedia.org/wikipedia/commons/d/d9/GravityPotential.jpg)\n",
        "\n",
        "*Das Gravitationspotential einer homogenen Kugel*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuqLkrgCPdB1"
      },
      "source": [
        "*(Skalar-) Potential bei Kurvenintegralen in $\\mathbb{R}^{3}$*\n",
        "\n",
        "* Ein [Skalarpotential](https://de.wikipedia.org/wiki/Skalarpotential) ist eine reelle Funktion, die auf einem einfach zusammenhängenden Gebiet zwei mal stetig differenzierbar ist. \n",
        "\n",
        "* **Wenn ein Vektorfeld so ein Potential besitzt, lassen sich viele Rechnungen mit z.B. Kurvenintegralen vereinfachen**. Man kann dieses Potential berechnen.\n",
        "\n",
        "Wenn es eine Funktion F : d -> $\\mathbb{R}$ gibt, mit (Nabla ist der Tangent der Funktion mit den drei Komponenten x,y,z): \n",
        "\n",
        "> $\\vec{\\nabla} F(x, y, z)=\\vec{v}(x, y, z)=\\left(\\begin{array}{l}v_{1}(x, y, z) \\\\ v_{2}(x, y, z) \\\\ v_{3}(x, y, z)\\end{array}\\right)$\n",
        "\n",
        "* Anmerkungen:\n",
        "\n",
        "  * leiten wir Nabla in die x-Richtung ab, bekommt man v1, fur y-Richtung v2 und fur z-Richtung v3\n",
        "\n",
        "  * ist wie die Stammfunktion, bezeichnet man hier aber als Potential\n",
        "\n",
        "> so gilt fur Kurve $\\gamma:[a, b] \\rightarrow R^{3}$,\n",
        "\n",
        "  * Kurvenintegral ist unabhängig vom gewaehlten Weg, man kann verschiedene gehen. Wichtig ist nur von a nach b zu kommen.\n",
        "\n",
        "* Nabla berechnen und es kommt Vektorfeld als Ergebnis heraus. **Solch eine Funktion F heisst Stammfunktion bzw. Potenzial zum Vektorfeld $\\vec{v}$.**\n",
        "\n",
        "* Ein Vektorfeld $\\vec{v}$ das eine solche Stammfunktion hat, nennt man '**konservativ**' (dann kann man so ein Kointegral leicht ausrechnen)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrnWapTgOqWX"
      },
      "source": [
        "Wichtiger Satz: Auf einem **einfach zusammenhängenden** Gebiet $G \\subseteq \\mathbb{R}^{3}$ (=keine Löcher, alle Kurven die geschlossen sind kann man immer kleiner zusammenziehen) hat ein stetig differenzierbares Vektorfeld $\\vec{v}$ : G -> ${R}^{3}$ genau dann ein Potential, wenn $\\frac{\\partial v_{j}}{\\partial x_{k}}=\\frac{\\partial v_{k}}{\\partial x_{j}} \\quad$ fur alle $j, k=1,2,3$. \n",
        "\n",
        "In drei Dimension, weil man das oft in Rotationen anwendet / ist aquivalent zu $\\operatorname{rot}(\\vec{v})=0$ (ich muss nur die Rotation ausrechnen, und weiss dann ob das Vektorfeld ein konservatives ist oder nicht, hat also eine Stammfunktion oder nicht)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQWLOqidYl8z"
      },
      "source": [
        "https://www.youtube.com/watch?v=KPRvYY9WXGg&list=PLBh2i93oe2quqhn4TZjMnBM2v7lG5QhDD&index=9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2de7qmNDYkPv"
      },
      "source": [
        "https://www.youtube.com/watch?v=aM4ktp8yO-s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2od0Mz9XkRX"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Skalarpotential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybqAMWlqJu7y"
      },
      "source": [
        "**Vektorpotential**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2pH152ScafZ"
      },
      "source": [
        "**Ist ein Vektorfeld $v$ das Gradientenfeld einer Funktion $f,$ das heißt $v=\\nabla f$  (=Skalarfeld ist abgeleitet nach Ort), so bezeichnet man $f$ als Potential**.\n",
        "\n",
        "* Wirbelfelder, die Rotationen eines anderen Vektorfelds sind, sind stets quellenfrei – quellenfreie Vektorfelder können daher umgekehrt immer auch als Rotation eines anderen Vektorfelds interpretiert werden, das man in diesem Fall als „Vektorpotential“ des betreffenden quellenfreien Vektorfelds bezeichnet\n",
        "\n",
        "* Mathematisch ist das Vektorpotential (im Unterschied zum Skalarpotential) ein Vektorfeld $\\mathbf{A}(\\mathbf{r}),$ dessen Rotation ein zweites Vektorfeld $\\mathbf{B}(\\mathbf{r})$ liefert gemäß folgender Formel:\n",
        "\n",
        "> $\n",
        "\\mathbf{B}(\\mathbf{r}) \\stackrel{\\text { def }}{=} \\operatorname{rot} \\mathbf{A}(\\mathbf{r})=\\nabla \\times \\mathbf{A}(\\mathbf{r})\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeHrm5Yc8Hur"
      },
      "source": [
        "Vektorpotentiale lassen sich u. a. dazu verwenden, die zur Beschreibung des elektromagnetischen Felds verwendeten Maxwell-Gleichungen zu entkoppeln und dadurch leichter lösbar zu machen.\n",
        "\n",
        "Obwohl es zunächst nur als mathematisches Hilfsmittel eingeführt wurde, kommt ihm in der Quantenmechanik physikalische Realität zu, wie das [Aharonov-Bohm-Experiment](https://de.wikipedia.org/wiki/Aharonov-Bohm-Effekt) zeigte."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63WNYqjy8X76"
      },
      "source": [
        "**Beziehungen zwischen Vektor- und Skalarpotential**: Gemäß dem helmholtzschen Theorem kann (fast) jedes Vektorfeld $\\mathrm{K}(\\mathrm{r})$ \n",
        "\n",
        "* als **Superposition zweier Komponenten $\\mathbf{F}(\\mathbf{r})$ und $\\mathbf{G}(\\mathbf{r})$ aufgefasst werden**, \n",
        "\n",
        "* deren erste der Gradient eines Skalarpotentials $\\Phi(\\mathbf{r})$ ist, die zweite dagegen die Rotation eines Vektorpotentials $\\mathbf{\\Gamma}(\\mathbf{r}):$\n",
        "\n",
        "> $\n",
        "\\mathbf{K}(\\mathbf{r})=\\mathbf{F}(\\mathbf{r})+\\mathbf{G}(\\mathbf{r})=\\operatorname{grad} \\Phi(\\mathbf{r})+\\operatorname{rot} \\mathbf{\\Gamma}(\\mathbf{r})=\\nabla \\Phi(\\mathbf{r})+\\nabla \\times \\mathbf{\\Gamma}(\\mathbf{r})\n",
        "$\n",
        "\n",
        "* Ist $\\mathbf{F}(\\mathbf{r})$ ein konservatives Kraftfeld, in dem die Kraft $\\mathbf{F}$ dem [Prinzip des kleinsten Zwanges](https://de.wikipedia.org/wiki/Prinzip_des_kleinsten_Zwanges) folgend stets der Richtung des maximalen Anstiegs des Potentials $\\Phi$ entgegengerichtet ist, gilt alternativ die Schreibweise\n",
        "\n",
        "> $\n",
        "\\mathbf{K}(\\mathbf{r})=\\mathbf{F}(\\mathbf{r})+\\mathbf{G}(\\mathbf{r})=-\\operatorname{grad} \\Phi(\\mathbf{r})+\\operatorname{rot} \\mathbf{\\Gamma}(\\mathbf{r})=-\\nabla \\Phi(\\mathbf{r})+\\nabla \\times \\mathbf{\\Gamma}(\\mathbf{r})\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNahSbyncc2R"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Skalarpotential#Beziehungen_zwischen_Skalar-_und_Vektorpotential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh0bxMZQXmXO"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Vektorpotential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HEOBISTrpoC"
      },
      "source": [
        "#### **Differentialoperatoren (Rotation, Divergenz, Gradient)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFKlWj90F3T4"
      },
      "source": [
        "Die drei kovarianten Differentialoperatoren"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-vCM9-DX-j2"
      },
      "source": [
        "**Differentialoperator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0-zFQD_Y17-"
      },
      "source": [
        "Rechenoperationen in der Vektoranalysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gyJV3RVZ5gc"
      },
      "source": [
        "**Folgende drei Rechenoperationen sind in der Vektoranalysis von besonderer Bedeutung**, weil sie Felder produzieren, die sich bei räumlicher Drehung des ursprünglichen Feldes mitdrehen. Operativ formuliert: Bei Gradient, Rotation und Divergenz **spielt es keine Rolle, ob sie vor oder nach einer Drehung angewendet werden**. Diese Eigenschaft folgt aus den **koordinatenunabhängigen** Definitionen. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpGcMJaKroS6"
      },
      "source": [
        "**Differential**: Der [**Differentialoperator**](https://de.wikipedia.org/wiki/Differentialoperator) $\\frac{\\mathrm{d}}{\\mathrm{d} x}$ zur Bildung von [Differentialen](https://de.wikipedia.org/wiki/Differential_(Mathematik)) (ist eine Funktion, die einer Funktion eine Funktion zuordnet und die Ableitung nach einer oder mehreren Variablen enthält.).\n",
        "\n",
        "  * [Gradient](https://de.wikipedia.org/wiki/Gradient_(Mathematik)): Gibt die Richtung und Stärke des steilsten Anstiegs eines Skalarfeldes an. Der Gradient eines Skalarfeldes ist ein Vektorfeld. $\\operatorname{grad} \\phi:=\\vec{\\nabla} \\phi=\\left(\\begin{array}{c}\\frac{\\partial \\phi}{\\partial x} \\\\ \\frac{\\partial \\phi}{\\partial y} \\\\ \\frac{\\partial \\phi}{\\partial z}\\end{array}\\right)$\n",
        "\n",
        "  * [Divergenz](https://de.wikipedia.org/wiki/Divergenz_eines_Vektorfeldes): Gibt die Tendenz eines Vektorfeldes an, von Punkten wegzufließen. $\\operatorname{div} \\vec{F}:=\\vec{\\nabla} \\cdot \\vec{F}=\\frac{\\partial F_{x}}{\\partial x}+\\frac{\\partial F_{y}}{\\partial y}+\\frac{\\partial F_{z}}{\\partial z}$\n",
        "\n",
        "  * [Rotation](https://de.wikipedia.org/wiki/Rotation_eines_Vektorfeldes): Gibt die Tendenz eines Vektorfeldes an, um Punkte zu rotieren. $\\operatorname{rot} \\vec{F}:=\\vec{\\nabla} \\times \\vec{F}=\\left(\\begin{array}{c}\\frac{\\partial F_{z}}{\\partial y}-\\frac{\\partial F_{y}}{\\partial z} \\\\ \\frac{\\partial F_{x}}{\\partial z}-\\frac{\\partial F_{z}}{\\partial x} \\\\ \\frac{\\partial F_{y}}{\\partial x}-\\frac{\\partial F_{x}}{\\partial y}\\end{array}\\right)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-XFwoBXDaqt"
      },
      "source": [
        "Interpretiert man das Vektorfeld als Strömungsfeld einer Größe, für die die Kontinuitätsgleichung gilt, dann ist die [Divergenz](https://physik.cosmos-indirekt.de/Physik-Schule/Divergenz_eines_Vektorfeldes) die Quelldichte. Senken haben negative Divergenz. Ist die Divergenz überall gleich null, so bezeichnet man das Feld als quellenfrei."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSvDHxVmgzEU"
      },
      "source": [
        "Der [**Laplace-Operator**](https://de.wikipedia.org/wiki/Laplace-Operator) ist ein linearer Differentialoperator innerhalb der [mehrdimensionalen Analysis](https://de.wikipedia.org/wiki/Analysis#Mehrdimensionale_reelle_Analysis) ($\\Delta \\colon D(\\Delta )\\to L^{2}(\\mathbb{R} ^{n})$ und ein unbeschränkter Operator). Der Laplace-Operator kommt in vielen Differentialgleichungen vor, die das Verhalten physikalischer Felder beschreiben. Beispiele sind die Poisson-Gleichung der Elektrostatik, die **Navier-Stokes-Gleichungen** für Strömungen von Flüssigkeiten oder Gasen und die Diffusionsgleichung für die Wärmeleitung.\n",
        "\n",
        "Der Laplace-Operator ordnet einem zweimal differenzierbaren Skalarfeld $f$ **die Divergenz seines Gradienten zu**,\n",
        "\n",
        ">$\n",
        "\\Delta f=\\operatorname{div}(\\operatorname{grad} f)\n",
        "$\n",
        "\n",
        "oder mit dem Nabla-Operator notiert\n",
        "\n",
        ">$\n",
        "\\Delta f=\\nabla \\cdot(\\nabla f)=(\\nabla \\cdot \\nabla) f=\\nabla^{2} f\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvwBG9AzZb-C"
      },
      "source": [
        "[**Kovariant**](https://de.wikipedia.org/wiki/Kovarianz_(Physik)) nennt man ein Transformationsverhalten, bei dem sich die Basisvektoren und die darin dargestellten Vektoren (Größen) in gleicher Weise transformieren. **Kontravariant** nennt man ein Transformationsverhalten, wenn sich die Basisvektoren und die darin dargestellten Vektoren (Größen) in unterschiedlicher Weise transformieren.\n",
        "\n",
        "Das kovariante Transformationsverhalten garantiert die Formerhaltung von Gleichungen beim Wechsel des Bezugsystems (Koordinatensystems) bzw. bei Gruppentransformationen. Diese Aussagen gelten auch für die tensorielle Schreibweise.\n",
        "\n",
        "Zum Beispiel: Unter Galilei-Transformationen transformieren sich die Beschleunigung und die Kraft in den newtonschen Bewegungsgleichungen im gleichen Sinne wie die Ortsvektoren. Daher sind die Newtonschen Bewegungsgleichungen und damit die klassische Mechanik kovariant bzgl. der Gruppe der Galilei-Transformationen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0Zw_t0Ptro-"
      },
      "source": [
        "**Nabla-Operator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHqNsnOYsVdm"
      },
      "source": [
        "*Koordinatenunabhängige Definition mit dem Nabla-Operator*\n",
        "\n",
        "* Der [Nabla-Operator](https://de.wikipedia.org/wiki/Nabla-Operator) ist ein Symbol, das in der Vektor- und Tensoranalysis benutzt wird, um kontextabhängig einen der drei Differentialoperatoren Gradient, Divergenz oder Rotation zu notieren.\n",
        "\n",
        "* [**Nabla Operator**](https://de.wikipedia.org/wiki/Nabla-Operator) $\\nabla$ zur Bestimmung des Gradienten einer mehrdimensionalen Funktion. Mit einem der drei **Differentialoperatoren**.\n",
        "\n",
        "* Der Nabla-Operator ist auch in anderen Koordinatensystemen definiert und so kann mit ihm zum Beispiel die Rotation [koordinatenunabhängig](https://de.wikipedia.org/wiki/Rotation_eines_Vektorfeldes#Koordinatenunabhängige_Definition_mit_dem_Nabla-Operator) durch \n",
        "\n",
        "> $\\operatorname{rot} \\vec{F}:=\\nabla \\times \\vec{F}$\n",
        "\n",
        "definiert werden. Mit dem Nabla-Operator können auch der Gradient- sowie die Divergenz eines Vektorfeldes dargestellt und Produktregeln hergeleitet werden.\n",
        "\n",
        "Formal ist der Nabla-Operator ein Vektor, dessen Komponenten die partiellen\n",
        "Ableitungsoperatoren $\\frac{\\partial}{\\partial x_{i}}$ sind:\n",
        "\n",
        "> $\n",
        "\\vec{\\nabla}=\\left(\\frac{\\partial}{\\partial x_{1}}, \\ldots, \\frac{\\partial}{\\partial x_{n}}\\right)\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2zTmFCuVE-u"
      },
      "source": [
        "**Rotation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP_Y-_K6qxVV"
      },
      "source": [
        "* Als [Rotation oder Rotor](https://de.wikipedia.org/wiki/Rotation_eines_Vektorfeldes) bezeichnet man in der Vektoranalysis, einem Teilgebiet der Mathematik, einen bestimmten Differentialoperator, der einem Vektorfeld im dreidimensionalen euklidischen Raum mit Hilfe der Differentiation ein neues Vektorfeld zuordnet.\n",
        "\n",
        "* Die Rotation eines [Strömungsfeldes](https://de.wikipedia.org/wiki/Strömungsfeld) gibt für jeden Ort das Doppelte der Winkelgeschwindigkeit an, mit der sich ein mitschwimmender Körper dreht („rotiert“). Dieser Zusammenhang ist namensgebend.\n",
        "\n",
        "* Es muss sich aber nicht immer um ein Geschwindigkeitsfeld und eine Drehbewegung handeln; beispielsweise betrifft das Induktionsgesetz die Rotation des elektrischen Feldes.\n",
        "\n",
        "* [Rotation](https://de.wikipedia.org/wiki/Rotation_eines_Vektorfeldes): Gibt die Tendenz eines Vektorfeldes an, um Punkte zu rotieren. $\\operatorname{rot} \\vec{F}:=\\vec{\\nabla} \\times \\vec{F}=\\left(\\begin{array}{c}\\frac{\\partial F_{z}}{\\partial y}-\\frac{\\partial F_{y}}{\\partial z} \\\\ \\frac{\\partial F_{x}}{\\partial z}-\\frac{\\partial F_{z}}{\\partial x} \\\\ \\frac{\\partial F_{y}}{\\partial x}-\\frac{\\partial F_{x}}{\\partial y}\\end{array}\\right)$\n",
        "\n",
        "* Siehe auch [Koordinatentransformation](https://de.wikipedia.org/wiki/Koordinatentransformation#Drehung_(Rotation)) sowie [Drehmatrix](https://de.wikipedia.org/wiki/Drehmatrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9e3prN3rXj-"
      },
      "source": [
        "**Divergenz**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRwBaz9bh-qg"
      },
      "source": [
        "* Die [Divergenz eines Vektorfeldes](https://de.wikipedia.org/wiki/Divergenz_eines_Vektorfeldes) ist ein Skalarfeld, das an jedem Punkt angibt, wie sehr die Vektoren in einer kleinen Umgebung des Punktes auseinanderstreben (lateinisch divergere). \n",
        "\n",
        "* Interpretiert man das Vektorfeld als Strömungsfeld einer Größe, für die die Kontinuitätsgleichung gilt, dann ist die Divergenz die Quelldichte. Senken haben negative Divergenz. Ist die Divergenz überall gleich null, so bezeichnet man das Feld als quellenfrei.\n",
        "\n",
        "* Man betrachtet zum Beispiel eine ruhige Wasseroberfläche, auf die ein dünner Strahl Öl trifft. Die Bewegung des Öls auf der Oberfläche kann durch ein zweidimensionales (zeitabhängiges) Vektorfeld beschrieben werden: An jedem Punkt ist zu jedem beliebigen Zeitpunkt die Fließgeschwindigkeit des Öls in Form eines Vektors gegeben. Die Stelle, an der der Strahl auf die Wasseroberfläche trifft, ist eine „Ölquelle“, da von dort Öl wegfließt, ohne dass es einen Zufluss auf der Oberfläche geben würde. Die Divergenz an dieser Stelle ist positiv. Im Gegensatz dazu bezeichnet man eine Stelle, an der das Öl beispielsweise am Rand aus dem Wasserbecken abfließt, als Senke. Die Divergenz an dieser Stelle ist negativ.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGSV9UrCvfQh"
      },
      "source": [
        "**Gradient**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O844e1Y6yuPP"
      },
      "source": [
        "* Der Gradient als Operator verallgemeinert die bekannten Gradienten, die den Verlauf von physikalischen Größen beschreiben. \n",
        "\n",
        "* **Als Differentialoperator kann er beispielsweise auf ein Skalarfeld angewandt werden und wird in diesem Fall ein Vektorfeld liefern, das Gradientenfeld genannt wird.**\n",
        "\n",
        "* Der Gradient ist eine Verallgemeinerung der Ableitung in der mehrdimensionalen Analysis. Zur besseren Abgrenzung zwischen Operator und Resultat seiner Anwendung bezeichnet man solche Gradienten skalarer Feldgrößen in manchen Quellen auch als Gradientvektoren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExMsKuyqyziD"
      },
      "source": [
        "*Gradientenfeld*\n",
        "\n",
        "Ein [Gradientenfeld](https://de.wikipedia.org/wiki/Gradientenfeld) **ist ein Vektorfeld**, das aus einem Skalarfeld durch Differentiation nach dem Ort abgeleitet wurde, bzw. – kürzer formuliert – der Gradient des Skalarfelds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzwtAAJ2vik-"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Gradient_(Mathematik)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4njkcQPvoYD"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R68NS5iUvjnn"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Partielle_Ableitung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vcm5d0r2fDD0"
      },
      "source": [
        "**Fundamentalzerlegung (Fundamentalsatz der Vektoranalysis)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE9TPhq5fEux"
      },
      "source": [
        "* der [Helmholtzscher Zerlegungssatz](https://de.m.wikipedia.org/wiki/Helmholtz-Theorem) ist der Fundamentalsatz der Vektoranalysis. Beschreibt den allgemeinen Fall. \n",
        "\n",
        "* Jedes Vektorfeld $\\vec{F}$ lässt sich als eine Überlagerung eines Quellenanteils $\\vec{F}_{Q}$ und eines Wirbelanteils $\\vec{F}_{W}$ beschreiben."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArSX-a3HWv_P"
      },
      "source": [
        "#### **Mehrdimensionale Integration (Kurven, Oberflächen, Volumen)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUq40bq5F6GH"
      },
      "source": [
        "Mehrdimensionale Integration im Skalar- & Vektorfeld\n",
        "\n",
        "* zB zur Berechnung der Laenge einer Kurve (zB an einer Spirale), die Oberflache eines Volumens, der Masse eines Koerpers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uimHevy5O9az"
      },
      "source": [
        "https://www.youtube.com/watch?v=H1Pj4SMVZ8s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dolnoE19IyYG"
      },
      "source": [
        "##### **Kurvenintegral**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILqKxv9BF4QY"
      },
      "source": [
        "https://www.youtube.com/watch?v=d_UX4_0KIGY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxEoDCIYLOem"
      },
      "source": [
        "* z.B. zur Berechnung des Umfangs eines Objekts. welche Kraft ist noetig, um durch ein Vektorfeld auf einer Kurve entlang zu gehen?\n",
        "\n",
        "* Das [Kurven-, Linien-, Weg- oder Konturintegral](https://de.wikipedia.org/wiki/Kurvenintegral) erweitert den gewöhnlichen Integralbegriff für die Integration \n",
        "\n",
        "  * in der komplexen Ebene (Funktionentheorie) oder \n",
        "  \n",
        "  * im mehrdimensionalen Raum (Vektoranalysis).\n",
        "\n",
        "* Den Weg, die Linie oder die Kurve, über die integriert wird, nennt man den Integrationsweg.\n",
        "\n",
        "* Wegintegrale über geschlossene Kurven werden auch als Ringintegral, Umlaufintegral oder Zirkulation bezeichnet und mit dem Symbol \n",
        "∮ bzw. $\\textstyle \\oint$  geschrieben."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3Oybmkc-zAl"
      },
      "source": [
        "Auch Linienintegral. Berechne z.B. den kurzesten Weg zwischen zwei Punkten unter Berucksichtigung der Geschwindigkeit (eine gerade Linie ist nicht immer der kurzeste Weg oder ein moglicher Weg)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_jWgM7A9OMt"
      },
      "source": [
        "![ff](https://upload.wikimedia.org/wikipedia/commons/4/42/Line_integral_of_scalar_field.gif)\n",
        "\n",
        "*The line integral over a scalar field f can be thought of as the area under the curve C along a surface z = f(x,y), described by the field*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2b6mZKu-Pe1"
      },
      "source": [
        "![xx](https://raw.githubusercontent.com/deltorobarba/repo/master/kurvenintegral_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pyf0MPG-VkL"
      },
      "source": [
        "![xx](https://raw.githubusercontent.com/deltorobarba/repo/master/kurvenintegral_02.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNdoF6CN-ucN"
      },
      "source": [
        "![xx](https://raw.githubusercontent.com/deltorobarba/repo/master/kurvenintegral_03.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNcecwnJ-vac"
      },
      "source": [
        "![xx](https://raw.githubusercontent.com/deltorobarba/repo/master/kurvenintegral_04.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F0Cp7AP-wRr"
      },
      "source": [
        "![xx](https://raw.githubusercontent.com/deltorobarba/repo/master/kurvenintegral_05.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_lY1plvJOZ-"
      },
      "source": [
        "**Kurvenintegral 1. Art (über Skalarfelder, nicht-orientiert)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2Y7uIIJGQcJ"
      },
      "source": [
        "* zB zur Berechnung der Masse eines Drahtes [entlang einer Helix](https://www.youtube.com/watch?v=8XcqTg1NPKg) mit einer gegebenen Dichte"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHbjxfJVJMrP"
      },
      "source": [
        "Wegintegral erster Art ist das **Wegintegral einer stetigen Funktion**, $\n",
        "f: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}\n",
        "$ entlang eines stückweise stetig differenzierbaren Weges $\n",
        "\\gamma:[a, b] \\rightarrow \\mathbb{R}^{n}\n",
        "$ ist definiert als\n",
        "\n",
        "> $\\int_{\\mathcal{C}} f \\mathrm{~d} s:=\\int_{a}^{b} f(\\gamma(t))\\|\\dot{\\gamma}(t)\\|_{2} \\mathrm{~d} t$\n",
        "\n",
        "Für eine stetige Funktion $f: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}$ und einem regulären Weg $\\gamma:[a, b] \\rightarrow \\mathbb{R}^{n}$ definiert man das Kurvenintegral von $f$ längs $\\gamma$ durch: $\\int_{\\gamma} f d s:=\\int_{a}^{b} f(\\gamma(t))\\|\\dot{\\gamma}(t)\\| d t$\n",
        "\n",
        "  * $ds$ sowie $ \\|\\dot{\\gamma}(t)\\| d t$ sind das '**Linienelement**'\n",
        "\n",
        "  * $ \\|\\dot{\\gamma}(t)\\|$ ist die Norm von der Ableitung, die man berucksichtigen muss beim Integrieren wie schnell man durch die Kurve lauft (Gewichtungsfaktor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HvuqF-aJDBO"
      },
      "source": [
        "**Kurvenintegral 2. Art (über Vektorfelder, orientiert)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ5fqgZGGky6"
      },
      "source": [
        "* nicht mehr skalare, sondern vektorielle Funktion integrieren (Vektorfeld)\n",
        "\n",
        "* ps: jedes Kurvenintegral zweiter Art ist auch ein Kurvenintegral erster Art\n",
        "\n",
        "* z.B. um eine Arbeit, Zirkulation oder elektrische Spannung [zu berechnen](https://www.youtube.com/watch?v=HmgkyI_Q0Oo)\n",
        "\n",
        "* nennt man daher auch \"Arbeitsintegral\", wenn man sich zB ein Kraftfeld v vorstellt. Oder Zirkulation mit Integral entlang des Weges berechnen, wenn v ein Geschwindigkeitsfeld ist. Oder elektrische Spannung, wenn es ein elektrisches Feld ist.\n",
        "\n",
        "* Zunächst fragen: hat v ein Skalarpotential? Ist die betrachtete Menge einfach zusammenhängend und ist zB die Rotation des Vektorfeldes gleich der Nullvektor? Berechnung des Skalarpotentials: mit der Ansatzmethode oder mit der Kurvenintegralmethode\n",
        "\n",
        "* Danach fragen, ob der Weg geschlossen oder offen ist? (geschlossen: Anfangspunkt = Endpunkt, wie bei Kreis oder Dreieck). Ist er geschlossen, ist der Wert des Kurvenintegrals gleich Null. (**Remember**: Als [wirbelfrei bzw. konservativ](https://de.wikipedia.org/wiki/Wirbelfreies_Vektorfeld) wird in der Physik und Potentialtheorie ein Vektorfeld $\\vec{X}(\\vec{r})$ bezeichnet, in dem das **Kurvenintegral** $\n",
        "\\oint_{S} \\vec{X}(\\vec{r}) \\cdot \\mathrm{d} \\vec{s}=0$ für beliebige in sich geschlossene Randkurven $S$ stets den Wert null liefert.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLe3mhoqDP36"
      },
      "source": [
        "Das Wegintegral zweiter Art ist das **Wegintegral über ein stetiges Vektorfeld** $\\mathbf{f}: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{n}$ mit einer ebenfalls so parametrisierten Kurve ist definiert als das Integral über das Skalarprodukt aus $\\mathrm{f} \\circ \\gamma$ und $\\dot{\\gamma}$ :\n",
        "\n",
        "> $\\int_{\\mathcal{C}} \\mathbf{f}(\\mathbf{x}) \\cdot \\mathrm{d} \\mathbf{x}:=\\int_{a}^{b} \\mathbf{f}(\\gamma(t)) \\cdot \\dot{\\gamma}(t) \\mathrm{d} t$\n",
        "\n",
        "* Ist ein **Kurvenintegral 2. Art (weil man Vektorfelder integriert)** und ist orientiert (es ist wichtig, wie man den Weg durchlauft wegen den Vektoren!)\n",
        "\n",
        "* Für ein stetiges Vektorfeld $\\mathbf{v}: D \\rightarrow \\mathbb{R}^{3}$ mit $D \\subset \\mathbb{R}^{3}$ und einen regulären Weg $\\gamma:[a, b] \\rightarrow \\mathbb{R}^{3}$ definiert man das Kurvenintegral von v längs $\\gamma$ durch:\n",
        "\n",
        "> $\\int_{\\gamma} v \\cdot d \\vec{s}$ $:=\\int_{a}^{b} v(\\gamma(t)) \\cdot \\dot{\\gamma}(t) d t$\n",
        "\n",
        "$v$ ist die Kraft\n",
        "\n",
        "$d \\vec{s}$ ist der Weg\n",
        "\n",
        "Kraft * Weg = Arbeit, aber Weg ist nicht geradlinig, sondern eine verschnoerkelte Kurve. Man nimmt unendlich kleine Wegelemente und berechnet die Arbeit, und summieren die Teile auf (Integral).\n",
        "\n",
        "* Anmerkungen:\n",
        "\n",
        "  * der dicke Punkt steht fur das Skalarprodukt. \n",
        "\n",
        "  * $\\dot{\\gamma}(t) d t$ - keine Norm der Ableitung der Kurve notig (dieser Tangentialvektor ist nicht normiert), wie bei Kurvenintegralen uber Funktionen\n",
        "\n",
        "  * $ d \\vec{s}$ ist ein **vektorielles Linienelement**\n",
        "\n",
        "* **Komponente des Vektorfeldes in Richtung des Weges - Das ist, was man berücksichtigen will im Integral: Wie viel von dem Vektorfeld ist in Wegrichtung? Und nur das macht einen Einfluss in das Integral.**\n",
        "\n",
        "* Beim Durchlaufen des Weges werden wir entweder mit dem Vektorfeld (in Richtung des Vektorfeldes) getrieben, oder es haelt uns zurück. = die Energie, die wir brauchen, um den Weg zu durchlaufen (wenn das Vektorfeld uns hilft oder daran hindert, wie eine Strömung).\n",
        "\n",
        "* **Die Komponente in Richtung des Weges ist wichtig, und die Komponente bekommt man durch das Skalarprodukt.** (siehe Bild unten)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-v9nefMJY9-"
      },
      "source": [
        "![vv](https://raw.githubusercontent.com/deltorobarba/repo/master/kurvenintegral_vektorfeld.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQdL1yhzPGzI"
      },
      "source": [
        "##### **Oberflächenintegral**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XChIebVaPLd6"
      },
      "source": [
        "* z.B. zur Berechnung der Oberfläche eines Balls\n",
        "\n",
        "* Durch Parametrisierung wird z.B. die Kruemmung einer Ebene in $R^3$ beruecksichtigt. Man berechnet naemlich die Flaeche, in dem man von $R^3$ auf $R^2$ projiziert und dann das Integral berechnet (das geht, weil Flaeche in $R^3$ ist offen, stetig differenzierbar und bijektiv)\n",
        "\n",
        "* Das Oberflächenintegral oder Flächenintegral ist eine Verallgemeinerung des Integralbegriffes auf ebenen oder gekrümmten Flächen. Das Integrationsgebiet $\\mathcal{F}$ ist also nicht ein eindimensionales Intervall, sondern eine zweidimensionale Menge im dreidimensionalen Raum $\\mathbb{R}^{3}$. Für eine allgemeinere Darstellung im $\\mathbb{R}^{n}$ mit $n \\geq 2$ siehe: Integration auf Mannigfaltigkeiten.\n",
        "\n",
        "Es wird generell zwischen einem skalaren und einem vektoriellen Oberflächenintegral unterschieden, je nach Form des Integranden und\n",
        "des sogenannten Oberflächenelements. Sie lauten\n",
        "\n",
        "> $\\iint_{\\mathcal{F}} f \\mathrm{~d} \\sigma$ mit skalarer Funktion $f$ und skalarem Oberflächenelement $\\mathrm{d} \\sigma$ sowie \n",
        "\n",
        "> $\\iint_{\\mathcal{F}} \\vec{v} \\cdot \\mathrm{d} \\vec{\\sigma}$ mit vektorwertiger Funktion $\\vec{v}$ und vektoriellem Oberflächenelement $\\mathrm{d} \\vec{\\sigma}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcvZH7qLBOzs"
      },
      "source": [
        "Allgemein lässt sich eine Fläche im $\\mathbb{R}^{3}$ mit zwei Parametern $u$ und $v$ in\n",
        "folgender Form darstellen:\n",
        "\n",
        "> $\n",
        "\\varphi: B \\rightarrow \\mathbb{R}^{3}, \\quad(u, v) \\mapsto \\vec{\\varphi}(u, v)=\\left(\\begin{array}{l}\n",
        "x(u, v) \\\\\n",
        "y(u, v) \\\\\n",
        "z(u, v)\n",
        "\\end{array}\\right)\n",
        "$\n",
        "\n",
        "Auf der Fläche $\\vec{\\varphi}(u, v)$ bilden die Kurvenscharen $u=$ const bzw. $v=$ const die Koordinatenlinien. Diese überziehen die Fläche mit einem Koordinatennetz.\n",
        "wobei durch jeden Punkt zwei Koordinatenlinien verlaufen. Somit hat ieder Punkt auf der Fläche eindeutige Koordinaten $\\left(u_{0}, v_{0}\\right)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e45jm0deB13y"
      },
      "source": [
        "Mit den Parametrisierungen und den Oberflächenelementen kann man nun die Oberflächenintegrale definieren. Diese mehrdimensionalen Integrale sind Lebesgue-Integrale, können aber in den meisten Anwendungsfällen als mehrfache Riemann-Integrale berechnet werden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yO9AukUtSzo"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Oberflächenintegral"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHwK1ZsvrPIY"
      },
      "source": [
        "##### **Volumenintegrale**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llLY5ZbxPR5j"
      },
      "source": [
        "* z.B. zur Berechnung des Volumeninhaltes eines Objektes\n",
        "\n",
        "* Das [Volumenintegral](https://de.wikipedia.org/wiki/Volumenintegral) erweitert das Oberflächenintegral auf die Integration über ein beliebiges dreidimensionales Integrationsgebiet, wobei eine Funktion dreimal hintereinander integriert wird, jeweils über eine Richtung eines dreidimensionalen Raumes. \n",
        "\n",
        "* **Dabei muss es sich jedoch nicht notwendigerweise um ein Volumen eines geometrischen Körpers handeln**. \n",
        "\n",
        "* Zur vereinfachten Darstellung wird oft nur ein einziges Integralzeichen geschrieben und die Volumenintegration lediglich durch das Volumenelement $\\mathrm {d} V$ angedeutet:\n",
        "\n",
        "> $\\iiint_{V} f(r) d^{3} r=\\int_{V} f(\\vec{x}) \\mathrm{d} V$\n",
        "\n",
        "* wobei die zu integrierende Funktion zumindest von drei Variablen ${\\vec {x}}=(x,y,z)$ für eine (kartesische) Beschreibung im dreidimensionalen Raum $\\mathbb{R^3}$ abhängt, **es sind aber auch höherdimensionale Räume möglich**.\n",
        "\n",
        "* Es handelt sich um ein **skalares Volumenintegral**, wenn der Integrand $f$ und das Volumenelement $\\mathrm{d} V$ skalar sind. Bei einem **vektoriellen Integranden**, z. B. einem Vektorfeld $\\vec{f}$, ist auch das Volumenelement $\\mathrm{d} \\vec{V}$ ein Vektor, sodass sich ein vektorielles Volumenintegral ergibt.\n",
        "\n",
        "* Um ein Volumenintegral zu berechnen, ist meist eine Parametrisierung des Integrationsgebiets nötig."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhQKZZ-1M-GE"
      },
      "source": [
        "##### **Integralsätze (Gauss, Stokes, Green)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-ifFM9ZKy3p"
      },
      "source": [
        "[Integralsatz](https://de.wikipedia.org/wiki/Integralsatz) ist ein Namensbestandteil bestimmter mathematischer Sätze, in deren Aussage ein Integral vorkommt.\n",
        "\n",
        "Unter dem Begriff der klassischen Integralsätze werden der **Satz von Gauß, der Satz von Green, der Satz von Stokes** und einige ihrer Spezialfälle zusammengefasst. Diese Sätze der Vektoranalysis hängen eng miteinander zusammen: der Integralsatz von Stokes umfasst die anderen beiden Sätze als Spezialfälle.\n",
        "\n",
        "Außerdem gibt es neben den klassischen Integralsätzen noch weitere Sätze, die man kurz als Integralsätze bezeichnet. Zu diesen zählt beispielsweise der cauchysche Integralsatz, der ein zentrales Resultat aus der Funktionentheorie ist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBGhKHdBNUv2"
      },
      "source": [
        "[Integralsatz von Gauß](https://de.m.wikipedia.org/wiki/Gaußscher_Integralsatz)\n",
        "\n",
        "* Im Folgenden sei das „Integrationsvolumen“ V n-dimensional. \n",
        "\n",
        "* Das [Volumenintegral](https://de.m.wikipedia.org/wiki/Volumenintegral) über den Gradienten einer skalaren Größe $\\phi$, kann dann in ein [Oberflächenintegral](https://de.m.wikipedia.org/wiki/Oberflächenintegral) (bzw. Hyperflächenintegral) über den Rand dieses Volumens umgewandelt werden:\n",
        "\n",
        "> $\n",
        "\\int_{V} \\operatorname{grad} \\phi(\\vec{x}) \\mathrm{d} V=\\oint_{\\partial V} \\phi \\mathrm{d} \\vec{A}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y64AmnhcNBpb"
      },
      "source": [
        "[Satz von Stokes](https://de.m.wikipedia.org/wiki/Satz_von_Stokes)\n",
        "\n",
        "* sehr grundlegenden Satz über die Integration von Differentialformen, der den Hauptsatz der Differential- und Integralrechnung erweitert\n",
        "\n",
        "*  eine Verbindungslinie von der Differentialgeometrie zur Algebraischen Topologie eröffnet. \n",
        "\n",
        "* Dieser Zusammenhang wird durch den Satz von de Rham beschrieben, für den der Satz von Stokes grundlegend ist.\n",
        "\n",
        "* Im Folaenden ist $n=3$ und es wird die Schreibweise mit Mehrfachintegralen\n",
        "verwendet.\n",
        "\n",
        "Das qeschlossene Kurvenintegral einer vektoriellen Größe (rechte Seite) kann\n",
        "mittels der Rotation in ein Flächenintegral über eine von dem geschlossenen\n",
        "Integrationsweg $\\Gamma=\\partial A$ berandete, nicht notwendig ebene Fläche\n",
        "umgewandelt werden (linke Seite). Dabei werden - wie auch beim\n",
        "Gauß'schen Satz - die gewöhnlichen Orientierungseigenschaften\n",
        "vorausgesetzt. Es gilt:\n",
        "\n",
        "> $\n",
        "\\iint_{A} \\operatorname{rot} \\vec{F} \\cdot \\mathrm{d} \\vec{A}=\\oint_{\\Gamma=\\partial A} \\vec{F}(\\vec{r}) \\cdot \\mathrm{d} \\vec{r}\n",
        "$\n",
        "\n",
        "Der Vektor $\\mathrm{d} \\vec{A}$ ist gleich dem Betrag der zur betrachteten Fläche $A$ bzw. zu\n",
        "$\\partial V$ gehörenden infinitesimalen Flächenelemente multipliziert mit dem\n",
        "zugehörigen Normalenvektor. Auf der rechten Seite wird durch das\n",
        "Kreissymbol im Integralzeichen daran erinnert, dass über eine geschlossene\n",
        "Kurve integriert wird."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRhCrZ_fK_8D"
      },
      "source": [
        "[Satz von Green](https://de.wikipedia.org/wiki/Satz_von_Green)\n",
        "\n",
        "* Der Satz von Green (auch Green-Riemannsche Formel oder Lemma von Green, gelegentlich auch Satz von Gauß-Green) \n",
        "\n",
        "* **erlaubt es, das Integral über eine ebene Fläche durch ein Kurvenintegral auszudrücken**. \n",
        "\n",
        "* Der Satz ist ein Spezialfall des Satzes von Stokes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWuiG_igrWtv"
      },
      "source": [
        "Integrals ̈atze (Gauss, Stokes, Greenschen Formeln, Lo ̈sung der Poissongleichung, Fundamentalsatz der Vektoranalysis II)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLvbjOH0rbDs"
      },
      "source": [
        "#### **Volumenform, Koordinatentransformationen und Funktionaldeterminante**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jX_Bp75Nurq"
      },
      "source": [
        "**Volumenform**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy2PCJfRNxDB"
      },
      "source": [
        "* Eine [Volumenform](https://de.m.wikipedia.org/wiki/Volumenform) ist ein mathematisches Objekt, welches zur Integration über Raumbereiche benötigt wird, insbesondere bei der Verwendung spezieller Koordinatensysteme, also ein Spezialfall eines Volumens.\n",
        "\n",
        "* In der Physik und im Ingenieurwesen sind auch Bezeichnungen wie infinitesimales Volumenelement oder Maßfaktor gebräuchlich.\n",
        "\n",
        "* Beispiele in 3 Dimensionen:\n",
        "\n",
        "  * [Kartesische Koordinaten](https://de.m.wikipedia.org/wiki/Kartesisches_Koordinatensystem): $\\mathrm{d} V=\\mathrm{d} x \\cdot \\mathrm{d} y \\cdot \\mathrm{d} z$\n",
        "  \n",
        "  * [Zylinderkoordinaten](https://de.m.wikipedia.org/wiki/Polarkoordinaten#Zylinderkoordinaten) (ebene Polarkoordinaten um eine dritte Koordinate ergänzt): $\\mathrm{d} V=\\rho \\cdot \\mathrm{d} \\rho \\cdot \\mathrm{d} \\varphi \\cdot \\mathrm{d} z$\n",
        "  \n",
        "  * [Kugelkoordinaten](https://de.m.wikipedia.org/wiki/Kugelkoordinaten): $\\mathrm{d} V=r^{2} \\cdot \\sin \\theta \\cdot \\mathrm{d} r \\cdot \\mathrm{d} \\theta \\cdot \\mathrm{d} \\varphi$\n",
        "\n",
        "* Das Volumenelement in drei Dimensionen lässt sich nach dem [Transformationssatz](https://de.m.wikipedia.org/wiki/Transformationssatz) mit Hilfe der [Funktionaldeterminante](https://de.m.wikipedia.org/wiki/Funktionaldeterminante) det $J$ berechnen. Die [Jacobi-Matrix](https://de.m.wikipedia.org/wiki/Jacobi-Matrix) für die Transformation von den Koordinaten $\\left\\{x_{1}, x_{2}, x_{3}\\right\\}$ zu $\\left\\{x_{1}^{\\prime}, x_{2}^{\\prime}, x_{3}^{\\prime}\\right\\}$ ist hierbei definiert durch\n",
        "\n",
        ">$\n",
        "J=\\frac{\\partial\\left(x_{1}, x_{2}, x_{3}\\right)}{\\partial\\left(x_{1}^{\\prime}, x_{2}^{\\prime}, x_{3}^{\\prime}\\right)}\n",
        "$\n",
        "\n",
        "* Das Volumenelement ist dann gegeben durch\n",
        "\n",
        ">$\n",
        "\\mathrm{d} V^{\\prime}=|\\operatorname{det} J| \\mathrm{d} x_{1}^{\\prime} \\mathrm{d} x_{2}^{\\prime} \\mathrm{d} x_{3}^{\\prime}\n",
        "$\n",
        "\n",
        "* Aus mathematischer Sicht ist **eine Volumenform auf einer $n$-dimensionalen Mannigfaltigkeit eine nirgends verschwindende Differentialform vom Grad $n$**. Im Fall einer orientierten riemannschen Mannigfaltigkeit ergibt sich eine kanonische Volumenform aus der verwendeten Metrik, die den Wert 1 auf einer positiv orientierten Orthonormalbasis annimmt. Diese wird [Riemann'sche Volumenform](https://de.m.wikipedia.org/wiki/Hodge-Stern-Operator#Riemannsche_Volumenform) genannt (Hodge-Stern-Operator in der Differentialgeometrie)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujcsbmyfEJDt"
      },
      "source": [
        "**Koordinatentransformation**\n",
        "\n",
        "https://de.wikipedia.org/wiki/Differentialgeometrie#Koordinatentransformationen\n",
        "\n",
        "* Fur die Berechnung des Flächen- oder Volumenintegrals eine geeignete Substitutionsfunktion zu finden ist nicht trivial. Sie transformiert das Volumenintegral oft von einem Koordinatensystem in ein anderes, um die Berechnung zu vereinfachen oder überhaupt zu ermöglichen. \n",
        "\n",
        "* Bei der Integration über geometrische Objekte ist es sogar oft unpraktisch, über kartesische Koordinaten zu integrieren. So lässt sich in der Physik das Integral über ein radialsymmetrisches Potentialfeld, dessen Wert nur von einem Radius r abhängt, wesentlich leichter in Kugelkoordinaten berechnen. Um dies zu tun, wendet man eine Koordinatentransformation $\\Phi$  an.\n",
        "\n",
        "* Um dies zu tun, wendet man eine Koordinatentransformation $\\Phi$ an. Nach dem [Transformationssatz](https://de.wikipedia.org/wiki/Transformationssatz) gilt dann in diesem Beispiel:\n",
        "\n",
        "> $\n",
        "\\int_{\\Omega} U(\\vec{r}) d V=\\int_{\\Phi^{-1}(\\Omega)} U(\\Phi(r, \\theta, \\varphi)) \\cdot|\\operatorname{det} D \\Phi(r, \\theta, \\varphi)| \\mathrm{d} r \\mathrm{~d} \\theta \\mathrm{d} \\varphi\n",
        "$\n",
        "\n",
        "* Der vektorielle Faktor ist das [Spatprodukt](https://de.wikipedia.org/wiki/Spatprodukt) aller partiellen Ableitungen von $\\vec{\\xi}(u, v, w)$\n",
        "\n",
        "> $\n",
        "\\vec{N}=\\left(\\frac{\\partial \\vec{\\xi}}{\\partial u} \\times \\frac{\\partial \\vec{\\xi}}{\\partial v}\\right) \\cdot \\frac{\\partial \\vec{\\xi}}{\\partial w}\n",
        "$\n",
        "\n",
        "Generell lassen sich Spatprodukte auch als Determinanten schreiben, so gilt hier:\n",
        "\n",
        "> $\n",
        "\\vec{N}=\\left(\\frac{\\partial \\vec{\\xi}}{\\partial u} \\times \\frac{\\partial \\vec{\\xi}}{\\partial v}\\right) \\cdot \\frac{\\partial \\vec{\\xi}}{\\partial w}=\\operatorname{det}\\left(\\frac{\\partial \\vec{\\xi}}{\\partial u} \\frac{\\partial \\vec{\\xi}}{\\partial v} \\frac{\\partial \\vec{\\xi}}{\\partial w}\\right)=\\operatorname{det}\\left(J_{\\vec{\\xi}}\\right)\n",
        "$\n",
        "\n",
        "Die aneinandergereihten partiellen Gradienten $(\\vec{\\xi}$ ist eine vektorwertige Funktion)\n",
        "formen gerade die Elemente der $3 \\times 3$ Jacobi-Matrix. Die zugehörige Jacobi-Determinante, auch als [**Funktionaldeterminante**](https://de.wikipedia.org/wiki/Funktionaldeterminante) bezeichnet, berechnet genau den\n",
        "zusätzlichen Faktor für eine Koordinatentransformation.\n",
        "\n",
        "Ist das Volumenelement skalar, reduziert sich der Faktor auf dessen euklidische Norm $\\|\\vec{N}\\| .$ Nachdem das Volumenintegral parametrisiert ist, kann mit Hilfe des [Satzes von Fubini](https://de.wikipedia.org/wiki/Satz_von_Fubini) das Integral Schritt für Schritt berechnet werden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCrJh93jH1D-"
      },
      "source": [
        "**Transformationssatz**\n",
        "\n",
        "* Der [Transformationssatz](https://de.wikipedia.org/wiki/Transformationssatz) (auch Transformationsformel) beschreibt in der Analysis das Verhalten von Integralen unter Koordinatentransformationen. Er ist somit die Verallgemeinerung der Integration durch Substitution auf Funktionen höherer Dimensionen. \n",
        "\n",
        "* Der Transformationssatz wird als Hilfsmittel bei der Berechnung von Integralen verwendet, wenn sich das Integral nach Überführung in ein anderes Koordinatensystem leichter berechnen lässt.\n",
        "\n",
        "* Es sei $\\Omega \\subseteq \\mathbb{R}^{d}$ eine offene Menge und $\\Phi: \\Omega \\rightarrow \\Phi(\\Omega) \\subseteq \\mathbb{R}^{d}$ ein [Diffeomorphismus](https://de.wikipedia.org/wiki/Diffeomorphismus) (=eine bijektive, stetig differenzierbare Abbildung, deren Umkehrabbildung auch stetig differenzierbar ist). Dann ist die Funktion $f$ auf $\\Phi(\\Omega)$ genau dann integrierbar, wenn die Funktion $x \\mapsto f(\\Phi(x)) \\cdot|\\operatorname{det}(D \\Phi(x))|$ auf $\\Omega$ integrierbar ist. In diesem Fall gilt:\n",
        "\n",
        "> $\n",
        "\\int_{\\Phi(\\Omega)} f(y) \\mathrm{d} y=\\int_{\\Omega} f(\\Phi(x)) \\cdot|\\operatorname{det}(D \\Phi(x))| \\mathrm{d} x\n",
        "$\n",
        "\n",
        "* Dabei ist $D \\Phi(x)$ die Jacobi-Matrix und $\\operatorname{det}(D \\Phi(x))$ die Funktionaldeterminante von $\\Phi$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUDAAXziE4Pj"
      },
      "source": [
        "**Funktionaldeterminante**\n",
        "\n",
        "* Die [Funktionaldeterminante oder Jacobi-Determinante](https://de.wikipedia.org/wiki/Funktionaldeterminante) ist eine mathematische Größe, die in der mehrdimensionalen Integralrechnung, also der Berechnung von **Oberflächen- und Volumenintegralen**, eine Rolle spielt. Insbesondere findet sie in der [Flächenformel](https://de.wikipedia.org/wiki/Flächenformel) und dem aus dieser hervorgehenden Transformationssatz Verwendung.\n",
        "\n",
        "* [Exkurs Determinante](https://de.wikipedia.org/wiki/Determinante): *die Determinante eine Zahl (ein Skalar), die einer quadratischen Matrix zugeordnet wird und aus ihren Einträgen berechnet werden kann. Sie gibt an, wie sich das **Volumen (oder der Flächeninhalt)** bei der durch die Matrix beschriebenen linearen Abbildung ändert*\n",
        "\n",
        "* **Lokales Verhalten einer Funktion**: Die Funktionaldeterminante gibt zu einem gegebenen Punkt wichtige Informationen über das Verhalten der Funktion $f$ in der Nähe dieses Punktes. \n",
        "\n",
        "  * Wenn beispielsweise die Funktionaldeterminante einer stetig differenzierbaren Funktion in einem Punkt $p$ ungleich null ist, so ist die Funktion in einer Umgebung von $p$ invertierbar. \n",
        "  \n",
        "  * Weiterhin gilt, dass bei positiver Determinante in $p$ die Funktion ihre Orientierung beibehält und bei negativer Funktionaldeterminante die Orientierung umkehrt. \n",
        "  \n",
        "  * Der absolute Wert der Determinante im Punkt $p$ gibt den Wert an, mit dem die Funktion in der Nähe von $p$ expandiert oder schrumpft.\n",
        "\n",
        "* Für eine differenzierbare Funktion $f: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{n}$ ist die Funktionaldeterminante definiert als die Determinante der Jacobi-Matrix von $f,$ also als\n",
        "det $D f(x)$\n",
        "mit\n",
        "\n",
        "> $\n",
        "D f(x)=\\left(\\frac{\\partial f_{i}}{\\partial x_{j}}(x)\\right)_{i, j=1, \\ldots, n}\n",
        "$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8Aix1sXHVnV"
      },
      "source": [
        "**Beispiel: Polarkoordinaten**\n",
        "\n",
        "**1. Koordinatentransformation**: Die Umrechnungsformeln von Polarkoordinaten in kartesische Koordinaten lauten:\n",
        "\n",
        "> $\n",
        "\\begin{array}{l}\n",
        "x=r \\cos \\varphi \\\\\n",
        "y=r \\sin \\varphi\n",
        "\\end{array}\n",
        "$\n",
        "\n",
        "**2. Funktionaldeterminante** lautet also:\n",
        "\n",
        "> $\n",
        "\\operatorname{det} \\frac{\\partial(x, y)}{\\partial(r, \\varphi)}=\\operatorname{det}\\left(\\begin{array}{ll}\n",
        "\\frac{\\partial x}{\\partial r} & \\frac{\\partial x}{\\partial \\varphi} \\\\\n",
        "\\frac{\\partial y}{\\partial r} & \\frac{\\partial y}{\\partial \\varphi}\n",
        "\\end{array}\\right)=\\operatorname{det}\\left(\\begin{array}{cc}\n",
        "\\cos \\varphi & -r \\sin \\varphi \\\\\n",
        "\\sin \\varphi & r \\cos \\varphi\n",
        "\\end{array}\\right)=r \\cdot(\\cos \\varphi)^{2}+r \\cdot(\\sin \\varphi)^{2}=r\n",
        "$\n",
        "\n",
        "**3. Flächen- oder Volumenintegral**: Folglich ergibt sich für das Flächenelement $\\mathrm{d} A$ (alternativ kann man bei dreidimensionalen Kugelkoordinaten an dieser Stelle auch das Volumenelement $\\mathrm {d} V$ mit der Funktionaldeterminante berechnen):\n",
        "\n",
        "> $\n",
        "\\mathrm{d} A=\\left|\\operatorname{det} \\frac{\\partial(x, y)}{\\partial(r, \\varphi)}\\right| \\mathrm{d} r \\mathrm{~d} \\varphi=r \\mathrm{~d} r \\mathrm{~d} \\varphi\n",
        "$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NB7LHkmNm_3"
      },
      "source": [
        "## **Differentialgeometrie**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjZH2A2rUEuE"
      },
      "source": [
        "#### **Allgemeine Relativitätstheorie**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfF3aeOkUNTk"
      },
      "source": [
        "* Gravitation als geometrische Eigenschaft der gekrümmten vierdimensionalen Raumzeit. \n",
        "\n",
        "* Zur Beschreibung der **Raumzeit und ihrer Krümmung bedient man sich der Differentialgeometrie**, die die Euklidische Geometrie des uns vertrauten „flachen“ dreidimensionalen Raumes der klassischen Mechanik umfasst und erweitert. \n",
        "\n",
        "* Die Differentialgeometrie verwendet zur Beschreibung gekrümmter Räume, wie der Raumzeit der ART, sogenannte **Mannigfaltigkeiten**. Wichtige **Eigenschaften werden mit sogenannten Tensoren beschrieben**, die Abbildungen auf der Mannigfaltigkeit darstellen.\n",
        "\n",
        "* Die gekrümmte Raumzeit wird als [Lorentz-Mannigfaltigkeit](https://de.wikipedia.org/wiki/Pseudo-riemannsche_Mannigfaltigkeit) (Pseudo-riemannsche Mannigfaltigkeit) beschrieben.\n",
        "\n",
        "* Eine besondere Bedeutung kommt dem [**metrischen Tensor**](https://de.wikipedia.org/wiki/Metrischer_Tensor) zu. Wenn man in den metrischen Tensor zwei Vektorfelder einsetzt, erhält man für jeden Punkt der Raumzeit eine reelle Zahl. \n",
        "\n",
        "  * In dieser Hinsicht kann man den metrischen Tensor als ein verallgemeinertes, punktabhängiges Skalarprodukt für Vektoren der Raumzeit verstehen. \n",
        "  \n",
        "  * Mit seiner Hilfe werden Abstand und Winkel definiert und er wird daher kurz als Metrik bezeichnet.\n",
        "\n",
        "* Ebenso bedeutend ist der [riemannsche Krümmungstensor](https://de.wikipedia.org/wiki/Riemannscher_Krümmungstensor) zur Beschreibung der Krümmung der Mannigfaltigkeit, \n",
        "\n",
        "  * der eine Kombination von ersten und zweiten Ableitungen des metrischen Tensors darstellt. \n",
        "\n",
        "  * Wenn ein beliebiger Tensor in irgendeinem Koordinatensystem in einem Punkt nicht null ist, kann man überhaupt kein Koordinatensystem finden, sodass er in diesem Punkt null wird. Dies gilt dementsprechend auch für den Krümmungstensor. \n",
        "  \n",
        "  * Umgekehrt ist der Krümmungstensor in allen Koordinatensystemen null, wenn er in einem Koordinatensystem null ist. Man wird also in jedem Koordinatensystem bezüglich der Frage, ob eine Mannigfaltigkeit an einem bestimmten Punkt gekrümmt ist oder nicht, zum gleichen Ergebnis gelangen.\n",
        "\n",
        "* Die maßgebliche Größe zur Beschreibung von Energie und Impuls der Materie ist der [Energie-Impuls-Tensor](https://de.wikipedia.org/wiki/Energie-Impuls-Tensor). Dieser Tensor bestimmt die Krümmungseigenschaften der Raumzeit. Siehe auch [Vierertensor](https://de.wikipedia.org/wiki/Vierertensor)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSwla15AVisJ"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Allgemeine_Relativitätstheorie#Mathematische_Beschreibung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BytRtSdcUHyV"
      },
      "source": [
        "#### **Normal Plane**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aanVl5irUQJK"
      },
      "source": [
        "The plane spanned by the normal vector N and the binormal vector B.\n",
        "\n",
        "* A [normal plane](https://en.wikipedia.org/wiki/Normal_plane_(geometry)#Normal_section) is any plane containing the normal vector of a surface at a particular point.\n",
        "\n",
        "* The normal plane also refers to the plane that is perpendicular to the tangent vector of a space curve; (this plane also contains the normal vector) see Frenet–Serret formulas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pKD7BJYUnsw"
      },
      "source": [
        "*Saddle surface with **normal planes** in directions of **principal curvatures**:*\n",
        "\n",
        "![gg](https://upload.wikimedia.org/wikipedia/commons/e/eb/Minimal_surface_curvature_planes-en.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k22NIZrbWOwi"
      },
      "source": [
        "*(a) Normal section of a surface. The surface crops out at points A and B , distance 2 d apart. The distance depends on the radius of curvature, r , and the distance between the tangent plane and the section plane, h . (b) In the section plane, the distances d 1 and d 2 are in a ratio that relates to the ratio of the values of :*\n",
        "\n",
        "![jj](https://raw.githubusercontent.com/deltorobarba/repo/master/normalsection.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlkflU-7U5Pq"
      },
      "source": [
        "**Normal section**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28Jtij1DU7k8"
      },
      "source": [
        "* The normal section of a surface at a particular point is the curve produced by the intersection of that surface with a normal plane\n",
        "\n",
        "* The curvature of the normal section is called the normal curvature.\n",
        "\n",
        "* If the surface is bow or cylinder shaped the maximum and the minimum of these curvatures are the principal curvatures.\n",
        "\n",
        "* If the surface is saddle shaped the maxima of both sides are the principal curvatures.\n",
        "\n",
        "* The product of the principal curvatures is the Gaussian curvature of the surface. (negative for saddle shaped surfaces)\n",
        "\n",
        "* The mean of the principal curvatures is the mean curvature of the surface, if (and only if) the mean curvature is zero the surface is a minimal surface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Png5YeQyXlTB"
      },
      "source": [
        "> At any point on a surface, we can find a normal vector that is at right angles to the surface; planes containing the normal vector are called normal planes. The intersection of a normal plane and the surface will form a curve called a **normal section** and the curvature of this curve is the **normal curvature**. **For most points on most surfaces, different normal sections will have different curvatures; the maximum and minimum values of these are called the principal curvatures, call these κ1, κ2.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tsnx4brGUDMS"
      },
      "source": [
        "**Normal**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3D7Xf8X1Rqx"
      },
      "source": [
        "* In geometry, a [normal](https://en.wikipedia.org/wiki/Normal_(geometry)) is an object such as a line, ray, or vector that is perpendicular to a given object. \n",
        "\n",
        "* For example, in two dimensions, **the normal line to a curve at a given point is the line perpendicular to the tangent line to the curve at the point**. \n",
        "\n",
        "* A normal vector may have \n",
        "\n",
        "  * length one (a unit vector) or \n",
        "  * its length may represent the curvature of the object, a [curvature vector](https://en.wikipedia.org/wiki/Differentiable_curve#Normal_or_curvature_vector),\n",
        "  * its algebraic sign may indicate sides (interior or exterior).\n",
        "\n",
        "* In three dimensions, a surface normal, or simply normal, to a surface at point P is a vector perpendicular to the tangent plane of the surface at P. \n",
        "\n",
        "* The word \"normal\" is also used as an adjective: a line normal to a plane, the normal component of a force, the normal vector, etc. \n",
        "\n",
        "* **The concept of normality generalizes to orthogonality (right angles)**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJCi6my82Bbn"
      },
      "source": [
        "*A normal to a surface at a point is the same as a normal to the tangent plane to the surface at the same point.*\n",
        "\n",
        "![fgggg](https://upload.wikimedia.org/wikipedia/commons/5/53/Surface_normal_illustration.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvkOBed02VoA"
      },
      "source": [
        "* The concept has been generalized to differentiable manifolds of arbitrary dimension embedded in a Euclidean space. The normal vector space or normal space of a manifold at point P is the set of vectors which are orthogonal to the tangent space at P. \n",
        "\n",
        "* Normal vectors are of special interest in the case of smooth curves (Differential curves) and smooth surfaces (Differential geometry of surfaces).\n",
        "\n",
        "* The normal is often used in 3D computer graphics (notice the singular, as only one normal will be defined) to determine a surface's orientation toward a light source for flat shading, or the orientation of each of the surface's corners (vertices) to mimic a curved surface with Phong shading.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VxxuqYf584k"
      },
      "source": [
        "*A vector field of normals to a surface*\n",
        "\n",
        "![hh](https://upload.wikimedia.org/wikipedia/commons/c/cc/Surface_normals.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlHA616e37Da"
      },
      "source": [
        "*Choice of normal*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89yLCoM7389W"
      },
      "source": [
        "* The normal to a (hyper)surface is usually scaled to have unit length, **but it does not have a unique direction, since its opposite is also a unit normal**. \n",
        "\n",
        "* For a surface which is the topological boundary of a set in three dimensions, one can **distinguish between the inward-pointing normal and outer-pointing normal**. \n",
        "\n",
        "* For an oriented surface, the normal is usually determined by the **right-hand rule** or its analog in higher dimensions.\n",
        "\n",
        "* **If the normal is constructed as the cross product of tangent vectors (as described in the text above), it is a [pseudovector](https://en.wikipedia.org/wiki/Pseudovector).**\n",
        "\n",
        "  * a pseudovector (or axial vector) is a quantity that transforms like a vector under a proper rotation, **but in three dimensions gains an additional sign flip under an improper rotation such as a reflection**. \n",
        "  \n",
        "  * Geometrically, the direction of a reflected pseudovector is opposite to its mirror image, but with equal magnitude. In contrast, the reflection of a true (or polar) vector is exactly the same as its mirror image.\n",
        "\n",
        "  * Ein Pseudovektor, auch Drehvektor, Axialvektor oder axialer Vektor genannt, ist in der Physik eine [vektorielle Größe](https://de.wikipedia.org/wiki/Vektorielle_Größe), die bei einer Punktspiegelung des betrachteten physikalischen Systems ihre Richtung beibehält. Im Gegensatz dazu kehren polare oder Schubvektoren bei einer Punktspiegelung ihre Richtung um.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_OSJC0c44eM"
      },
      "source": [
        "*Der Drehimpuls L als Beispiel eines Pseudovektors: während der Ortsvektor r und Impuls m·v bei einer Punktspiegelung ihre Richtung umkehren, bleibt die des Drehimpulses L=m·r×v unverändert.*\n",
        "\n",
        "![gjgjg](https://upload.wikimedia.org/wikipedia/commons/a/af/Angular_momentum_as_pseudo-vector.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhCnyEAjgscS"
      },
      "source": [
        "**Mannigfaltigkeit**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "833Uwx-OgKLn"
      },
      "source": [
        "Unter einer [Mannigfaltigkeit](https://de.wikipedia.org/wiki/Mannigfaltigkeit) versteht man in der Mathematik einen topologischen Raum, der lokal dem euklidischen Raum \n",
        "$\\mathbb {R} ^{n}$ gleicht. Global muss die Mannigfaltigkeit jedoch nicht einem euklidischen Raum gleichen (nicht zu ihm homöomorph sein).\n",
        "\n",
        "> Siehe auch: [Klassifizierung und Invarianten von Mannigfaltigkeiten](https://de.wikipedia.org/wiki/Mannigfaltigkeit#Klassifizierung_und_Invarianten_von_Mannigfaltigkeiten)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF5KxIxPhpOD"
      },
      "source": [
        "**Topologische Mannigfaltigkeiten**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL2c5EqKhIbY"
      },
      "source": [
        "Sei $M$ ein topologischer Raum. Man nennt $M$ eine (topologische) Mannigfaltigkeit der Dimension $n$ oder kurz eine $n$ -Mannigfaltigkeit, falls die folgenden Eigenschaften erfüllt werden:\n",
        "\n",
        "1. $M$ ist ein Hausdorff-Raum.\n",
        "\n",
        "2. $M$ erfüllt das zweite Abzählbarkeitsaxiom.\n",
        "\n",
        "3. $M$ ist lokal euklidisch, das heißt, jeder Punkt besitzt eine Umgebung, \n",
        "\n",
        "welche homöomorph zu einer offenen Teilmenge des $\\mathbb{R}^{n}$ ist.\n",
        "Mannigfaltigkeiten erben viele lokale Eigenschaften vom Euklidischen Raum: sie sind lokal wegzusammenhängend, lokalkompakt und lokal metrisierbar. Mannigfaltigkeiten, welche homöomorph zueinander sind, werden als gleich (beziehungsweise äquivalent) angesehen. Daraus entstand die Frage nach der Klassifikation, also die Frage, wie viele nicht äquivalente Mannigfaltigkeiten es gibt.\n",
        "\n",
        "> **Um differenzierbare Funktionen zu betrachten, reicht die Struktur einer topologischen Mannigfaltigkeit nicht aus.** Dafur braucht man eine Differenzierbare Mannigfaltigkeiten."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDgn-dFcg7Gq"
      },
      "source": [
        "**Differenzierbare Mannigfaltigkeit (Einleitung)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCEr54z3-xiI"
      },
      "source": [
        "* [Differenzierbare Mannigfaltigkeiten](https://de.wikipedia.org/wiki/Differenzierbare_Mannigfaltigkeit) sind ein Oberbegriff für Kurven, Flächen und andere geometrische Objekte, die – aus der Sicht der Analysis – lokal aussehen wie ein [euklidischer Raum](https://de.m.wikipedia.org/wiki/Euklidischer_Raum) (differenzierbare Mannigfaltigkeiten sind per Definition lokal diffeomorph zum euklidischen Raum)\n",
        "\n",
        "* Im Unterschied zu topologischen Mannigfaltigkeiten ist es auf differenzierbaren Mannigfaltigkeiten möglich, über Ableitungen und verwandte Konzepte zu sprechen. \n",
        "\n",
        "* Sie spielen auch eine zentrale Rolle in der Differentialgeometrie, der Differentialtopologie, in der theoretischen Physik, insbesondere in der klassischen Mechanik bei Systemen, die Zwangsbedingungen unterliegen, und bei der Beschreibung der Raumzeit in der allgemeinen Relativitätstheorie.\n",
        "\n",
        "* Es gibt zwei Herangehensweisen an differenzierbare Mannigfaltigkeiten: \n",
        "\n",
        "  * einerseits als Teilmengen eines höherdimensionalen euklidischen Raumes, die entweder durch Gleichungen oder durch [Parametrisierungen](https://de.wikipedia.org/wiki/Parameterdarstellung) beschrieben sind und im Artikel [Untermannigfaltigkeit des $\\mathbb {R} ^{n}$](https://de.wikipedia.org/wiki/Untermannigfaltigkeit_des_ℝn) behandelt werden, und \n",
        "  \n",
        "  * andererseits als abstrakte Mannigfaltigkeiten, deren differenzierbare Struktur durch einen [Atlas](https://de.wikipedia.org/wiki/Atlas_(Mathematik)) gegeben ist. \n",
        "  \n",
        "* Die Äquivalenz der beiden Sichtweisen wird durch den [Einbettungssatz von Whitney](https://de.m.wikipedia.org/wiki/Einbettungssatz_von_Whitney) sichergestellt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30lmkM3NcjcD"
      },
      "source": [
        "**Karte & differenzierbarer Atlas**\n",
        "\n",
        "Eine Karte eines topologischen Raums $M$ ist ein Paar $(U, \\phi)$ bestehend aus einer in $M$ offenen, nichtleeren Menge $U \\subseteq M$ und einem Homöomorphismus\n",
        "\n",
        ">$\n",
        "\\phi: U \\rightarrow \\phi(U) \\subseteq \\mathbb{R}^{n}\n",
        "$\n",
        "\n",
        "Sind $(U, \\phi)$ und $(V, \\psi)$ zwei Karten von $M$ mit $U \\cap V \\neq \\emptyset$, so nennt man die Abbildung\n",
        "\n",
        ">$\n",
        "\\psi \\circ \\phi^{-1}: \\phi(U \\cap V) \\rightarrow \\psi(U \\cap V)\n",
        "$\n",
        "\n",
        "einen Kartenwechsel. \n",
        "\n",
        "Ein Atlas für $M$ ist dann eine Familie $\\left(U_{i}, \\phi_{i}\\right)_{i \\in I}$ von Karten ( $I$ ist eine Indexmenge), so dass \n",
        "\n",
        ">$M=\\bigcup_{i \\in I} U_{i}$\n",
        "\n",
        "gilt. Man nennt einen Atlas $C^{k}$ -differenzierbar mit $k \\geq 1$, wenn alle seine Kartenwechsel $C^{k}$ Diffeomorphismen sind."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-PvvyXXc-3M"
      },
      "source": [
        "**Differenzierbare Struktur**\n",
        "\n",
        "* Zwei $C^{k}$ -differenzierbare Atlanten sind äquivalent, wenn auch ihre Vereinigung ein $C^{k}$. differenzierbarer Atlas ist. \n",
        "\n",
        "* Eine Äquivalenzklasse von Atlanten bezüglich dieser Äquivalenzrelation wird $C^{k}$ -differenzierbare Struktur der Mannigfaltigkeit genannt.\n",
        "\n",
        "* Ist $k=\\infty$, so spricht man auch von einer glatten Struktur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwCQ-9PCa7ao"
      },
      "source": [
        "**Differenzierbare Mannigfaltigkeit (Definition)**\n",
        "\n",
        "> Eine k-mal differenzierbare Mannigfaltigkeit ist ein topologischer [Hausdorffraum](https://de.wikipedia.org/wiki/Hausdorff-Raum) (=ein [topologischer Raum](https://de.wikipedia.org/wiki/Topologischer_Raum) $M$, in dem das [Trennungsaxiom](https://de.wikipedia.org/wiki/Trennungsaxiom) $T_{2}$), der das zweite Abzählbarkeitsaxiom erfüllt, zusammen mit einer \n",
        "$C^{k}$-differenzierbaren Struktur. Die differenzierbare Mannigfaltigkeit hat die Dimension \n",
        "n, wenn eine Karte und damit alle Karten in eine Teilmenge des $\\mathbb {R} ^{n}$ abbilden.\n",
        "\n",
        "> Eine differenzierbare Mannigfaltigkeit mit einer riemannschen Metrik heißt [Riemannsche Mannigfaltigkeit](https://de.wikipedia.org/wiki/Mannigfaltigkeit#Riemannsche_Mannigfaltigkeiten). (*Um auf einer differenzierbaren Mannigfaltigkeit von Längen, Abständen, Winkeln und Volumen zu sprechen, benötigt man eine zusätzliche Struktur. Eine Riemannsche Metrik (auch Metrischer Tensor genannt) definiert im Tangentialraum jedes Punktes der Mannigfaltigkeit ein Skalarprodukt.*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNQWJEs2by72"
      },
      "source": [
        "**Glatte Mannigfaltigkeit**\n",
        "\n",
        "Eine [glatte Mannigfaltigkeit](https://de.wikipedia.org/wiki/Differenzierbare_Mannigfaltigkeit#Glatte_Mannigfaltigkeit) ist ebenfalls ein topologischer Hausdorffraum, der das zweite Abzählbarkeitsaxiom erfüllt, zusammen mit einer glatten Struktur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO_Pg9paZmuJ"
      },
      "source": [
        "**Beispiele**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7h8OWfZZpz6"
      },
      "source": [
        "* Der euklidische Vektorraum $\\mathbb {R} ^{n}$ kann auch als n-dimensionale differenzierbare Mannigfaltigkeit verstanden werden. Einen differenzierbaren Atlas bestehend aus einer Karte erhält man mittels der identischen Abbildung.\n",
        "\n",
        "* Das wahrscheinlich einfachste, aber nichttriviale Beispiel einer differenzierbaren Mannigfaltigkeit ist die \n",
        "n-dimensionale Sphäre. Die zweidimensionale Sphäre kann man sich als Hülle einer Kugel vorstellen. Einen differenzierbaren Atlas der Sphäre erhält man schon mit Hilfe von zwei Karten beispielsweise mit Hilfe der [stereographischen Projektion](https://de.wikipedia.org/wiki/Stereografische_Projektion) (=eine Abbildung einer Kugelfläche in eine Ebene mit Hilfe einer Zentralprojektion, deren Projektionszentrum (PZ) auf der Kugel liegt). Auf der Sphäre ist es allerdings je nach Dimension möglich, unterschiedliche nicht kompatible differenzierbare Atlanten zu definieren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_ny37AvMYht"
      },
      "source": [
        "#### **Differenzierbare Kurven (Frenet-Frame)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOgMn-z5Nt1c"
      },
      "source": [
        "**Definition**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms1yMaabTBGv"
      },
      "source": [
        "* Differenzierbare Kurven deals with [smooth curves](https://en.wikipedia.org/wiki/Differentiable_curve) in the plane and the Euclidean space by methods of differential and integral calculus.\n",
        "\n",
        "* Background: Many [specific curves](https://en.wikipedia.org/wiki/List_of_curves) have been thoroughly investigated using the [synthetic approach](https://en.wikipedia.org/wiki/Synthetic_geometry). \n",
        "\n",
        "> Differential geometry takes another path: curves are represented in a parametrized form, and their geometric properties and various quantities associated with them, such as the **curvature and the arc length, are expressed via derivatives and integrals using vector calculus**. \n",
        "\n",
        "* One of the most important tools used to analyze a curve is the **Frenet frame**, a moving frame that provides a coordinate system at each point of the curve that is \"best adapted\" to the curve near that point.\n",
        "\n",
        "* The theory of curves is much simpler and narrower in scope than the theory of surfaces and its higher-dimensional generalizations **because a regular curve in a Euclidean space has no intrinsic geometry**.\n",
        "\n",
        "* Any regular curve may be parametrized by the arc length (the natural parametrization). \n",
        "\n",
        "* From the point of view of a theoretical point particle on the curve that does not know anything about the ambient space, all curves would appear the same. Different space curves are only distinguished by how they bend and twist. Quantitatively, this is **measured by the differential-geometric invariants called the curvature and the torsion of a curve**. The [fundamental theorem of curves](https://en.wikipedia.org/wiki/Fundamental_theorem_of_curves) asserts that the knowledge of these invariants completely determines the curve.\n",
        "\n",
        "  * the fundamental theorem of space curves states that every regular curve in three-dimensional space, with non-zero curvature, has its shape (and size) completely determined by its [curvature (Krümmung)](https://en.wikipedia.org/wiki/Curvature) and [torsion (Windung)](https://en.wikipedia.org/wiki/Torsion_of_a_curve).\n",
        "\n",
        "  * **A curve can be described, and thereby defined, by a pair of scalar fields: curvature $\\kappa$  and torsion $\\tau$**, both of which depend on some parameter which parametrizes the curve but which can ideally be the arc length of the curve. \n",
        "  \n",
        "  * From just the curvature and torsion, the vector fields for the tangent, normal, and binormal vectors can be derived using the Frenet–Serret formulas. Then, integration of the tangent field (done numerically, if not analytically) yields the curve.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX3ON_EN5pTt"
      },
      "source": [
        "See also: https://en.wikipedia.org/wiki/Curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92sEhWjv5raF"
      },
      "source": [
        "**Definition**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvCIjsaD6Cdo"
      },
      "source": [
        "A parametric $C^{r}$ -curve or a $C^{r}$ - parametrization is a vector-valued function\n",
        "\n",
        ">$\\gamma: I \\rightarrow \\mathbb{R}^{n}$\n",
        "\n",
        "that is $r$ -times continuously differentiable (that is, the component functions of $\\gamma$ are continuously differentiable), where $n \\in \\mathbb{N}, r \\in \\mathbb{N} \\cup\\{\\infty\\},$ and $I$ be a non-empty interval of real numbers. \n",
        "\n",
        "* The image of the parametric curve is $\\gamma[I] \\subseteq \\mathbb{R}^{n}$. **The parametric curve $\\gamma$ and its image $\\gamma[I]$ must be distinguished because a given subset of $\\mathbb{R}^{n}$ can be the image of several distinct parametric curves.** \n",
        "\n",
        "* The parameter $t$ in $\\gamma(t)$ can be thought of as representing time, and $\\gamma$ the trajectory of a moving point in space. When $I$ is a closed interval $[a, b], \\gamma(a)$ is called the starting point and $\\gamma(b)$ is the endpoint of $\\gamma$. \n",
        "\n",
        "* If the starting and the end points coincide (that is, $\\gamma(a)=\\gamma(b)$ ), then $\\gamma$ is a closed curve or a loop. For being a $C^{r}$ -loop, the function $\\gamma$ must be $r$ -times continuously differentiable and satisfy $\\gamma^{(k)}(a)=\\gamma^{(k)}(b)$ for $0 \\leq k \\leq r$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNxVQ6gtIMSA"
      },
      "source": [
        "**Re-parametrization and equivalence relation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6ZP368nIHOm"
      },
      "source": [
        "* Given the image of a parametric curve, there are several different parametrizations of the parametric curve. \n",
        "\n",
        "* **Differential geometry aims to describe the properties of parametric curves that are invariant under certain reparametrizations**. \n",
        "\n",
        "  *  A suitable equivalence relation on the set of all parametric curves must be defined.\n",
        "  \n",
        "  * The differential-geometric properties of a parametric curve (such as its length, its Frenet frame, and its generalized curvature) are invariant under reparametrization and therefore properties of the equivalence class itself. \n",
        "  \n",
        ">  **The equivalence classes are called $C$<sup>r</sup>-curves and are central objects studied in the differential geometry of curves.**\n",
        "\n",
        "Two parametric $C^{r}$ -curves, $\\gamma_{1}: I_{1} \\rightarrow \\mathbb{R}^{n}$ and $\\gamma_{2}: I_{2} \\rightarrow \\mathbb{R}^{n}$, are\n",
        "said to be equivalent if and only if there exists a bijective $C^{r}$ -map $\\varphi: I_{1} \\rightarrow I_{2}$ such that\n",
        "\n",
        ">$\n",
        "\\forall t \\in I_{1}: \\quad \\varphi^{\\prime}(t) \\neq 0\n",
        "$\n",
        "\n",
        "and\n",
        "\n",
        ">$\n",
        "\\forall t \\in I_{1}: \\quad \\gamma_{2}(\\varphi(t))=\\gamma_{1}(t)\n",
        "$\n",
        "\n",
        "$\\gamma_{2}$ is then said to be a re-parametrization of $\\gamma_{1}$.\n",
        "\n",
        "Re-parametrization defines an equivalence relation on the set of all parametric $C^{r}$ -curves of class $C^{r}$. The equivalence class of this\n",
        "relation simply a $C^{r}$ -curve.\n",
        "An even finer equivalence relation of oriented parametric $C^{r}-$ curves can be defined by requiring $\\varphi$ to satisfy $\\varphi^{\\prime}(t)>0$.\n",
        "\n",
        "Equivalent parametric $C^{r}$ -curves have the same image, and equivalent oriented parametric $C^{r}$ -curves even traverse the image in the same direction.\n",
        "\n",
        "More details [see here](https://en.wikipedia.org/wiki/Differentiable_curve#Re-parametrization_and_equivalence_relation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKPlaOka4I4Y"
      },
      "source": [
        "**Osculating circle**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogZDs9mH4Ka1"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Osculating_circle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTEBfB0u5Utc"
      },
      "source": [
        "defines the curvature of the given curve at that point"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2H6Xr532xIw"
      },
      "source": [
        "**Frenet–Serret formulas ('Frenet-Frame')**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGmwoXZW8EXe"
      },
      "source": [
        "![ghjg](https://upload.wikimedia.org/wikipedia/commons/3/32/Frenet_frame.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr9uTAz_8Jy7"
      },
      "source": [
        "*An illustration of the Frenet frame for a point on a space curve. T is the unit tangent, P the unit normal, and B the unit binormal (=cross product of T and P).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0O6_rZSbKgi"
      },
      "source": [
        "* The [Frenet frame](https://en.m.wikipedia.org/wiki/Frenet–Serret_formulas), see also [Moving Frame](https://en.wikipedia.org/wiki/Moving_frame), and the generalized curvatures are invariant under reparametrization and are therefore differential geometric properties of the curve.\n",
        "\n",
        "* A Frenet frame is a [moving reference frame](https://en.wikipedia.org/wiki/Moving_frame) of $n$\n",
        "orthonormal vectors $e_{i}(t)$ which are used to describe a curve locally at each point $\\gamma(t)$. \n",
        "\n",
        "* **It is the\n",
        "main tool in the differential geometric treatment of\n",
        "curves because it is far easier and more natural to\n",
        "describe local properties (e.g. curvature, torsion)\n",
        "in terms of a local reference system than using a\n",
        "global one such as Euclidean coordinates**.\n",
        "\n",
        "* The Frenet–Serret frame is a moving frame defined on a curve which can be constructed purely from the velocity and acceleration of the curve.\n",
        "\n",
        "* The Frenet–Serret frame plays a key role in the differential geometry of curves, ultimately leading to a more or less complete classification of smooth curves in Euclidean space up to [congruence (Geometry](https://en.wikipedia.org/wiki/Congruence_(geometry)).\n",
        "\n",
        "* The Frenet–Serret formulas show that **there is a pair of functions defined on the curve**, the torsion and curvature, which are **obtained by differentiating the frame**, and which describe completely how the frame evolves in time along the curve. A key feature of the general method is that a preferred moving frame, provided it can be found, gives a complete kinematic description of the curve.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMEsN5NIDBAU"
      },
      "source": [
        "Given a $C^{n+1}$ -curve $\\gamma$ in $\\mathbb{R}^{n}$ which is regular of order $n$ the Frenet frame for the curve is the set of orthonormal\n",
        "vectors\n",
        "\n",
        ">$\n",
        "\\mathbf{e}_{1}(t), \\ldots, \\mathbf{e}_{n}(t)\n",
        "$\n",
        "\n",
        "called Frenet vectors. They are constructed from the derivatives of $\\gamma(t)$\n",
        "using the [Gram-Schmidt orthogonalization](https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process) algorithm with\n",
        "\n",
        ">$\n",
        "\\begin{aligned}\n",
        "\\mathbf{e}_{1}(t) &=\\frac{\\gamma^{\\prime}(t)}{\\left\\|\\gamma^{\\prime}(t)\\right\\|} \\\\\n",
        "\\mathbf{e}_{j}(t) &=\\frac{\\overline{\\mathbf{e}_{j}}(t)}{\\left\\|\\overline{\\mathbf{e}_{j}}(t)\\right\\|}, \\quad \\overline{\\mathbf{e}_{j}}(t)=\\gamma^{(j)}(t)-\\sum_{i=1}^{j-1}\\left\\langle\\gamma^{(j)}(t), \\mathbf{e}_{i}(t)\\right\\rangle \\mathbf{e}_{i}(t)\n",
        "\\end{aligned}\n",
        "$\n",
        "\n",
        "The Frenet frame and the generalized curvatures are invariant under reparametrization and are therefore differential geometric properties of the curve.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oajgE5hNDsvE"
      },
      "source": [
        "![hh](https://upload.wikimedia.org/wikipedia/commons/0/01/FrenetTN.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvFJgS2eErsD"
      },
      "source": [
        "*The $\\mathrm{T}$ and $\\mathrm{N}$ vectors at two points on a plane curve, a translated version of the second frame (dotted), and the change in $\\mathrm{T}: \\delta \\mathrm{T}^{\\prime}$. $\\delta$ s is the distance between the points. In the limit $\\frac{d \\mathrm{~T}}{d s}$ will be in the direction $\\mathrm{N}$ and the curvature describes the speed of rotation of the frame.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro0O-zcGIYcL"
      },
      "source": [
        "The **tangent unit vector** $\\mathrm{T}$ is defined as\n",
        "\n",
        ">$\n",
        "\\mathbf{T}=\\frac{d \\mathbf{r}}{d s}\n",
        "$\n",
        "\n",
        "*If a curve γ represents the path of a particle, then the instantaneous **velocity** of the particle at a given point P is expressed by a vector, called the tangent vector to the curve at P.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JItjWzs-Ia0a"
      },
      "source": [
        "\n",
        "The **normal unit vector** $\\mathrm{N}$ is defined as\n",
        "\n",
        ">$\n",
        "\\mathbf{N}=\\frac{\\frac{d \\mathbf{T}}{d s}}{\\left\\|\\frac{d \\mathbf{T}}{d s}\\right\\|} .\n",
        "$\n",
        "\n",
        "*The normal vector, sometimes called the **curvature** vector, indicates the deviance of the curve from being a straight line.*\n",
        "\n",
        "Note that by calling curvature $\\kappa=\\left\\|\\frac{d \\mathbf{T}}{d s}\\right\\|$ we automatically obtain the first relation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCXP45eqFIKA"
      },
      "source": [
        "The **binormal unit vector** $\\mathrm{B}$ is defined as the cross product of $\\mathrm{T}$ and $\\mathrm{N}$ :\n",
        "$\\mathbf{B}=\\mathbf{T} \\times \\mathbf{N}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJdvLG5bMVZj"
      },
      "source": [
        "**See more details about all three here**: https://en.wikipedia.org/wiki/Differentiable_curve#Special_Frenet_vectors_and_generalized_curvatures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py9xY6DxIrnX"
      },
      "source": [
        "*Example of a moving Frenet basis (T in blue, N in green, B in purple) along [Viviani's curve](https://en.wikipedia.org/wiki/Viviani%27s_curve):*\n",
        "\n",
        "![ggg](https://upload.wikimedia.org/wikipedia/commons/1/14/Frenet-Serret-frame_along_Vivani-curve.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1J7uj68Idoa"
      },
      "source": [
        "**The three unit vectors T, N, and B are all perpendicular to each other.** The Frenet–Serret formulas are a set of ordinary differential equations of first order. The solution is the set of Frenet vectors describing the curve specified by the generalized curvature functions χi. The Frenet-Serret formulas are:\n",
        "\n",
        ">$\n",
        "\\begin{array}{lc}\n",
        "\\frac{d \\mathbf{T}}{d s}= & \\kappa \\mathbf{N} \\\\\n",
        "\\frac{d \\mathbf{N}}{d s}=-\\kappa \\mathbf{T} & \\quad+\\tau \\mathbf{B} \\\\\n",
        "\\frac{d \\mathbf{B}}{d s}= & -\\tau \\mathbf{N}\n",
        "\\end{array}\n",
        "$\n",
        "\n",
        "where $\\kappa$ is the curvature and $\\tau$ is the torsion.\n",
        "\n",
        "See more details: https://en.wikipedia.org/wiki/Frenet%E2%80%93Serret_formulas#Definitions\n",
        "\n",
        "Special Cases:\n",
        "\n",
        "* If the curvature is always zero then the curve will be a straight line. Here the vectors N, B and the torsion are not well defined.\n",
        "\n",
        "* If the torsion is always zero then the curve will lie in a plane.\n",
        "\n",
        "* A helix has constant curvature and constant torsion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFNOxgfQFpf-"
      },
      "source": [
        "![ggg](https://upload.wikimedia.org/wikipedia/commons/8/87/Frenetframehelix.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqKfzRVoFtam"
      },
      "source": [
        "*The Frenet-Serret frame moving along a helix. The T is represented by the blue arrow, N is represented by the red arrow while B is represented by the black arrow.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btiOrMfFJgr7"
      },
      "source": [
        "* The Frenet–Serret frame consisting of the tangent T, normal N, and binormal B collectively forms an **orthonormal basis of 3-space**. At each point of the curve, this attaches a frame of reference or rectilinear coordinate system\n",
        "\n",
        "* The Frenet–Serret formulas admit a **kinematic interpretation**. Imagine that an observer moves along the curve in time, using the attached frame at each point as their coordinate system. The Frenet–Serret formulas mean that this coordinate system is constantly rotating as an observer moves along the curve. Hence, this coordinate system is always [non-inertial](https://en.wikipedia.org/wiki/Non-inertial_reference_frame) (*A non-inertial reference frame is a frame of reference that undergoes acceleration with respect to an inertial frame*). The angular momentum of the observer's coordinate system is proportional to the Darboux vector of the frame.\n",
        "\n",
        "* In the life sciences, particularly in models of microbial motion, considerations of the Frenet-Serret frame have been used to explain the mechanism by which a moving organism in a viscous medium changes its direction.\n",
        "\n",
        "* In physics, the Frenet-Serret frame is useful when it is impossible or inconvenient to assign a natural coordinate system for a trajectory. Such is often the case, for instance, in relativity theory. Within this setting, Frenet-Serret frames have been used to model the precession of a gyroscope in a gravitational well.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE74j4-aKEpe"
      },
      "source": [
        "*On the example of a torus knot, the tangent vector T, the normal vector N, and the binormal vector B, along with the curvature κ(s), and the torsion τ(s) are displayed. \n",
        "At the peaks of the torsion function the rotation of the Frenet-Serret frame (T,N,B) around the tangent vector is clearly visible.*\n",
        "\n",
        "![ggg](https://upload.wikimedia.org/wikipedia/commons/7/70/Torus-Knot_nebeneinander_animated.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtv7pXEfKfuo"
      },
      "source": [
        "Repeatedly differentiating the curve and applying the Frenet–Serret formulas gives the following Taylor approximation to the curve near s = 0:\n",
        "\n",
        "> $\\mathbf{r}(s)=\\mathbf{r}(0)+\\left(s-\\frac{s^{3} \\kappa^{2}(0)}{6}\\right) \\mathbf{T}(0)+\\left(\\frac{s^{2} \\kappa(0)}{2}+\\frac{s^{3} \\kappa^{\\prime}(0)}{6}\\right) \\mathbf{N}(0)+\\left(\\frac{s^{3} \\kappa(0) \\tau(0)}{6}\\right) \\mathbf{B}(0)+o\\left(s^{4}\\right)$\n",
        "\n",
        "See [more here](https://en.wikipedia.org/wiki/Frenet–Serret_formulas#Taylor_expansion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxFO_aPZK1_M"
      },
      "source": [
        "**Ribbons and tubes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr1tqJ0oK4dO"
      },
      "source": [
        "The Frenet–Serret apparatus allows one to define certain optimal ribbons and tubes centered around a curve. These have diverse applications in materials science and elasticity theory, as well as to computer graphics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLOKEYj7K7QS"
      },
      "source": [
        "*A ribbon defined by a curve of constant torsion and a highly oscillating curvature. The arc length parameterization of the curve was defined via integration of the Frenet-Serret equations.*\n",
        "\n",
        "![hhh](https://upload.wikimedia.org/wikipedia/commons/d/dd/Ribbon-Frenet.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w82qUiRLMGz"
      },
      "source": [
        "**Congruence of curves**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDaontSfLOWx"
      },
      "source": [
        "* In classical Euclidean geometry, one is interested in studying the properties of figures in the plane which are invariant under congruence, so that if two figures are congruent then they must have the same properties. The Frenet-Serret apparatus presents the curvature and torsion as numerical invariants of a space curve.\n",
        "\n",
        "* Roughly speaking, two curves C and C′ in space are congruent if one can be rigidly moved to the other. A rigid motion consists of a combination of a translation and a rotation. A translation moves one point of C to a point of C′. The rotation then adjusts the orientation of the curve C to line up with that of C′. Such a combination of translation and rotation is called a Euclidean motion. In terms of the parametrization r(t) defining the first curve C, a general [Euclidean motion](https://en.wikipedia.org/wiki/Rigid_transformation) of C is a composite of the following operations:\n",
        "\n",
        "  * (Translation) r(t) → r(t) + v, where v is a constant vector.\n",
        "\n",
        "  * (Rotation) r(t) + v → M(r(t) + v), where M is the matrix of a rotation.\n",
        "\n",
        "* The Frenet–Serret frame is particularly well-behaved with regard to Euclidean motions. First, since T, N, and B can all be given as successive derivatives of the parametrization of the curve, each of them is insensitive to the addition of a constant vector to r(t). Intuitively, the TNB frame attached to r(t) is the same as the TNB frame attached to the new curve r(t) + v.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7N9Drp8MaU_"
      },
      "source": [
        "#### **Differenzierbare Oberflächen (Gaussian Curvature for $\\mathbb{R}^{3}$)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9B0-W5pOH1j"
      },
      "source": [
        "##### **Summary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxCVvgA_N8cJ"
      },
      "source": [
        "**Intrinsic vs Extrinsic Properties**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdXxyd9VNBzy"
      },
      "source": [
        "* [Differential geometry of surfaces (smooth surfaces)](https://en.wikipedia.org/wiki/Differential_geometry_of_surfaces) deals with the differential geometry of smooth surfaces with various additional structures, most often, a Riemannian metric.\n",
        "\n",
        "* What's so special? Surfaces have been extensively studied from various perspectives: \n",
        "\n",
        "  * extrinsically, relating to their embedding in Euclidean space and \n",
        "  \n",
        "  * intrinsically, reflecting their properties determined solely by the distance within the surface as measured along curves on the surface.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qQSKka7Rbns"
      },
      "source": [
        "**Intrinsic Properties**\n",
        "\n",
        "* intrinsic geometry of a surface: the properties which are determined only by the geodesic distances between points on the surface independently of the particular way in which the surface is located in the ambient Euclidean space.\n",
        "  \n",
        "* One of the fundamental concepts investigated is the [Gaussian curvature](https://en.m.wikipedia.org/wiki/Gaussian_curvature), first studied in depth by Carl Friedrich Gauss, who showed that curvature was an intrinsic property of a surface, independent of its isometric embedding in Euclidean space.\n",
        "\n",
        "* Surfaces naturally arise as graphs of functions of a pair of variables, and sometimes appear in parametric form or as loci associated to space curves. \n",
        "\n",
        "* An important role in their study has been played by Lie groups (in the spirit of the Erlangen program), namely the [symmetry groups](https://en.m.wikipedia.org/wiki/Symmetry_group) of the Euclidean plane, the sphere and the hyperbolic plane. \n",
        "\n",
        "* **These Lie groups can be used to describe surfaces of constant Gaussian curvature**; they also provide an essential ingredient in the modern approach to intrinsic differential geometry through [connections](https://en.m.wikipedia.org/wiki/Connection_(mathematics))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wST7YUpRZ4D"
      },
      "source": [
        "**Extrinsic Properties**\n",
        "\n",
        "* On the other hand, extrinsic properties relying on an embedding of a surface in Euclidean space have also been extensively studied. \n",
        "\n",
        "* This is well illustrated by the non-linear [Euler–Lagrange equations](https://en.m.wikipedia.org/wiki/Euler–Lagrange_equation) in the [calculus of variations](https://en.m.wikipedia.org/wiki/Calculus_of_variations): although Euler developed the one variable equations to understand [geodesics](https://en.m.wikipedia.org/wiki/Geodesic), defined independently of an embedding, one of Lagrange's main applications of the two variable equations was to [minimal surfaces](https://en.m.wikipedia.org/wiki/Minimal_surface), a concept that can only be defined in terms of an embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuGMPwNrTZRE"
      },
      "source": [
        "**Summary of Differential geometry of surfaces (smooth surfaces)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBm-zkuiTLWf"
      },
      "source": [
        "* The essential mathematical object is that of a regular surface (form a general class of subsets of three-dimensional Euclidean space ℝ3). \n",
        "\n",
        "* By analyzing the class of curves which lie on such a surface, and the **degree to which the surfaces force them to curve in ℝ3**, one can associate to each point of the surface two numbers, called the **principal curvatures**. Their average is called the  **mean curvature** of the surface, and their product is called the **Gaussian curvature**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7hRCbiWTq7p"
      },
      "source": [
        "There are many classic examples of regular surfaces, including:\n",
        "\n",
        "* familiar examples such as planes, cylinders, and spheres\n",
        "minimal surfaces, which are defined by the property that their mean curvature is zero at every point. The best-known examples are catenoids and helicoids, although many more have been discovered. \n",
        "\n",
        "* Minimal surfaces can also be defined by properties to do with surface area, with the consequence that they provide a mathematical model for the shape of soap films when stretched across a wire frame\n",
        "\n",
        "* [ruled surfaces](https://en.m.wikipedia.org/wiki/Ruled_surface), which are surfaces that have at least one straight line running through every point; examples include the cylinder and the hyperboloid of one sheet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKX-RkKKUBvU"
      },
      "source": [
        "A surprising result of Carl Friedrich Gauss, known as the theorema egregium, showed that the Gaussian curvature of a surface, which by its definition has to do with how curves on the surface change directions in three dimensional space, \n",
        "\n",
        "* can actually be measured by the lengths of curves lying on the surfaces together with the angles made when two curves on the surface intersect. Terminologically, this says that the Gaussian curvature can be calculated from the **first fundamental form**, also called [metric tensor](https://en.m.wikipedia.org/wiki/Metric_tensor) of the surface.\n",
        "\n",
        "* The **second fundamental form**, by contrast, is an object which encodes how lengths and angles of curves on the surface are distorted when the curves are pushed off of the surface.\n",
        "\n",
        "* Despite measuring different aspects of length and angle, the **first and second fundamental forms are not independent from one another**, and they satisfy certain constraints called the **Gauss-Codazzi equations**. A major theorem, often called the **fundamental theorem of the differential geometry of surfaces**, asserts that whenever two objects satisfy the Gauss-Codazzi constraints, they will arise as the first and second fundamental forms of a regular surface.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C_KtXkhVbkx"
      },
      "source": [
        "Using the first fundamental form, it is possible to **define new objects on a regular surface**. \n",
        "\n",
        "  * Geodesics are curves on the surface which satisfy a certain second-order ordinary differential equation which is specified by the first fundamental form. \n",
        "  \n",
        "  * They are very directly connected to the study of lengths of curves; a geodesic of sufficiently short length will always be the curve of shortest length on the surface which connects its two endpoints. \n",
        "  \n",
        "  * Thus, geodesics are fundamental to the optimization problem of determining the shortest path between two given points on a regular surface.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOkBoADKVMAa"
      },
      "source": [
        "One can also define **parallel transport** along any given curve, \n",
        "\n",
        "  * which gives a prescription for how to deform a tangent vector to the surface at one point of the curve to tangent vectors at all other points of the curve. \n",
        "  \n",
        "  * The prescription is determined by a first-order [ordinary differential equation](https://en.m.wikipedia.org/wiki/Ordinary_differential_equation) which is specified by the first fundamental form."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF1bKk70Vj4a"
      },
      "source": [
        "The above concepts are essentially all to do with multivariable calculus. The **Gauss-Bonnet theorem** is a more global result, which relates the Gaussian curvature of a surface together with its topological type. It asserts that **the average value of the Gaussian curvature is completely determined by the Euler characteristic of the surface together with its surface area**.\n",
        "\n",
        "The notion of **Riemannian manifold and Riemann surface are two generalizations of the regular surfaces discussed above**. \n",
        "\n",
        "  * In particular, essentially all of the theory of regular surfaces as discussed here has a generalization in the theory of Riemannian manifolds. \n",
        "  \n",
        "  * This is not the case for Riemann surfaces, although every regular surface gives an example of a Riemann surface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMa5zbOiRpJX"
      },
      "source": [
        "**First and second fundamental forms, shape operator, and Gaussian / Mean / Principle curvature(s***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjFSF5W7bNgX"
      },
      "source": [
        "http://wordpress.discretization.de/geometryprocessingandapplicationsws19/a-quick-and-dirty-introduction-to-the-curvature-of-surfaces/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SRtr-gkR1tP"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Differential_geometry_of_surfaces#First_and_second_fundamental_forms,_the_shape_operator,_and_the_curvature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Tk5O4qb6l_"
      },
      "source": [
        "Source: https://www.researchgate.net/figure/Measures-of-surface-curvature-a-The-principal-curvatures-are-calculated-from-the_fig6_321165318\n",
        "\n",
        "![jj](https://raw.githubusercontent.com/deltorobarba/repo/master/gaussiancurvature.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5b2Y8K9go3V"
      },
      "source": [
        "##### **Principal curvature, Gaussian curvature, Shape Operator, Weingarten Map, Darboux_frame, Covariant Derivatives, First & Second Fundamental Form, Christoffel symbols & Isometry**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg-aCsfN3OL-"
      },
      "source": [
        "[a-quick-and-dirty-introduction-to-the-curvature-of-surfaces](http://wordpress.discretization.de/geometryprocessingandapplicationsws19/a-quick-and-dirty-introduction-to-the-curvature-of-surfaces/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkJarn2C5x-p"
      },
      "source": [
        "**Principal curvature**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdJxhVi158i0"
      },
      "source": [
        "* The two [principal curvatures](https://en.m.wikipedia.org/wiki/Principal_curvature) at a given point of a surface are the eigenvalues of the **shape operator** at the point. They measure how the surface bends by different amounts in different directions at that point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LXOfuGk6EV1"
      },
      "source": [
        "![jj](https://upload.wikimedia.org/wikipedia/commons/e/eb/Minimal_surface_curvature_planes-en.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjM66LWvnmXY"
      },
      "source": [
        "* At each point p of a differentiable surface in 3-dimensional Euclidean space one may choose a unit normal vector. \n",
        "\n",
        "  * A normal plane at p is one that contains the normal vector, and will therefore also contain a unique direction tangent to the surface \n",
        "  \n",
        "  * and cut the surface in a plane curve, called **normal section**.\n",
        "  \n",
        "  * This curve will in general have different curvatures for different normal planes at p. \n",
        "  \n",
        "  * **The principal curvatures at p, denoted k1 and k2, are the maximum and minimum values of this curvature.**\n",
        "\n",
        "* Here the curvature of a curve is by definition the [reciprocal](https://en.m.wikipedia.org/wiki/Multiplicative_inverse) of the radius (1/r) of the [osculating circle](https://en.m.wikipedia.org/wiki/Osculating_circle) (defines the curvature of the given curve at that point). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSgpKHRQ5nS3"
      },
      "source": [
        "*An osculating circle (osculating circle of a sufficiently smooth plane curve at a given point p on the curve has been traditionally defined as the circle passing through p and a pair of additional points on the curve infinitesimally close to p. Its center lies on the inner normal line, and its curvature defines the curvature of the given curve at that point)*\n",
        "\n",
        "![hh](https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Osculating_circle.svg/440px-Osculating_circle.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUEqpKJv5ggq"
      },
      "source": [
        "* **The curvature is taken to be positive if the curve turns in the same direction as the surface's chosen normal, and otherwise negative.**\n",
        "\n",
        "* **The directions in the normal plane where the curvature takes its maximum and minimum values are always perpendicular**, if k1 does not equal k2, a result of Euler (1760), and are called **principal directions**. From a modern perspective, this theorem follows from the spectral theorem because these directions are as the principal axes of a symmetric tensor—the second fundamental form. A systematic analysis of the principal curvatures and principal directions was undertaken by Gaston Darboux, using [Darboux frames](https://en.m.wikipedia.org/wiki/Darboux_frame).\n",
        "\n",
        "* The product k1k2 of the two principal curvatures is the Gaussian curvature, K, and the average (k1 + k2)/2 is the mean curvature, H. For a minimal surface, the mean curvature is zero at every point.\n",
        "\n",
        "* **If at least one of the principal curvatures is zero at every point, then the Gaussian curvature will be 0 and the surface is a developable surface**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF5CEpF4nLg5"
      },
      "source": [
        "*Formal definition of principal curvatures* \n",
        "\n",
        "Let $M$ be a surface in Euclidean space with **second fundamental form** $\\Pi(X, Y)$. Fix a point $p \\in M$, and an orthonormal basis $X_{1}, X_{2}$ of tangent vectors at $p$. Then the principal\n",
        "curvatures are the eigenvalues of the symmetric matrix\n",
        "\n",
        ">$\n",
        "\\left[I_{i j}\\right]=\\left[\\begin{array}{ll}\n",
        "\\Pi\\left(X_{1}, X_{1}\\right) & \\Pi\\left(X_{1}, X_{2}\\right) \\\\\n",
        "\\Pi\\left(X_{2}, X_{1}\\right) & \\Pi\\left(X_{2}, X_{2}\\right)\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n",
        "If $X_{1}$ and $X_{2}$ are selected so that the matrix $\\left[I_{i j}\\right]$ is a diagonal matrix, then they are called the principal directions. If the surface is oriented, then one often requires that\n",
        "the pair $\\left(X_{1}, X_{2}\\right)$ be positively oriented with respect to the given orientation.\n",
        "\n",
        "Without reference to a particular orthonormal basis, the principal curvatures are the\n",
        "eigenvalues of the shape operator, and the principal directions are its eigenvectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_z89MITn8Whw"
      },
      "source": [
        "*An example [taken from here](http://wordpress.discretization.de/geometryprocessingandapplicationsws19/a-quick-and-dirty-introduction-to-the-curvature-of-surfaces/)*\n",
        "\n",
        "Along one direction the bottle quickly curves around in a circle; along another direction it’s completely flat and travels along a straight line: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuJ_ijmA8H4l"
      },
      "source": [
        "![gg](https://raw.githubusercontent.com/deltorobarba/repo/master/curvature_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4Z0ktl58YTM"
      },
      "source": [
        "* This way of looking at curvature - in terms of curves traveling along the surface $-$ is often how we treat curvature in general. \n",
        "\n",
        "* In particular, let $X$ be a unit tangent direction at some distinguished point on the surface, and consider a plane containing both $d f(X)$ and the corresponding normal $N$. \n",
        "\n",
        "* This plane intersects the surface in a curve, and the curvature $\\kappa_{n}$ of this curve is called the normal curvature in the direction $X$ (note here also the above mentioned: *curvature of a curve is by definition the reciprocal of the radius (1/r) of the osculating circle*): "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhlByAk38K69"
      },
      "source": [
        "![gg](https://raw.githubusercontent.com/deltorobarba/repo/master/curvature_02.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRN2T3YV8_LJ"
      },
      "source": [
        "Remember the Frenet-Serret formulas (Theorem 1.1)? They tell us that the change in the normal along a curve is given by $d N=\\kappa T+\\tau B$ (with kappa for curvature and tau for torsion). We can therefore get the normal curvature along $X$ by extracting the tangential part of $d N$ :\n",
        "\n",
        ">$\n",
        "\\kappa_{n}(X)=\\frac{d f(X) \\cdot d N(X)}{|d f(X)|^{2}}\n",
        "$\n",
        "\n",
        "The factor $|d f(X)|^{2}$ in the denominator simply normalizes any \"stretching out\" that occurs as we go from the domain $M$ into $\\mathbb{R}^{3}$ - a derivation of this formula can be found in Appendix A. Note\n",
        "that normal curvature is signed, meaning the surface can bend toward the normal or away from it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBl8uT4j8MIM"
      },
      "source": [
        "![gg](https://raw.githubusercontent.com/deltorobarba/repo/master/curvature_03.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJSbRQdU-H3b"
      },
      "source": [
        "* At any given point we can ask: **along which directions does the surface bend the most?** \n",
        "\n",
        "* The unit vectors $X_{1}$ and $X_{2}$ along which\n",
        "we find the maximum and minimum normal curvatures $\\kappa_{1}$ and $\\kappa_{2}$ are called the **principal directions**; the curvatures $\\kappa_{i}$ are called the principal curvatures. \n",
        "\n",
        "* For instance, the beer bottle above might have principal curvatures $\\kappa_{1}=1, \\kappa_{2}=0$ at the marked point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9ft5DKc-wJ3"
      },
      "source": [
        "*Shape Operator and Weingarten Map*\n",
        "\n",
        "* We can also talk about principal curvature in terms of the **shape operator**, which is the unique map $S: T M \\rightarrow T M$ satisfying\n",
        "\n",
        ">$\n",
        "d f(S X)=d N(X)\n",
        "$\n",
        "\n",
        "* for all tangent vectors $X$. **The shape operator $S$ and the Weingarten map $d N$ essentially represent the same idea: they both tell us how the normal changes as we travel along a direction $X$**. \n",
        "\n",
        "* The only difference is that $S$ specifies this change in terms of a tangent vector on $M$, whereas $d N$ gives us the change as a tangent vector in $\\mathbb{R}^{3}$. \n",
        "\n",
        "* It's worth noting that many authors do not make this distinction, and simply assume an isometric identification of tangent vectors on $M$ and the corresponding tangent vectors in $\\mathbb{R}^{3}$. \n",
        "\n",
        "* However, we choose to be more careful so that we can explicitly account for the dependence of various quantities on the immersion $f$ - this dependence becomes particularly important if you actually want to compute something! (By the way, why can we always express the change in $N$ in terms of a tangent vector? It's because iv is the unit normal, hence it cannot grow or shrink in the normal direction.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSIx8Elk-NuN"
      },
      "source": [
        "* One important fact about the principal directions and principal curvatures is that they correspond to eigenvectors and eigenvalues (respectively) of the shape operator:\n",
        "\n",
        ">$\n",
        "S X_{i}=\\kappa_{i} X_{i}\n",
        "$\n",
        "\n",
        "* Moreover, the principal directions are orthogonal with respect to the induced metric: \n",
        "\n",
        "> $g\\left(X_{1}, X_{2}\\right)=d f\\left(X_{1}\\right) \\cdot d f\\left(X_{2}\\right)=0$. \n",
        "\n",
        "* The **principal curvatures therefore tell us everything there is to know about normal curvature at a point**, since we can express any tangent vector $Y$ as a linear combination of the principal directions $X_{1}$ and $X_{2}$.\n",
        "\n",
        "* In particular, if $Y$ is a unit vector offset from $X_{1}$ by an angle $\\theta$, then the associated normal curvature is\n",
        "\n",
        ">$\n",
        "\\kappa_{n}(Y)=\\kappa_{1} \\cos ^{2} \\theta+\\kappa_{2} \\sin ^{2} \\theta\n",
        "$\n",
        "\n",
        "* as you should be able to easily verify using the relationships above. **Often, however, working directly with principal curvatures is fairly inconvenient - especially in the discrete setting**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSxGp792-P9l"
      },
      "source": [
        "*Mean curvature and the Gaussian curvature*\n",
        "\n",
        "* On the other hand, two closely related quantities - called the mean curvature and the Gaussian curvature will show up over\n",
        "and over again (and have some particularly nice interpretations in the discrete world). \n",
        "\n",
        "* The mean curvature $H$ is the arithmetic\n",
        "mean of principal curvatures:\n",
        "\n",
        "> $\n",
        "H=\\frac{\\kappa_{1}+\\kappa_{2}}{2}\n",
        "$\n",
        "\n",
        "* and the Gaussian curvature is the (square of the) geometric mean:\n",
        "\n",
        ">$\n",
        "K=\\kappa_{1} \\kappa_{2}\n",
        "$\n",
        "\n",
        "* What do the values of $H$ and $K$ imply about the shape of the surface? Perhaps the most elementary interpretation is that Gaussian curvature is like a logical \"and\" (is there curvature along both directions?) whereas mean curvature is more like a logical \"or\" (is there curvature along at least one direction?) Of course, you have to be a little careful here since you can also get zero mean curva-\n",
        "ture when $\\kappa_{1}=-\\kappa_{2}$.\n",
        "\n",
        "* It also helps to see pictures of surfaces with zero mean and Gaussian curvature. Zero-curvature surfaces are so well-studied in\n",
        "mathematics that they have special names. Surfaces with zero Gaussian curvature are called **developable surfaces** because they can be \"developed\" or flattened out into the plane without any\n",
        "stretching or tearing. For instance, any piece of a cylinder is developable since one of the principal curvatures is zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4BJc0zN6pNt"
      },
      "source": [
        "**Gaussian Curvature (Kruemmung)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD0dRE-gZwTX"
      },
      "source": [
        "* At any point on a surface, we can find a normal vector that is at right angles to the surface; planes containing the normal vector are called normal planes. \n",
        "\n",
        "* **The intersection of a normal plane and the surface will form a curve called a normal section and the curvature of this curve is the normal curvature**. \n",
        "\n",
        "* For most points on most surfaces, different normal sections will have different curvatures; the maximum and minimum values of these are called the principal curvatures, call these κ1, κ2. \n",
        "\n",
        "* The Gaussian curvature is the product of the two principal curvatures Κ = κ1κ2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDfNQWcS7Hy7"
      },
      "source": [
        "[Gaussian curvature](https://en.wikipedia.org/wiki/Gaussian_curvature), also see [here](https://en.wikipedia.org/wiki/Differential_geometry_of_surfaces#First_and_second_fundamental_forms,_the_shape_operator,_and_the_curvature), is an intrinsic invariant, i.e. invariant under local [isometries](https://en.m.wikipedia.org/wiki/Isometry). **This point of view was extended to higher-dimensional spaces by Riemann and led to what is known today as [Riemannian geometry](https://en.m.wikipedia.org/wiki/Riemannian_geometry).** \n",
        "\n",
        "In differential geometry, the Gaussian curvature or Gauss curvature $K$ of a surface at a point is\n",
        "the product of the principal curvatures, $\\kappa_{1}$ and $\\kappa_{2}$, at the given point:\n",
        "\n",
        ">$\n",
        "K=\\kappa_{1} \\kappa_{2}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfCAULGn6xqY"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Gaussian_curvature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6bT4unv6nS-"
      },
      "source": [
        "*From left to right: a surface of negative Gaussian curvature (hyperboloid), a surface of zero Gaussian curvature (cylinder), and a surface of positive Gaussian curvature (sphere).*\n",
        "\n",
        "![gg](https://upload.wikimedia.org/wikipedia/commons/thumb/6/61/Gaussian_curvature.svg/240px-Gaussian_curvature.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWnL0wFbhVnc"
      },
      "source": [
        "**Gauss Map**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGNBbUmghiG5"
      },
      "source": [
        "* The [Gauss map](https://en.wikipedia.org/wiki/Gauss_map) provides a mapping from every point on a curve or a surface to a corresponding point on a unit sphere\n",
        "\n",
        "* The differential dn of the Gauss map n can be used to define a type of extrinsic curvature, known as the shape operator or Weingarten map.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE8-HMn8hm7w"
      },
      "source": [
        "![jj](https://upload.wikimedia.org/wikipedia/commons/8/8e/Gauss_map.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzu8fN1N6gC8"
      },
      "source": [
        "*See also: [osculating circle](https://en.m.wikipedia.org/wiki/Osculating_circle) (osculating circle of a sufficiently smooth plane curve at a given point p on the curve has been traditionally defined as the circle passing through p and a pair of additional points on the curve infinitesimally close to p. Its center lies on the inner normal line, and its curvature defines the curvature of the given curve at that point)*\n",
        "\n",
        "![hh](https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Osculating_circle.svg/440px-Osculating_circle.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUlA25exWP79"
      },
      "source": [
        "**Shape Operator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_zaMVA6iPlY"
      },
      "source": [
        "* The **differential dn of the Gauss map n** can be used to define a type of **extrinsic curvature**, known as the [**shape operator**](https://en.wikipedia.org/wiki/Differential_geometry_of_surfaces#First_and_second_fundamental_forms,_the_shape_operator,_and_the_curvature) or Weingarten map.\n",
        "\n",
        "* Since at each point $x$ of the surface, the tangent space is an inner product space, the shape operator $S_{x}$ can be defined as a linear operator on this space by the following formula for tangent vectors $v, w$ (the inner product makes sense because $d n(v)$ and $w$ both lie in $\\mathbf{E}^{3}$ ):\n",
        "\n",
        ">$\n",
        "\\left(S_{x} v, w\\right)=(d n(v), w)\n",
        "$\n",
        "\n",
        "* The right hand side is symmetric in $v$ and $w$, so the shape operator is [**self-adjoint**](https://en.wikipedia.org/wiki/Symmetric_matrix) on the tangent space. \n",
        "\n",
        "* The eigenvalues of $S_{x}$ are just the principal curvatures $k_{1}$ and $k_{2}$ at $x$. \n",
        "\n",
        "* In particular **the determinant of the shape operator at a point is the Gaussian curvature**, but it also contains other information, since the mean curvature is half the trace of the shape operator. \n",
        "\n",
        "* The **mean curvature** is an extrinsic invariant. In intrinsic geometry, a cylinder is developable, meaning that every piece of it is intrinsically indistinguishable from a piece of a plane since its Gauss curvature vanishes identically. Its mean curvature is not zero, though; hence extrinsically it is different from a plane.\n",
        "\n",
        "* Equivalently, the shape operator can be defined as a linear operator on tangent spaces, $S_{p}: T_{p} M \\rightarrow T_{p} M$ If $n$ is a unit normal field to $M$ and $v$ is a tangent vector then\n",
        "\n",
        ">$\n",
        "S(v)=\\pm \\nabla_{v} n\n",
        "$\n",
        "\n",
        "* **In general, the eigenvectors and eigenvalues of the shape operator at each point determine the directions in which the surface bends at each point**. The eigenvalues correspond to the principal curvatures of the surface and the eigenvectors are the corresponding principal directions. The principal directions specify the directions that a curve embedded in the surface must travel to have maximum and minimum curvature, these being given by the principal curvatures.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpj2CHEDWnXo"
      },
      "source": [
        "**Mean curvature**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPUvezX2mdwF"
      },
      "source": [
        "* The [mean curvature](https://en.wikipedia.org/wiki/Differential_geometry_of_surfaces#First_and_second_fundamental_forms,_the_shape_operator,_and_the_curvature) H is the arithmetic mean of principal curvatures:\n",
        "\n",
        "> $H=\\frac{\\kappa_{1}+\\kappa_{2}}{2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E08W4HSvmAAp"
      },
      "source": [
        "**Minimal surface**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjWF9uX8mAPr"
      },
      "source": [
        "* A surface is a [minimal surface](https://en.wikipedia.org/wiki/Minimal_surface) / [Minimalfläche](https://de.wikipedia.org/wiki/Minimalfläche) if and only if the **mean curvature is zero**. \n",
        "\n",
        "* Surfaces with zero mean curvature are called minimal surfaces because (as we’ll see later) they minimize surface area (with respect to certain constraints). Minimal surfaces tend to be saddle-like since principal curvatures have equal magnitude but opposite sign:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hbqko_8xo1mo"
      },
      "source": [
        "**Darboux_frame**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtT3ZnBboz_f"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Darboux_frame#Geodesic_curvature,_normal_curvature,_and_relative_torsion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvVJ8EjQX9pR"
      },
      "source": [
        "**Covariant derivatives**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYLkw8QEXT53"
      },
      "source": [
        "https://www.youtube.com/watch?v=BHKd6-IJgVI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTNGBY2Fk40H"
      },
      "source": [
        "* Connections on a surface can be defined from various equivalent but equally important points of view. The Riemannian connection or Levi-Civita connection. is perhaps most easily understood in terms of lifting vector fields, considered as first order differential operators acting on functions on the manifold, to differential operators on the tangent bundle or frame bundle. \n",
        "\n",
        "> In the case of an embedded surface, the lift to an operator on vector fields, called the [**covariant derivative**](https://en.wikipedia.org/wiki/Differential_geometry_of_surfaces#Covariant_derivative), is very simply described in terms of orthogonal projection. \n",
        "\n",
        "* Indeed, a vector field on a surface embedded in R3 can be regarded as a function from the surface into R3. Another vector field acts as a differential operator component-wise. The resulting vector field will not be tangent to the surface, but this can be corrected taking its orthogonal projection onto the tangent space at each point of the surface. As Ricci and Levi-Civita realised at the turn of the twentieth century, this process depends only on the metric and can be locally expressed in terms of the Christoffel symbols.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn1y6WkLZBzR"
      },
      "source": [
        "Covariant derivative of a vector in a given direction:\n",
        "\n",
        "$\\nabla \\frac{\\partial}{\\partial x^{i}} \\vec{v}=\\nabla_{\\vec{e}_{i}} \\vec{v}=\\underbrace{\\left(\\frac{\\partial v^{k}}{\\partial x^{i}}+v^{j} \\Gamma_{i j}^{k}\\right) \\overrightarrow{e_{k}}}$\n",
        "\n",
        "Gammas are connection coefficients:\n",
        "\n",
        "$\\nabla \\overrightarrow{e_{i}} \\overrightarrow{e_{j}}=\\Gamma_{i j}^{k} \\overrightarrow{e_{k}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48web-QoWeP7"
      },
      "source": [
        "**First fundamental form**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo_dvWAtWi0s"
      },
      "source": [
        "* In differential geometry, the [first fundamental form](https://en.wikipedia.org/wiki/Differential_geometry_of_surfaces#First_and_second_fundamental_forms,_the_shape_operator,_and_the_curvature) is the inner product on the tangent space of a surface in three-dimensional Euclidean space which is induced canonically from the dot product of $\\mathbf{R}^{3}$. \n",
        "\n",
        "* It permits the calculation of curvature and metric properties of a surface such as length and area in a manner consistent with the ambient space. The first fundamental form is denoted by the Roman numeral I,\n",
        "\n",
        "> $\\mathrm{I}(x, y)=\\langle x, y\\rangle .$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tYfDMpRWgUC"
      },
      "source": [
        "**Second fundamental form**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Uu_BKh9DF8S"
      },
      "source": [
        "* In differential geometry, the [second fundamental form](https://en.wikipedia.org/wiki/Second_fundamental_form) (or shape tensor), also see [here](https://en.wikipedia.org/wiki/Differential_geometry_of_surfaces#First_and_second_fundamental_forms,_the_shape_operator,_and_the_curvature), is a quadratic form on the tangent plane of a smooth surface in the three-dimensional Euclidean space, usually denoted by $\\mathrm {I\\!I}$ .\n",
        "\n",
        "* Together with the first fundamental form, it serves to define extrinsic invariants of the surface, **its principal curvatures**. More generally, such a quadratic form is defined for a smooth immersed submanifold in a Riemannian manifold.\n",
        "\n",
        "* The second fundamental form at the origin in the\n",
        "coordinates $(x, y)$ is the quadratic form\n",
        "\n",
        ">$\n",
        "L d x^{2}+2 M d x d y+N d y^{2}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0Q1Esn-Xjua"
      },
      "source": [
        "*Definition of second fundamental form*\n",
        "\n",
        "![ggg](https://upload.wikimedia.org/wikipedia/commons/5/5e/Second_fundamental_form.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEd_dn_lXYuA"
      },
      "source": [
        "**Tangent vectors and normal vectors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B13CVbvpLELE"
      },
      "source": [
        "[Source here](https://en.wikipedia.org/wiki/Differential_geometry_of_surfaces#Tangent_vectors_and_normal_vectors)\n",
        "\n",
        "Let $S$ be a regular surface in $\\mathbb{R}^{3}$, and let $p$ be an element of $S$. Using any of the above definitions, one can single out certain vectors in $\\mathbb{R}^{3}$ as being tangent to $S$ at $p$, and certain vectors in $\\mathbb{R}^{3}$ as being orthogonal to $S$ at $p$.\n",
        "\n",
        "* the tangent space to $S$ at $p$, which is defined to consist of all tangent vectors to $S$ at $p$, is a two-dimensional linear subspace of $\\mathbb{R}^{3} ;$ it is often denoted by $T_{p} S .$ \n",
        "\n",
        "* The normal space to $S$ at $p$, which is defined to consist of all normal vectors to $S$ at $p$, is a one-dimensional linear subspace of $\\mathbb{R}^{3}$ which is orthogonal to the tangent space $T_{p} S$. \n",
        "\n",
        "* As such, at each point $p$ of $S$, there are two normal vectors of unit length, called unit normal vectors. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeLv7ZD3XyiE"
      },
      "source": [
        "**Christoffel symbols, Gauss–Codazzi equations, and the Theorema Egregium**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYDwO5vfFpD7"
      },
      "source": [
        "* the [Christoffel symbols](https://en.wikipedia.org/wiki/Christoffel_symbols), also see [here](https://en.wikipedia.org/wiki/Differential_geometry_of_surfaces#Christoffel_symbols,_Gauss–Codazzi_equations,_and_the_Theorema_Egregium), are an array of numbers describing a metric connection. The metric connection is a specialization of the affine connection to surfaces or other manifolds endowed with a metric, allowing distances to be measured on that surface. \n",
        "\n",
        "* In differential geometry, an **affine connection can be defined without reference to a metric**, and many additional concepts follow: parallel transport, covariant derivatives, geodesics, etc. **also do not require the concept of a metric**.\n",
        "\n",
        "* However, when a metric is available, these concepts can be directly tied to the \"shape\" of the manifold itself; **that shape is determined by how the tangent space is attached to the cotangent space by the metric tensor**.\n",
        "\n",
        "* Abstractly, one would say that the manifold has an associated (orthonormal) frame bundle, with each \"frame\" being a possible choice of a coordinate frame. An invariant metric implies that the structure group of the frame bundle is the [orthogonal group O(p, q)](https://en.wikipedia.org/wiki/Orthogonal_group). As a result, such a manifold is necessarily a (pseudo-)Riemannian manifold.\n",
        "\n",
        "> **The Christoffel symbols provide a concrete representation of the connection of (pseudo-)Riemannian geometry in terms of coordinates on the manifold. Additional concepts, such as parallel transport, geodesics, etc. can then be expressed in terms of Christoffel symbols.**\n",
        "\n",
        "* the arrays represented by the Christoffel symbols track how the basis changes from point to poin\n",
        "\n",
        "* For example, in Euclidean spaces, the Christoffel symbols describe how the local coordinate bases change from point to point.\n",
        "\n",
        "* In general, there are an infinite number of metric connections for a given metric tensor; however, there is a unique connection that is free of torsion, the Levi-Civita connection. It is common in physics and general relativity to work almost exclusively with the **Levi-Civita connection**, by working in coordinate frames (called [holonomic coordinates](https://en.wikipedia.org/wiki/Holonomic_basis)) where the torsion vanishes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaecowEfJ4Ba"
      },
      "source": [
        "Let $S$ be a regular surface in $\\mathbb{R}^{3}$. The Christoffel symbols assign, to each local parametrization $f: V \\rightarrow S$, eight functions on $V$, defined by\n",
        "\n",
        ">$\n",
        "\\left(\\begin{array}{cccc}\n",
        "\\Gamma_{11}^{1} & \\Gamma_{12}^{1} & \\Gamma_{21}^{1} & \\Gamma_{22}^{1} \\\\\n",
        "\\Gamma_{11}^{2} & \\Gamma_{12}^{2} & \\Gamma_{21}^{2} & \\Gamma_{22}^{2}\n",
        "\\end{array}\\right)=\\left(\\begin{array}{cc}\n",
        "E & F \\\\\n",
        "F & G\n",
        "\\end{array}\\right)^{-1}\\left(\\begin{array}{cccc}\n",
        "\\frac{1}{2} \\frac{\\partial E}{\\partial u} & \\frac{1}{2} \\frac{\\partial E}{\\partial v} & \\frac{1}{2} \\frac{\\partial E}{\\partial v} & \\frac{\\partial F}{\\partial v}-\\frac{1}{2} \\frac{\\partial G}{\\partial u} \\\\\n",
        "\\frac{\\partial F}{\\partial u}-\\frac{1}{2} \\frac{\\partial E}{\\partial v} & \\frac{1}{2} \\frac{\\partial G}{\\partial u} & \\frac{1}{2} \\frac{\\partial G}{\\partial u} & \\frac{1}{2} \\frac{\\partial G}{\\partial v}\n",
        "\\end{array}\\right)\n",
        "$\n",
        "\n",
        "They can also be defined by the following formulas, in which $n$ is a unit normal vector field along $f(V)$ and $L, M, N$ are the corresponding components of the second fundamental form:\n",
        "\n",
        "$\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial^{2} f}{\\partial u^{2}} &=\\Gamma_{11}^{1} \\frac{\\partial f}{\\partial u}+\\Gamma_{11}^{2} \\frac{\\partial f}{\\partial v}+L n \\\\\n",
        "\\frac{\\partial^{2} f}{\\partial u \\partial v} &=\\Gamma_{12}^{1} \\frac{\\partial f}{\\partial u}+\\Gamma_{12}^{2} \\frac{\\partial f}{\\partial v}+M n \\\\\n",
        "\\frac{\\partial^{2} f}{\\partial v^{2}} &=\\Gamma_{22}^{1} \\frac{\\partial f}{\\partial u}+\\Gamma_{22}^{2} \\frac{\\partial f}{\\partial v}+N n\n",
        "\\end{aligned}\n",
        "$\n",
        "\n",
        "The key to this definition is that $\\frac{\\partial f}{\\partial u}, \\frac{\\partial f}{\\partial v}$, and $n$ **form a basis of $\\mathbb{R}^{3}$ at each point, relative to which each of the three equations uniquely specifies the Christoffel symbols as coordinates of the second partial derivatives of $f$**. The choice of unit normal has no effect on the Christoffel symbols, since if $n$ is exchanged for its negation, then the components of the second fundamental form are also negated, and so the signs of $L n, M n, N n$ are left unchanged."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuQjfl72NRi8"
      },
      "source": [
        "**Isometrie (Riemannsche Geometrie)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsYv-6m2X50e"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Differential_geometry_of_surfaces#Isometries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EClMFa51VzC4"
      },
      "source": [
        "* In der Differentialgeometrie bezeichnet man Abbildungen als lokale [Isometrien](https://de.wikipedia.org/wiki/Isometrie_(Riemannsche_Geometrie)), wenn sie die Riemannsche Metrik erhalten. Als Isometrien bezeichnet man Diffeomorphismen, die lokale Isometrien sind.\n",
        "\n",
        "  * Ein [Diffeomorphismus](https://de.wikipedia.org/wiki/Diffeomorphismus) ist eine bijektive, stetig differenzierbare Abbildung, deren Umkehrabbildung auch stetig differenzierbar ist\n",
        "\n",
        "* Beispiel: Die [Isometrien des euklidischen Raumes](https://de.wikipedia.org/wiki/Euklidischer_Raum#Isometrien_2) sind Drehungen, Spiegelungen und Verschiebungen.\n",
        "\n",
        "* Die Isometrien eines metrischen Raumes bilden immer eine Gruppe. \n",
        "\n",
        "  * Steenrod und Myers bewiesen 1939, dass die IsometrieGruppe einer Riemannschen Mannigfaltigkeit immer eine LieGruppe ist (Satz von Myers-Steenrod).\n",
        "Beispiele:\n",
        "\n",
        "  * Die Isometrie-Gruppe der n-dimensionalen [Sphäre](https://de.wikipedia.org/wiki/Sphäre) ist die [orthogonale Gruppe(https://de.wikipedia.org/wiki/Orthogonale_Gruppe) $\\mathrm{O}(\\mathrm{n}+1)$.\n",
        "\n",
        "  * Die Isometrie-Gruppe des n-dimensionalen [hyperbolischen Raumes](https://de.wikipedia.org/wiki/Hyperbolischer_Raum) ist die [Lorentz-Gruppe](https://de.wikipedia.org/wiki/Lorentz-Gruppe) $\\mathrm{O}(\\mathrm{n}, 1)$.\n",
        "\n",
        "  * Die Dimension der Isometriegruppe einer n-dimensionalen kompakten Mannigfaltigkeit ist höchstens $\\frac{1}{2} n(n+1)$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_nEymmONZ6k"
      },
      "source": [
        "**Hodge-Stern-Operator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfy856rnZbiF"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Hodge-Stern-Operator#Riemannsche_Volumenform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shNCWGvR83PM"
      },
      "source": [
        "**Exkurs: Parameterdarstellungen (Parametric equation)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5YVq3SW9b96"
      },
      "source": [
        "Unter einer Parameterdarstellung versteht man in der Mathematik eine Darstellung, bei der die Punkte einer Kurve oder Fläche als Funktion einer oder mehrerer Variablen, der Parameter, durchlaufen werden. Für die Beschreibung einer Kurve in der Ebene oder im Raum wird ein Parameter benötigt, für die Beschreibung einer Fläche ein Satz von zwei Parametern.\n",
        "\n",
        "**Eine Kurve/Fläche mit Parametern zu beschreiben, wird Parametrisierung genannt. Die Zuweisung von konkreten Werten zu den einzelnen Parametern wird Parametrierung genannt**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLes0YF9846T"
      },
      "source": [
        "* [Parameterdarstellungen](https://de.wikipedia.org/wiki/Parameterdarstellung) werden auch in der Differentialgeometrie verwendet. \n",
        "\n",
        "* Mit Hilfe von Ableitungen der Ortsvektoren nach den Parametern lassen sich Längen, Tangentenvektoren oder Tangentialebenen, Krümmungen, Winkel oder Flächeninhalte bestimmen. \n",
        "\n",
        "* Zur Berechnung von Längen, Winkeln und Flächeninhalten in Flächen ist es nicht nötig, eine explizite Parameterdarstellung der Fläche im Raum zu kennen. Es reicht, wenn die Metrik (erste Fundamentalform) der Fläche, die die Längen entlang den Parameterlinien und die Winkel zwischen den Parameterlinien beschreibt, bekannt ist. Dies kann bei gekrümmten Flächen vorteilhaft sein.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0Q3IsUD9T_-"
      },
      "source": [
        "* In der Physik eignet sich die Parameterdarstellung zur Beschreibung der Bahn bewegter Objekte, **wobei meist die Zeit $t$ als Parameter gewählt wird**. \n",
        "\n",
        "  * Die Ableitung des Ortsvektors $\\vec{r}(t)$ nach der Zeit ergibt dann die zeitabhängige Geschwindigkeit $\\vec{v}(t)=\\vec{r}^{\\prime}(t),\n",
        "  * $ die zweite Ableitung die Beschleunigung $\\vec{a}(t)=\\vec{r}^{\\prime \\prime}(t) .$ \n",
        "\n",
        "* Ist umgekehrt eine Anfangsposition $\\vec{r}_{0}$ und Anfangsgeschwindigkeit $\\vec{v}_{0}$ zum Zeitpunkt $t_{0}$ sowie ein (möglicherweise ortsund zeitabhängiges) Beschleunigungsfeld $\\vec{a}(\\vec{r}, t)$ gegeben, erhält man die Parameterdarstellung der Bahnkurve durch Integration. Bei einer konstanten\n",
        "Beschleunigung wie beim schrägen Wurf ohne Luftwiderstand ergibt sich beispielsweise folgende Bahnkurve:\n",
        "\n",
        ">$\n",
        "\\vec{r}(t)=\\vec{r}_{0}+\\vec{v}_{0} \\cdot\\left(t-t_{0}\\right)+\\frac{1}{2} \\vec{a} \\cdot\\left(t-t_{0}\\right)^{2}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0FfxBbbwDc_"
      },
      "source": [
        "##### **Paralleltransport, Zusammenhang, Bündel, Schnitte & Differentialformen**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24ZchbC2SN99"
      },
      "source": [
        "**Paralleltransport**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZjN5CdZYMDm"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Differential_geometry_of_surfaces#Covariant_derivative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uEfr2ybSJ8A"
      },
      "source": [
        "* [Paralleltransport](https://de.wikipedia.org/wiki/Paralleltransport) oder Parallelverschiebung bezeichnet ein Verfahren, geometrische Objekte entlang glatter Kurven in einer Mannigfaltigkeit zu transportieren.\n",
        "\n",
        "* Tullio Levi-Civita erweiterte 1917 die riemannsche Geometrie um diesen Begriff, der dann zur Definition des **Zusammenhangs** führte"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL2YZCFhSmFD"
      },
      "source": [
        "*Paralleltransport eines Vektors auf der Kugeloberfläche entlang eines geschlossenen Weges von A nach $N$ und $\\mathrm{B}$ und wieder zurück nach $\\mathrm{A}$. Der\n",
        "Winkel $\\alpha,$ um den der Vektor dabei gedreht wird, ist proportional zur eingeschlossenen Fläche innerhalb des Weges.*\n",
        "\n",
        "![ggg](https://upload.wikimedia.org/wikipedia/commons/7/7d/Parallel_Transport.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by6-UpZJoqq3"
      },
      "source": [
        "**Connection / Levi-Civita-Zusammenhang & Hauptsatz der riemannschen Geometrie**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjoKdtAzAll-"
      },
      "source": [
        "*Zusammenhang (Connection)*\n",
        "\n",
        "* Der [Zusammenhang](https://de.wikipedia.org/wiki/Zusammenhang_(Differentialgeometrie)) (Connection) ist in der Differentialgeometrie ein Hilfsmittel, um Richtungsänderungen im Laufe einer Bewegung zu quantifizieren und Richtungen in verschiedenen Punkten miteinander in Beziehung zu setzen.\n",
        "\n",
        "* Dieser Artikel behandelt im Wesentlichen den Zusammenhang auf einer differenzierbaren Mannigfaltigkeit beziehungsweise auf einem [Vektorbündel](https://de.wikipedia.org/wiki/Vektorbündel). Ein ausgezeichneter Zusammenhang auf einem Tensorbündel, einem besonderen Vektorbündel, heißt kovariante Ableitung. \n",
        "\n",
        "* Allgemeiner existieren auch [Zusammenhänge auf Prinzipalbündeln](https://de.wikipedia.org/wiki/Zusammenhang_(Prinzipalbündel)) mit analogen definierenden Eigenschaften.\n",
        "\n",
        "* In der Differentialgeometrie interessiert man sich für die Krümmung von Kurven, insbesondere von Geodäten. In euklidischen Räumen ist die Krümmung einfach durch die zweite Ableitung gegeben. \n",
        "\n",
        "* **Auf differenzierbaren Mannigfaltigkeiten ist die zweite Ableitung nicht direkt zu bilden. Ist $\\gamma$ eine Kurve, so muss man für die zweite Ableitung dieser Kurve den Differenzenquotienten mit den Vektoren $\\gamma^{\\prime}(t)$ und $\\gamma^{\\prime}\\left(t_{0}\\right)$ bilden. Diese Vektoren befinden sich jedoch in unterschiedlichen Vektorräumen, daher kann man nicht einfach die Differenz der beiden bilden**. \n",
        "\n",
        "* **Um das Problem zu lösen, hat man eine Abbildung definiert, welche man Zusammenhang nennt. Diese Abbildung soll einen Zusammenhang zwischen den beteiligten Vektorräumen bereitstellen und trägt daher auch diesen Namen**.\n",
        "\n",
        "In diesem Abschnitt bezeichnet $M$ eine glatte Mannigfaltigkeit, $T M$ das Tangentialbündel und $\\pi: E \\rightarrow M$ ein Vektorbündel. Mit $\\Gamma(E)$ wird die Menge der glatten Schnitte im Vektorbündel $E$ notiert.\n",
        "\n",
        "* **Indem man sagt, was die Richtungsableitung eines Vektorfeldes in Richtung eines Tangentialvektors ist, erhält man einen Zusammenhang auf einer differenzierbaren Mannigfaltigkeit $M$**. Demgemäß definiert man einen Zusammenhang auf einem Vektorbündel als eine Abbildung\n",
        "\n",
        ">$\n",
        "\\begin{aligned}\n",
        "\\nabla: \\Gamma(T M) \\times \\Gamma(E) & \\rightarrow \\Gamma(E) \\\\\n",
        "(X, s) & \\mapsto \\nabla_{X} s\n",
        "\\end{aligned}\n",
        "$\n",
        "\n",
        "* die einem Vektorfeld $X$ auf $M$ und einem Schnitt $s$ im Vektorbündel $E$ wieder einen Schnitt in $E$ zuordnet.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxbzAYNlopOj"
      },
      "source": [
        "*Levi-Civita-Zusammenhang*\n",
        "\n",
        "* Der [Levi-Civita-Zusammenhang](https://de.wikipedia.org/wiki/Levi-Civita-Zusammenhang#Hauptsatz_der_riemannschen_Geometrie) ist ein wesentliches Hilfsmittel zum Aufbau der riemannschen Krümmungstheorie. Denn der Krümmungstensor wird mit Hilfe eines Zusammenhangs definiert, daher bietet es sich an, in der riemannschen Geometrie den eindeutig ausgezeichneten Levi-Civita-Zusammenhang für die Definition des riemannschen Krümmungstensors zu verwenden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0F7rh_DFRat"
      },
      "source": [
        "*Anwendungen*\n",
        "\n",
        "Die zentralen Begriffe dieses Artikels betreffen in der Physik u. a. die Allgemeine Relativitätstheorie und die Eichtheorien (z. B. Quantenelektrodynamik, Quantenchromodynamik und Yang-Mills-Theorie) der Hochenergiephysik, sowie in der Festkörperphysik die BCS-Theorie der Supraleitung. Das Gemeinsame an diesen Theorien ist, dass „Zusammenhang“ und „kovariante Ableitung“ durch Vektorpotentiale generiert werden, die gewissen Eichbedingungen genügen, und dass sie explizit in bestimmter Weise in die Energiefunktion des Systems eingehen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hImcbeVim2L"
      },
      "source": [
        "**Vektorbündel, Tensorbündel & Tangentialbündel**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLWvleyYWFoM"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Normal_bundle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "746HzQqAORxv"
      },
      "source": [
        "**Tangentialbündel**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X6nLw_DOUI-"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Tangentialbündel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHFoC8HuPKV5"
      },
      "source": [
        "**Vektorbündel & Tensorbündel**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLtNZ8d0eBNq"
      },
      "source": [
        "* [Vektorbündel](https://de.wikipedia.org/wiki/Vektorbündel) oder manchmal auch Vektorraumbündel sind Familien von Vektorräumen, die **durch die Punkte eines topologischen Raumes parametrisiert sind**.\n",
        "\n",
        "* Vektorbündel gehören damit auch zu den [Faserbündeln](https://de.m.wikipedia.org/wiki/Faserbündel). Remind: Faser ist ein Urbild von einem Element (\"Faser der Abbildung über einem Element\") - surjektiv! kann also mehrere Elemente im Urbild haben. Daher Faser $\\mathbb{R}$<sup>2</sup> zu Punkt auf $\\mathbb{R}$ (siehe [hier](https://de.m.wikipedia.org/wiki/Vektorbündel) die Illustration:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KgzQEwbeRK5"
      },
      "source": [
        "![cc](https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Vectorbundle.svg/320px-Vectorbundle.svg.png)\n",
        "\n",
        "*Illustration des Vektorbündels $(E, B, \\pi)$. Hier ist der **Totalraum** $E=\\mathbb{R}^{2}$ und der **Basisraum** $B=\\mathbb{R} .$ Die Abbildung $\\pi: E \\rightarrow B$ projiziert jede Gerade $E_{x}$ auf den Punkt $x$. Der Raum $E_{x}=\\{p \\in E \\mid \\pi(p)=x\\}$ wird **Faser über $x$** genannt. Außerdem ist der Totalraum $E$ die Vereinigung aller Fasern.* (Comment: also Totalraum E ist Urbild mit Faser und Basisraum B ist Zielbild mit Element das von der Faser stammt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpPiBg4nd_uw"
      },
      "source": [
        "* [Tensorbündel](https://de.m.wikipedia.org/wiki/Tensoranalysis#Tensorbündel) ist ein bestimmtes Vektorbündel. Tensorfelder sind dann besondere glatte Abbildungen, die in dieses Vektorbündel hinein abbilden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76yFULrjPgX5"
      },
      "source": [
        "**Schnitt (Faserbündel)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69bEWfo_PjUV"
      },
      "source": [
        "* [Schnitte](https://de.m.wikipedia.org/wiki/Schnitt_(Faserbündel)) sind Abbildungen, welche in der algebraischen Topologie, insbesondere in der Homotopietheorie, untersucht werden. Insbesondere interessiert man sich dafür, unter welchen Bedingungen solche Abbildungen existieren. \n",
        "\n",
        "* Das bekannteste Beispiel von Schnitten sind die [**Differentialformen**](https://de.m.wikipedia.org/wiki/Differentialform).\n",
        "\n",
        "* Ein Schnitt kann als **Verallgemeinerung des Graphen einer Funktion** aufgefasst werden. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1oJRas2e5yT"
      },
      "source": [
        "![cc](https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Bundle_section.svg/187px-Bundle_section.svg.png)\n",
        "\n",
        "*Die Abbildung s ist ein Schnitt in einem Faserbündel $p: E \\rightarrow B$. Dieser Schnitt s erlaubt es, den Basisraum $B$ mit dem Teilraum $s(B)$ von $E$ zu identifizieren.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZqK7smAzDQF"
      },
      "source": [
        "*Schnittkrümmung*\n",
        "\n",
        "* Die [Schnittkrümmung](https://de.wikipedia.org/wiki/Schnittkrümmung) ist eine Größe der riemannschen Geometrie, eines Teilgebiets der Mathematik. Mit ihrer Hilfe kann man die Krümmung einer n-dimensionalen riemannschen Mannigfaltigkeit beschreiben. \n",
        "\n",
        "* Dabei wird jeder (zweidimensionalen) Ebene im Tangentialraum an einem Punkt dieser Mannigfaltigkeit eine Zahl als Krümmung zugeordnet. Die Schnittkrümmung kann als Verallgemeinerung der gaußschen Krümmung verstanden werden. \n",
        "\n",
        "* Der Name kommt daher, dass man sozusagen einen Schnitt durch die Mannigfaltigkeit in Richtung der gegebenen Ebene legt und die gaußsche Krümmung der so entstandenen Fläche bestimmt.\n",
        "\n",
        "* Siehe weiter unten auch 'Schnitt (Faserbündel)'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4eRWJglr_6-"
      },
      "source": [
        "**Zusammenhang im Tensorbündel**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ggc7g3gsEJx"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Zusammenhang_(Differentialgeometrie)#Zusammenhänge_auf_dem_Tensorbündel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHvXBMnoRB8h"
      },
      "source": [
        "**Differential Form**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxXHLIt6Q70b"
      },
      "source": [
        "* [Differentialform](https://de.wikipedia.org/wiki/Differentialform) erlauben eine koordinatenunabhängige Integration auf allgemeinen orientierten differenzierbaren Mannigfaltigkeiten.\n",
        "\n",
        "* [Youtube Video](https://www.youtube.com/watch?v=CYz_s82JnY8)\n",
        "\n",
        "* Das bekannteste Beispiel von Schnitten sind die Differentialformen.\n",
        "\n",
        "* Beispiele:\n",
        "\n",
        "  * Glatte Funktionen sind 0-Formen.\n",
        "  * Pfaffsche Formen sind 1-Formen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfyrcBqf99Ka"
      },
      "source": [
        "**Glatte Funktionen (Smoothness)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQfcAm-7971y"
      },
      "source": [
        "* Eine [glatte Funktion](https://de.wikipedia.org/wiki/Glatte_Funktion) ist eine mathematische Funktion, die unendlich oft differenzierbar (insbesondere stetig) ist\n",
        "\n",
        "* Zum Beispiel ist jede [holomorphe Funktion](https://de.m.wikipedia.org/wiki/Holomorphe_Funktion) (=in jedem Punkt komplex differenzierbar) auch eine glatte Funktion. Außerdem werden glatte Funktionen als Abschneidefunktionen oder als Testfunktionen für Distributionen verwendet.\n",
        "\n",
        "* Eine Funktion $f: D \\rightarrow \\mathbb{R}$ heißt unendlich oft (stetig) differenzierbar oder glatt, wenn $f \\in C^{n}(D)$ für alle $n \\in \\mathbb{N}$ gilt. Die Menge aller glatten Funktionen auf $D$ wird mit $C^{\\infty}(D)$ notiert und es gilt\n",
        "$\n",
        "C^{\\infty}(D):=\\bigcap_{n \\in \\mathbb{N}} C^{n}(D)\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOySjqTlor8_"
      },
      "source": [
        "#### **Riemannsche Mannigfaltigkeit (Riemanntensor for $\\mathbb{R}^{4}$ and higher)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoh7lWgMNHYS"
      },
      "source": [
        "##### **Riemannsche Geometrie**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-Q_FIsvX-Mn"
      },
      "source": [
        "https://www.youtube.com/watch?v=BHKd6-IJgVI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdkFzxz0ou4f"
      },
      "source": [
        "* Die [riemannsche Geometrie](https://de.m.wikipedia.org/wiki/Riemannsche_Geometrie) ist ein Teilgebiet der Differentialgeometrie. \n",
        "\n",
        "* In dieser Theorie werden die geometrischen Eigenschaften einer [riemannschen Mannigfaltigkeit](https://de.m.wikipedia.org/wiki/Riemannsche_Mannigfaltigkeit) untersucht. \n",
        "\n",
        "* Dies sind [glatte Mannigfaltigkeiten](https://de.m.wikipedia.org/wiki/Differenzierbare_Mannigfaltigkeit#Glatte_Mannigfaltigkeit) mit einer Art [Skalarprodukt](https://de.m.wikipedia.org/wiki/Skalarprodukt). Mit Hilfe dieser Funktion **kann man Winkel, Längen, Abstände und Volumen messen**.\n",
        "\n",
        "* Die ersten Arbeiten der Differentialgeometrie: Gauß begründete die **Theorie der gekrümmten Flächen**, die im dreidimensionalen Raum eingebettet waren.\n",
        "\n",
        "* 1854: Einfuhrung der **riemannschen Metriken**. Im Gegensatz zu Gauß betrachtete er nicht nur Flächen, sondern höherdimensionale, **gekrümmte Räume**. Diese Räume waren jedoch **immer noch in einen euklidischen Raum** eingebettet\n",
        "\n",
        "* Die abstrakte topologische Definition von differenzierbaren und damit insbesondere von riemannschen Mannigfaltigkeiten wurde erst in den 1930er Jahren von Hassler Whitney entwickelt. Besonders bekannt ist die Aussage, dass jede differenzierbare Mannigfaltigkeit eingebettet werden kann. Dieses Resultat ist heute unter dem Namen [Einbettungssatz von Whitney](https://de.m.wikipedia.org/wiki/Einbettungssatz_von_Whitney) bekannt.\n",
        "\n",
        "* Auftrieb erhielt die Theorie durch die allgemeine Relativitätstheorie von Albert Einstein (1916), deren Grundlage die pseudo-riemannschen Mannigfaltigkeiten sind. In diesem Zusammenhang wurde die Theorie insbesondere von Hermann Weyl und Élie Cartan weiterentwickelt, die die Rolle affiner [Zusammenhänge](https://de.m.wikipedia.org/wiki/Zusammenhang_(Differentialgeometrie)) und des [Paralleltransports](https://de.m.wikipedia.org/wiki/Paralleltransport) herausstellten."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IPAiZ28NJWe"
      },
      "source": [
        "##### **Riemannsche Mannigfaltigkeit**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99uS3AoiG7Dp"
      },
      "source": [
        "Gauß’ Theorie der gekrümmten Flächen verwendet eine extrinsische Beschreibung, das heißt, die gekrümmten Flächen werden mit Hilfe eines umgebenden, euklidischen Raumes beschrieben. Riemann vertritt dagegen einen abstrakteren Ansatz (= instrinsic geometry of surfaces).\n",
        "\n",
        "* Eine [riemannsche Mannigfaltigkeit](https://de.wikipedia.org/wiki/Riemannsche_Mannigfaltigkeit) oder ein riemannscher Raum ist **ein Objekt** aus dem mathematischen Teilgebiet der riemannschen Geometrie. \n",
        "\n",
        "* Diese Mannigfaltigkeiten haben die zusätzliche Eigenschaft, dass sie eine **Metrik ähnlich wie ein [Prähilbertraum](https://de.wikipedia.org/wiki/Prähilbertraum) besitzen** (=Vektorraum mit Skalarprodukt). Mit Hilfe dieser riemannschen Metrik lassen sich dann die wesentlichen geometrischen Eigenschaften der Mannigfaltigkeit beschreiben. \n",
        "\n",
        "* So gelten auf jeder riemannschen Mannigfaltigkeit die folgenden, teilweise äquivalenten, Eigenschaften:\n",
        "\n",
        "  * Die kürzesten Strecken zwischen unterschiedlichen Punkten (die sogenannten Geodäten) sind nicht zwingend Geradenstücke, sondern können gekrümmte Kurven sein.\n",
        "\n",
        "  * Die Winkelsumme von Dreiecken kann, im Gegensatz zur Ebene, auch größer (z. B. Kugel) oder kleiner (hyperbolische Räume) als 180° sein.\n",
        "\n",
        "  * Die Parallelverschiebung von Tangentialvektoren entlang geschlossener Kurven kann die Richtung des Vektors ändern.\n",
        "\n",
        "  * Das Ergebnis einer Parallelverschiebung eines Tangentialvektors hängt auch vom Weg ab, entlang dessen der Tangentialvektor verschoben wird.\n",
        "\n",
        "  * Die Krümmung ist im Allgemeinen eine Funktion des Ortes auf der Mannigfaltigkeit.\n",
        "Abstandsmessungen zwischen unterschiedlichen Punkten sind nur mit Hilfe einer Metrik möglich, die vom Ort auf der Mannigfaltigkeit abhängen kann.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXDK0a0XKUH5"
      },
      "source": [
        "Eine riemannsche Mannigfaltigkeit ist eine differenzierbare $n$ -dimensionale Mannigfaltigkeit $M$ mit einer Funktion $g$, die jedem Punkt $p \\in M$ ein Skalarprodukt des Tangentialraums $T_{p} M$ zuordnet, das heißt eine positiv definite, symmetrische Bilinearform\n",
        "\n",
        ">$\n",
        "g_{p}: T_{p} M \\times T_{p} M \\rightarrow \\mathbb{R}\n",
        "$\n",
        "\n",
        "die differenzierbar von $p$ abhängt. \n",
        "\n",
        "Das heißt, bei gegebenen differenzierbaren Vektorfeldern $X, Y \\in \\mathfrak{X}(M)$ ist\n",
        "\n",
        ">$\n",
        "\\begin{aligned}\n",
        "M & \\rightarrow \\mathbb{R} \\\\\n",
        "p & \\mapsto g_{p}\\left(X_{p}, Y_{p}\\right)\n",
        "\\end{aligned}\n",
        "$\n",
        "\n",
        "eine differenzierbare Funktion. Die Funktion $g$ heißt riemannsche Metrik oder auch [metrischer Tensor](https://de.wikipedia.org/wiki/Metrischer_Tensor), ist aber keine Metrik im Sinne der metrischen Räume."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eMSUKSVLX5Y"
      },
      "source": [
        "*Beispiel: Euklidischer Vektorraum*\n",
        "\n",
        "* Ein euklidischer Vektorraum ist isometrisch isomorph zum $\\mathbb{R}^{n}$ mit dem Standardskalarprodukt\n",
        "\n",
        ">$\n",
        "\\left\\langle\\left(x_{1}, \\ldots, x_{n}\\right),\\left(y_{1}, \\ldots, y_{n}\\right)\\right\\rangle=x_{1} y_{1}+\\cdots+x_{n} y_{n}\n",
        "$\n",
        "\n",
        "* Der Vektorraum $\\mathbb{R}^{n}$ kann als differenzierbare Mannigfaltigkeit verstanden werden und zusammen mit dem [Standardskalarprodukt](https://de.wikipedia.org/wiki/Standardskalarprodukt), =positiv definite symmetrische [Bilinearform](https://de.wikipedia.org/wiki/Bilinearform), wird er zu einer riemannschen Mannigfaltigkeit. \n",
        "\n",
        "* In diesem Fall ist der Tangentialraum $T_{x} \\mathbb{R}^{n}$ identisch mit dem Ausgangsraum, also wieder der $\\mathbb{R}^{n}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPt04CAWNpBU"
      },
      "source": [
        "*Beispiel: Induzierte Metrik*\n",
        "\n",
        "* Da das Tangentialbündel $T N$ einer Untermannigfaltigkeit einer riemannschen Mannigfaltigkeit $M$ auch eine Teilmenge des Tangentialbündels $T M$ von $M$ ist, kann die Metrik von $M$ auch auf die Tangentialvektoren der Untermannigfaltigkeit $N$ angewendet werden. \n",
        "\n",
        "* Die so erhaltene Metrik der Untermannigfaltigkeit wird deswegen auch induzierte Metrik genannt. Die Untermannigfaltigkeit $N$ bildet zusammen mit der induzierten Metrik wieder eine riemannsche Mannigfaltigkeit.\n",
        "\n",
        "* Induzierte Metriken finden insbesondere bei der geometrischen Untersuchung von Kurven und Flächen als Untermannigfaltigkeit des $\\mathbb{R}^{n}$ Verwendung."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hkgmdUfS5vs"
      },
      "source": [
        "*Riemannsche Mannigfaltigkeiten als metrische Räume*\n",
        "\n",
        "* Die riemannsche Metrik ist keine Metrik im Sinne der Theorie der metrischen Räume, sondern ein Skalarprodukt. Man kann jedoch ähnlich wie in der Theorie der Skalarprodukträume aus dem Skalarprodukt eine Metrik gewinnen. **Somit können riemannsche Mannigfaltigkeiten als metrische Räume verstanden werden.** \n",
        "\n",
        "* Auf riemannschen Mannigfaltigkeiten sind also im Gegensatz zu differenzierbaren Mannigfaltigen Begriffe wie Abstand, Durchmesser oder Vollständigkeit definiert.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l3_b_nmTQv2"
      },
      "source": [
        "*Abstandsfunktion (riemannsche Metrik)*\n",
        "\n",
        "* Im Folgenden sei $(M, g)$ eine riemannsche Mannigfaltigkeit. Die Abstandsfunktion auf einer (zusammenhängenden) riemannschen Mannigfaltigkeit wird dann definiert durch\n",
        "\n",
        ">$\n",
        "d(x, y):=\\inf \\{L(\\gamma) \\mid \\gamma:[0,1] \\rightarrow M, \\gamma(0)=x, \\gamma(1)=y\\}\n",
        "$\n",
        "\n",
        "* Dabei durchläuft $\\gamma$ alle (stückweise) differenzierbaren Wege, die $x$ und $y$ verbinden, und $L(\\gamma)$ bezeichnet die Länge von $\\gamma$, die gemäß\n",
        "\n",
        ">$\n",
        "L(\\gamma)=\\int_{0}^{1} \\sqrt{g_{\\gamma(t)}(\\dot{\\gamma}(t), \\dot{\\gamma}(t))} \\mathrm{d} t\n",
        "$\n",
        "\n",
        "* definiert ist. Das Funktional $L$ wird auch Längenfunktional genannt. Ein mit konstanter Geschwindigkeit durchlaufener Weg, der lokal (das heißt für ausreichend nahe beieinander liegende Punkte) die kürzeste Verbindung realisiert, heißt [Geodätische](https://de.wikipedia.org/wiki/Geodäte).\n",
        "\n",
        "* Die so definierte Metrik $d$ induziert wieder die ursprüngliche Topologie von $M$. Da man zeigen kann, dass jede differenzierbare $n$ -dimensionale Mannigfaltigkeit riemannsche Metriken besitzt, lässt sich so auch zeigen, dass jede differenzierbare $n$ -dimensionale Mannigfaltigkeit metrisierbar ist. Ähnlich wie bei metrischen Vektorräumen kann man auch von\n",
        "vollständigen riemannschen Mannigfaltigkeiten sprechen. Der [Satz von Hopf-Rinow](https://de.wikipedia.org/wiki/Satz_von_Hopf-Rinow) ist das zentrale Resultat bezüglich der Vollständigkeit riemannscher Mannigfaltigkeiten."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8fjsYlKUW56"
      },
      "source": [
        "*Durchmesser (riemannsche Metrik)*\n",
        "\n",
        "* Genauso wie in der Theorie der metrischen Räume wird durch\n",
        "\n",
        ">$\n",
        "\\operatorname{diam}(M):=\\sup \\{d(p, q) \\mid p, q \\in M\\} \\in \\mathbb{R}_{\\geq 0} \\cup\\{\\infty\\}\n",
        "$\n",
        "\n",
        "* der Durchmesser einer riemannschen Mannigfaltigkeiten $(M, g)$ definiert.\n",
        "Der Durchmesser ist eine Invariante einer riemannschen Mannigfaltigkeit unter globalen Isometrien. \n",
        "\n",
        "* Außerdem gilt für (endlichdimensionale) riemannsche Mannigfaltigkeiten die Heine-Borel-Eigenschaft, das heißt, eine vollständige riemannsche Mannigfaltigkeit ist genau dann kompakt, wenn der Durchmesser endlich ist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql9Z6ZU4N6yl"
      },
      "source": [
        "##### **Untermannigfaltigkeit des $\\mathbb{R}^{n}$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7hsned6N_DT"
      },
      "source": [
        "* Da die [Untermannigfaltigkeiten](https://de.wikipedia.org/wiki/Untermannigfaltigkeit_des_ℝn) Teilmengen eines euklidischen Raumes sind, erben sie von diesem viele Eigenschaften wie zum Beispiel die Möglichkeit Abstände zu messen. \n",
        "\n",
        "* Jedoch kann man jede Untermannigfaltigkeit auch als abstrakte differenzierbare Mannigfaltigkeit (ohne umgebenden Raum) betrachten. Die Äquivalenz der beiden Sichtweisen wird durch den Einbettungssatz von Whitney sichergestellt.\n",
        "\n",
        "*  Ausgewählte Beispiele, in denen Untermannigfaltigkeiten des\n",
        "$\\mathbb {R} ^{n}$ eine Rolle spielen, sind:\n",
        "\n",
        "  * Optimierung unter Nebenbedingungen\n",
        "\n",
        "  * Mechanische Systeme mit Zwangsbedingungen\n",
        "\n",
        "  * Algebro-Differentialgleichungssysteme, beispielsweise bei der numerischen Netzwerkanalyse in der Elektrotechnik\n",
        "\n",
        "* In all diesen Anwendungen wird die Menge der betrachteten Punkte von vornherein auf eine Teilmenge $M$ des $\\mathbb{R}^{n}$ eingeschränkt, die sich lokal durch [Diffeomorphismen](https://de.wikipedia.org/wiki/Diffeomorphismus) auf Gebiete eines $\\mathbb{R}^{m}$ mit $0 \\leq m \\leq n$ abbilden lässt. \n",
        "\n",
        "* Diese Teilmenge $M$ wird als $m$ -dimensionale Untermannigfaltigkeit des $\\mathbb{R}^{n}$ bezeichnet. Mit Hilfe der Diffeomorphismen kann man auf der Untermannigfaltigkeit im differentialgeometrischen Sinne genauso rechnen wie in Gebieten des $\\mathbb{R}^{m}$.\n",
        "\n",
        "* Meistens wird die Menge $M$ durch Nebenbedingungen beschrieben. Das heißt, $M$ enthält gerade diejenigen Punkte $x,$ die mit einer vorgegeben stetig differenzierbaren Funktion $f: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{n-m}$ mit $0<m<n$ die Gleichung $f(x)=0$ erfüllen. Außerdem wird noch gefordert, dass 0 ein regulärer Wert von $f$ ist, also die Jacobi-Matrix $D f(x)$ von $f$ für alle Punkte $x \\in M$ den Maximalrang $n-m$\n",
        "hat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXHFSYKFo8Lk"
      },
      "source": [
        "##### **Pseudo-riemannsche & Einsteinsche Mannigfaltigkeit**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBSHz9YQH4mK"
      },
      "source": [
        "*Pseudo-riemannsche Mannigfaltigkeit (Lorentz-Mannigfaltigkeit )*\n",
        "\n",
        "* Der etwas allgemeinere Begriff der [pseudo-riemannschen](https://de.wikipedia.org/wiki/Pseudo-riemannsche_Mannigfaltigkeit) oder semi-riemannschen Mannigfaltigkeit ist in der [allgemeinen Relativitätstheorie](https://de.wikipedia.org/wiki/Allgemeine_Relativitätstheorie) von entscheidender Bedeutung, da in dieser die [Raumzeit](https://de.wikipedia.org/wiki/Raumzeit) als solche beschrieben wird.\n",
        "\n",
        "* Mit $T_{p} M$ wird im Folgenden der Tangentialraum an einem Punkt $p$ einer differenzierbaren Mannigfaltigkeit $M$ bezeichnet. \n",
        "\n",
        "* **Eine pseudo-riemannsche Mannigfaltigkeit ist eine differenzierbare Mannigfaltigkeit $M$ zusammen mit einer Funktion:** \n",
        "\n",
        "> $g_{p}: T_{p} M \\times T_{p} M \\rightarrow \\mathbb{R}$.\n",
        "\n",
        "* Diese Funktion ist tensoriell, symmetrisch und nicht ausgeartet, das heißt für alle Tangentialvektoren $X, Y, Z \\in T_{p} M$ und Funktionen $a, b \\in C^{\\infty}(M)$ gilt\n",
        "\n",
        "1. $g_{p}(a X+b Y, Z)=a(p) g_{p}(X, Z)+b(p) g_{p}(Y, Z)$ (tensoriell),\n",
        "2. $g_{p}(X, Y)=g_{p}(Y, X)$ (symmetrisch),\n",
        "3. falls für $X \\in T_{p} M$ gilt, dass $g_{p}(X, Y)=0$ für alle $Y$, so folgt $X=0$.\n",
        "\n",
        "Außerdem ist $g_{p}$ differenzierbar abhängig von $p$. Die Funktion $g$ ist also ein differenzierbares Tensorfeld $g: T M \\times T M \\rightarrow C^{\\infty}(M)$ und heißt pseudoriemannsche Metrik oder metrischer Tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NuNr_Gv0MCW"
      },
      "source": [
        "*Einsteinsche Mannigfaltigkeit*\n",
        "\n",
        "* Die [Einsteinsche Mannigfaltigkeit](https://de.wikipedia.org/wiki/Einsteinsche_Mannigfaltigkeit) oder Einsteinmannigfaltigkeit ist ein Begriff aus dem mathematischen Teilgebiet der Differentialgeometrie sowie aus der allgemeinen Relativitätstheorie. \n",
        "\n",
        "* Es handelt sich um einen Spezialfall einer (pseudo-)riemannschen Mannigfaltigkeit und wurde nach dem Physiker Albert Einstein benannt.\n",
        "\n",
        "* Eine pseudo-riemannsche Mannigfaltigkeit $(M, g)$ heißt Einsteinmannigfaltigkeit, falls eine reelle Konstante $\\lambda$ existiert, so dass\n",
        "\n",
        ">$\n",
        "\\operatorname{Ric}_{p}(X, Y)=\\lambda g_{p}(X, Y)\n",
        "$\n",
        "\n",
        "* gilt. Dabei ist $\\operatorname{Ric}_{p}$ der (0,2) -Ricci-Tensor und $X, Y \\in T_{p} M$ für jedes $p \\in M$. Die pseudo-riemannsche Metrik $g$ heißt unter diesen Gegebenheiten Einsteinmetrik.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke4QbSguzrVQ"
      },
      "source": [
        "##### **Metrischer Tensor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytHdb5npav0j"
      },
      "source": [
        "> $\\left[\\begin{array}{cc}1 & 0 \\\\ 0 & \\left(\\sin \\left(u^{1}\\right)\\right)^{2}\\end{array}\\right]$ = Metric Tensor $g_{i j}$ \n",
        "\n",
        "* measures lengths and angles, and whether space is curved or flat\n",
        "\n",
        "* or using Connection coefficients $\\Gamma_{i j}^{k}$, derivates of metric tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tTuUgmZUiFi"
      },
      "source": [
        "In the mathematical field of differential geometry, one definition of a metric tensor is a type of **function which takes as input a pair of tangent vectors v and w at a point of a surface (or higher dimensional differentiable manifold) and produces a real number scalar g(v, w)** in a way that **generalizes many of the familiar properties of the dot product of vectors in Euclidean space**. \n",
        "\n",
        "In the same way as a dot product, metric tensors are used to **define the length of and angle between tangent vectors**. \n",
        "\n",
        "**Through integration, the metric tensor allows one to define and compute the length of curves on the manifold**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVAdIOrTKyB4"
      },
      "source": [
        "* Der [metrische Tensor](https://de.wikipedia.org/wiki/Metrischer_Tensor) (auch Metriktensor oder Maßtensor) bzw [metric tensor](https://en.m.wikipedia.org/wiki/Metric_tensor) dient dazu, mathematische Räume, insbesondere differenzierbare Mannigfaltigkeiten, mit einem **Maß für Abstände und Winkel auszustatten**.\n",
        "\n",
        "* **Dieses Maß muss nicht notwendig alle Bedingungen erfüllen**, die in der Definition eines metrischen Raums an eine Metrik gestellt werden: im Minkowski-Raum der Speziellen Relativitätstheorie gelten diese Bedingungen nur für Abstände, die entweder einheitlich raumartig oder einheitlich zeitartig sind.\n",
        "\n",
        "* Für die Differentialgeometrie und die Allgemeine Relativitätstheorie bedeutsam ist, dass der metrische Tensor, **anders als eine über inneres Produkt und Norm definierte Metrik, vom Ort abhängen kann**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlWtZfXOZR9x"
      },
      "source": [
        "Der metrische Tensor $g$ über einem [affinen Punktraum](https://de.wikipedia.org/wiki/Affiner_Raum) $A$ mit reellem Verschiebungsvektorraum $V$ ist eine Abbildung von $A$ in den Raum der Skalarprodukte auf $V$. \n",
        "\n",
        "Das heißt, für jeden Punkt $P \\in A$ ist\n",
        "\n",
        "> $g(P): V \\times V \\rightarrow \\mathbb{R}$\n",
        "\n",
        "eine positiv definite, symmetrische [Bilinearform](https://de.wikipedia.org/wiki/Bilinearform): cross product of two vectors, normal and tangent, see [Frenet–Serret_formulas](https://en.m.wikipedia.org/wiki/Frenet–Serret_formulas)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fuJkBd4yOg1"
      },
      "source": [
        "##### **Riemannscher Krümmungstensor (Riemanntensor)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC9Wl-ifZdAK"
      },
      "source": [
        "> $R(\\vec{u}, \\vec{v}) \\vec{w}=\\nabla_{\\vec{u}} \\nabla_{\\vec{v}} \\vec{w}-\\nabla_{\\vec{v}} \\nabla_{\\vec{u}} \\vec{w}-\\nabla_{[\\vec{u}, \\vec{v}]} \\vec{w}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFL1mLJ9c8EI"
      },
      "source": [
        "* Riemann curvature tensor: $R^{d} a b c$ (1-contra, 3-co-Tensor)\n",
        "\n",
        "* Paralle transport vector and then make parallelogram smaller up to limit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aX8HG_hgRQY"
      },
      "source": [
        "![gg](https://raw.githubusercontent.com/deltorobarba/repo/master/riemanntensor_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_RaMj3ucB90"
      },
      "source": [
        "https://www.youtube.com/watch?v=-Il2FrmJtcQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0KSw8ApySBd"
      },
      "source": [
        "* Der [riemannsche Krümmungstensor](https://de.wikipedia.org/wiki/Riemannscher_Krümmungstensor) (kürzer auch Riemanntensor, riemannsche Krümmung oder Krümmungstensor) beschreibt die Krümmung von Räumen beliebiger Dimension, genauer gesagt riemannscher oder pseudo-riemannscher Mannigfaltigkeiten. \n",
        "\n",
        "* Er ist eines der wichtigsten Hilfsmittel der riemannschen Geometrie. Eine andere wichtige Anwendung findet er im Zusammenhang mit der Krümmung der Raumzeit in der allgemeinen Relativitätstheorie.\n",
        "\n",
        "  * Zur Beschreibung der Krümmung der Mannigfaltigkeit, der eine Kombination von ersten und zweiten Ableitungen des metrischen Tensors darstellt.\n",
        "  * Wenn ein beliebiger Tensor in irgendeinem Koordinatensystem in einem Punkt nicht null ist, kann man überhaupt kein Koordinatensystem finden, sodass er in diesem Punkt null wird. Dies gilt dementsprechend auch für den Krümmungstensor.\n",
        "\n",
        "  * Umgekehrt ist der Krümmungstensor in allen Koordinatensystemen null, wenn er in einem Koordinatensystem null ist. Man wird also in jedem Koordinatensystem bezüglich der Frage, ob eine Mannigfaltigkeit an einem bestimmten Punkt gekrümmt ist oder nicht, zum gleichen Ergebnis gelangen.\n",
        "* Der riemannsche Krümmungstensor ist ein Tensor der Stufe 4. Man kann seine Koeffizienten zum Beispiel in der Form $R_{i k p}^{m}$ angeben. In diesem Artikel wird die einsteinsche Summenkonvention verwendet.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUkHz19Q5pdc"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Riemann_curvature_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WGGOihv4kO6"
      },
      "source": [
        "##### **Flache Mannigfaltigkeit**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WaBPMZt42QB"
      },
      "source": [
        "* Eine riemannsche Mannigfaltigkeit $(M, g)$ heißt flach( [Flache Mannigfaltigkeit](https://de.wikipedia.org/wiki/Flache_Mannigfaltigkeit) ), **falls sie lokal isometrisch zum euklidischen Raum ist**. \n",
        "\n",
        "* Flache Mannigfaltigkeiten sind Riemannsche Mannigfaltigkeiten mit [Schnittkrümmung](https://de.wikipedia.org/wiki/Schnittkrümmung) konstant null.\n",
        "\n",
        "* Das heißt, für jeden Punkt $p \\in M$ gibt es eine Umgebung $U$ und eine Abbildung $\\phi: U \\rightarrow V \\subset \\mathbb{R}^{n},$ welche isometrisch ist, also für welche $g(X, Y)=\\phi^{*} \\bar{g}(X, Y)=\\bar{g}\\left(\\phi_{*} X, \\phi_{*} Y\\right)$ gilt. Hier bezeichnet $\\bar{g}$ das\n",
        "euklidische Skalarprodukt und $\\phi_{*}$ den Pushforward von $\\phi$.\n",
        "\n",
        "* Verbindung zum Krümmungstensor: Eine riemannsche Mannigfaltigkeit mit Levi-Civita-Zusammenhang $\\nabla$ ist genau dann flach, wenn der riemannsche Krümmungstensor identisch null ist. Daher ist die abwickelbare Fläche das\n",
        "zweidimensionale Analogon zur flachen Mannigfaltigkeit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU5v-uJp5Q2U"
      },
      "source": [
        "*Schnittkrümmung*\n",
        "\n",
        "* Die [Schnittkrümmung](https://de.wikipedia.org/wiki/Schnittkrümmung) ist eine Größe der riemannschen Geometrie, eines Teilgebiets der Mathematik. Mit ihrer Hilfe kann man die Krümmung einer n-dimensionalen riemannschen Mannigfaltigkeit beschreiben. \n",
        "\n",
        "* Dabei wird jeder (zweidimensionalen) Ebene im Tangentialraum an einem Punkt dieser Mannigfaltigkeit eine Zahl als Krümmung zugeordnet. Die Schnittkrümmung kann als Verallgemeinerung der gaußschen Krümmung verstanden werden. \n",
        "\n",
        "* Der Name kommt daher, dass man sozusagen einen Schnitt durch die Mannigfaltigkeit in Richtung der gegebenen Ebene legt und die gaußsche Krümmung der so entstandenen Fläche bestimmt.\n",
        "\n",
        "* Siehe weiter unten auch 'Schnitt (Faserbündel)'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAqpVM7nYdgJ"
      },
      "source": [
        "## **Tensoranalysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA0pXc2eO8EQ"
      },
      "source": [
        "### **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR05LFbobsrI"
      },
      "source": [
        "##### **Summary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s90glUymbvJx"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_overview.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMoHRoCufpuk"
      },
      "source": [
        "The forward matrix for example is constructed from the scaling coefficients (=basis vector coiefficients) in this case from the new basis * the old basis coefficients:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_89.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDlBHetgbvkI"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_35.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DNoeSuPyLwf"
      },
      "source": [
        "**Summary of all transformations for vectors and covectors (for example between Cartesian and polar coordinate system):**\n",
        "\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_136.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbAbsxKF1jwV"
      },
      "source": [
        "**Summary of all transformations for vector fields and covector fields / differential forms (not single vectors!) (for example between Cartesian and polar coordinate system):**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_138.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k4R8JsxwlZ_"
      },
      "source": [
        "##### **Motivation for Tensor Algebra**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpCveREqlwcz"
      },
      "source": [
        "**Motivation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufUcTtIBVlAc"
      },
      "source": [
        "**First Example for Tensors: Einstein Field Equations in General Relativity:**\n",
        "\n",
        "> $\n",
        "R_{\\mu \\nu}-\\frac{1}{2} R g_{\\mu \\nu}+\\Lambda {g_{\\mu v}}=\\frac{8 \\pi G}{c^{4}} T_{\\mu \\nu}\n",
        "$\n",
        "\n",
        "4x4 rank 2 metric tensor: ${g_{\\mu v}}$ (measure lengths and angles in the curved geometry of spacetime)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl63Xrr5WEQ_"
      },
      "source": [
        "**Second Example for Tensors: Quantum Mechanics & Quantum Computing**\n",
        "\n",
        "Quantum Superposition: \n",
        "\n",
        "> $\\vec{\\psi}=a \\vec{v}+b \\vec{w}$\n",
        "\n",
        "* linear combination, physical quantum states are just vectors, using linear combinations to give more complicated states\n",
        "\n",
        "\n",
        "Quantum Entanglement\n",
        "\n",
        "> $\\vec{\\psi} \\otimes \\vec{\\phi}$\n",
        "\n",
        "* two states are 'entangled' together means state these state vectors have been combined together using the 'tensor product' (circle X)\n",
        "\n",
        "* Takes the geometrical space where the first system lives and the second system and combines them together to create a more complicated geometrical space, and that's where the entangled system lives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd4fOqn-tVdo"
      },
      "source": [
        "**Definition of a Tensor**\n",
        "\n",
        "> **Tensor = an object that is invariant under a change of coordinates, and... has components that change in a special, predictable way under a change of coordinates**\n",
        "\n",
        "* the direction and the lengths of an object are invariant (=vector)\n",
        "\n",
        "> **The vector components are NOT invariant. They change  depending on the coordinate system they use.**\n",
        "\n",
        "* if you know how to switch between coordinate system, you should be able to know how to switch between vector components (forward and backward)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ2JAmplwMBJ"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_07.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaT0xx-bWA3a"
      },
      "source": [
        "https://www.youtube.com/watch?v=8ptMTLzV4-I&list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekRZB5zfwTYd"
      },
      "source": [
        "> **Tensor: A collection of vectors and convectors combined together using the tensor product.** (abstract definition)\n",
        "\n",
        "> **Tensors as partial derivatives and gradients that transform with the Jacobian matrix.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNgeGnbhm91L"
      },
      "source": [
        "##### **Tensor Product, Outer Product, Kronecker Product $\\otimes$ and Tensor vs Matrix**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyYoH_C2BPKg"
      },
      "source": [
        "[Tensoranalyse](https://de.m.wikipedia.org/wiki/Tensoranalysis) mit [Tensoren](https://de.m.wikipedia.org/wiki/Tensor) ist ein Teilgebiet der Differentialgeometrie bzw. der Differentialtopologie. Sie verallgemeinert die Vektoranalysis. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N19bhGkKbEpJ"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_61.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRJb3fSRbWSM"
      },
      "source": [
        "**The 2 different tensor product use cases**\n",
        "\n",
        "* the \"little\" tensor product which combines individual tensors\n",
        "\n",
        "* the \"big\" tensor product which combines entire tensor vector spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NI4aI2gbTHJ"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_62.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR9iEvXU69bq"
      },
      "source": [
        "**Tensor vs Matrix**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_6F-3BE7AXH"
      },
      "source": [
        "- A tensor of rank n is a mathematical object that has n indices and m^n components\n",
        "- Matrix is a tensor rank 2, because you need 2 basis vectors \n",
        "- Tensors rank 3 are the boxes with several stacked matrices\n",
        "- Matrix is just and array of numbers, meanwhile a tensor (like stress tensor) obeys specific transformation rules and has a rules physical meaning. We can use a matrix to represent a tensor, but a tensor has a deeper physical significance.\n",
        "- Matrix: I can just write down the matrix and its elements, but don’t have to add anything else\n",
        "- Tensor: I need to specify the coordinate system, the components, and the basis vectors that each of those components correspond to. A tensor requires more detailed specification than a matrix. And it has these transformation properties where it’s invariant under a change of coordinate system, it has physical significance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH9e31Xv7C07"
      },
      "source": [
        "https://www.youtube.com/watch?v=uaQeXi4E7gA&list=PLdgVBOaXkb9D6zw47gsrtE5XqLeRPh27_&index=1&t=187s "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKpnWKLp668Z"
      },
      "source": [
        "**Tensor Product, Outer Product and process-state duality**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6RijH3U6wd6"
      },
      "source": [
        "Technically, $\\mathbf{v} \\otimes \\mathbf{w}$ is called the outer product of $\\mathbf{v}$ and $\\mathbf{w}$ and is defined by\n",
        "\n",
        ">$\n",
        "\\mathbf{v} \\otimes \\mathbf{w}:=\\mathbf{v} \\mathbf{w}^{\\top}\n",
        "$\n",
        "\n",
        "where $\\mathbf{w}^{\\top}$ is the same as $\\mathbf{w}$ but written as a row vector. (And if the entries of $\\mathbf{w}$ are complex numbers, then we also replace each entry by its complex conjugate.) So technically the tensor product of vectors is matrix.\n",
        "\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/outerproduct.jpg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFTslBM_SGHE"
      },
      "source": [
        "See duality also here: https://en.m.wikipedia.org/wiki/Outer_product\n",
        "Flattening is kronecker, matrix form is outer product! To find under ‚Connection with Kronecker product‘:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/kronecker_outer.png)\n",
        "\n",
        "* **In the case of column vectors, the Kronecker product can be viewed as a form of [vectorization](https://en.m.wikipedia.org/wiki/Vectorization_(mathematics)) (or flattening) of the outer product**. \n",
        "\n",
        "* In particular, for two column vectors $\\mathbf{u}$\n",
        "and $\\mathbf{v}$, we can write:\n",
        "\n",
        "> $\\mathbf{u} \\otimes_{\\text {Kron }} \\mathbf{v}=\\operatorname{vec}\\left(\\mathbf{v} \\otimes_{\\text {outer }} \\mathbf{u}\\right)$\n",
        "\n",
        "* Note that the order of the vectors is reversed in the right side of the equation.\n",
        "\n",
        "* Another similar identity that further highlights the similarity between the operations is \n",
        "\n",
        "> $\\mathbf{u} \\otimes_{\\text {Kron }} \\mathbf{v}^{\\top}=\\mathbf{u v}^{\\top}=\\mathbf{u} \\otimes_{\\text {outer }} \\mathbf{v}$ \n",
        "\n",
        "* where the order of vectors needs not be flipped. The middle expression uses matrix multiplication, where the vectors are considered as column/row matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBU3KrQTSHEB"
      },
      "source": [
        "It's a little like a process-state duality. On the one hand, a matrix $\\mathbf{v} \\otimes \\mathrm{w}$ is a process-it's a concrete representation of a (linear) transformation. On the other hand, $\\mathbf{v} \\otimes \\mathbf{w}$ is, abstractly speaking, a vector. And a vector is the mathematical gadget that physicists use to describe the state of a quantum system. So matrices encode processes; vectors encode states. The upshot is that a vector in a tensor product $V \\otimes W$ can be viewed in either way simply by reshaping the numbers as a list or as a rectangle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S68b5iIXSJiL"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensorduality.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62OZYBfd6x9J"
      },
      "source": [
        "https://www.math3ma.com/blog/the-tensor-product-demystified\n",
        "\n",
        "https://www.math3ma.com/blog/matrices-as-tensor-network-diagrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbgOvonE6zN7"
      },
      "source": [
        "**Kronecker product vs outer product vs matrix multiplication**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ9-005a61ac"
      },
      "source": [
        "* the Kronecker product, sometimes denoted by ⊗,[1] is an operation on two matrices of arbitrary size resulting in a block matrix. \n",
        "* It is a generalization of the outer product (which is denoted by the same symbol) from vectors to matrices, and gives the matrix of the tensor product with respect to a standard choice of basis. \n",
        "* The Kronecker product is to be distinguished from the usual matrix multiplication, which is an entirely different operation. The Kronecker product is also sometimes called matrix direct product.\n",
        "* The Kronecker product is a special case of the tensor product, so it is bilinear and associative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p14axKnm626g"
      },
      "source": [
        "\n",
        "https://en.m.wikipedia.org/wiki/Kronecker_product\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Tensor_product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfDD1ch-Fm94"
      },
      "source": [
        "##### **Exkurs: Einstein Notation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrrAQDzt4TLM"
      },
      "source": [
        "> $\\sum_{i=1}^{3} a_{i} x_{i}=a_{1} x_{1}+a_{2} x_{2}+a_{3} x_{3}$\n",
        "\n",
        "is in this case the same as saying:\n",
        "\n",
        "> $a_{i} x_{i}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjmBhLTU4dc0"
      },
      "source": [
        "Dummy vs free index: free indices cannot be replaced, dummy indices are those that come up twice or more and where the summation sign can be removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Xn5L7Wf58JX"
      },
      "source": [
        "See 4 rules of Einetsine notation:\n",
        "\n",
        "https://www.youtube.com/watch?v=CLrTj7D2fLM&list=PLdgVBOaXkb9D6zw47gsrtE5XqLeRPh27_&index=3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRYDD-LKGqg8"
      },
      "source": [
        "https://www.youtube.com/watch?v=SSSGA6ohkfw&list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG&index=11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwAt1Fl7FtXi"
      },
      "source": [
        "This derivation to transform matrix components is pretty complex and can be written in a much easier way:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32kPgV5pFpKa"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_25.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-654OULNd0Fv"
      },
      "source": [
        "If we have the same index on and top and on the bottom we end up summing over that index letter and can drop the summation sign, in this case: $\\color{red}{\\sum_{k=1}^{n}}$:\n",
        "\n",
        "> $L\\left(\\overrightarrow{e_{j}}\\right)= \\color{red}{\\sum_{k=1}^{n}} L_{j}^{\\color{red}{k}} \\overrightarrow{e_{\\color{red}{k}}}$\n",
        "\n",
        "and rewrite it to:\n",
        "\n",
        " > $L\\left(\\overrightarrow{e_{j}}\\right)= L_{j}^{\\color{red}{k}} \\overrightarrow{e_{\\color{red}{k}}}$\n",
        "\n",
        "**Because when we see an index repeated on the top and bottom we know that there is a summation that's going to happen.**\n",
        "\n",
        "Another examples:\n",
        "\n",
        "> $\\color{red}{\\sum_{q=1}^{n}} \\widetilde{L_{i}^{\\color{red}{q}}} \\widetilde{e_{\\color{red}{q}}}$\n",
        "\n",
        "can be rewritten by dropping the summation sign because ${\\color{red}{q}}$ (to which the sum sign refers to) is on the top and bottom:\n",
        "\n",
        "> $\\widetilde{L_{i}^{\\color{red}{q}}} \\widetilde{e_{\\color{red}{q}}}$\n",
        "\n",
        "And as for the total formula: \n",
        "\n",
        "> $\\widetilde{L_{i}^{l}}= \\sum_{j=1}^{n} \\sum_{k=1}^{n} B_{k}^{l} L_{j}^{k} F_{i}^{j}$\n",
        "\n",
        "> $\\widetilde{L_{i}^{l}}=  B_{k}^{l} L_{j}^{k} F_{i}^{j}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGI_E_gBGkwM"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_26.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYNJU1prdIJU"
      },
      "source": [
        "* According to the [Einstein notation](https://en.wikipedia.org/wiki/Einstein_notation), when an index variable appears twice in a single term and is not otherwise defined (see free and bound variables), it implies summation of that term over all the values of the index. So where the indices can range over the set \\{1,2,3\\} ,\n",
        "\n",
        "> $\n",
        "y=\\sum_{i=1}^{3} c_{i} x^{i}=c_{1} x^{1}+c_{2} x^{2}+c_{3} x^{3}\n",
        "$\n",
        "\n",
        "is simplified by the convention to:\n",
        "\n",
        ">$\n",
        "y=c_{i} x^{i}\n",
        "$\n",
        "\n",
        "* The upper indices are not exponents but are indices of coordinates, coefficients or basis vectors. \n",
        "\n",
        "In [general relativity](https://en.wikipedia.org/wiki/General_relativity), a common convention is that\n",
        "\n",
        "* the Greek alphabet is used for space and time components, where indices take on values 0,1,2 ,\n",
        "or 3 (frequently used letters are $\\mu, v, \\ldots),$ \n",
        "\n",
        "* the Latin alphabet is used for spatial components only, where indices take on values $1,2,$ or 3 (frequently used letters are $i, j, \\ldots)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqpFJcC27fAX"
      },
      "source": [
        "##### **Tensors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC9G8sF95z8P"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Pseudovektor#Zusammenhang_mit_Tensoren"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_IlXCIao4mV"
      },
      "source": [
        "* Tensoren sind Grössen, mit deren Hilfe man **Skalare, Vektoren und weitere Grössen analoger Struktur in ein einheitliches Schema** zur Beschreibung mathematischer und physikalischer Zusammenhänge einordnen kann. \n",
        "\n",
        "* Sie sind **definiert durch ihre Transformationseigenschaften gegenüber orthogonalen Transformationen wie z.B. Drehungen**. Es geht darum, was ändert sich, was ändert sich nicht, wenn man das Bezugssystem ändert?\n",
        "\n",
        "* Die Besonderheit von Tensorgleichungen ist, dass sie **transformations-invariant** sind. Wenn es gelingt, einen physikalischen Sachverhalt in Tensorschreibweise zu formulieren, so kann man wegen der speziellen Art, wie Tensoren transformieren, sicher sein, **dass die Gleichungen in jedem beliebigen Koordinatensystem gelten**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZVNl5kQpUbh"
      },
      "source": [
        "**Rang oder Stufe eines Tensors und Indizes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiRlRg10pVFH"
      },
      "source": [
        "* Tensoren haben **Indizes**. Die Anzahl der Indizes gibt den Rang oder die Stufe des Tensors an.\n",
        "\n",
        "* Die Indizes laufen entsprechend der **Dimension** $D$ des Raumes über $1 . . D$. Bei der 4-dimensionalen Raumzeit beginnt die Nummerierung bei $0,$ wobei der Index 0 die zeitliche Komponente betrifft.\n",
        "\n",
        "* Beim Arbeiten mit den Tensoren muss die **Reihenfolge der Indices** immer klar sein.\n",
        "Das Element $t_{12}$ eines Tensors ist in der Regel vom Element $t_{21}$ verschieden.\n",
        "\n",
        "* Der einfachste Tensor ist ein Tensor mit Rang 0 . Dabei handelt es sich einfach um\n",
        "einen **Skalar**. Ein Skalar hat eigentlich keine Komponenten, sondern ist nur ein\n",
        "einzelner Wert und benötigt somit keinen Index; daher der Rang $0 .$\n",
        "\n",
        "* Ein Tensor mit nur einem Index nennt man auch **Vektor**. Man sagt, der Vektor ist ein Tensor mit dem Rang 1. Der Index hat so viele Werte, wie die Dimension des Vektors. Bei einem 3 -dimensionalen Vektor hat der Index also 3 Werte (z.B: 1,2,3$),$ weil der Vektor 3 Komponenten hat: $\\vec{V}=\\left(V^{1}, V^{2}, V^{3}\\right)$.\n",
        "\n",
        "* Ein Tensor vom Rang 2 hat 2 Indizes und stellt eine quadratische **Matrix** dar usw.\n",
        "\n",
        "* Jede Tensor-Komponente kann eine Funktion oder eine Zahl sein. In der AR (allgemeinen Relativitatstheorie) sind die Komponenten in der Regel Funktionen der Raumzeit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOJSsnvbqEhc"
      },
      "source": [
        "**Dimension eines Tensors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCOvwL-xqGjo"
      },
      "source": [
        "* Ein Vektor oder Tensor ist ein Objekt, welches Komponenten hat. Die Anzahl der Komponenten eines Vektors enstpricht der Dimension D des Raumes. \n",
        "\n",
        "* Ein 3-dimensionaler Vektor besteht somit aus 3 Komponenten. Ein 3-dimensionaler Tensor der Stufe 2 besteht aus 3x3 Komponenten usw."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHKyjdOBqoHf"
      },
      "source": [
        "**Tensoren und Koordinatensysteme**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRg44ZhRquA1"
      },
      "source": [
        "* In der Anwendung steht das Tensorsymbol immer für eine bestimmte Bedeutung. Zum Beispiel den Ort eines Teilchens. Der Ort kann in verschiedenen Koordinatensystemen gemessen werden. Entsprechend haben die Komponenten des Tensors in jedem Koordinatensystem andere Werte. Doch der Tensor bleibt der Selbe, egal in welchem Koordinatensystem er gemessen wird. \n",
        "\n",
        "* So ist z.B. die Länge eines Vektors in jedem Koordinatensystem dieselbe, auch wenn sich die Komponenten in den verschiedenen Koordinatensystemen unterscheiden.\n",
        "\n",
        "* Man unterscheidet bei Tensoren zwei Arten von Komponenten:\n",
        "\n",
        "  * **Kontravariante** Komponenten Index oben z.B. $v^{i}$\n",
        "  \n",
        "  * **Kovariante** Komponenten Index unten Z.B. $v_{i}$\n",
        "\n",
        "* Bei **Tensoren ab Rang 2** können kontravariante und kovariante Komponenten gleichzeitig vorkommen. Ein solcher Tensor hat dann Indizes sowohl oben als auch unten: $T^{m}{ }_{n} .$\n",
        "\n",
        "* Jeder Tensor kann sowohl in kontravarianten, als auch in kovarianten Komponenten\n",
        "dargestellt werden. Der Wechsel von einem Tensor in kontravarianter Darstellung zu einem Tensor in kovarianter Darstellung, wird [**\"Index ziehen\" oder Index Manipulation**](http://walter.bislins.ch/physik/index.asp?page=Index%2DManipulation+per+Metrik%2DTensor) genannt. Die Umrechnung geht durch Multiplikation mit dem sog. **Metrischen Tensor**.\n",
        "\n",
        "* Ob die Indizes oben oder unten sind, es handelt sich jeweils um ein und denselben\n",
        "Tensor mit derselben physikalischen Bedeutung. Lediglich die Werte der\n",
        "Komponenten unterscheiden sich, weil sie sich auf verschiedene Koordinatensysteme beziehen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1ypHeW4tmwC"
      },
      "source": [
        "**Typ eines Tensors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdgcorxvtqZ2"
      },
      "source": [
        "* Wenn Rang, Dimension und Komponenten-Arten (Anzahl Indizes oben und unten) von Tensoren übereinstimmen, dann sagt man, die Tensoren sind vom selben Typ. Dies muss bei der Tensor-Arithmetik beachtet werden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMxWkbFFtBrh"
      },
      "source": [
        "**Index ziehen bzw. Index Manipulation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDayLcTItDmB"
      },
      "source": [
        "http://walter.bislins.ch/physik/index.asp?page=Index%2DManipulation+per+Metrik%2DTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgqSu2ShtwLq"
      },
      "source": [
        "**Tensor-Arithmetik**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hI5CC3pt2_b"
      },
      "source": [
        "Weil Skalare und Vektoren Subklassen von Tensoren sind ist zu erwarten, dass Tensoren denselben bekannten Rechenregeln für Addition, Subtraktion, Multiplikation und Division folgen. Dies stimmt meistens, jedoch mit einigen Änderungen und Einschränkungen. Tensoren zeigen zudem neue Eigenschaften, die es bei Skalaren und Vektoren nicht gibt.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znmkqskmtyLU"
      },
      "source": [
        "http://walter.bislins.ch/physik/index.asp?page=Tensor%2DArithmetik"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aY3WiYn1ds1"
      },
      "source": [
        "**Tensornotation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2WzA8O72DE-"
      },
      "source": [
        "Transformation von einer Basis zur naechsten, dann ist das ein Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59aiPSQT2Tq3"
      },
      "source": [
        "![iiu](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_06.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgBA5uB7ltdE"
      },
      "source": [
        "http://walter.bislins.ch/physik/index.asp?page=Kovariante+und+Kontravariante+Komponenten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4rOmgVllvLf"
      },
      "source": [
        "http://walter.bislins.ch/physik/index.asp?page=Kovarianz+und+Kontravarianz+von+Vektoren"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzAM7aBOc9aA"
      },
      "source": [
        "*Tensor Notation*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKmyA1GY3ZIG"
      },
      "source": [
        "* Kovarianz und Kontravarianz beschreiben wie die Werte bzw. Komponenten von geometrischen oder physikalischen Dingen mit der Wahl einer Basis ändern. In der Physik denkt man sich die Basis als eine Gruppe von Referenz-Achsen. Ändert man die Skalierung der Achsen, ändern sich die Einheiten der Dinge.\n",
        "\n",
        "* Damit ein Vektor, wie zum Beispiel ein Richtungsvektor oder ein Geschwindigkeitsvektor, basis-unabhängig ist, müssen die Komponenten zur Änderung der Basis contra-vary (gegen-variieren), um diese Änderung zu kompensieren. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpMm7chy3V7x"
      },
      "source": [
        "http://walter.bislins.ch/physik/index.asp?page=Kovarianz+und+Kontravarianz+von+Vektoren"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37JaCthupMDw"
      },
      "source": [
        "*Ko- und kontravariante Darstellung*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v950hT6GpPGJ"
      },
      "source": [
        "https://www.math.tugraz.at/~ganster/lv_vektoranalysis_ss_10/20_ko-_und_kontravariante_darstellung.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8aEOKhHdskP"
      },
      "source": [
        "> In multilinear algebra and tensor analysis, [covariance and contravariance](https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors) describe how the quantitative description of certain geometric or physical entities changes with a [change of basis](https://en.wikipedia.org/wiki/Change_of_basis).\n",
        "\n",
        "* [Tensor notation](https://en.wikipedia.org/wiki/Tensor_calculus#Syntax) makes use of upper and lower indexes on objects that are used to label a variable object as \n",
        "\n",
        "  * **covariant** - lower index: $x_{1}$\n",
        "  \n",
        "  * **contravariant** - upper index: $c^{1}$\n",
        "  \n",
        "  * [**mixed**](https://en.wikipedia.org/wiki/Mixed_tensor) covariant and contravariant (having both upper and lower indexes). \n",
        "\n",
        "* In conventional math syntax we make **use of covariant indexes when dealing with Cartesian coordinate systems** $(x_{1},x_{2},x_{3})$ frequently without realizing this is a limited use of tensor syntax as covariant indexed components.\n",
        "\n",
        "* Tensor notation allows upper index on an object that may be confused with normal power operations from conventional math syntax. In tensor syntax a parenthesis should be used around an object before raising it to a power to disambiguate the use of a tensor index versus a normal power operation. For example:\n",
        "\n",
        "  * In normal math syntax: $e=m c^{2}=m c c,$ \n",
        "  * In tensor syntax: $e=m\\left(c^{1}\\right)^{2}=m\\left(c^{1}\\right)\\left(c^{1}\\right)$ and $e=m\\left(c^{2}\\right)^{2}=m\\left(c^{2}\\right)\\left(c^{2}\\right)$. \n",
        "  * The number in the inner parenthesis distinguishes the contravariant component where the outer parenthesis number distinguishes the power to raise the quantities to.\n",
        "\n",
        "* On a manifold, a tensor field will typically have multiple, upper and lower indices, where Einstein notation is widely used.\n",
        "\n",
        "* The distinction between covariance and contravariance is particularly important for computations with tensors, **which often have mixed variance**, which means that they have both covariant and contravariant components, or both vector and covector components.\n",
        "\n",
        "* The explanation in geometric terms is that a general tensor will have contravariant indices as well as covariant indices, because it has parts that live in the [tangent bundle](https://en.wikipedia.org/wiki/Tangent_bundle) as well as the [cotangent bundle](https://en.wikipedia.org/wiki/Cotangent_bundle).\n",
        "\n",
        "* **The reason of having covariant or contravariant tensors is because you want to represent the same thing in a different coordinate system. Such a new representation is achieved by a transformation using a set of partial derivatives. In tensor analysis, a good transformation is one that leaves invariant the quantity you are interested in.**\n",
        "\n",
        "* **In category theory**, covariance and contravariance are properties of functors; unfortunately, it is the lower-index objects (covectors) that generically have pullbacks, which are contravariant, while the upper-index objects (vectors) instead have pushforwards, which are covariant. This terminological conflict may be avoided by calling contravariant functors \"cofunctors\"—in accord with the \"covector\" terminology, and continuing the tradition of treating vectors as the concept and covectors as the coconcept.\n",
        "\n",
        "* [Curvilinear coordinate systems](https://en.wikipedia.org/wiki/Curvilinear_coordinates), such as **cylindrical or spherical coordinates**, are often used in physical and geometric problems. Associated with any coordinate system is a natural choice of coordinate basis for vectors based at each point of the space, and **covariance and contravariance are particularly important for understanding how the coordinate description of a vector changes by passing from one coordinate system to another**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O0Iihfu4Av9"
      },
      "source": [
        "**Invariance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9aO7p2S4Byo"
      },
      "source": [
        "* A third concept related to covariance and contravariance is invariance. An example of a physical observable that does not change with a change of scale on the reference axes is the mass of a particle, which has units of mass (that is, no units of distance). \n",
        "  \n",
        "* The single, scalar value of mass is independent of changes to the scale of the reference axes and consequently is called invariant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6D_WkqjMzWr"
      },
      "source": [
        "**Mathematische Darstellung**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mo7ydW9Msu8"
      },
      "source": [
        "In einem engeren Wortsinn bezeichnet kovariant in der mathematischen Physik Größen, **die wie Differentialformen transformieren**. Diese kovarianten Größen $P$ bilden einen Vektorraum\n",
        "$\\mathcal{V}$, auf dem eine Gruppe von linearen Transformationen wirkt.\n",
        "\n",
        "Die Menge der linearen Abbildungen der kovarianten Größen in die reellen Zahlen\n",
        "\n",
        "$\n",
        "Q: P \\mapsto Q(P) \\in \\mathbb{R}, \\quad Q(a P+b \\tilde{P})=a Q(P)+b Q(\\tilde{P})\n",
        "$\n",
        "\n",
        "bildet den zu $\\mathcal{V}$ dualen Vektorraum $\\mathcal{V}^{*}$. Schreiben wir die transformierten, kovarianten Größen $P^{\\prime}$ mit einer Matrix $\\Lambda$ als\n",
        "\n",
        "$\n",
        "P^{\\prime}=\\Lambda P\n",
        "$\n",
        "\n",
        "dann definiert $Q^{\\prime}\\left(P^{\\prime}\\right)=Q(P)$ das kontravariante oder kontragrediente Transformationsgesetz des Dualraumes\n",
        "\n",
        "$\n",
        "Q^{\\prime}=\\Lambda^{-1 \\mathrm{~T}} Q\n",
        "$\n",
        "\n",
        "Wegen\n",
        "\n",
        "$\n",
        "\\left(\\Lambda_{2}\\right)^{-1 \\mathrm{~T}}\\left(\\Lambda_{1}\\right)^{-1 \\mathrm{~T}}=\\left(\\Lambda_{2} \\Lambda_{1}\\right)^{-1 \\mathrm{~T}}\n",
        "$\n",
        "\n",
        "genügt die kontravariante Transformation derselben Gruppenverknüpfung wie die kovariante Transformation.\n",
        "\n",
        "Tensoren aus dem $u$ -fachen Tensorprodukt von $\\mathcal{V}^{*}$ mit dem $o$ -fachen Tensorprodukt von $\\mathcal{V}$ heißen $u$ -fach kovariant und $o$ -fach kontravariant.\n",
        "In Indexschreibweise macht man an der Indexstellung mit unten und oben stehenden Indizes deutlich, ob es sich um die Komponenten eines kovarianten oder eines kontravarianten Vektors handelt,\n",
        "\n",
        "$\n",
        "P_{m}^{\\prime}=\\sum_{n} \\Lambda_{m}{ }^{n} P_{n}, \\quad Q^{\\prime m}=\\sum_{r}\\left(\\Lambda^{-1 \\mathrm{~T}}\\right)^{m}{ }_{r} Q^{r}\n",
        "$\n",
        "\n",
        "Dass $Q^{\\prime}\\left(P^{\\prime}\\right)=Q(P)$ gilt, zeigen die Rechenschritte\n",
        "\n",
        "$\n",
        "\\begin{aligned}\n",
        "Q^{\\prime}\\left(P^{\\prime}\\right) &=\\sum_{m} Q^{\\prime m} P_{m}^{\\prime} \\\\\n",
        "&=\\sum_{m n r}\\left(\\Lambda^{-1 \\mathrm{~T}}\\right)_{r}^{m} Q^{r} \\Lambda_{m}{ }^{n} P_{n} \\\\\n",
        "&=\\sum_{m n r} \\Lambda^{-1}{ }_{r}^{m} \\Lambda_{m}{ }^{n} Q^{r} P_{n} \\\\\n",
        "&=\\sum_{n r} \\delta_{r}{ }^{n} Q^{r} P_{n} \\\\\n",
        "&=\\sum_{n} Q^{n} P_{n} \\\\\n",
        "&=Q(P) .\n",
        "\\end{aligned}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOpRBfFvMuPK"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Kovarianz_(Physik)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddHwTCF6Arbs"
      },
      "source": [
        "**Tensor contraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9WA6hpJA3d8"
      },
      "source": [
        "* In multilinear algebra, a [tensor contraction](https://en.wikipedia.org/wiki/Tensor_contraction) is an operation on a tensor that arises from the natural pairing of a finite-dimensional vector space and its dual. \n",
        "\n",
        "* In components, it is expressed as a sum of products of scalar components of the tensor(s) caused by applying the summation convention to a pair of dummy indices that are bound to each other in an expression. \n",
        "\n",
        "* The contraction of a single mixed tensor occurs when a pair of literal indices (one a subscript, the other a superscript) of the tensor are set equal to each other and summed over. In the Einstein notation this summation is built into the notation. **The result is another tensor with order reduced by 2.**\n",
        "\n",
        "* Es ist eine Verallgemeinerung der Spur einer linearen Abbildung auf Tensoren, die mindestens einfach kovariant und einfach kontravariant sind.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sXtSb9SMyHz"
      },
      "source": [
        "**Higher rank generalizations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi2yBC_VNPHF"
      },
      "source": [
        "Accordingly, a reasonable generalization is having a quantity which transforms like the **product of the components of two contravariant tensors**, that is\n",
        "\n",
        "> $A^{i k}=\\frac{\\partial x^{i}}{\\partial x^{\\prime} l} \\frac{\\partial x^{k}}{\\partial x^{\\prime m}} A^{\\prime l m}$\n",
        "\n",
        "which is called a **contravariant tensor of rank two**. The same applies to **covariant tensors of rank n or mixed tensor of rank n**.\n",
        "\n",
        "Having in mind the analogy to coordinate differentials and derivative of a scalar, take a look at this picture, which I think will help to make it clearer:\n",
        "\n",
        "![ddd](https://raw.githubusercontent.com/deltorobarba/repo/master/covariant.gif)\n",
        "\n",
        "> The contravariant components of a vector are obtained by projecting onto the coordinate axes.\n",
        "\n",
        "> The covariant components are obtained by projecting onto the normal lines to the coordinate hyperplanes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32JGoyi1b3vG"
      },
      "source": [
        "**Mixed Tensor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWTYw1Uqb6CX"
      },
      "source": [
        "* In tensor analysis, a [mixed tensor](https://en.wikipedia.org/wiki/Mixed_tensor) is a tensor which is neither strictly covariant nor strictly contravariant; at least one of the indices of a mixed tensor will be a subscript (covariant) and at least one of the indices will be a superscript (contravariant).\n",
        "\n",
        "* A mixed tensor of type or valence $\\left(\\begin{array}{l}M \\\\ N\\end{array}\\right),$ also written \"type $(M, N)$\", with both $M>0$ and $N>0,$ is a tensor which has $M$ contravariant indices and $N$ covariant indices. \n",
        "\n",
        "* Such a tensor can be defined as a linear function which maps an $(M+N)$ -tuple of $M$ one-forms and $N$ vectors to a scalar.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbSOinzDc_Gy"
      },
      "source": [
        "Consider the following octet of related tensors:\n",
        "\n",
        "> $\n",
        "T_{\\alpha \\beta \\gamma}, T_{\\alpha \\beta}^{\\gamma}, T_{\\alpha}{ }^{\\beta}{ }_{\\gamma}, T_{\\alpha}{ }^{\\beta \\gamma}, T_{\\beta \\gamma}^{\\alpha}, T^{\\alpha}{ }_{\\beta}^{\\gamma}, T^{\\alpha \\beta}{ }_{\\gamma}, T^{\\alpha \\beta \\gamma}\n",
        "$\n",
        "\n",
        "\n",
        "* The first one is covariant, the last one contravariant, and the remaining ones mixed.\n",
        "\n",
        "* Notationally, these tensors differ from each other by the covariance/contravariance of their indices. \n",
        "\n",
        "* A given **contravariant index of a tensor can be lowered using the [metric tensor](https://en.wikipedia.org/wiki/Metric_tensor)** $g_{\\mu v}$ and a given covariant index can be raised using the inverse metric tensor $g^{\\mu v}$. \n",
        "\n",
        "* Thus, $g_{\\mu v}$ could be called the index lowering operator and $g^{\\mu v}$ the index raising operator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zglWxx_a7Q_3"
      },
      "source": [
        "**Tensoranalyse**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHNHid3-NfOe"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Tensoranalysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pIIAEDf-4JK"
      },
      "source": [
        "**Motivation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL9soSZadOSm"
      },
      "source": [
        "*In our subject of differential geometry, where you talk about manifolds, **one difficulty is that the geometry is described by coordinates, but the coordinates do not have meaning**. They are allowed to undergo transformation. And in order to handle this kind of situation, an important tool is the so-called tensor analysis, or Ricci calculus, which was new to mathematicians. In mathematics you have a function, you write down the function, you calculate, or you add, or you multiply, or you can differentiate. You have something very concrete. In geometry the geometric situation is described by numbers, but you can change your numbers arbitrarily. So to handle this, you need the Ricci calculus.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnxwQGT8YfIk"
      },
      "source": [
        "* Die [Tensoranalysis](https://de.wikipedia.org/wiki/Tensoranalysis) ist ein Teilgebiet der Differentialgeometrie beziehungsweise der Differentialtopologie.\n",
        "\n",
        "* In der Tensoranalysis wird **das Verhalten von geometrischen Differentialoperatoren auf Tensorfeldern untersucht**.\n",
        "\n",
        "* Sie ist eine **Verallgemeinerung der Vektoranalysis**\n",
        "\n",
        "* Zum Beispiel kann der Differentialoperator Rotation in diesem Kontext auf n Dimensionen verallgemeinert werden. \n",
        "\n",
        "* Zentrale Objekte der Tensoranalysis sind Tensorfelder. Es wird untersucht, wie Differentialoperatoren auf diesen Feldern wirken.\n",
        "\n",
        "* Vektoren und Matrizen, sofern sie geometrische oder physikalische Groessen reprasentieren, koennen unter dem begriff eines tensors subsumiert werden\n",
        "\n",
        "* tensorrechnung in 2 teilen: anschauungsraum fur ingenieure (kartesische tensoren). Fur schiefwinklige (also affine) oder krummlinige Koordinaten sind begriffe wie kovariant und kontravariant wichtig (zur arbeit mit metriken, deren skalarproduktauf einer nicht positiv definiten bilinearform beruht). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyUcAVz5eqB9"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Raising_and_lowering_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74Dg7m3BT1vI"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Tensor_calculus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d3gdJDoTx5G"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Ricci_calculus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdfJaWZATzyW"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Glossary_of_tensor_theory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNJNE7fili4G"
      },
      "source": [
        "https://youtube.com/playlist?list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ_R6eImihmR"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Weingartenabbildung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pue7628gifls"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Hauptkr%C3%BCmmung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnISzsK_vdR7"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Krummlinige_Koordinaten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCtDLHvCnP9t"
      },
      "source": [
        "https://www.britannica.com/science/differential-geometry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JU7pvq7nRwf"
      },
      "source": [
        "https://www.google.com/imgres?imgurl=https%3A%2F%2Fupload.wikimedia.org%2Fwikipedia%2Fcommons%2Fthumb%2Fe%2Feb%2FMinimal_surface_curvature_planes-en.svg%2F220px-Minimal_surface_curvature_planes-en.svg.png&imgrefurl=https%3A%2F%2Fde.wikipedia.org%2Fwiki%2FWeingartenabbildung&tbnid=uSAqTnfjJUzAwM&vet=12ahUKEwjys97wlNjvAhUR5IUKHbgZAToQMygMegUIARCuAQ..i&docid=mqvKH_RaU3T2mM&w=220&h=150&q=Tangentialraum&ved=2ahUKEwjys97wlNjvAhUR5IUKHbgZAToQMygMegUIARCuAQ#imgrc=vJHgf3rzRtthxM&imgdii=GmYL3yE9Rq13KM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu3vloEDrTHI"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Pushforward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MthVadEfrXZV"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Rücktransport"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwTERXX027aS"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Cotangent_space#The_pullback_of_a_smooth_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gZ39Mp3fUJW"
      },
      "source": [
        "**Vector Decomposition**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB8gI8A_8aRe"
      },
      "source": [
        "Tensors notation allows a vector $(\\vec{V})$ to be decomposed into an [Einstein summation](https://en.wikipedia.org/wiki/Einstein_notation) representing the [tensor contraction](https://en.wikipedia.org/wiki/Tensor_contraction) of a [basis vector](https://en.wikipedia.org/wiki/Basis_(linear_algebra)) $\\left(\\vec{Z}_{i}\\right.$ or $\\left.\\vec{Z}^{i}\\right)$ with a component vector $\\left(V_{i}\\right.$ or $\\left.V^{i}\\right)$.\n",
        "\n",
        "> $\\vec{V}=V^{i} \\vec{Z}_{i}=V_{i} \\vec{Z}^{i}$\n",
        "\n",
        "Every vector has two different representations, one referred to as contravariant component $\\left(V^{i}\\right)$ with a covariant basis $\\left(\\vec{Z}_{i}\\right),$ and the other as a covariant component $\\left(V_{i}\\right)$ with a contravariant basis $\\left(\\vec{Z}^{i}\\right)$. \n",
        "\n",
        "The need to distinguish between contravariant and covariant arises from the fact that when we dot an arbitrary vector with its basis vector related to a particular coordinate system, there are two ways of interpreting this dot product, \n",
        "\n",
        "* either we view it as the projection of the basis vector onto the arbitrary vector, \n",
        "\n",
        "> $\\vec{V} \\cdot \\vec{Z}_{i}=V_{i}=\\vec{V}^{T} \\vec{Z}_{i}=\\vec{Z}_{i}^{T} \\vec{V}=\\operatorname{proj}_{\\vec{Z}^{i}}(\\vec{V}) \\cdot \\vec{Z}_{i}=\\operatorname{proj}_{\\vec{V}}\\left(\\vec{Z}^{i}\\right) \\cdot \\vec{V}$\n",
        "\n",
        "* or we view it as the projection of the arbitrary vector onto the basis vector.\n",
        "\n",
        "> $\\vec{V} \\cdot \\vec{Z}^{i}=V^{i}=\\vec{V}^{T} \\vec{Z}^{i}=\\vec{Z}^{i T} \\vec{V}=\\operatorname{proj}_{\\vec{Z}_{i}}(\\vec{V}) \\cdot \\vec{Z}^{i}=\\operatorname{proj}_{\\vec{V}}\\left(\\vec{Z}_{i}\\right) \\cdot \\vec{V}$\n",
        "\n",
        "Both views of the dot product are entirely equivalent, but have different component elements and different basis vectors.\n",
        "\n",
        "> **For example, in physics you start with a vector field, you decompose it with respect to the covariant basis, and that's how you get the contravariant coordinates.**\n",
        "\n",
        "* For **orthonormal cartesian coordinates, the covariant and contravariant basis are identical**, since the basis set in this case is just the identity matrix.\n",
        "\n",
        "* However, for **non-affine coordinate system such as polar or spherical there is a need to distinguish between decomposition by use of contravariant or covariant basis** set for generating the components of the coordinate system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvSbnf6qPwbW"
      },
      "source": [
        "Covariant vector decomposition:\n",
        "\n",
        "> $\\vec{V}=V^{i} \\vec{Z}_{i}$\n",
        "\n",
        "$V^{i}$ contravariant components (ordered set of scalars)\n",
        "\n",
        "$\\vec{Z}_{i}$ covariant bases (ordered set of vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsW6JrNDPzt6"
      },
      "source": [
        "Contravariant vector decomposition\n",
        "\n",
        "$\\vec{V}=V_{i} \\vec{Z}^{i}$\n",
        "\n",
        "$V_{i}$ covariant components (ordered set of scalars)\n",
        "\n",
        "$\\vec{Z}^{i}$ contravariant bases (ordered set of covectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbsGhFYefeni"
      },
      "source": [
        "**Metric Tensor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay4WSQYaSdya"
      },
      "source": [
        "The metric tensor represents a matrix with scalar elements $\\left(Z_{i j}\\right.$ or $Z^{i j}$ ) and is a tensor object which is used to raise or lower the index on another tensor object by an operation called\n",
        "contraction, thus allowing a covariant tensor to be converted to\n",
        "a contravariant tensor, and vice versa.\n",
        "\n",
        "Example of lowering index using metric tensor:\n",
        "\n",
        "$T_{i}=Z_{i j} T^{j}$\n",
        "\n",
        "Example of raising index using metric tensor:\n",
        "\n",
        "$T^{i}=Z^{i j} T_{j}$\n",
        "\n",
        "The metric tensor is defined as:\n",
        "\n",
        "$Z_{i j}=\\vec{Z}_{i} \\cdot \\vec{Z}_{j}$\n",
        "\n",
        "$Z^{i j}=\\vec{Z}^{i} \\cdot \\vec{Z}^{j}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6v0WBxsSwkY"
      },
      "source": [
        "Two flavors of metric tensors exist: (1) the contravariant metric tensor $\\left(Z^{i j}\\right),$ and (2) the covariant metric tensor $\\left(Z_{i j}\\right.$). These two flavors of metric tensor are related by the identity:\n",
        "\n",
        "> $Z_{i k} Z^{j k}=\\delta_{i}^{j}$\n",
        "\n",
        "For an orthonormal [Cartesian coordinate system](https://en.wikipedia.org/wiki/Cartesian_coordinate_system), the metric\n",
        "tensor is just the [kronecker delta](https://en.wikipedia.org/wiki/Kronecker_delta) $\\delta_{i j}$ or $\\delta^{i j},$ which is just a tensor equivalent of the identity matrix, and $\\delta_{i j}=\\delta^{i j}=\\delta_{j}^{i}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyZKbVQYff6-"
      },
      "source": [
        "**Jacobian**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH8gB0QUYsMU"
      },
      "source": [
        "In addition a tensor can be readily converted from an\n",
        "unbarred $(x)$ to a barred coordinate $(\\bar{x})$ system having different sets of basis vectors:\n",
        "\n",
        "> $f\\left(x^{1}, x^{2}, \\ldots, x^{n}\\right)=f\\left(x^{1}(\\bar{x}), x^{2}(\\bar{x}), \\ldots, x^{n}(\\bar{x})\\right)=\\bar{f}\\left(\\bar{x}^{1}, \\bar{x}^{2}, \\ldots, \\bar{x}^{n}\\right)=\\bar{f}\\left(\\bar{x}^{1}(x), \\bar{x}^{2}(x), \\ldots, \\bar{x}^{n}(x)\\right)$\n",
        "\n",
        "by use of Jacobian matrix relationships between the barred and unbarred coordinate system $\\left(\\bar{J}=J^{-1}\\right)$. The Jacobian between the barred and unbarred system is\n",
        "instrumental in defining the covariant and contravariant basis vectors, in that in order\n",
        "for these vectors to exist they need to satisfy the following relationship relative to the\n",
        "barred and unbarred system:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVRo7ERcaGFN"
      },
      "source": [
        "*Unbarred and barred basically means the old and new system respectively here. The name Unbarred comes from the bar over the $\\bar{x}$ and $\\bar{y}$.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lA4KvAMY4Zv"
      },
      "source": [
        "Contravariant vectors are required to obey the laws:\n",
        "\n",
        "$v^{i}=\\bar{v}^{r} \\frac{\\partial x^{i}(\\bar{x})}{\\partial \\bar{x}^{r}}$\n",
        "\n",
        "$\\bar{v}^{i}=v^{r} \\frac{\\partial \\bar{x}^{i}(x)}{\\partial x^{r}}$\n",
        "\n",
        "Covariant vectors are required to obey the laws:\n",
        "\n",
        "$v_{i}=\\bar{v}_{r} \\frac{\\partial \\bar{x}^{i}(x)}{\\partial x^{r}}$\n",
        "\n",
        "$\\bar{v}_{i}=v_{r} \\frac{\\partial x^{r}(\\bar{x})}{\\partial \\bar{x}^{i}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihTmYeSBZyNe"
      },
      "source": [
        "There are two flavors of Jacobian matrix:\n",
        "\n",
        "1. The J matrix representing the change from unbarred to barred coordinates. To find\n",
        "J, we take the \"barred gradient\", i.e. partial derive with respect to $\\bar{x}^{i}$ :\n",
        "$J=\\bar{\\nabla} f(x(\\bar{x}))$\n",
        "\n",
        "2. The $\\bar{J}$ matrix, representing the change from barred to unbarred coordinates. To find $\\bar{J},$ we take the \"unbarred gradient\", i.e. partial derive with respect to $x^{i}$ :\n",
        "$\\bar{J}=\\nabla \\bar{f}(\\bar{x}(x))$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uilyVl8CfilP"
      },
      "source": [
        "**Gradient Vector**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hug2uym9flmO"
      },
      "source": [
        "Tensor calculus provides a generalization to the gradient vector formula from standard calculus **that works in all coordinate systems**:\n",
        "\n",
        "> $\\nabla F=\\nabla_{i} F \\vec{Z}^{i}$\n",
        "\n",
        "where:\n",
        "\n",
        "> $\\nabla_{i} F=\\frac{\\partial F}{\\partial Z^{i}}$\n",
        "\n",
        "* In contrast, for standard calculus, the gradient vector formula is dependent on the coordinate system in use (example: Cartesian gradient vector formula vs. the polar gradient vector formula vs. the spherical gradient vector formula, etc.). \n",
        "\n",
        "* In standard calculus, each coordinate system has its own specific formula, unlike **tensor calculus that has only one gradient formula that is equivalent for all coordinate systems**. This is made possible by an understanding of the metric tensor that tensor calculus makes use of."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A29VRuMPiw4O"
      },
      "source": [
        "**Tensorfeld**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1ndD9U8PSkd"
      },
      "source": [
        "* Tensorfelder sind Funktionen, **die jedem Punkt einen Tensor zuordnen** (Tensor meint in diesem Fall ein rein algebraisches Objekt)\n",
        "\n",
        "* Tensorfelder werden auf ihre analytischen Eigenschaften untersucht (zB differenziert). Man erhält durch Differenzieren eines Tensorfeldes wieder ein Tensorfeld. Tensorfelder sind besondere glatte Abbildungen, die in Tensorbündel hinein abbilden (siehe unten).\n",
        "\n",
        "* Sei $M$ eine differenzierbare Mannigfaltigkeit. Ein [Tensorfeld](https://de.wikipedia.org/wiki/Tensorfeld) vom Typ (r,s) ist ein glatter [Schnitt](https://de.m.wikipedia.org/wiki/Schnitt_(Faserbündel)) im Tensorbündel $T_{s}^{r}(M)$. \n",
        "\n",
        "  * Ein Tensorfeld ist also ein glattes Feld $M \\rightarrow T_{s}^{r}(M),$ welches jedem Punkt der Mannigfaltigkeit einen (r,s)-Tensor zuordnet. \n",
        "\n",
        "  * Die Menge der Tensorfelder wird oft mit $\\Gamma^{\\infty}\\left(T_{s}^{r}(M)\\right)$ bezeichnet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o6ozZvJXdHS"
      },
      "source": [
        "**Tensordichte**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpVQEH92Xf4m"
      },
      "source": [
        "* [Tensordichte](https://de.wikipedia.org/wiki/Tensordichte) ist die Quantitätsgröße eines Tensorfeldes (Generalisierung)\n",
        "\n",
        "* die Tensordichte ist eine **Verallgemeinerung der Tensorfelder** in der Tensoranalysis \n",
        "\n",
        "* wurde eingeführt, um den „Unterschied zwischen Quantität und Intensität, soweit er physikalische Bedeutung hat“, zu erfassen: „die Tensoren sind die Intensitäts-, die Tensordichten die Quantitätsgrößen“. \n",
        "\n",
        "* eine **Tensordichte** ordnet einem Koordinatensystem ein Tensorfeld derart zu, dass es bei einem Koordinatenwechsel mit dem Absolutbetrag der Funktionaldeterminante multipliziert wird. Eine Tensordichte der Stufe null ist demnach eine skalare Dichte, deren Integral gemäß dem Transformationssatz eine Invariante liefert."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fr1laSwL3_0"
      },
      "source": [
        "##### **Multilinear Algebra**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zperKT5CPLHF"
      },
      "source": [
        "* [Multilineare Abbildung](https://de.m.wikipedia.org/wiki/Multilineare_Abbildung): Abbildung, die für jedes ihrer Argumente linear ist\n",
        "\n",
        "* [multilinear algebra](https://en.m.wikipedia.org/wiki/Multilinear_algebra) extends the methods of linear algebra. Just as linear algebra is built on the concept of a vector and develops the theory of vector spaces, multilinear algebra builds on the concepts of [p-vectors and multivectors](https://en.m.wikipedia.org/wiki/Multivector) with [Exterior algebra](https://en.m.wikipedia.org/wiki/Exterior_algebra) bzw. [Grassmann-Algebra](https://de.m.wikipedia.org/wiki/Graßmann-Algebra).\n",
        "\n",
        "* Abbildung von Modul in einen Ring (also Verallgemeinerung der K-Algebra von Vektorraum in den Korper, zB bei Integration oder Differential)\n",
        "\n",
        "  * Die Determinante in einem n-dimensionalen Vektorraum ist eine n-lineare Multilinearform.\n",
        "\n",
        "  * Jede lineare Abbildung ist eine 1-lineare Abbildung.\n",
        "\n",
        "  * Jede bilineare Abbildung ist eine 2-lineare Abbildung. (Sämtliche gemeinhin übliche Produkte sind bilineare Abbildungen: die Multiplikation in einem Körper (reelle, komplexe, rationale Zahlen) oder einem Ring (ganze Zahlen, Matrizen), aber auch das Vektor- oder Kreuzprodukt, und das Skalarprodukt auf einem reellen Vektorraum. Ein Spezialfall der bilinearen Abbildungen sind die Bilinearformen. Bei diesen ist der Wertebereich G mit dem Skalarkörper K der Vektorräume E und F identisch.)\n",
        "\n",
        "  * Sparprodukt ist eine 3-lineare Abbildung\n",
        "\n",
        "*  Multilinearform: wie linear- oder bilinearform, nur mehr argumente. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yEx_PiphBhK"
      },
      "source": [
        "**Multivector (Clifford number)**\n",
        "\n",
        "* In multilinear algebra, a [multivector](https://en.m.wikipedia.org/wiki/Multivector), sometimes called **Clifford number**,  is an element of the exterior algebra $\\Lambda(V)$ of a vector space $V$. \n",
        "\n",
        "* This algebra is graded, associative and alternating, and consists of linear combinations of simple $k$ -vectors  (also known as decomposable $k$ -vectors  or $k$ -blades) of the form\n",
        "\n",
        "> $v_{1} \\wedge \\cdots \\wedge v_{k}$\n",
        "\n",
        "where $v_{1}, \\ldots, v_{k}$ are in $V$.\n",
        "\n",
        "* A $k$ -vector is such a linear combination that is homogeneous of degree $k$ (all terms are\n",
        "$k$ -blades for the same $k$ ). Depending on the authors, a \"multivector\" may be either a $k-$\n",
        "vector or any element of the exterior algebra (any linear combination of $k$ -blades with potentially differing values of $k$ ).\n",
        "\n",
        "* In differential geometry, a $k$ -vector is a vector in the exterior algebra of the tangent\n",
        "vector space; that is, it is an antisymmetric tensor obtained by taking linear\n",
        "combinations of the exterior product of $k$ tangent vectors, for some integer $k \\geq 0 .$ \n",
        "\n",
        "* A differential $k$ -form is a $k$ -vector in the exterior algebra of the dual of the tangent space,\n",
        "which is also the dual of the exterior algebra of the tangent space.\n",
        "\n",
        "* **For $k=0,1,2$ and $3, k$ -vectors are often called respectively scalars, vectors, bivectors and trivectors; they are respectively dual to 0 -forms, 1 -forms, 2 -forms and 3 forms.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu87J-2uEEKJ"
      },
      "source": [
        "**Outer Product**\n",
        "\n",
        "* In linear algebra, the [outer product](https://en.m.wikipedia.org/wiki/Outer_product) of two coordinate vectors is a matrix. \n",
        "\n",
        "* If the two vectors have dimensions n and m, then their outer product is an n × m matrix. More generally, given two tensors (multidimensional arrays of numbers), their outer product is a tensor. \n",
        "\n",
        "* The outer product of tensors is also referred to as their tensor product, and can be used to define the tensor algebra.\n",
        "\n",
        "* **Not to be confused with Exterior product**. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQisesrD4aTm"
      },
      "source": [
        "##### **Exterior Algebra**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyjt2yfs3ZLn"
      },
      "source": [
        "**Graßmann-Algebra bzw. äußere Algebra (exterior algebra with exterior algebra / wedge product)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJHLcvME3bgo"
      },
      "source": [
        "* the [exterior product or wedge product of vectors](https://en.m.wikipedia.org/wiki/Exterior_algebra) is an algebraic construction used in geometry to study areas, volumes, and their higher-dimensional analogues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw0nrRMf3jJb"
      },
      "source": [
        "![gg](https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/N_vector_positive.svg/417px-N_vector_positive.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYOP0XEXPAnI"
      },
      "source": [
        "* Die [Graßmann-Algebra](https://de.m.wikipedia.org/wiki/Graßmann-Algebra) oder **äußere Algebra** eines Vektorraums V ist eine assoziative, schiefsymmetrisch-graduierte Algebra mit Einselement. \n",
        "\n",
        "> Sie ist – je nach Definition – **Unteralgebra oder eine Faktoralgebra einer antisymmetrisierten** [**Tensoralgebra**](https://de.m.wikipedia.org/wiki/Tensoralgebra) von V und wird durch $\\Lambda V$ dargestellt.\n",
        "\n",
        "* Die Multiplikation wird als **äußeres Produkt, Keilprodukt, Dachprodukt oder Wedgeprodukt** bezeichnet. Ein Spezialfall dieses Produkts ist mit dem Kreuzprodukt verwandt.\n",
        "\n",
        "* Anwendung findet dieser Kalkül in der elementaren linearen Algebra (zum Beispiel in der Theorie der Determinanten), und vor allem in der algebraischen Geometrie und der Differentialgeometrie als Algebra der Differentialformen. \n",
        "\n",
        "* In dieser Form geht die Theorie der alternierenden Differentialformen auf Élie Cartan zurück, der damit die bestehenden Begriffe der Flächentheorie vereinheitlichte. Antikommutative Produkte von Vektoren wie auch abstrakte Vektorräume überhaupt wurden erstmals 1846 von Hermann Graßmann betrachtet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAbAIifp5yxR"
      },
      "source": [
        "https://towardsdatascience.com/exterior-product-ecd5836c28ab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa-kd0Yp4eKI"
      },
      "source": [
        "##### **Tensor Algebra**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvhTNRlSU7Uc"
      },
      "source": [
        "**Tensoralgebra**\n",
        "\n",
        "* Die [Tensoralgebra](https://de.m.wikipedia.org/wiki/Tensoralgebra) ist ein mathematischer Begriff, der in vielen Bereichen der Mathematik wie der linearen Algebra, der Algebra, der Differentialgeometrie sowie in der Physik verwendet wird. \n",
        "\n",
        "* Sie fasst \"alle Tensoren\" über einem Vektorraum in der Struktur einer graduierten Algebra zusammen.\n",
        "\n",
        "* Es sei $V$ ein Vektorraum über einem Körper $K$ oder allgemeiner ein Modul über einem kommutativen Ring mit Einselement. Dann ist die Tensoralgebra (als Vektorraum) definiert durch die direkte Summe aller Tensorprodukte des Raums mit sich selbst.\n",
        "\n",
        ">$\n",
        "\\mathrm{T}(V):=\\bigoplus_{n \\geq 0} V^{\\otimes n}=K \\oplus V \\oplus(V \\otimes V) \\oplus(V \\otimes V \\otimes V) \\oplus \\ldots\n",
        "$\n",
        "\n",
        "* Mit der Multiplikation, die auf den homogenen Bestandteilen durch das Tensorprodukt gegeben ist, wird $\\mathrm{T}(V)$ zu einer $\\mathbb{N}_{0}$ -graduierten, unitären, assoziativen Algebra.\n",
        "\n",
        "* Quotientenräume der Tensoralgebra: Durch Herausteilen eines bestimmten Ideals kann man aus der Tensoralgebra beispielsweise die symmetrische Algebra, die äußere Algebra oder die **Clifford-Algebra** gewinnen. Diese Algebren sind in der Differentialgeometrie von Bedeutung.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw9zix-_EcMb"
      },
      "source": [
        "**Tensor Product**\n",
        "\n",
        "* the [tensor product V ⊗ W](https://en.m.wikipedia.org/wiki/Tensor_product) of two vector spaces V and W (over the same field) is a vector space which can be thought of as the space of all tensors that can be built from vectors from its constituent spaces using an additional operation which can be **considered as a generalization and abstraction of the outer product**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SR7NUJt4vwu"
      },
      "source": [
        "##### **Miscellaneous**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8grPyKTQJX1"
      },
      "source": [
        "**Graduierung (Algebra)**\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Graduierung_(Algebra)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7_0U6YPQftC"
      },
      "source": [
        "**Differentialform (Tangent Spaces)**\n",
        "\n",
        "*Beispiele fur Differentialformen*:\n",
        "\n",
        "* [Glatte Funktionen](https://de.m.wikipedia.org/wiki/Glatte_Funktion) sind 0-Formen.\n",
        "\n",
        "* [Pfaffsche Formen](https://de.m.wikipedia.org/wiki/Pfaffsche_Form) sind 1-Formen (= zB Wegintegral)\n",
        "\n",
        "https://www.youtube.com/watch?app=desktop&v=CYz_s82JnY8\n",
        "\n",
        "https://www.youtube.com/watch?v=ziD8ewQjaf4\n",
        "\n",
        "* [Differentialformen](https://de.m.wikipedia.org/wiki/Differentialform) sind ein grundlegendes Konzept der Differentialgeometrie. Sie erlauben eine koordinatenunabhängige Integration auf allgemeinen orientierten differenzierbaren Mannigfaltigkeiten.\n",
        "\n",
        "Es sei $U$\n",
        "- eine offene Teilmenge des $\\mathbb{R}^{n}$\n",
        "- oder eine differenzierbare Untermannigfaltigkeit des $\\mathbb{R}^{n}$\n",
        "- oder eine differenzierbare Mannigfaltigkeit.\n",
        "\n",
        "In jedem dieser Fälle gibt es:\n",
        "- den Begriff der differenzierbaren Funktion auf $U$; der Raum der beliebig oft differenzierbaren Funktionen auf $U$ werde mit $C^{\\infty}(U)$ bezeichnet;\n",
        "- den Begriff des Tangentialraums $\\mathrm{T}_{p} U$ an $U$ in einem Punkt $p \\in U$;\n",
        "- den Begriff der Richtungsableitung $\\frac{\\partial f}{\\partial X}$ für einen Tangentialvektor $X \\in \\mathrm{T}_{p} U$ und eine differenzierbare Funktion $f$;\n",
        "- den Begriff des differenzierbaren Vektorfeldes auf $U$; der Raum der Vektorfelder auf $U$ sei mit $\\Gamma(\\mathrm{T} U)$ bezeichnet.\n",
        "- Der Dualraum des Tangentialraums $\\mathrm{T}_{p} U$ wird als Kotangentialraum $\\mathrm{T}_{p}^{*} U$\n",
        "bezeichnet.\n",
        "\n",
        "*Definition*\n",
        "\n",
        "Eine Differentialform vom Grad $k$ auf $U$ oder kurz $k$ -Form $\\omega$ ist ein glatter Schnitt in der $k$ -ten äußeren Potenz des Kotangentialbündels von $U$. In symbolischer Schreibweise bedeutet dies $\\omega \\in \\Gamma\\left(\\Lambda^{k}\\left(T^{*} U\\right)\\right)$, wobei $T^{*} U$ das Kotangentialbündel von $U, \\Lambda^{k}\\left(T^{*} U\\right)$ die $k$ -te äußere Potenz von $T^{*} U$ und $\\Gamma\\left(\\Lambda^{k}\\left(T^{*} U\\right)\\right)$ somit die Menge der glatten Schnitte von $\\Lambda^{k}\\left(T^{*} U\\right)$ bezeichnet.\n",
        "\n",
        "Dies bedeutet, dass jedem Punkt $p \\in U$ eine alternierende Multilinearform $\\omega_{p}$ auf dem Tangentialraum $T_{p} U$ zugeordnet wird; und zwar so, dass für $k$ glatte Vektorfelder $X_{1}, \\ldots, X_{k}$ die Funktion\n",
        "\n",
        "$\n",
        "p \\mapsto \\omega_{p}\\left(\\left(X_{1}\\right)_{p}, \\ldots,\\left(X_{k}\\right)_{p}\\right) \\in \\mathbb{R}\n",
        "$\n",
        "\n",
        "glatt, also beliebig oft differenzierbar, ist.\n",
        "\n",
        "Alternativ dazu kann man eine $k$ -Form $\\omega$ als eine alternierende, glatte multilineare Abbildung $\\omega:(\\Gamma T U)^{k} \\rightarrow C^{\\infty}(U)$ auffassen. Das bedeutet: $\\omega$ ordnet $k$ Vektorfeldern $X_{1}, \\ldots, X_{k}$ eine Funktion $\\omega\\left(X_{1}, \\ldots, X_{k}\\right)$ zu, sodass\n",
        "\n",
        "* $\\omega\\left(X_{1}, \\ldots, X_{i}^{\\prime}+X_{i}^{\\prime \\prime}, \\ldots, X_{k}\\right)=\\omega\\left(X_{1}, \\ldots, X_{i}^{\\prime}, \\ldots, X_{k}\\right)+\\omega\\left(X_{1}, \\ldots, X_{i}^{\\prime \\prime}, \\ldots, X_{k}\\right)$\n",
        "\n",
        "* $\\omega\\left(X_{1}, \\ldots, f \\cdot X_{i}, \\ldots, X_{k}\\right)=f \\cdot \\omega\\left(X_{1}, \\ldots, X_{i}, \\ldots, X_{k}\\right)$ für $f \\in C^{\\infty}(U), 1 \\leq i \\leq k$\n",
        "\n",
        "und\n",
        "\n",
        "* $\\omega\\left(X_{1}, \\ldots, X_{i}, \\ldots, X_{j}, \\ldots, X_{k}\\right)=-\\omega\\left(X_{1}, \\ldots, X_{j}, \\ldots, X_{i}, \\ldots, X_{k}\\right)$\n",
        "gilt.\n",
        "\n",
        "Alternative unter Rückgriff auf Tensorfelder: Eine $k$ -Form ist ein alternierendes, kovariantes Tensorfeld der Stufe $k$.\n",
        "\n",
        "*Raum der Differentialformen*\n",
        "\n",
        "Die Menge der $k$ -Formen auf $U$ bildet einen Vektorraum und wird mit $\\Omega^{k}(U)$ bezeichnet. Weiterhin setzt man\n",
        "\n",
        "> $\n",
        "\\Omega(U)=\\bigoplus_{k=1}^{\\infty} \\Omega^{k}(U) .\n",
        "$\n",
        "\n",
        "Für endlichdimensionale Mannigfaltigkeiten ist diese Summe endlich, da für $k>\\operatorname{dim} U$ der Vektorraum $\\Omega^{k}(U)$ der Nullvektorraum ist. Die Menge $\\Omega(U)$ ist eine Algebra mit dem äußeren Produkt als Multiplikation und somit auch wieder ein Vektorraum. Aus topologischer Sicht ist dieser Raum auch eine [Garbe](https://de.m.wikipedia.org/wiki/Garbe_(Mathematik)).\n",
        "\n",
        "Man kann $\\omega_{p}$ als Element der äußeren Potenz $\\Lambda^{k}\\left(T_{p}^{*} U\\right)$ auffassen; infolgedessen definiert das äußere Produkt (d. h. das Produkt $\\wedge$ in der äußeren Algebra) Abbildungen\n",
        "\n",
        "$\n",
        "\\Omega^{k}(U) \\times \\Omega^{\\ell}(U) \\rightarrow \\Omega^{k+\\ell}(U), \\quad(\\omega, \\eta) \\mapsto \\omega \\wedge \\eta\n",
        "$\n",
        "\n",
        "wobei $\\omega \\wedge \\eta$ durch\n",
        "\n",
        "$\n",
        "(\\omega \\wedge \\eta)_{p}=\\omega_{p} \\wedge \\eta_{p}\n",
        "$\n",
        "\n",
        "punktweise definiert ist.\n",
        "Dieses Produkt ist graduiert-kommutativ, es gilt\n",
        "\n",
        "$\n",
        "\\omega \\wedge \\eta=(-1)^{\\operatorname{deg} \\omega \\cdot \\operatorname{deg} \\eta} \\cdot \\eta \\wedge \\omega ;\n",
        "$\n",
        "\n",
        "dabei bezeichnet $\\operatorname{deg} \\omega$ den Grad von $\\omega, d$. h.: Ist $\\omega$ eine $k$ -Form, so ist $\\operatorname{deg} \\omega=k$. Demnach ist das Produkt zweier Formen ungeraden Grades antikommutativ und in allen anderen Kombinationen kommutativ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWBbB6GSU-3b"
      },
      "source": [
        "**Äußere Ableitung**\n",
        "\n",
        "* Die [äußere Ableitung](https://de.m.wikipedia.org/wiki/Äußere_Ableitung) ist ein Operator, der einer k-Differentialform eine $(k+1)$-Differentialform zuordnet. \n",
        "\n",
        "* Betrachtet man sie auf der Menge der $0$-Differentialformen, also auf der Menge der glatten Funktionen, so entspricht die äußere Ableitung der üblichen Ableitung für Funktionen.\n",
        "\n",
        "Die äußere Ableitung $\\mathrm{d} \\omega$ einer $k$ -Form $\\omega$ wird induktiv mithilfe der [Lie-Ableitung](https://de.m.wikipedia.org/wiki/Lie-Ableitung) (=die Ableitung eines Vektorfeldes oder allgemeiner eines Tensorfeldes entlang eines Vektorfeldes. ) und der Cartan-Formel\n",
        "\n",
        "> $\n",
        "\\mathcal{L}_{X}=i_{X} \\circ \\mathrm{d}+\\mathrm{d} \\circ i_{X}\n",
        "$\n",
        "\n",
        "definiert; dabei ist $X$ ein Vektorfeld, $\\mathcal{L}_{X}$ die Lie-Ableitung und $i_{X}$ die Einsetzung von $X$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1RnWJ05kRBh"
      },
      "source": [
        "[Cross product as an external product](https://en.m.wikipedia.org/wiki/Cross_product#Cross_product_as_an_external_product)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfeurdJUVNdv"
      },
      "source": [
        "**Geometric algebra**\n",
        "\n",
        "* the [geometric algebra](https://en.m.wikipedia.org/wiki/Geometric_algebra) (GA) of a vector space with a quadratic form (usually the Euclidean metric or the Lorentz metric) is an algebra over a field, the Clifford algebra of a vector space with a quadratic form with its multiplication operation called the geometric product. \n",
        "\n",
        "* The algebra elements are called multivectors, which contains both the scalars F and the vector space V.\n",
        "\n",
        "[*Comparison of vector algebra and geometric algebra*](https://en.m.wikipedia.org/wiki/Comparison_of_vector_algebra_and_geometric_algebra)\n",
        "\n",
        "* Geometric algebra is an extension of vector algebra, providing additional algebraic structures on vector spaces, with geometric interpretations.\n",
        "\n",
        "* Vector algebra uses all dimensions and signatures, as does geometric algebra, notably 3+1 spacetime as well as 2 dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjBfngofijVg"
      },
      "source": [
        "**Spacetime algebra**\n",
        "\n",
        "* In mathematical physics, [spacetime algebra (STA)](https://en.m.wikipedia.org/wiki/Spacetime_algebra) is a name for the Clifford algebra Cl1,3(R), or equivalently the geometric algebra G(M4). \n",
        "\n",
        "* According to David Hestenes, spacetime algebra can be particularly closely associated with the geometry of special relativity and relativistic spacetime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSUJ4lrpPZh7"
      },
      "source": [
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C00Q8w5akdP3"
      },
      "source": [
        "Multilinear algebra, p-vectors / multivectors & Grassmann algebra (Exterior algebra)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMSofzfPK69d"
      },
      "source": [
        "* [Satz von Stokes](https://de.m.wikipedia.org/wiki/Satz_von_Stokes) (Vektoranalysis): sehr grundlegenden Satz über die Integration von Differentialformen, der den Hauptsatz der Differential- und Integralrechnung erweitert\n",
        "\n",
        "* [Volumenform](https://de.m.wikipedia.org/wiki/Volumenform) (sowie Koordinatentransformationen und Funktionaldeterminante in der Vektoranalysis): Aus mathematischer Sicht ist eine Volumenform auf einer $n$-dimensionalen Mannigfaltigkeit eine nirgends verschwindende Differentialform vom Grad $n$. Im Fall einer orientierten riemannschen Mannigfaltigkeit ergibt sich eine kanonische Volumenform aus der verwendeten Metrik, die den Wert 1 auf einer positiv orientierten Orthonormalbasis annimmt. Diese wird Riemann'sche Volumenform genannt (**Hodge-Stern-Operator in der Differentialgeometrie**).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbZakT_JTqO3"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Vector_algebra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWkYX2SwTtOs"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Multivector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LTIwlVeT2Cd"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Tensorprodukt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZiwlF6bT9Dh"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Tensorprodukt_von_Moduln"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SnZ4pJ6fbbu"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Grassmann–Cayley_algebra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhvMR1gITiev"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Comparison_of_vector_algebra_and_geometric_algebra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPn5K0s4_de-"
      },
      "source": [
        "### **Basis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un7FkOhvAakA"
      },
      "source": [
        "##### **Globale vs lokale Basisvektoren (orthogonal vs krummlinig)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv2c-HChQpDh"
      },
      "source": [
        "**Orthogonale Koordinaten = globale Basisvektoren**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmwbmPUR-705"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Orthogonal_coordinates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S59OJhxbDkHw"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Cartesian_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIcIqTGCYSBQ"
      },
      "source": [
        "* In der linearen Algebra ist eine [Basis](https://de.wikipedia.org/wiki/Basis_(Vektorraum)), siehe auch hier [english basis](https://en.wikipedia.org/wiki/Basis_(linear_algebra)), eine Teilmenge eines Vektorraumes, mit deren Hilfe sich jeder Vektor des Raumes eindeutig als **endliche Linearkombination darstellen lässt**. Die Koeffizienten dieser Linearkombination heißen die Koordinaten des Vektors bezüglich dieser Basis. Ein Element der Basis heißt Basisvektor. \n",
        "\n",
        "> **Es koennen sehr viele verschiedene Vektorbasen in einem Vektorraum existieren (im Ggs zur Koordinatenbasis), zB im zweidimensionalen linearen Untervektorraum eines dreidimensionalen Vektorraumens, und ein [Basiswechsel wird mit einer Transformationsmatrix](https://www.youtube.com/watch?v=CR7e7Zc0QLg) gemacht.**\n",
        "\n",
        "* Wenn Verwechslungen mit anderen Basisbegriffen (z. B. der Schauderbasis) zu befürchten sind, nennt man eine solche Teilmenge auch Hamelbasis (nach Georg Hamel). \n",
        "\n",
        "* Ein Vektorraum besitzt im Allgemeinen verschiedene Basen, ein Wechsel der Basis erzwingt eine [Koordinatentransformation](https://de.wikipedia.org/wiki/Basiswechsel_(Vektorraum)). \n",
        "\n",
        "* Eigenschaften - Eine Basis eines Vektorraums $V$ ist eine Teilmenge $B$ von $V$ mit folgenden gleichwertigen Eigenschaften:\n",
        "\n",
        "  1. Jedes Element von $V$ lässt sich als Linearkombination von Vektoren aus $B$ darstellen und diese Darstellung ist eindeutig.\n",
        "\n",
        "  2. $B$ ist ein minimales Erzeugendensystem von $V$, jeder Vektor aus $V$ lässt sich also als Linearkombination aus $B$ darstellen ( $V$ ist lineare Hülle von $B$ ) und diese Eigenschaft gilt nicht mehr, wenn ein Element aus $B$ entfernt wird.\n",
        "\n",
        "  3. $B$ ist eine maximale linear unabhängige Teilmenge von $V$. Wird also ein weiteres Element aus $V$ zu $B$ hinzugefügt, ist die neue Menge nicht mehr linear unabhängig.\n",
        "\n",
        "  4. $B$ ist ein linear unabhängiges Erzeugendensystem von $V$.\n",
        "\n",
        "* Beispiele\n",
        "\n",
        "  * In der euklidischen Ebene $\\mathbb {R} ^{2}$ gibt es die so genannte [Standardbasis](https://de.wikipedia.org/wiki/Standardbasis) $\\{(1,0),(0,1)\\}$. Darüber hinaus bilden in dieser Ebene zwei Vektoren genau dann eine Basis, wenn sie nicht in dieselbe (oder die entgegengesetzte) Richtung zeigen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K97l6x6R8rE"
      },
      "source": [
        "*Deep Dive: Basistransformation im Vektorraum*\n",
        "\n",
        "**Jeder beliebige Vektor kann als Linearkombination der Basisvektoren dargestellt werden, wobei die Koeffizienten der Linearkombination die Komponenten des Vektors genannt werden.**\n",
        "\n",
        "* Ein Vektorraum besitzt im Allgemeinen verschiedene Basen, ein Wechsel der Basis erzwingt eine [Koordinatentransformation](https://de.wikipedia.org/wiki/Basiswechsel_(Vektorraum)). \n",
        "\n",
        "* Mit welcher Linearkombination der Vektoren von Basis B lassen sich die Vektoren aus Basis A erschaffen? (Gauss-Verfahren, Einheitsmatrix von B + Transformationsmatrix von Basis A nach Basis B)\n",
        "\n",
        "* Source: [Video](https://www.youtube.com/watch?v=CR7e7Zc0QLg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyLBZdoaRuDQ"
      },
      "source": [
        "*Step 1: Ein Zielvektor = Basisvektor B * Koeffizienten von B oder Basisvektor A * Koeffizienten von A (hier ist: Koordinatenvektor = Koeffizienten)*\n",
        "\n",
        "![hh](https://raw.githubusercontent.com/deltorobarba/repo/master/transformationsmatrix_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1SJju7PR2q3"
      },
      "source": [
        "*Step 2: Transformationsmatrix * Koeffizienten von A = Koeffizienten von B* \n",
        "\n",
        "*Die Transformationsmatrix 'vermitteln' also zwischen den Koeffizienten (=Koordinatenvektoren) zu den verschiedenen Basen, damit immer der gleiche Zielvektor am Ende entsteht.*\n",
        "\n",
        "![hh](https://raw.githubusercontent.com/deltorobarba/repo/master/transformationsmatrix_02.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNTFCxpiu_N6"
      },
      "source": [
        "> **Die Hamelbasis (im Vektorraum) sollte nicht mit der [Basis eines Koordinatensystems](https://de.wikipedia.org/wiki/Koordinatensystem#Basisvektoren_im_Koordinatensystem) verwechselt werden, da diese Begriffe unter bestimmten Bedingungen nicht gleichgesetzt werden können (z. B. bei [krummlinigen Koordinaten](https://de.wikipedia.org/wiki/Krummlinige_Koordinaten)).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usYiqJlmZQvn"
      },
      "source": [
        "**Basis im Koordinatensystem**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3RWxL3raMQB"
      },
      "source": [
        "* Für [Koordinatensysteme kommt dem Begriff \"Basisvektor\"](https://de.wikipedia.org/wiki/Koordinatensystem#Basisvektoren_im_Koordinatensystem) eine etwas andere Bedeutung als für die Basisvektor eines Vektorräume zu. \n",
        "\n",
        "* Ein Basisvektor (für einen beliebigen Punkt) ist dann ein Vektor, der tangential zu einer bestimmten Koordinatenlinie an diesem Punkt verläuft. Daraus folgt, dass Basisvektoren im Koordinatensystem eine Basis im Koordinatensystem bilden, die im Allgemeinen von der Basis eines Vektorraums zu unterscheiden ist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRnTNuYOUuCv"
      },
      "source": [
        "**Orthogonal Coordinates & Cartesian Tensor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqwYWmlX6eQd"
      },
      "source": [
        "* Orthogonal coordinates are a **special but extremely common case of curvilinear coordinates**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaNSFzGjTVvp"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Cartesian_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdXgpe0PUwY9"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Orthogonal_coordinates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W7Acz5mTbMJ"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Orthogonal_transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byknWnywLLpB"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Bezugssystem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bi2KfCNOx4r"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Orthogonal_coordinates#Basis_vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naJqTJGwn-Uw"
      },
      "source": [
        "**Curvilinear Coordinates (Krummlinige Koordinaten) / Krummlinigen Koordinaten (Ortsabhängigkeit) = Lokale Basisvektoren**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w84rGWbbck2L"
      },
      "source": [
        "https://www.youtube.com/watch?v=rr5qEb_kT6c&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM01yC7PeNdN"
      },
      "source": [
        "* [Krummlinige Koordinaten](https://de.wikipedia.org/wiki/Krummlinige_Koordinaten) bzw. [Curvilinear coordinates](https://en.wikipedia.org/wiki/Curvilinear_coordinates) sowie [Tensors_in_curvilinear_coordinates](https://en.wikipedia.org/wiki/Tensors_in_curvilinear_coordinates) sind Koordinatensysteme auf dem euklidischen Raum $E^{n}$, bei denen die Koordinatenlinien gekrümmt sein können und die diffeomorph zu kartesischen Koordinaten sind.\n",
        "\n",
        "* Das heißt, die Transformation zwischen kartesischen Koordinaten und krummlinigen Koordinaten muss lokal invertierbar sein, wobei die Abbildung wie auch die Umkehrabbildung stetig differenzierbar sein müssen.\n",
        "\n",
        "* Die am häufigsten verwendeten krummlinigen Koordinatensysteme, die beide zu den orthogonalen Koordinatensystemen zählen, sind:\n",
        "\n",
        "  * ebene [Polarkoordinaten](https://de.wikipedia.org/wiki/Polarkoordinaten) (2D) \n",
        "  \n",
        "  * bzw. deren 3-dimensionale Entsprechung, die [Zylinderkoordinaten](https://de.wikipedia.org/wiki/Polarkoordinaten#Zylinderkoordinaten)\n",
        "\n",
        "  * [Kugelkoordinaten](https://de.wikipedia.org/wiki/Kugelkoordinaten), auch sphärische Koordinaten genannt (3D)\n",
        "\n",
        "* Je nach Problemstellung sind Berechnungen in krummlinigen Koordinatensystemen einfacher als in kartesischen durchzuführen. Zum Beispiel sind physikalische Systeme mit [Radialsymmetrie](https://de.wikipedia.org/wiki/Radialsymmetrie) oft einfacher in Kugelkoordinaten zu behandeln.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsZZBUfBn-JM"
      },
      "source": [
        "**Lokale Basisvektoren**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVeO8Remn8jo"
      },
      "source": [
        "* Die Koordinatenachsen sind als Tangenten an die **Koordinatenlinien** definiert. Da die Koordinatenlinien im Allgemeinen gekrümmt sind, sind die Koordinatenachsen nicht räumlich fest, wie es für kartesische Koordinaten gilt. \n",
        "\n",
        "* Dies führt auf das Konzept der [**lokalen Basisvektoren**](https://de.wikipedia.org/wiki/Krummlinige_Koordinaten#Koordinatenflächen,_-linien_und_-achsen), **deren Richtung vom betrachteten Raumpunkt abhängt** – im Gegensatz zu globalen Basisvektoren der kartesischen oder affinen Koordinaten."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE5xinzZpqDS"
      },
      "source": [
        "[**Verschiedene Basen bei krummlinigen Koordinaten**:](https://de.wikipedia.org/wiki/Krummlinige_Koordinaten#Verschiedene_Basen) \n",
        "\n",
        "* Um einen Vektor mittels Koordinaten darstellen zu können, ist eine Basis nötig. Im \n",
        "n-dimensionalen Raum besteht diese aus \n",
        "n linear unabhängigen Vektoren, den Basisvektoren. \n",
        "\n",
        "* **Jeder beliebige Vektor kann als Linearkombination der Basisvektoren dargestellt werden, wobei die Koeffizienten der Linearkombination die <u>Komponenten des Vektors</u> genannt werden**.\n",
        "\n",
        "* Für echt **krummlinige (also nicht-geradlinige) Koordinaten variieren Basisvektoren und Komponenten von Punkt zu Punkt**, weshalb die Basis als **lokale Basis** bezeichnet wird. Die Ortsabhängigkeit eines Vektorfeldes verteilt sich auf die Koordinaten sowie auf die Basisvektoren. \n",
        "\n",
        "* Im Gegensatz dazu zeichnen sich **globale Basen** dadurch aus, dass die Basisvektoren in jedem Punkt identisch sind, was nur für lineare bzw. affine Koordinaten (die Koordinatenlinien sind geradlinig, aber im Allgemeinen schiefwinklig) möglich ist. \n",
        "\n",
        "> **Die Ortsabhängigkeit eines Vektorfeldes steckt bei geradlinigen Koordinatensystemen allein in den Koordinaten (und nicht in den Basen)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9nsnWFXABd5"
      },
      "source": [
        "**Die <u>Koordinatenachsen sind als Tangenten an die Koordinatenlinien</u> definiert**. \n",
        "\n",
        "**Da die Koordinatenlinien im Allgemeinen gekrümmt sind, sind die Koordinatenachsen nicht räumlich fest, wie es für kartesische Koordinaten gilt.**\n",
        "\n",
        "**Dies führt auf das Konzept der <u>lokalen Basisvektoren</u>, deren Richtung vom betrachteten Raumpunkt abhängt – im Gegensatz zu globalen Basisvektoren der kartesischen oder affinen Koordinaten.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXq4fobVAFsP"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Krummlinige_Koordinaten#Koordinatenflächen,_-linien_und_-achsen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFbwI12TAUVH"
      },
      "source": [
        "![fff](https://upload.wikimedia.org/wikipedia/commons/5/57/General_curvilinear_coordinates_1.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRahASq3iF1r"
      },
      "source": [
        "##### **Basis (kovariante Basisvektoren)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7do7RC5SV4I3"
      },
      "source": [
        "*Forward and Backward Transformation with Kronecker Delta*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScPumApjxY3L"
      },
      "source": [
        "**Forward:  build the new basis vectors (not any vector!) from the old basis vectors**\n",
        "\n",
        "$\n",
        "\\begin{array}{l}\n",
        "\\text { Old Basis: }\\left\\{\\overrightarrow{e_{1}}, \\overrightarrow{e_{2}}\\right\\} \\\\\n",
        "\\text { New Basis: }\\left\\{\\widetilde{e_{1}}, \\widetilde{e_{2}}\\right\\}\n",
        "\\end{array}\n",
        "$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nzq-w-OOxdb0"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_08.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kls7jAoBybYZ"
      },
      "source": [
        "Forward transformation (create new basis vectors):\n",
        "\n",
        "$\n",
        "\\begin{array}{ll}\n",
        "\\widetilde{e_{1}}= & \\overrightarrow{e_{1}}+\\overrightarrow{e_{2}} \\\\\n",
        "\\widetilde{e_{2}}= & \\overrightarrow{e_{1}}+\\overrightarrow{e_{2}}\n",
        "\\end{array}\n",
        "$\n",
        "\n",
        "Which gives us for the image above:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\begin{array}{l}\n",
        "\\widetilde{e_{1}}=2 \\overrightarrow{e_{1}}+1 \\overrightarrow{e_{2}} \\\\\n",
        "\\widetilde{e_{2}}=-1 / 2 \\overrightarrow{e_{1}}+1 / 4 \\overrightarrow{e_{2}}\n",
        "\\end{array}\n",
        "\\end{equation}$\n",
        "\n",
        "Result is in the forward matrix (Notice how the coefficient from the first equation end up in the first column (2 and 1), and how the coefficients from the second equation end up in the second column)\n",
        "\n",
        "$\\begin{equation}\n",
        "F=\\left[\\begin{array}{cc}\n",
        "2 & -1 / 2 \\\\\n",
        "1 & 1 / 4\n",
        "\\end{array}\\right]\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2ZbNJn6yVIB"
      },
      "source": [
        "Backward transformation:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\begin{array}{l}\n",
        "\\overrightarrow{e_{1}}=1 / 4 \\widetilde{e_{1}}+(-1) \\widetilde{\\overrightarrow{e_{2}}} \\\\\n",
        "\\overrightarrow{e_{2}}=1 / 2 \\widetilde{e_{1}}+2 \\widetilde{e_{2}}\n",
        "\\end{array}\n",
        "\\end{equation}$\n",
        "\n",
        "Which gives as the backward matrix:\n",
        "\n",
        "$\\begin{equation}\n",
        "B=\\left[\\begin{array}{cc}\n",
        "1 / 4 & 1 / 2 \\\\\n",
        "-1 & 2\n",
        "\\end{array}\\right]\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2neQY72JzGkd"
      },
      "source": [
        "How do forward and backward matrices relate to each other? They are inverses, and matrix multiplication (dot product) leads to the identity matrix:\n",
        "\n",
        "$\n",
        "\\begin{aligned}\n",
        "F B &=\\left[\\begin{array}{cc}\n",
        "2 & -1 / 2 \\\\\n",
        "1 & 1 / 4\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "1 / 4 & 1 / 2 \\\\\n",
        "-1 & 2\n",
        "\\end{array}\\right] \n",
        "\\\\\n",
        "&=\\left[\\begin{array}{ll}\n",
        "(2*1/4)+(-1/2*-1) & (2*1/2)+(-1/2*2) \\\\\n",
        "(1*1/4)+(1/4*-1) & (1*1/2)+(1/4*2)\n",
        "\\end{array}\\right]\n",
        "\\\\\n",
        "&=\\left[\\begin{array}{ll}\n",
        "1 & 0 \\\\\n",
        "0 & 1\n",
        "\\end{array}\\right]\n",
        "\\end{aligned}\n",
        "$\n",
        "\n",
        "> This means: $\n",
        "B=F^{-1}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6G9Hp2p6s_K"
      },
      "source": [
        "**Reminder: Matrix Multiplication Rules**\n",
        "\n",
        "$\\begin{aligned}\n",
        "&=\\left[\\begin{array}{cc}\n",
        "a & b \\\\\n",
        "c & d\n",
        "\\end{array}\\right]\\left[\\begin{array}{cc}\n",
        "e & f \\\\\n",
        "g & h\n",
        "\\end{array}\\right] \n",
        "\\\\\n",
        "&=\\left[\\begin{array}{ll}\n",
        "ae+bg & af+bh \\\\\n",
        "ce+dg & cf+dh\n",
        "\\end{array}\\right]\n",
        "\\end{aligned}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa3sC7uC1RJX"
      },
      "source": [
        "**That was an example in 2 dimensions. What if we generalize it to n dimensions?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elhxOMyM0h4c"
      },
      "source": [
        "First construct the new basis vectors from the old ones with right coefficients:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\begin{array}{l}\n",
        "\\widetilde{e_{1}}=F_{11} \\overrightarrow{e_{1}}+F_{21} \\overrightarrow{e_{2}}+\\cdots+F_{n 1} \\overrightarrow{e_{n}} \\\\\n",
        "\\widetilde{e_{2}}={F_{12} \\overrightarrow{e_{1}}+F_{22} \\overrightarrow{e_{2}}+\\cdots+F_{n 2} \\overrightarrow{e_{n}}}\\\\\n",
        "{\\ldots} \\\\\n",
        "\\widetilde{e_{n}}=F_{1 n} \\overrightarrow{e_{1}}+F_{2 n} \\overrightarrow{e_{2}}+\\cdots+F_{n n} \\overrightarrow{e_{n}}\n",
        "\\end{array}\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VICDcbAF14lP"
      },
      "source": [
        "Write it as a n x n coefficient matrix $F$ (notice again **how it's transposed to the coefficients above**!)\n",
        "\n",
        "$\\begin{equation}\n",
        "\\left[\\begin{array}{cccc}\n",
        "F_{11} & F_{12} & \\ldots & F_{1 n} \\\\\n",
        "F_{21} & F_{22} & \\ldots & F_{2 n} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "F_{n 1} & F_{n 2} & \\ldots & F_{n n}\n",
        "\\end{array}\\right]\n",
        "\\end{equation}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymat9p8qvS7Y"
      },
      "source": [
        "**How to facilitate it without writing all these equations above?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEL6IpO42d6v"
      },
      "source": [
        "Let’s take an example: in the following equation taken from the table above (not the coefficient matrix, because there the values are transposed!):\n",
        "\n",
        "$F_{12}$ tells us how much of $\\overrightarrow{e_{1}}$ is in $\\widetilde{e_{2}}$:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\widetilde{e_{2}}=F_{12} \\overrightarrow{e_{1}}\n",
        "\\end{equation}$\n",
        "\n",
        "**So what I want is $\\sum F_{k j}$ that tells us how much of $\\overrightarrow{e_{k}}$ makes up $\\widetilde{{e}_{j}}$**:\n",
        "\n",
        "> $\\begin{equation}\n",
        "\\widetilde{e_{j}}=\\sum_{k=1}^{n} F_{k j} \\overrightarrow{e_{k}}\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwrK9EMSlVPg"
      },
      "source": [
        "**Exkurs: later we will use the Einstein notation and drop the summation sign to make it easier:**\n",
        "\n",
        "> $L\\left(\\overrightarrow{e_{j}}\\right)= \\color{red}{\\sum_{k=1}^{n}} L_{j}^{\\color{red}{k}} \\overrightarrow{e_{\\color{red}{k}}}$\n",
        "\n",
        "and rewrite it to:\n",
        "\n",
        " > $L\\left(\\overrightarrow{e_{j}}\\right)= L_{j}^{\\color{red}{k}} \\overrightarrow{e_{\\color{red}{k}}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF_AUcLo4tr0"
      },
      "source": [
        "Now we do the same for the backward transformation:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\begin{aligned}\n",
        "\\overrightarrow{e_{1}} &=B_{11} \\widetilde{e_{1}}+B_{21} \\widetilde{e_{2}}+\\cdots+B_{n 1} \\widetilde{e_{n}} \\\\\n",
        "\\overrightarrow{e_{2}} &=B_{1 2} \\widetilde{e_{1}}+B_{22} \\widetilde{e_{2}}+\\cdots+B_{n 2} \\widetilde{e_{n}} \\\\\n",
        "{\\ldots} \\\\\n",
        "\\overrightarrow{e_{n}} & =B_{1 n} \\widetilde{e_{1}}+B_{2 n} \\widetilde{e_{2}}+\\cdots+B_{n n} \\widetilde{e_{n}}\n",
        "\\end{aligned}\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-4vB7Rk4yOu"
      },
      "source": [
        "Write it as a n x n coefficient matrix $B$:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\left[\\begin{array}{cccc}\n",
        "B_{11} & B_{12} & \\ldots & B_{1 n} \\\\\n",
        "B_{21} & B_{22} & \\ldots & B_{2 n} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "B_{n 1} & B_{n 2} & \\ldots & B_{n n}\n",
        "\\end{array}\\right]\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd70Izk-5T8e"
      },
      "source": [
        "Summarize the backward transformation as well:\n",
        "\n",
        "> $\\begin{equation}\n",
        "\\overrightarrow{e_{i}}=\\sum_{j=1}^{n} B_{j i} \\widetilde{e_{j}}\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OztVUtrA1Fn4"
      },
      "source": [
        "Now both together forward and backward transformation:\n",
        "\n",
        "> $\\begin{equation}\n",
        "\\widetilde{e_{j}}=\\sum_{k=1}^{n} F_{k j} \\overrightarrow{e_{k}}\n",
        "\\end{equation}$\n",
        "\n",
        "> $\\begin{equation}\n",
        "\\overrightarrow{e_{i}}=\\sum_{j=1}^{n} B_{j i} \\widetilde{e_{j}}\n",
        "\\end{equation}$\n",
        "\n",
        "* The index that we do the summation over (here: k = 1 and j = 1 under the summation sign) is the first letter of the forward or backward transform and **corresponds to the index of the basis vector that we’re transforming**.\n",
        "\n",
        "* The second index of the transform (j and i at F, B and e) **corresponds to the output basis vector**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg45QeT1vmV1"
      },
      "source": [
        "**How are they related to each other?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM2-fBTt5ydc"
      },
      "source": [
        "How are they related to each other? (once again proving)\n",
        "\n",
        "$\\begin{equation}\n",
        "\\overrightarrow{e_{i}}=\\sum_{j=1}^{n} B_{j i} \\widetilde{e_{j}}\n",
        "\\end{equation}$\n",
        "\n",
        "Replacing with following at the last term above:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\stackrel{\\sim}{e_{j}}=\\sum_{k=1}^{n} F_{k j} \\overrightarrow{e_{k}}\n",
        "\\end{equation}$\n",
        "\n",
        "And you get: \n",
        "\n",
        "$\\begin{equation}\n",
        "\\overrightarrow{e_{i}}=\\sum_{j=1}^{n} B_{j i} \\sum_{k=1}^{n} F_{k j} \\overrightarrow{e_{k}}\n",
        "\\end{equation}$\n",
        "\n",
        "Rearranging summation signs:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\overrightarrow{e_{i}}=\\sum_{k}\\left(\\sum_{j} F_{k j} B_{j i}\\right) \\overrightarrow{e_{k}}\n",
        "\\end{equation}$\n",
        "\n",
        "So now we build the old basis vectors $\\overrightarrow{e_{i}}$ using the summation of the old basis vectors $\\overrightarrow{e_{k}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb3IDOvpv-Av"
      },
      "source": [
        "Now the following middle part should be an identity matrix:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\left(\\sum_{j}  F_{k j} B_{j i }\\right)\n",
        "\\end{equation}$ = $I$\n",
        "\n",
        "so that:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\overrightarrow{e_{i}}=\\sum_{k} \\overrightarrow{e_{k}}\n",
        "\\end{equation}$\n",
        "\n",
        "Which means then that:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\begin{aligned}\n",
        "\\overrightarrow{e_{1}} &=\\overrightarrow{e_{1}} \\\\\n",
        "\\overrightarrow{e_{2}} &=\\overrightarrow{e_{2}} \\\\\n",
        "& \\vdots \\\\\n",
        "\\overrightarrow{e_{n}} &=\\overrightarrow{e_{n}}\n",
        "\\end{aligned}\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI4qeZZmw0x0"
      },
      "source": [
        "In order to achieve that we want for this part the following conditions:\n",
        "\n",
        "for this $\\begin{equation}\n",
        "\\left(\\sum_{j}  F_{k j} B_{j i }\\right)\n",
        "\\end{equation}$ we want:\n",
        "\n",
        "* it is 1 when i = k\n",
        "\n",
        "* it is 0 when i ≠ k\n",
        "\n",
        "because that will give us the identity matrix (because 1 is where row is equal to the columns, so i = k, and all else 0):\n",
        "\n",
        "$\\begin{equation}\n",
        "I_{n}=\\left[\\begin{array}{ccccc}\n",
        "1 & 0 & 0 & \\cdots & 0 \\\\\n",
        "0 & 1 & 0 & \\cdots & 0 \\\\\n",
        "0 & 0 & 1 & \\cdots & 0 \\\\\n",
        "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "0 & 0 & 0 & \\cdots & 1\n",
        "\\end{array}\\right]\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrJ0cre_1ES3"
      },
      "source": [
        "So for this operation we have the Kronecker Delta:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\sum_{j} F_{k j} B_{j i}=\\delta_{i k}=\\left\\{\\begin{array}{l}\n",
        "1 \\text { if } i=k \\\\\n",
        "0 \\text { if } i \\neq k\n",
        "\\end{array}\\right.\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVFQgGqM0jIN"
      },
      "source": [
        "https://www.youtube.com/watch?v=sdCmW5N1LW4&list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG&index=3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNWssGHl5ZHr"
      },
      "source": [
        "https://www.youtube.com/watch?v=ipRrCPvftTk&list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG&index=4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hePBaTYIVEVe"
      },
      "source": [
        "##### **Dualbasis (kontravariante Basisvektoren)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W3tht0ppj3c"
      },
      "source": [
        "Um Basisvektoren mit einem Koordinatensystem zu verknüpfen gibt es zwei gebräuchliche Methoden:\n",
        "\n",
        "* **kovariante Basisvektoren (= \"kontravarianten Vektor\", weil Koordinaten kontravariant, dazu später mehr)**: Tangential an die Koordinatenlinien, d. h. kollinear zu den Koordinatenachsen (da, wie oben beschrieben, die Koordinatenachsen als Tangenten an die Koordinatenlinien definiert sind).\n",
        "\n",
        "* **kontravariante Basisvektoren (= \"kovarianten Vektor\", weil Koordinaten kovariant, dazu später mehr)**: Normal zu den Koordinatenflächen\n",
        "\n",
        "* Die beiden Klassen von Basisvektoren sind dual bzw. reziprok zueinander (siehe [duale Basis](https://de.wikipedia.org/wiki/Duale_Basis)). Diese beiden Basen bezeichnet man als **holonome Basen**. \n",
        "\n",
        "> Sie unterscheiden sich in ihrem Transformationsverhalten unter Koordinatenwechsel. **Dabei sind die Transformationen invers zueinander**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lHo6sUZxxix"
      },
      "source": [
        "**Zwei Basen**:\n",
        "\n",
        "* $\\left\\{\\overrightarrow{g_{i}}\\right\\}$ **kovariant** und \n",
        "  \n",
        "* $\\left\\{\\overrightarrow{g^{j}}\\right\\}$ **kontravariant** und **Dualbasis** zu $\\left\\{\\overrightarrow{g_{i}}\\right\\}$\n",
        "\n",
        "Wenn $\\vec{g}_{i} \\cdot \\vec{g}^{j}=\\delta_{i}^{j}$ (**Kronecker Delta / Skalarprodukt ist Null**) dann heissen $\\left\\{\\overrightarrow{g_{i}}\\right\\}$ und $\\left\\{\\overrightarrow{g^{j}}\\right\\}$ **reziprok** zueinander"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMGnUPxYzsfP"
      },
      "source": [
        "**Geometrische Interpretation** (\"paarweise Orthogonalitat\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRDfznSrzmkN"
      },
      "source": [
        "$\\left\\{\\overrightarrow{g_{1}}\\right\\}$ (kovariant von Basis 1) muss senkrecht stehen zu $\\left\\{\\overrightarrow{g^{2}}\\right\\}$ (kontravariant von Basis 2) und\n",
        "\n",
        "$\\left\\{\\overrightarrow{g_{2}}\\right\\}$ (kovariant von Basis 2) muss senkrecht stehen zu $\\left\\{\\overrightarrow{g^{1}}\\right\\}$ (kontravariant von Basis 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZjLhYyj0Jbd"
      },
      "source": [
        "![dd](https://raw.githubusercontent.com/deltorobarba/repo/master/paarweise_orthogonalitat.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-dcuzirYiHQ"
      },
      "source": [
        "https://av.tib.eu/media/19916"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU78Q46pzHVR"
      },
      "source": [
        "https://www.youtube.com/watch?v=PNRoBOzije8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_sNqeIOw7mo"
      },
      "source": [
        "![gg](https://upload.wikimedia.org/wikipedia/commons/5/57/General_curvilinear_coordinates_1.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPuk6DEuskis"
      },
      "source": [
        "**Bestimmung der Dualbasen aus den Basen**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjYPXuMKo0cq"
      },
      "source": [
        "![iiu](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhTGg_namsZI"
      },
      "source": [
        "Bestimmung der Dualbasen in diesem zweidimensionalen Fall in $\\mathbb{R}$:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzG2bnwwl-Qm"
      },
      "source": [
        "$e^{1}\\left(e_{1}\\right)=1$\n",
        "\n",
        "$e^{1}\\left(e_{2}\\right)=0$\n",
        "\n",
        "$e^{2}\\left(e_{1}\\right)=0$\n",
        "\n",
        "$e^{2}\\left(e_{2}\\right)=1$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A9lXQYqmmSv"
      },
      "source": [
        "Verallgemeinert kann man sie folgendermassen berechnen mit dem Kronecker-Delta:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Nb-_te9mWb1"
      },
      "source": [
        "$e^{k}\\left(e_{l}\\right)=\\left\\{\\begin{array}{l}1, \\text { wenn } k=l \\\\ 0, \\text { sonst }\\end{array}\\right.$\n",
        "\n",
        "$=\\delta_{l}^{k}$ Kronecker-Delta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJWHwObPnF4h"
      },
      "source": [
        "##### **Koordinatentransformation auf neue Basisvektoren**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN053jP7po2U"
      },
      "source": [
        "* Grundfrage: Wie werden alte Basisvektoren zu neuen Basivektoren?\n",
        "\n",
        "* Antwort: mittels der dualen Basen der alten Basisvektoren !\n",
        "\n",
        "* Basis ist beliebig ausgewahlt, aber physikalische Prozesse sollten jedesmal identisch abgebildet sein\n",
        "\n",
        "* Den neuen Basisvektor muss man mit den alten ausdruecken koennen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF8nN8rXqdJ5"
      },
      "source": [
        "![iiu](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_02.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A23YImRDrbEs"
      },
      "source": [
        "Verallgemeinerung dessen:\n",
        "\n",
        "> $e_{l}^{\\prime}=\\sum_{k=1}^{n} e^{k}\\left(e_{l}^{\\prime}\\right) e_{k}$\n",
        "\n",
        "das nennt sich: **kovariantes Transformationsverhalten**, weil sie mit der Basis gehen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jk36EWcVnM4"
      },
      "source": [
        "**Exkurs: Koordinatentransformation (Geometric transformation)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn_jMO4bXnP4"
      },
      "source": [
        "* Bei einer [Koordinatentransformation](https://de.wikipedia.org/wiki/Koordinatentransformation) werden aus den Koordinaten eines Punktes in einem Koordinatensystem dessen Koordinaten in einem anderen Koordinatensystem berechnet.\n",
        "\n",
        "* Typische Koordinatentransformationen entstehen im Koordinatensystems, die auch kombiniert werden können, durch:\n",
        "\n",
        "  * [Drehung](https://de.wikipedia.org/wiki/Drehung) (Rotation), \n",
        "  \n",
        "  * [Skalierung](https://de.wikipedia.org/wiki/Skalar_(Mathematik)) (Veränderung des Maßstabs), \n",
        "  \n",
        "  * [Scherung](https://de.wikipedia.org/wiki/Scherung_(Geometrie))\n",
        "  \n",
        "  * [Verschiebung](https://de.wikipedia.org/wiki/Parallelverschiebung) (Translation)\n",
        "\n",
        "* In der Regel verwendet man spezielle Transformationen, bei denen diese Funktionen gewissen Einschränkungen – z. B. Differenzierbarkeit, Linearität oder Formtreue – unterliegen. \n",
        "\n",
        "* Koordinatentransformationen können angewendet werden, wenn sich ein Problem in einem anderen Koordinatensystem leichter lösen lässt, z. B. bei der Transformation von kartesischen Koordinaten in Kugelkoordinaten oder umgekehrt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-VY4FmRvbTu"
      },
      "source": [
        "**Beispiele von Koordinatentransformationen**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqOlm2e7vV4s"
      },
      "source": [
        "Bei **lineare Transformationen** ([Lineare Abbildung](https://de.wikipedia.org/wiki/Lineare_Abbildung)) sind die neuen Koordinaten lineare Funktionen der ursprünglichen:\n",
        "\n",
        "$x_{1}^{\\prime}=a_{11} x_{1}+a_{12} x_{2}+\\cdots+a_{1 n} x_{n}$\n",
        "\n",
        "$x_{2}^{\\prime}=a_{21} x_{1}+a_{22} x_{2}+\\cdots+a_{2 n} x_{n}$\n",
        "\n",
        "$\\cdots$\n",
        "\n",
        "$x_{n}^{\\prime}=a_{n 1} x_{1}+a_{n 2} x_{2}+\\cdots+a_{n n} x_{n} .$\n",
        "  \n",
        "* Dies kann man kompakt als [Matrixmultiplikation](https://de.wikipedia.org/wiki/Matrizenmultiplikation) des alten Koordinatenvektors $\\vec{x} = (x_1, \\dots, x_n)$ mit der Matrix $A$, die die Koeffizienten $a_{ij}$ enthält, darstellen ${\\vec {x}}'=A{\\vec {x}}$.\n",
        "\n",
        "* Wichtige Typen linearer Koordinatentransformationen:\n",
        "\n",
        "  * [Drehung](https://de.wikipedia.org/wiki/Drehung) (Rotation), \n",
        "  \n",
        "  * [Skalierung](https://de.wikipedia.org/wiki/Skalar_(Mathematik)) (Veränderung des Maßstabs), \n",
        "  \n",
        "  * [Scherung](https://de.wikipedia.org/wiki/Scherung_(Geometrie))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U-UQd9KvT1M"
      },
      "source": [
        "[**Affine Transformationen**](https://de.wikipedia.org/wiki/Affine_Abbildung) bestehen aus einer linearen Transformation und einer Translation.\n",
        "\n",
        "* [Verschiebung](https://de.wikipedia.org/wiki/Parallelverschiebung) (Translation) - Die Translation ist ein Spezialfall einer affinen Transformation, bei der A die Einheitsmatrix ist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og2CmTW6nsQt"
      },
      "source": [
        "Der [**Basiswechsel im Vektorraum (Transformationsmatrix)**](https://de.wikipedia.org/wiki/Basiswechsel_(Vektorraum)) (lineare Algebra) ist der Übergang zwischen zwei verschiedenen Basen eines endlichdimensionalen Vektorraums über einem Körper $K$. Dadurch ändern sich im Allgemeinen die Koordinaten der Vektoren und die Abbildungsmatrizen von linearen Abbildungen. \n",
        "\n",
        "* **Ein Basiswechsel ist somit ein Spezialfall einer Koordinatentransformation**.\n",
        "\n",
        "* [Youtube Video 1](https://www.youtube.com/watch?v=CR7e7Zc0QLg) und [Youtube Video 2](https://www.youtube.com/watch?v=FFVauAY_FMI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DicyTGWvR4G"
      },
      "source": [
        "[Kartesische Koordinaten und Polarkoordinaten](https://de.wikipedia.org/wiki/Koordinatentransformation#Beispiele): Ein Punkt in der Ebene wird im kartesischen Koordinatensystem durch seine Koordinaten $(\\mathrm{x}, \\mathrm{y})$ und im Polarkoordinatensystem durch den Abstand $r$ vom Ursprung und dem (positiven) Winkel $\\varphi$ zur $x$ -Achse bestimmt.\n",
        "\n",
        "* Dabei gilt für die Umrechnung von Polarkoordinaten in kartesische Koordinaten:\n",
        "\n",
        "* $x=r \\cdot \\cos \\varphi$\n",
        "\n",
        "* $y=r \\cdot \\sin \\varphi$\n",
        "\n",
        "* Für die Umrechnung von kartesischen Koordinaten in Polarkoordinaten gilt:\n",
        "\n",
        "$\\begin{aligned} \\text { - } r &=\\sqrt{x^{2}+y^{2}} \\\\ \\text { - } \\varphi &=\\left\\{\\begin{array}{ll}\\arctan \\frac{y}{x} & \\text { für } x>0 \\\\ \\arctan \\frac{y}{x}+\\pi & \\text { für } x<0, y \\geq 0 \\\\ \\arctan \\frac{y}{x}-\\pi & \\text { für } x<0, y<0 \\\\ \\pi / 2 & \\text { für } x=0, y>0 \\\\ -\\pi / 2 & \\text { für } x=0, y<0 \\\\ \\arccos \\frac{x}{r} & \\text { für } y \\geq 0 \\\\ -\\arccos \\left(\\frac{x}{r}\\right) & \\text { für } y<0\\end{array}\\right.\\end{aligned}$\n",
        "\n",
        "\n",
        "* Bei der Implementierung der Variante mit arccos ist mit\n",
        "Rundungsfehlern zu rechnen, welche bei Nutzung des arctan deutlich geringer ausfallen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_LA4jr-x993"
      },
      "source": [
        "Die [Transformation von Differential-Operatoren](https://de.wikipedia.org/wiki/Kugelkoordinaten#Transformation_von_Differentialen) (Jacobi-Matrix)\n",
        "\n",
        "* Die lokalen Eigenschaften der Koordinatentransformation werden durch die Jacobi-Matrix beschrieben. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7stZASTx8Vh"
      },
      "source": [
        "Die [Transformation von Vektorfeldern](https://de.wikipedia.org/wiki/Kugelkoordinaten#Transformation_von_Vektorfeldern_und_-Operatoren)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upcGdiC2vZlQ"
      },
      "source": [
        "Die [Galilei-Transformation](https://de.wikipedia.org/wiki/Galilei-Transformation) ist die einfachste Koordinatentransformation, mit der physikalische Aussagen von einem Bezugssystem in ein anderes umgerechnet werden können. \n",
        "\n",
        "* Sie ist anwendbar, wenn die beiden Bezugssysteme sich durch eine geradlinig-gleichförmige Bewegung, Drehung und/oder eine Verschiebung in Raum oder Zeit unterscheiden. \n",
        "  \n",
        "* Alle Beobachtungen von Strecken, Winkeln und Zeitdifferenzen stimmen in beiden Bezugssystemen überein; alle beobachteten Geschwindigkeiten unterscheiden sich um die konstante Relativgeschwindigkeit der beiden Bezugssysteme."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPVYCoFdviIM"
      },
      "source": [
        "Die [Lorentz-Transformationen](https://de.wikipedia.org/wiki/Lorentz-Transformation), nach Hendrik Antoon Lorentz, sind eine Klasse von Koordinatentransformationen, die in der Physik Beschreibungen von Phänomenen in verschiedenen Bezugssystemen ineinander überführen. \n",
        "\n",
        "* Sie verbinden in einer vierdimensionalen Raumzeit die Zeit- und Ortskoordinaten, mit denen verschiedene Beobachter angeben, wann und wo Ereignisse stattfinden. \n",
        "\n",
        "* Die Lorentz-Transformationen bilden daher die Grundlage der Speziellen Relativitätstheorie von Albert Einstein.\n",
        "\n",
        "* **Das Äquivalent zu den Lorentz-Transformationen im dreidimensionalen euklidischen Raum sind die Galilei-Transformationen**.\n",
        "\n",
        "* Genauso wie diese Abstände und Winkel erhalten, erhalten die Lorentz-Transformationen die Abstände in der nichteuklidischen Raumzeit ([Minkowskiraum](https://de.wikipedia.org/wiki/Minkowski-Raum)). Winkel werden im Minkowskiraum nicht erhalten, da der Minkowskiraum kein normierter Raum ist.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBHTQSJ5yNSp"
      },
      "source": [
        "Eine [Eichtransformation](https://de.wikipedia.org/wiki/Eichtransformation) verändert die Eichfelder einer physikalischen Theorie (z. B. die elektromagnetischen Potentiale oder die potentielle Energie) dergestalt, dass die physikalisch wirksamen Felder (z. B. das elektromagnetische Feld oder ein Kraftfeld) und damit alle beobachtbaren Abläufe dabei die gleichen bleiben. Dies wird als Eichfreiheit bezeichnet. Man unterscheidet:\n",
        "\n",
        "* globale Eichtransformationen: sie werden an jedem Ort mit gleichem Wert durchgeführt, z. B. die Verschiebung des Nullpunkts der potentiellen Energie, die Wahl des Referenzpotentials bei der Messung elektrischer Spannungen, ein konstanter Phasenfaktor an der komplexen Wellenfunktion der Quantenmechanik.\n",
        "\n",
        "* lokale Eichtransformationen: dabei werden die Veränderungen an einem Parameter nicht durch einen einzigen Wert bestimmt, sondern mit Hilfe einer örtlich und/oder zeitlich variierenden Funktion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bFTx-nGvNcV"
      },
      "source": [
        "Siehe auch [Liste von Transformationen in der Mathematik](https://de.wikipedia.org/wiki/Liste_von_Transformationen_in_der_Mathematik)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjnbCM_1oQtX"
      },
      "source": [
        "http://walter.bislins.ch/physik/index.asp?page=Koordinatentransformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV9zDahD-li_"
      },
      "source": [
        "### **Vector**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USxCwRx3_1pK"
      },
      "source": [
        "##### **Tangential-, Kotangential- & Normalvektor (Linear/Bilinear)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQaOAIdS1O8C"
      },
      "source": [
        "**Tangential and Normal Components (Koordinaten)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1r3w_7TyDlB"
      },
      "source": [
        "* **Given a vector at a point on a curve (just a vector, not a tangential vector!), that vector can be decomposed uniquely as a sum of two vectors**, \n",
        "\n",
        "  * $\\mathbf{v}_{\\|}$ : one tangent to the curve, called the **tangential component** of the vector\n",
        "  * $\\mathbf{v}_{\\perp}$  : another one perpendicular to the curve, called the **normal component** of the vector\n",
        "\n",
        "  * Zusatzlich gibt es noch: The binormal unit vector B is defined as the cross product of T and N ([Source](https://en.m.wikipedia.org/wiki/Frenet%E2%80%93Serret_formulas))\n",
        "\n",
        "* More formally, let $S$ be a surface, and $x$ be a point on the surface. Let $\\mathbf{v}$\n",
        "be a vector at $x$. Then one can write uniquely $\\mathbf{v}$ as a sum:\n",
        "\n",
        ">$\n",
        "\\mathbf{v}=\\mathbf{v}_{\\|}+\\mathbf{v}_{\\perp}\n",
        "$\n",
        "\n",
        "* Similarly a vector at a point on a surface can be broken down the same way.\n",
        "\n",
        "* More generally, given a submanifold $N$ of a manifold $M,$ and\n",
        "a vector in the tangent space to $M$ at a point of $N$, it can be\n",
        "decomposed into the component tangent to $N$ and the\n",
        "component normal to $N$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvmoMSwEx9mx"
      },
      "source": [
        "![ggg](https://upload.wikimedia.org/wikipedia/commons/7/7a/Surface_normal_tangent.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWKbULdl0A6_"
      },
      "source": [
        "*Calculate the components*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK_fxXVW0Dw5"
      },
      "source": [
        "To calculate the tangential and normal components, consider a [unit normal](https://en.wikipedia.org/wiki/Normal_(geometry)) to the surface, that is, a [unit vector](https://en.wikipedia.org/wiki/Unit_vector) $\\hat{n}$ perpendicular to $S$ at $x$. Then, normal component:\n",
        "\n",
        ">$\n",
        "\\mathbf{v}_{\\perp}=(\\mathbf{v} \\cdot \\hat{n}) \\hat{n}\n",
        "$\n",
        "\n",
        "and thus tangential component:\n",
        "\n",
        ">$\n",
        "\\mathbf{v}_{\\|}=\\mathbf{V}-\\mathbf{V}_{\\perp}\n",
        "$\n",
        "\n",
        "where \".\" denotes the [dot product](https://en.wikipedia.org/wiki/Dot_product). \n",
        "\n",
        "Another formula for the tangential component is\n",
        "\n",
        ">$\n",
        "\\mathbf{v}_{\\|}=-\\hat{n} \\times(\\hat{n} \\times \\mathbf{v})\n",
        "$\n",
        "\n",
        "where \" $\\times$ \" denotes the [cross product](https://en.wikipedia.org/wiki/Cross_product).\n",
        "\n",
        "Note that these formulas do not depend on the particular unit normal $\\hat{n}$ used (there exist two unit normals to any surface at a given point, pointing in opposite directions, so one of the unit normals is the negative of the other one)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXJLcYOrMqS6"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Tangential_and_normal_components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArOg6IjI9Jd8"
      },
      "source": [
        "**Tangentialvektor & Tangentialraum**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI6zzIlG_0Yp"
      },
      "source": [
        "Sei $\\gamma:(-\\varepsilon, \\varepsilon) \\rightarrow M$ eine differenzierbare Kurve mit $\\gamma(0)=x$ und dem **Kurvenparameter $t$** (siehe 'Parameterdarstellungen' oben), dann ist:\n",
        "\n",
        ">$\n",
        "v=\\frac{d \\gamma}{d t}(0) \\in T_{x} M\n",
        "$\n",
        "\n",
        "ein [Tangentialvektor](https://en.wikipedia.org/wiki/Tangent_vector). \n",
        "\n",
        "Die Tangentialvektoren in einem Punkt $x \\in M$ spannen einen Vektorraum auf, den Tangentialraum $T_{x} M$. Siehe auch [Tangentialbündel](https://de.wikipedia.org/wiki/Tangentialbündel)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpv1Yq_Q-ZUg"
      },
      "source": [
        "**Tangent Space (Tangentialraum)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7hh5sOy-P24"
      },
      "source": [
        "* Ein [Tangentialraum](https://de.wikipedia.org/wiki/Tangentialraum) ist $T_{x} M$ ein Vektorraum, der eine differenzierbare Mannigfaltigkeit $M$ am Punkt $x$ linear approximiert. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2ru85Mxr0tL"
      },
      "source": [
        "**Normal (Vector) Space**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtmsBHksr3fP"
      },
      "source": [
        "* The normal vector space or normal space of a manifold at point P is the **set of vectors which are orthogonal to the tangent space at P**. \n",
        "\n",
        "* Normal vectors are of special interest in the case of smooth curves and smooth surfaces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSZASnOkiGPv"
      },
      "source": [
        "*Die [Hauptkrümmungen](https://de.wikipedia.org/wiki/Hauptkr%C3%BCmmung) sind [Eigenwerte](https://de.wikipedia.org/wiki/Eigenwertproblem) der [Weingartenabbildung](https://de.wikipedia.org/wiki/Weingartenabbildung)*\n",
        "\n",
        "![ggg](https://upload.wikimedia.org/wikipedia/commons/e/eb/Minimal_surface_curvature_planes-en.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsTbBraH_yr5"
      },
      "source": [
        "**Kotangentialraum**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv2jwEgm_xuC"
      },
      "source": [
        "* Der [Kotangentialraum](https://de.wikipedia.org/wiki/Kotangentialraum) ist der Dualraum des entsprechenden Tangentialraums. \n",
        "\n",
        "* Er ist ein Vektorraum, der einem Punkt einer differenzierbaren Mannigfaltigkeit $M$ zugeordnet wird.\n",
        "\n",
        "* Sei $M$ eine differenzierbare Mannigfaltigkeit und $T_{p} M$ ihr Tangentialraum am Punkt $p \\in M$. Dann ist der Kotangentialraum definiert als der Dualraum von $T_{p} M$. \n",
        "\n",
        "* **Das heißt, der Kotangentialraum besteht aus allen Linearformen auf dem Tangentialraum $T_{p} M$**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbvuY51s3dBD"
      },
      "source": [
        "In differential geometry, **one can attach to every point $x$ of a smooth (or differentiable) manifold, $\\mathcal{M},$ a vector space called the cotangent space at $x .$** Typically, the cotangent space, $T_{x}^{*} \\mathcal{M}$ is defined as the dual space of the tangent space at $x, T_{x} \\mathcal{M},$ although there are more direct definitions. The elements of the cotangent space are **called cotangent vectors or tangent covectors**.\n",
        "\n",
        "Let $\\mathcal{M}$ be a smooth manifold and let $x$ be a point in $\\mathcal{M}$. Let $T_{x} \\mathcal{M}$ be\n",
        "the tangent space at $x$. Then the cotangent space at $x$ is defined as the dual space of $T_{x} \\mathcal{M}$ :\n",
        "\n",
        "$\n",
        "T_{x}^{*} \\mathcal{M}=\\left(T_{x} \\mathcal{M}\\right)^{*}\n",
        "$\n",
        "\n",
        "Concretely, **elements of the cotangent space are linear functionals on $T_{x} \\mathcal{M}$**. That is, **every element $\\alpha \\in T_{x}^{*} \\mathcal{M}$ is a linear map**\n",
        "\n",
        "$\n",
        "\\alpha: T_{x} \\mathcal{M} \\rightarrow F\n",
        "$\n",
        "\n",
        "where $F$ is the underlying field of the vector space being considered, for example, the field of real numbers. \n",
        "\n",
        "**The elements of $T_{x}^{*} \\mathcal{M}$ are called cotangent vectors.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g97eVLPZebnS"
      },
      "source": [
        "**Bilinearform**: cross product of normal and tangent: https://en.m.wikipedia.org/wiki/Frenet–Serret_formulas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71BYhuzC572k"
      },
      "source": [
        "##### **Kombination von Basisvektoren mit Koordinaten zur Darstellung von Vektoren**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEs-I1SiCPbA"
      },
      "source": [
        "Thema: Kombination von Basisvektoren mit Koordinaten zur **Darstellung** von Vektoren, noch nicht zur **Transformation** (next chapter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyznJc8nwdEu"
      },
      "source": [
        "* An jedem Punkt der betrachteten Mannigfaltigkeit existieren gleichzeitig beide Basen.\n",
        "\n",
        "* **Somit kann ein beliebiger Vektor als Linearkombination entweder der kovarianten Basisvektoren <u>oder</u> der kontravarianten Basisvektoren dargestellt werden**. \n",
        "\n",
        "> **Dabei werden stets kontravariante Koordinaten $a_{u_{i}}$ mit kovarianten Basisvektoren $\\vec{b}_{u}$ kombiniert und kovariante Koordinaten $a_{u_{i}}^{*}$ mit kontravarianten Basisvektoren $\\vec{b}_{u_{i}}^{*}$.**\n",
        "\n",
        "> $\n",
        "\\vec{a}=\\sum_{i=1}^{n} a_{u_{i}} \\vec{b}_{u_{i}}=\\sum_{i=1}^{n} a_{u_{i}}^{*} \\vec{b}_{u_{i}}^{*}\n",
        "$\n",
        "\n",
        "* Wahrscheinlich das hier (?): Also zB fur Vektor im Originalvektorraum mit den Koordinaten von der Basis: a = 1,3 e<sub>1</sub> + 1,2 e<sub>2</sub> (kovariante Basis), dann sind 1,3 = e<sup>1</sup> und 1,2 = e<sup>2</sup> (kontravariante Vektorkomponenten / Koordinaten)\n",
        "\n",
        "* <u>Diese kreuzweise Paarung (kontra-ko bzw. ko-kontra) sorgt dafür, dass der Vektor $\\vec{a}$ unter Koordinatentransformation invariant ist, da die Transformationen von Koordinaten\n",
        "und Basisvektoren invers zueinander sind und sich gegenseitig aufheben.</u>\n",
        "\n",
        "* Diese Eigenschaft ist für den Begriff eines Vektors in der Physik essentiell: In der Physik müssen Gesetzmäßigkeiten unabhängig vom speziellen Koordinatensystem gelten. Aus physikalischer Sicht muss ein Vektor, der z. B. die Geschwindigkeit eines Teilchens beschreibt, unabhängig vom gewählten Koordinatensystem sein.\n",
        "\n",
        "> **Man spricht von einem kontravarianten Vektor (besser: kontravarianter Koordinatenvektor), wenn die Koordinaten kontravariant und die Basisvektoren\n",
        "kovariant sind.**\n",
        "\n",
        "> **Analog spricht man von einem kovarianten Vektor (auch Kovektor), wenn die Koordinaten kovariant und die Basisvektoren kontravariant sind. (Kovektoren als Linearformen von Normalenvektoren)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jLrbXE_VdYz"
      },
      "source": [
        "##### **Vectors (contravariant): Transformation of vectors across two basis (with forward/backward)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9TgyAbOVgyy"
      },
      "source": [
        "* Vectors: List of numbers in a vector are **vector components**, not vectors themself, like $\\alpha$ in $\\alpha$ * $v_{1}$\n",
        "> **This is important because vectors are invariant under a change of coordinates, meanwhile vector components are not invariant**\n",
        "* Arrows for vectors are Euclidean vectors!\n",
        "* Vectors is a member of a vector space! (Vector, Scalar, + addition, * scale)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG60HZzDWFNF"
      },
      "source": [
        "Let's take an example: here we have a vector $\\vec{v}$ and defined in our two different vector bases:\n",
        "\n",
        "* in old basis: $\\begin{equation}\n",
        "\\vec{v}=1 \\overrightarrow{e_{1}}+1.5 \\overrightarrow{e_{2}}\\end{equation}$\n",
        "\n",
        "* in new basis: $\\begin{equation}\n",
        "\\widetilde{v}=1 \\widetilde{e_{1}}+2 \\widetilde{e_{2}}\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWmDJmbRW9XH"
      },
      "source": [
        "The results written as a component vector looks like this:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\left[\\begin{array}{c}\n",
        "1 \\\\\n",
        "1.5\n",
        "\\end{array}\\right]_{\\overrightarrow{e_{i}}} \\quad\\left[\\begin{array}{l}\n",
        "1 \\\\\n",
        "2\n",
        "\\end{array}\\right]_{\\widetilde{e_{i}}}\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL6UbTl2XOTL"
      },
      "source": [
        "**Now how can you transform from one basis to the other?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9Rz5sSAV74P"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_09.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJDhTLk9XfOx"
      },
      "source": [
        "Remember from the last chapter that we had two transformation matrices between old basis and new basis: \n",
        "\n",
        "Forward Matrix\n",
        "\n",
        "$\\begin{equation}\n",
        "F=\\left[\\begin{array}{cc}\n",
        "2 & -1 / 2 \\\\\n",
        "1 & 1 / 4\n",
        "\\end{array}\\right]\n",
        "\\end{equation}$\n",
        "\n",
        "Backward Matrix:\n",
        "\n",
        "$\\begin{equation}\n",
        "B=\\left[\\begin{array}{cc}\n",
        "1 / 4 & 1 / 2 \\\\\n",
        "-1 & 2\n",
        "\\end{array}\\right]\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DILZVv9XtJK"
      },
      "source": [
        "Now one could apply the forward matrix to the vector components of the old basis $\\overrightarrow{e_{i}}$ and should get the vector components of the new basis $\\widetilde{e_{i}}$ with\n",
        "\n",
        "$\\begin{equation}\n",
        "\\left[\\begin{array}{c}\n",
        "1 \\\\\n",
        "1.5\n",
        "\\end{array}\\right]_{\\overrightarrow{e_{i}} (old vector components)} \\quad\\left[\\begin{array}{l}\n",
        "1 \\\\\n",
        "2\n",
        "\\end{array}\\right]_{\\widetilde{e_{i}} (new  vector components)}\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3U6C9h2XrLZ"
      },
      "source": [
        "**Forward Transform in Basis Vectors and Backward Transform in Vector Components to get from old to new vector basis!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfn1dN1IXp5t"
      },
      "source": [
        "> **Achtung: In this case (=for vector components) you need to apply the <u>backward</u> transformation to get from the old components to the new components!**. \n",
        "\n",
        "> **The reason is: for basis vectors, forward brings us from old to new, and backward from new to old. <u>But with vector components it’s the opposite!</u>**\n",
        "\n",
        "> **This will be important for understanding covariance & contravariance !!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abbHSKdLYwRg"
      },
      "source": [
        "Details: So, we take the vector components of the old basis:\n",
        "\n",
        "$\\begin{equation}\n",
        "B\\left[\\begin{array}{c}\n",
        "1 \\\\\n",
        "1.5\n",
        "\\end{array}\\right]_{e_{i}}\n",
        "\\end{equation}$\n",
        "\n",
        "Then we multiply it with our backward transformation matrix:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\left[\\begin{array}{cc}\n",
        "0.25 & 0.5 \\\\\n",
        "-1 & 2\n",
        "\\end{array}\\right]\\left[\\begin{array}{c}\n",
        "1 \\\\\n",
        "1.5\n",
        "\\end{array}\\right]\n",
        "\\end{equation}$\n",
        "\n",
        "Making a few transformations:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\begin{array}{l}\n",
        "{\\left[\\begin{array}{l}\n",
        "0.25(1)+0.5(1.5) \\\\\n",
        "(-1)(1)+2(1.5)\n",
        "\\end{array}\\right]} \\\\\n",
        "{\\left[\\begin{array}{c}\n",
        "0.25+0.75 \\\\\n",
        "-1+3\n",
        "\\end{array}\\right]}\n",
        "\\end{array}\n",
        "\\end{equation}$\n",
        "\n",
        "And the result are the correct vector components of the new basis:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\left[\\begin{array}{l}\n",
        "1 \\\\\n",
        "2\n",
        "\\end{array}\\right]\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASMMu5B3Z4BW"
      },
      "source": [
        "https://www.youtube.com/watch?v=uPbBDToXjBw&list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG&index=5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tACEfVSLYDLJ"
      },
      "source": [
        "> **Be aware of difference between changes with basis vectors (forward from old to new, backward from new to old) and vector components (forward from new to old, backward from old to new):**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99FruTUjaOpk"
      },
      "source": [
        "\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_10.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBOva8UzcBaA"
      },
      "source": [
        "**Why does this make perfect sense?**\n",
        "\n",
        "* Look at this example: the vector components on the left (original) are [1, 1], \n",
        "\n",
        "* and the size of the new basis vectors $\\widetilde{e_{1}}$ is just double of the old one: $\\begin{equation}\n",
        "\\widetilde{e_{1}}=2 \\overrightarrow{e_{1}}\n",
        "\\end{equation}$ as well as $\\begin{equation}\n",
        "\\widetilde{e_{2}}=2 \\overrightarrow{e_{2}}\n",
        "\\end{equation}$. \n",
        "\n",
        "* This corresponds to a forward transformation matrix for the basis vector $\\begin{equation}\n",
        "F=\\left[\\begin{array}{cc}\n",
        "2 & 0 \\\\\n",
        "0 & 2\n",
        "\\end{array}\\right]\n",
        "\\end{equation}$ to get the new basis vector\n",
        "\n",
        "* the vector components of the vector $\\vec{v}$ are then in the new coordinate system half: [0.5, 0.5], which makes sense.\n",
        "\n",
        "* **This is because (as said in the beginning) the <u>length and the direction of a vector should never change</u> (it's invariant!), but the vector component can change and in this case they change opposite to the change of the basis vectors to keep the vectors stable as they were in both bcoordinate systems!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAKN4-jkbcud"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_11.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pql8Zb6IfdO1"
      },
      "source": [
        "> **Learning: Vector components behave the opposite way that basis vectors do !**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0_bAXdde1RG"
      },
      "source": [
        "Similar, **if you rotate the basis vector clockwise, the vector components of the vector $\\vec{v}$ rotate anti-clockwise**. \n",
        "\n",
        "But remember: $\\vec{v}$ has not moved, just its components changed opposite to the basis vector components!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVJE4EWuez-m"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_12.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd3XzoaLhzxA"
      },
      "source": [
        "**So we have two ways of writing a vector $\\vec{v}$:**\n",
        "\n",
        "  * **a linear combination of the old basis vectors with the coefficient being the old components,**\n",
        "  \n",
        "  * **or we can write it as a linear combination of the new basis vectors with the coefficient being the new components**.\n",
        "\n",
        "> $\\begin{equation}\n",
        "\\vec{v}=v_{1} \\overrightarrow{e_{1}}+v_{2} \\overrightarrow{e_{2}}+\\cdots+v_{n} \\overrightarrow{e_{n}}=\\sum_{j=1}^{n} v_{j} \\overrightarrow{e_{j}}\n",
        "\\end{equation}$\n",
        "\n",
        "as well as:\n",
        "\n",
        "> $\\begin{equation}\n",
        "\\vec{v}=\\widetilde{v_{1}} \\widetilde{{e_{1}}}+\\widetilde{v_{2}} \\widetilde{e_{2}}+\\cdots+\\widetilde{v_{n}} \\widetilde{e_{n}}=\\sum_{j=1}^{n} \\widetilde{v_{j}} \\widetilde{e_{j}}\n",
        "\\end{equation}$\n",
        "\n",
        "So both if these summations are equal to $\\vec{v}$:\n",
        "\n",
        "> $\\begin{equation}\n",
        "\\vec{v}=\\sum_{j=1}^{n} v_{j} \\overrightarrow{e_{j}}=\\sum_{i=1}^{n} \\widetilde{v}_{i} \\widetilde{e_{i}}\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ec2gl19mtSA"
      },
      "source": [
        "So let’s bring out the forward and backward transformations at this point. \n",
        "\n",
        "Forward: $\\begin{equation}\n",
        "\\widetilde{e_{j}}=\\sum_{i=1}^{n} F_{i j} \\overrightarrow{e_{i}}\n",
        "\\end{equation}$\n",
        "\n",
        "Backward: $\\begin{equation}\n",
        "\\overrightarrow{e_{j}}=\\sum_{i=1}^{n} B_{i j} \\stackrel{\\sim}{e_{i}}\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAI6edomnJbt"
      },
      "source": [
        "If we take the old basis and the old components, what we can do is we can use the backward transformation B to replace the old basis vectors $\\overrightarrow{e_{j}}$ with the new basis vectors from B:\n",
        "\n",
        "$\\begin{equation}\n",
        "=\\sum_{j=1}^{n} v_{j} \\overrightarrow{e_{j}}=\\sum_{j=1}^{n} v_{j}\\left(\\sum_{i=1}^{n} B_{i j} \\widetilde{{e}_{i}}\\right)\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0maKSBFZnWAR"
      },
      "source": [
        "Rearranging the summation we get this:\n",
        "\n",
        "> $\\begin{equation}\n",
        "\\sum_{i=1}^{n}\\left(\\sum_{j=1}^{n} B_{i j} v_{j}\\right) \\widetilde{e_{i}}\n",
        "\\end{equation}$\n",
        "\n",
        "**Now we have $\\vec{v}$ written as a summation of the new basis vectors**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HQb8HFWn894"
      },
      "source": [
        "Nut now, let’s have a look at the middle part of the equation above:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\left(\\sum_{j=1}^{n} B_{i j} v_{j}\\right)\n",
        "\\end{equation}$\n",
        "\n",
        "If we compare that to our summation in the step before when we wrote $\\vec{v}$ as a summation of new basis vectors:\n",
        "\n",
        "> $\\begin{equation}\n",
        "\\vec{v}=\\sum_{j=1}^{n} v_{j} \\overrightarrow{e_{j}}=\\sum_{i=1}^{n} \\widetilde{v}_{i} \\widetilde{e_{i}}\n",
        "\\end{equation}$\n",
        "\n",
        "the coefficients have to be the new components $\\widetilde{v}_{i}$. And indeed $\\widetilde{v}_{i}$ equals:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\widetilde{v}_{i}=\\sum_{j=1}^{n} B_{i j} v_{j}\n",
        "\\end{equation}$\n",
        "\n",
        "we actually used the backward transformation! So, **this is the proof that to move from the old components to the new components we actually used the backwards transformation!**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrWHBML1tDGd"
      },
      "source": [
        "**Summary**: We know how basis vectors transform and how vector components transform (opposite direction). \n",
        "\n",
        "* Now because vector components behave contrary to the basis vectors we say that vector components are contra variant! \n",
        "\n",
        "* And we see later that vectors are contra variant tensors! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSiCvn8Ys6Zz"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_13.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNu2dS-vtaLM"
      },
      "source": [
        "**This means also we make a small but important change:**\n",
        "\n",
        "Here you can see we wrote the vector $\\vec{v}$ as a linear combination of the old and the new basis:\n",
        "\n",
        "\n",
        "> $\\begin{equation}\n",
        "\\vec{v}=\\sum_{i=1}^{n} v_{i} \\overrightarrow{e_{i}}=\\sum_{i=1}^{n} \\widetilde{v}_{i} \\widetilde{{e}_{i}}\n",
        "\\end{equation}$\n",
        "\n",
        "But since the vector components $v_{i}$ and $\\widetilde{v}_{i}$ behave contra variant we put the index up $v^{i}$ and $\\widetilde{v}^{i}$:\n",
        "\n",
        "> $\\begin{equation}\n",
        "\\vec{v}=\\sum_{i=1}^{n} v^{i} \\overrightarrow{e_{i}}=\\sum_{i=1}^{n} \\widetilde{v}^{i} \\widetilde{{e}_{i}}\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivNfnoNUuR33"
      },
      "source": [
        "https://www.youtube.com/watch?v=A1h_eucHFW4&t=177s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhQ9Bdz6srjf"
      },
      "source": [
        "##### **Kontravariantes (Vektor) Transformationsverhalten**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBJMxotsSJ2s"
      },
      "source": [
        "**Vektorkoordinaten verhalten sich kontravariant**\n",
        "\n",
        "* **Problem**: For example, we consider the transformation from one coordinate system $x^{1}, \\ldots, x^{n}$ to another $x^{\\prime}, \\ldots, x^{\\prime n}$\n",
        "$x^{i}=f^{i}\\left(x^{\\prime}, x^{\\prime 2}, \\ldots, x^{\\prime n}\\right)$ where $f^{i}$ are certain functions.\n",
        "Take a look at a couple of specific quantities. How do we transform coordinates? The answer is \"**coordinate differentials**\":\n",
        "\n",
        "> $d x^{i}=\\frac{\\partial x^{i}}{\\partial x^{\\prime k}} d x^{\\prime k}$ \n",
        "\n",
        "* **Darstellung**: $c^{1}$ (upper index, hochgestellte Indizes)\n",
        "\n",
        "* **Definition**: \n",
        "\n",
        "  * Vektorkoordinaten verhalten sich kontravariant. (wahrscheinlich: kovariante Basisvektoren (= \"kontravarianten Vektor\", weil Koordinaten kontravariant): Tangential an die Koordinatenlinien, d. h. kollinear zu den Koordinatenachsen (da, wie oben beschrieben, die Koordinatenachsen als Tangenten an die Koordinatenlinien definiert sind).\n",
        "  \n",
        "  * Every quantity which under a transformation of (vector) coordinates, transforms like the coordinate differentials is called a contravariant tensor.\n",
        "\n",
        "  * **Vectors exhibit a behavior of changing scale inversely to changes in scale to the reference axes are called contravariant** (see second example below). As a result, vectors often have units of distance or distance with other units (as, for example, velocity has units of distance divided by time).\n",
        "\n",
        "* **Examples**: (of contravariant vectors / vectors with contravariant components)\n",
        "\n",
        "  * position of an object relative to an observer, or any derivative of position with respect to time: velocity, acceleration, jerk, displacement, momentum, force.\n",
        "\n",
        "  * For instance, by changing scale from meters to centimeters (that is, **dividing the scale of the reference axes by 100**), the components of a measured velocity vector are **multiplied by 100**. \n",
        "\n",
        "* **Extension**:\n",
        "\n",
        "  * In physics, a basis is sometimes thought of as a set of reference axes. A change of scale on the reference axes corresponds to a change of units in the problem. \n",
        "\n",
        "  * A contravariant vector or tangent vector (often abbreviated simply as vector, such as a direction vector or velocity vector) has components that contra-vary with a change of basis to compensate. That is, the matrix that transforms the vector components must be the inverse of the matrix that transforms the basis vectors. The components of vectors (as opposed to those of covectors) are said to be contravariant. \n",
        "  \n",
        "  * If the **reference axes** were rotated in one direction, the **component representation** of the vector would rotate in exactly the opposite way. Similarly, if the reference axes were stretched in one direction, the components of the vector, like the coordinates, would reduce in an exactly compensating way. In Einstein notation, contravariant components are denoted with upper indices as in $\\mathbf{v}=v^{i} \\mathbf{e}_{i}$ (note: implicit summation over index \"i\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3EtqX0_U0Ma"
      },
      "source": [
        "https://math.stackexchange.com/questions/8170/intuitive-way-to-understand-covariance-and-contravariance-in-tensor-algebra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm8kHjgIkrNk"
      },
      "source": [
        "*Kontravariantes Transformationsverhalten*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGhodqSVsLX9"
      },
      "source": [
        "* Grundfrage: Wie werden Normalenvektoren in den alten Basisvektoren zu Normalenvektoren in neuen Basivektoren?\n",
        "\n",
        "* Die normalen Vektoren gehen gegen die Basis, d.h. kontravariant\n",
        "\n",
        "* Gegeben einen Normalenvektor a aus dem Vektorraum V, und diesen zerlegen in die Basisvektoren in alter Basis und dann transformieren in neue Basis:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysce5NemuvyE"
      },
      "source": [
        "![iiu](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_03.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFUAks5OvK_A"
      },
      "source": [
        "Nun Kovektor angewandt auf Summe von Zahlen mal Vektoren (Vektoren sind kontravariant): "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-kR_brZvzx8"
      },
      "source": [
        "![iiu](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_04.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qywg9CZ-wQgC"
      },
      "source": [
        "Man nennt a einen \"kontravarianten\" Vektor, aber eigentlich muss man sagen, dass seine Komponenten kontravariant transformieren. Die eigentlichen Vektoren aus dem Originalvektorraum sind kontravariant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu7CQrMtVDqi"
      },
      "source": [
        "* and a tangent vector of a smooth curve will transform as a contravariant tensor of order one under a change of coordinates\n",
        "\n",
        "* The inverse of a covariant transformation is a **contravariant transformation**.\n",
        "\n",
        "  * Whenever a vector should be invariant under a change of basis, that is to say **it should represent the same geometrical or physical object <u>having the same magnitude and direction as before</u>, its components must transform according to the contravariant rule**. \n",
        "\n",
        "  * Conventionally, indices identifying the components of a vector are placed as upper indices and so are all indices of entities that transform in the same way. \n",
        "\n",
        "* The sum over pairwise matching indices of a product with the same lower and upper indices are invariant under a transformation.\n",
        "\n",
        "* A vector itself is a geometrical quantity, in principle, independent (invariant) of the chosen basis. A vector $\\mathbf{v}$ is given, say, in components $V^{\\prime}$ on a chosen basis $\\mathbf{e}_{i}$. On another basis, say $\\mathbf{e}^{\\prime}{ }_{j}$, the same vector $\\mathbf{v}$ has different components $v^{\\prime j}$ and\n",
        "\n",
        "> $\n",
        "\\mathbf{v}=\\sum_{i} v^{i} \\mathbf{e}_{i}=\\sum_{j} v^{\\prime j} \\mathbf{e}_{j}^{\\prime}\n",
        "$\n",
        "\n",
        "* As a vector, $\\mathbf{v}$ should be invariant to the chosen coordinate system and independent of any chosen basis, i.e. its \"real world\" direction and magnitude should appear the same regardless of the basis vectors. \n",
        "\n",
        "* If we perform a change of basis by transforming the vectors $\\mathbf{e}_{i}$ into the basis vectors $\\mathbf{e}_{j}$, we must also ensure that the components $v^{i}$ transform into the new components $v$ to compensate.\n",
        "\n",
        "* The needed transformation of $\\mathbf{v}$ is called the contravariant\n",
        "transformation rule."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYVA-IStucoJ"
      },
      "source": [
        "### **Linear Form (Covector)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1DyadwjGbxH"
      },
      "source": [
        "##### **Linearform & Bilinearform**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3QmuPGbFcDF"
      },
      "source": [
        "* Eine [Linearform](https://de.wikipedia.org/wiki/Linearform) $f$ ist ein **kovarianter Tensor erster Stufe**; man nennt sie deshalb manchmal auch 1-Form.\n",
        "\n",
        "* 1-Formen bilden die Grundlage für die Einführung von Differentialformen.\n",
        "\n",
        "* Zu einem Vektorraum $V$ über einem Körper $K$ bezeichnet $V^{*}$ den zu $V$ gehörigen [Dualraum](https://de.wikipedia.org/wiki/Dualraum), das heißt die Menge aller linearen Abbildungen von $V$ nach $K$. \n",
        "\n",
        "  * Seine Elemente werden je nach Kontext auch Funktionale,\n",
        "Linearformen oder auch 1 -Formen genannt. \n",
        "\n",
        "* Insbesondere in der Physik\n",
        "verwendet man gerne die Sprache der Tensoralgebra; \n",
        "\n",
        "  * dann heißen die\n",
        "Elemente von $V$ **kontravariante Vektoren** (=Koordinaten kontravariant und die Basisvektoren kovariant??), \n",
        "\n",
        "  * die von $V^{*}$ **kovariante Vektoren oder auch Kovektoren** (=Koordinaten kovariant und die Basisvektoren kontravariant??). \n",
        "  \n",
        "* Die Abbildung $V \\times V^{*} \\rightarrow K,(x, f) \\mapsto\\langle x, f\\rangle:=f(x)$ ist eine nicht ausgeartete Bilinearform und heißt duale Paarung."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDm5IZEElHBs"
      },
      "source": [
        "- Kovektoren als Linearformen von [Normalenvektoren](https://de.wikipedia.org/wiki/Normalenvektor) (das Ergebnis ist eine Zahl), ist sowas wie ein Zeilenvektor\n",
        "- Zeilenvektor (Kovektor, Linearform) c * Spaltenvektor (Normalenvektor) a = eine Zahl, zB 2\n",
        "- Linearform: c(phi * a) = phi*c(a) und c (a+b) = c(a) + c(b)\n",
        "- Vektorraume haben Eigenschaft, dass man nur einige wenige Vektoren braucht, um alle anderen zu bilden (das Minimum ist das eine “Basis”).\n",
        "- Aus Basis fur den Vektorraum V {e<sub>1</sub>, e<sub>2</sub>} kann man nun überlegen, wie man daraus eine Basis fur den Dualraum V* bekommt {e<sup>1</sup>, e<sup>2</sup>}\n",
        "- Die Dualbasis soll jetzt einen Originalvektor aus V nehmen und eine reelle Zahl als Ergebnis liefern\n",
        "- Also zB fur Vektor im Originalvektorraum mit den Koordinaten von der Basis: a = 1,3 e<sub>1</sub> + 1,2 e<sub>2</sub> , dann sind 1,3 = e<sup>1</sup> und 1,2 = e<sup>2</sup>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHJ-eqoOkuml"
      },
      "source": [
        "> **Siehe auch [Level Sets](https://en.wikipedia.org/wiki/Level_set) bzw. Niveaumenge** (= die Menge aller Punkte des Definitionsbereichs einer Funktion, denen ein gleicher Funktionswert zugeordnet ist.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRhsinrdkr_H"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_127.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFEBtN5Jk_V-"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_126.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdT3Wkd0lIcX"
      },
      "source": [
        "Hier mit Niveaumenge (level sets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYtKUdJGlFz6"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_125.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHZL3G7fmuxR"
      },
      "source": [
        "*Example: If we think of x as a scalar field, it would look like this: it’s a scalar field where each point is given the x value at that point. And the covector field $dx$ would like like the other picture on top right: Covector fields $dx$ with level set curves being vertical lines and orientation to the right (because all x values are the same along this line, whcih aligns with the definition of a [**Level Set (Niveaumenge)**](https://de.wikipedia.org/wiki/Niveaumenge). Covector fields $dy$ with level set curves being horizontal lines and orientation upwards:*\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_128.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWgruW33n7HK"
      },
      "source": [
        "Another examples: Circles with constant radius are along the same lines:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_129.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyDv-SOGmxD_"
      },
      "source": [
        "https://www.youtube.com/watch?v=XGL-vpk-8dU&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=8&t=201s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PdTY5I2lyWs"
      },
      "source": [
        "https://av.tib.eu/media/19916"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3ncOAgfrrAn"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Tensor#Basiswechsel_und_Koordinatentransformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLk2I9sbvY2-"
      },
      "source": [
        "* covectors / linear forms, like scalars (for example differentials), change with basis (=covariant)\n",
        "\n",
        "* change of coordinate system does not change scalar (like temperature), hence linear forms =scalars) bechave covariant with basis (meanwhile direction in vectors change contravariant to keep the original position of a vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST2ML1wSvkB-"
      },
      "source": [
        "https://bjlkeng.github.io/posts/tensors-tensors-tensors/#id1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFnztey0hZOO"
      },
      "source": [
        "* Eine [Linearform](https://de.wikipedia.org/wiki/Linearform) ist ein Objekt aus dem mathematischen Teilgebiet der linearen Algebra. Es handelt sich dabei um eine lineare Abbildung von einem Vektorraum in den zugrundeliegenden Körper.\n",
        "\n",
        "* Im Kontext der Funktionalanalysis, das heißt im Falle eines topologischen \n",
        "R\n",
        "\\mathbb {R} - oder \n",
        "C\n",
        "{\\displaystyle \\mathbb {C} }-Vektorraums, sind die betrachteten Linearformen meistens stetige lineare Funktionale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo90zO_QTANO"
      },
      "source": [
        "##### **Linear Forms: Transformation of covectors across two dual basis (with forward/backward)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jopQDnMD-U-B"
      },
      "source": [
        "Covectors are also called called one-form because they take one vector and outout a scalar. \n",
        "\n",
        "* In math they are called Funktionale, Linearformen oder auch 1-Formen\n",
        "\n",
        "* in physics they are more often called covariant vectors, or covectors\n",
        "\n",
        "This scalar can be a integrand (Wegintegral) or Differential, Temperature, Speed etc..\n",
        "\n",
        "(meanwhile a metric tensor is two-form because it takes 2 vectors to output one scalar, which is length or angle)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJs6HUZfam3h"
      },
      "source": [
        "* vector components in vector space behave contravariant\n",
        "\n",
        "* covector components in dual space behave covariant = covectors = covariant vectors\n",
        "\n",
        "* Covectors are linear forms, because they take one vector as input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysoilIITKW0z"
      },
      "source": [
        "**How to visualise a one-form**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LznWMYl8KZDe"
      },
      "source": [
        "https://www.youtube.com/watch?v=dxz9JZPewu8\n",
        "\n",
        "* family of surfaces that it pierces\n",
        "\n",
        "* Integrating a one-form, we are just counting the number of surfaces that the line actually passes through"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am0y_YIhTQ4Z"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_87.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmXwmwQ-TbXF"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_88.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B14x8SmLpsL"
      },
      "source": [
        "https://www.youtube.com/watch?v=T04Yq1D20AM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN1i-3-SLrS0"
      },
      "source": [
        "https://www.youtube.com/watch?v=LyGKycYT2v0&t=74s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioHwLYD5KUOl"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Equipotential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf3NeeNoLm-m"
      },
      "source": [
        "https://www.youtube.com/watch?v=d5da-mcVJ20&list=WL&index=1&t=9s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS95OLOyzWfc"
      },
      "source": [
        "##### **Kovariantes (Covector) Transformationsverhalten**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBacRrxdJaon"
      },
      "source": [
        "**Die Koeffizienten der Linearformen (Skalare) verhalten sich kovariant**\n",
        "\n",
        "* **Problem**: How do we transform some scalar $\\Phi$ ? The answer is \"**derivatives of a scalar**\":\n",
        "\n",
        "> $\\frac{\\partial \\Phi}{\\partial x^{i}}=\\frac{\\partial \\Phi}{\\partial x^{\\prime k}} \\frac{\\partial x^{\\prime k}}{\\partial x^{i}}$\n",
        "\n",
        "* **Darstellung**: $x_{1}$ (lower index, tiefgestellte Indizes)\n",
        "\n",
        "* **Definition**: \n",
        "\n",
        "  * Koeffizienten der Linearformen (=zB Skalare) verhalten sich kovariant. (wahrscheinlich: kontravariante Basisvektoren (= \"kovarianten Vektor\", weil Koordinaten kovariant): Normal zu den Koordinatenflächen)\n",
        "\n",
        "  * [Skalar](https://de.m.wikipedia.org/wiki/Skalar_(Mathematik)): In der Physik werden Skalare verwendet zur Beschreibung physikalischer Größen, die **richtungsunabhängig** sind. Beispiele für skalare physikalische Größen sind die **Masse eines Körpers, seine Temperatur, seine Energie und auch seine Entfernung von einem anderen Körper** (als Betrag der Differenz der Ortsvektoren). Anders gesagt: Eine skalare physikalische Größe ändert sich bei Änderungen der Lage oder Orientierung nicht. Wird hingegen für die vollständige Beschreibung der Größe eine Richtung benötigt, wie bei der Kraft oder der Geschwindigkeit, so wird ein Vektor verwendet, bei Abhängigkeit von mehreren Richtungen ein Tensor (genauer: Tensor 2. oder noch höherer Stufe).\n",
        "  \n",
        "  * Every quantity which under a coordinate transformation, transforms like the derivatives of a scalar is called a covariant tensor. \n",
        "\n",
        "  * Covectors (also called **dual vectors**) typically have units of the inverse of distance or the inverse of distance with other units. The components of covectors **change in the same way as changes to scale of the reference axes and consequently are called covariant**. \n",
        "\n",
        "* **Examples**:\n",
        "\n",
        "  * Koeffizienten der [Linearformen](https://de.wikipedia.org/wiki/Linearform) (=zB Skalare)\n",
        "  \n",
        "  * An example of a covector is the gradient, which has units of a spatial derivative, or distance<sup>−1</sup>. \n",
        "  \n",
        "  * Examples of covariant vectors generally appear when taking a gradient of a function.\n",
        "\n",
        "* **Beispiele fur Kovarianz [in der Physik](https://de.wikipedia.org/wiki/Kovarianz_(Physik))**\n",
        "\n",
        "  * Unter Galilei-Transformationen transformieren sich die Beschleunigung und die Kraft in den newtonschen Bewegungsgleichungen im gleichen Sinne wie die Ortsvektoren. Daher sind die Newtonschen Bewegungsgleichungen und damit die klassische Mechanik kovariant bzgl. der Gruppe der Galilei-Transformationen.\n",
        "\n",
        "  * Im gleichen Sinne sind die Einstein-Gleichungen der Gravitation in der allgemeinen Relativitätstheorie kovariant unter beliebigen (nichtlinearen glatten) Koordinatentransformationen.\n",
        "\n",
        "  * Ebenso ist die Dirac-Gleichung der Quantenelektrodynamik kovariant unter der Gruppe der linearen Lorentz-Transformationen.\n",
        "\n",
        "  * Die linke Seite der Klein-Gordon-Gleichung für ein Skalarfeld ändert sich unter Lorentz-Transformationen nicht, sie ist spezieller invariant oder skalar.\n",
        "\n",
        "* **Extension**:\n",
        "\n",
        "  * A covariant vector or cotangent vector (often abbreviated as covector) has components that co-vary with a change of basis. \n",
        "  \n",
        "  * That is, the **components must be transformed by the same matrix as the change of basis matrix**. The components of covectors (as opposed to those of vectors) are said to be covariant.  In Einstein notation, covariant components are denoted with lower indices as in $\\mathbf{e}_{i}(\\mathbf{v})=v_{i}$\n",
        "\n",
        "  * A covariant vector has **components (=coordinates) that change oppositely to the coordinates or, equivalently,\n",
        "transform like the reference axes**. \n",
        "\n",
        "  * For instance, the components of the gradient vector of a function $\\nabla f=\\frac{\\partial f}{\\partial x^{1}} \\widehat{x}^{1}+\\frac{\\partial f}{\\partial x^{2}} \\widehat{x}^{2}+\\frac{\\partial f}{\\partial x^{3}} \\widehat{x}^{3}$\n",
        "transform like the reference axes themselves.\n",
        "\n",
        "  * See also [Covariant Transformation](https://en.wikipedia.org/wiki/Covariant_transformation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrOXAL8v1aLX"
      },
      "source": [
        "Die Komponenten eines Kovektors, eines Vektors aus dem Dualraum, transformieren kovariant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHpVMegR1Xm9"
      },
      "source": [
        "![iiu](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_05.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD4p6oTDQIJG"
      },
      "source": [
        "> **The derivative of a function transforms covariantly!** (and a tangent vector of a smooth curve will transform as a contravariant tensor of order one under a change of coordinates)\n",
        "\n",
        "* In physics, a [covariant transformation](https://en.wikipedia.org/wiki/Covariant_transformation) is a rule that specifies how certain entities, such as vectors or tensors, change under a change of basis.\n",
        "\n",
        "* The transformation that describes the new basis vectors as a linear combination of the old basis vectors is defined as a covariant transformation.\n",
        "\n",
        "* Conventionally, indices identifying the basis vectors are placed as lower indices and so are all entities that transform in the same way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKJ7sjExGa7F"
      },
      "source": [
        "*Covariant Derivative*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybFgARMAJoai"
      },
      "source": [
        "* the [covariant derivative](https://en.wikipedia.org/wiki/Covariant_derivative) is a way of specifying **a derivative along tangent vectors of a manifold**. \n",
        "\n",
        "* The name is motivated by the importance of changes of coordinate in physics: the covariant derivative transforms covariantly under a general coordinate transformation, that is, linearly via the [Jacobian matrix](https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant) of the transformation.\n",
        "\n",
        "* The covariant derivative is a generalization of the [directional derivative](https://en.wikipedia.org/wiki/Directional_derivative) / [Richtungsableitung](https://de.wikipedia.org/wiki/Richtungsableitung) from vector calculus (ps: Eine Verallgemeinerung der Richtungsableitung auf unendlichdimensionale Räume ist das [Gâteaux-Differential](https://de.wikipedia.org/wiki/Gâteaux-Differential).)\n",
        "\n",
        "* The covariant derivative is a generalization of the directional derivative from vector calculus. As with the directional derivative, the covariant derivative is a rule, \n",
        "\n",
        "  * $\\nabla_{\\mathbf{u}} \\mathbf{v},$ which takes as its inputs: \n",
        "\n",
        "  * (1) a vector, $\\mathbf{u},$ defined at a point $P$, and \n",
        "  \n",
        "  * (2) a vector field, $\\mathbf{v}$, defined in a neighborhood of $P$ \n",
        "  \n",
        "  * The output is the vector $\\nabla_{\\mathbf{u}} \\mathbf{v}(P)$, also at the point $P$. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPzhpz3ZL2dM"
      },
      "source": [
        "*Covariant derivative and covariant transformation*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldudp_TQL-ie"
      },
      "source": [
        "* The primary difference from the usual directional derivative is that $\\nabla_{\\mathrm{u}} \\mathrm{v}$ must, in a certain precise sense, **be independent of the manner in which it is expressed in a coordinate system**.\n",
        "\n",
        "* A vector may be described as a list of numbers in terms of a basis, **but as a geometrical object a vector retains its own identity regardless of how one chooses to describe it in a basis**. \n",
        "\n",
        "* This persistence of identity is reflected in the fact that when a vector is written in one basis, and then the basis is changed, the components of the vector transform according to a change of basis formula. Such a transformation law is known as a covariant transformation. \n",
        "\n",
        "> **The covariant derivative is required to transform, under a change in coordinates, in the same way as a basis does: <u>the covariant derivative must change by a covariant transformation</u>.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1QfDh8ZLyqY"
      },
      "source": [
        "*In the Euclidean Space*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFBVUlMHLx-J"
      },
      "source": [
        "* In the case of Euclidean space, one tends to define the derivative of a vector field in terms of the difference between two vectors at two nearby points. In such a system one translates one of the vectors to the origin of the other, keeping it parallel. \n",
        "\n",
        "* **With a Cartesian (fixed orthonormal) coordinate system \"keeping it parallel\" amounts to keeping the components constant**. \n",
        "\n",
        "* Euclidean space provides the simplest example: a covariant derivative which is obtained by taking the ordinary directional derivative of the components in the direction of the displacement vector between the two nearby points.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H7NE8ydMBkM"
      },
      "source": [
        "*In other (more general) Spaces*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUeg0ZYjMGBQ"
      },
      "source": [
        "* In the general case, however, one must take into account the change of the coordinate system. For example, if the same covariant derivative is written in **polar coordinates** in a two dimensional Euclidean plane, **then it contains extra terms that describe how the coordinate grid itself \"rotates\"**. \n",
        "\n",
        "* **In other cases the extra terms describe how the coordinate grid expands, contracts, twists, interweaves**, etc. \n",
        "\n",
        "* **In this case \"keeping it parallel\" does NOT amount to keeping components constant under translation**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu2tISKaWYgS"
      },
      "source": [
        "##### **Dual Space: How do Covector Components transform?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO-sjnx8JbTi"
      },
      "source": [
        "> **A column vector $\\begin{equation}\n",
        "\\left[\\begin{array}{l}\n",
        "x \\\\\n",
        "y\n",
        "\\end{array}\\right]\n",
        "\\end{equation}$ represents the components of a <u>vector</u>.**\n",
        "\n",
        "> **A row vector $\\begin{equation}\n",
        "\\left[\\begin{array}{ll}\n",
        "2 & 1\n",
        "\\end{array}\\right]\n",
        "\\end{equation}$ represents the components of a <u>covector</u>.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "And just like with vectors: Covectors are invariant (don't depend on a coordinate system), covector components are NOT invariant!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efkuDxI_IwK1"
      },
      "source": [
        "$\\begin{equation}\n",
        "\\left[\\begin{array}{ll}\n",
        "2 & 1\n",
        "\\end{array}\\right]\\left(\\left[\\begin{array}{l}\n",
        "x \\\\\n",
        "y\n",
        "\\end{array}\\right]\\right)=2 x+1 y\n",
        "\\end{equation}$\n",
        "\n",
        "[2, 1] can the thought of as a function, rather than a row vector, that acts on another vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI4ReAXbHpFt"
      },
      "source": [
        "$\\begin{equation}\n",
        "\\begin{array}{l}\n",
        "\\text { Vector Space }\n",
        "(V, S,+, \\cdot)\\\\\n",
        "\\text { Dual Vector Space }\\left(V^{*}, S,+,^{\\circ}\\right)\n",
        "\\end{array}\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9eSwD1fHsWs"
      },
      "source": [
        "$\\begin{equation}\n",
        "\\begin{array}{l}\n",
        "\\text { Elements of } V^{*} \\text { are covectors, } V \\rightarrow \\mathbb{R}\\\\\n",
        "(n \\cdot \\alpha)(\\vec{v})=n \\alpha(\\vec{v})\\\\\n",
        "(\\beta+\\gamma)(\\vec{v})=\\beta(\\vec{v})+\\gamma(\\vec{v})\n",
        "\\end{array}\n",
        "\\end{equation}$\n",
        "\n",
        "= Linearity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXmIUpxCIHSS"
      },
      "source": [
        "**Covectors are functions from vectors to real numbers**\n",
        "\n",
        "Functions $\\alpha: V \\rightarrow \\mathbb{R}$ that map a vector to a number and also obey the following rules:\n",
        "\n",
        "$\n",
        "\\begin{array}{l}\n",
        "\\alpha(\\vec{v}+\\vec{w})=\\alpha(\\vec{v})+\\alpha(\\vec{w}) \\\\\n",
        "\\alpha(n \\vec{v})=n \\alpha(\\vec{v})\n",
        "\\end{array}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X6fe_ybueeq"
      },
      "source": [
        "https://www.youtube.com/watch?v=LNoQ_Q5JQMY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdxY0nIRLy52"
      },
      "source": [
        "* Zu einem Vektorraum $V$ über einem Körper $K$ bezeichnet $V^{*}$ den zu $V$ gehörigen Dualraum, das heißt die Menge aller linearen Abbildungen von $V$ nach $K$. \n",
        "\n",
        "* Seine Elemente werden je nach Kontext auch **Funktionale, Linearformen oder auch 1-Formen** genannt (zB natürlichen Integranden für Wegintegrale)\n",
        "\n",
        "* Insbesondere in der Physik verwendet man gerne die Sprache der Tensoralgebra; dann heißen die Elemente von $V$ kontravariante Vektoren, und die **Elemente von $V^{*}$ kovariante Vektoren oder auch Kovektoren**. \n",
        "\n",
        "* Die Abbildung $V \\times V^{*} \\rightarrow K,(x, f) \\mapsto\\langle x, f\\rangle:=f(x)$ ist eine nicht ausgeartete Bilinearform und heißt duale Paarung."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hczcIbgLfBd"
      },
      "source": [
        "https://de.wikipedia.org/wiki/Dualraum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHf2s1Yzkzcd"
      },
      "source": [
        "**Exkurs: Beispiel fur Dualraum (Menge aller Linearformen / Kovektoren) und Bidualraum**\n",
        "\n",
        "> **A typical example of a linear functional is integration** [Source](https://en.m.wikipedia.org/wiki/Linear_form)\n",
        "\n",
        "*In Quantum mechanics: Linear functionals are particularly important in quantum mechanics. Quantum mechanical systems are represented by Hilbert spaces, which are anti–isomorphic to their own dual spaces. A state of a quantum mechanical system can be identified with a linear functional. For more information see bra–ket notation.*\n",
        "\n",
        "> **All covectors can be written as the linear combination of the dual basis vectors!**\n",
        "\n",
        "\n",
        "(Fun fact: wenn V endlichdimensional ist, dann kann man den Bidualraum bilden: V = (V*) * (isomorph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UTniY67lKvV"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_17.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMxamcQGh9RS"
      },
      "source": [
        "Dualraum: https://www.youtube.com/watch?v=2vvjrBbcTZU&t=480s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNA8y79MNMgK"
      },
      "source": [
        "**What does it mean when we say the covector has components?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuDzMIgGNQrj"
      },
      "source": [
        "* Look at this example: $\\begin{equation}\n",
        "\\left[\\begin{array}{l}\n",
        "2 \\\\\n",
        "1\n",
        "\\end{array}\\right]_{\\vec{e}_{i}} \\text { = } 2 \\overrightarrow{e_{1}}+1 \\overrightarrow{e_{2}}\n",
        "\\end{equation}$\n",
        "\n",
        "* So when we write a **column** vector $\\begin{equation}\n",
        "\\left[\\begin{array}{l}\n",
        "2 \\\\\n",
        "1\n",
        "\\end{array}\\right]_{\\vec{e}_{i}}\n",
        "\\end{equation}$\n",
        "\n",
        "* What we mean is: This vector is given by the **linear combination of** $2 \\overrightarrow{e_{1}}+1 \\overrightarrow{e_{2}}$\n",
        "\n",
        "> **It tells you how much of each basis vector is needed to make the vector**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUcacE3dPDKV"
      },
      "source": [
        "**So what exactly are we measuring with when we write [2 1] ?**\n",
        "\n",
        "**2 of what and 1 of what?**\n",
        "\n",
        "* Remember: Covectors are functions $\\begin{equation}\n",
        "\\alpha: V \\rightarrow \\mathbb{R}\n",
        "\\end{equation}$ (Linearformen, Funktionale etc)\n",
        "\n",
        "* **Covectors don't live in vector space $V$. They take vectors in $V$ as inputs.** (and then spit out scalar number etc, like integral or differential)\n",
        "\n",
        "* **We use can't basis vectors in $V$ like $\\left\\{\\overrightarrow{e_{1}}, \\overrightarrow{e_{2}}\\right\\}$ to measure covectors !!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YRHw-7aJXjv"
      },
      "source": [
        "**Epsilon $\\epsilon^{n}$ as dual basis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ppl0M3gHWDOs"
      },
      "source": [
        "Take the basis $\\begin{equation}\n",
        "\\left\\{\\overrightarrow{e_{1}}, \\overrightarrow{e_{2}}\\right\\} \\text { for } V \\text { . }\n",
        "\\end{equation}$\n",
        "\n",
        "We introduce two special covectors: $\\epsilon^{1},\\epsilon^{2}: V \\rightarrow \\mathbb{R}$, which are both functions from vectors to numbers (notice how the labels 1 and 2 are now above instead of below).\n",
        "\n",
        "> $\\begin{equation}\n",
        "\\begin{array}{ll}\n",
        "\\epsilon^{1}\\left(\\overrightarrow{e_{1}}\\right)=1 & \\epsilon^{1}\\left(\\overrightarrow{e_{2}}\\right)=0 \\\\\n",
        "\\epsilon^{2}\\left(\\overrightarrow{e_{1}}\\right)=0 & \\epsilon^{2}\\left(\\overrightarrow{e_{2}}\\right)=1\n",
        "\\end{array}\n",
        "\\end{equation}$\n",
        "\n",
        "(Hint: kovariant basis from $V$ with kontravariant basis from $V*$ equals the identity)\n",
        "\n",
        "this means we can use the Kronecker-Delta:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\epsilon^{i}\\left(\\overrightarrow{e_{j}}\\right)=\\delta_{i j}=\\left\\{\\begin{array}{l}\n",
        "1 \\text { if } i=j \\\\\n",
        "0 \\text { if } i \\neq j\n",
        "\\end{array}\\right.\n",
        "\\end{equation}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86zx1FzpYKRj"
      },
      "source": [
        "**So what does this epsilon $\\epsilon$ mean?**\n",
        "\n",
        "$\\begin{equation}\n",
        "\\epsilon^{1}(\\vec{v})=\\epsilon^{1}\\left(v^{1} \\overrightarrow{e_{1}}+v^{2} \\overrightarrow{e_{2}}\\right)\n",
        "\\end{equation}$\n",
        "\n",
        "We can rewrite this like this (this addition and scaling can be brought outside the function since it's a linear combination):\n",
        "\n",
        "$\\begin{equation}\n",
        "=v^{1} \\epsilon^{1}\\left(\\overrightarrow{e_{1}}\\right)+v^{2} \\epsilon^{1}\\left(\\overrightarrow{e_{2}}\\right)\n",
        "\\end{equation}$\n",
        "\n",
        "From the previous part we know that: \n",
        "\n",
        "$\\begin{equation}\n",
        "\\begin{array}{ll}\n",
        "\\epsilon^{1}\\left(\\overrightarrow{e_{1}}\\right)=1 & \\epsilon^{1}\\left(\\overrightarrow{e_{2}}\\right)=0\n",
        "\\end{array}\n",
        "\\end{equation}$\n",
        "\n",
        "So we can rewrite the equation above as:\n",
        "\n",
        "$\\begin{equation}\n",
        "=v^{1} * 1 +v^{2} * 0\n",
        "\\end{equation}$\n",
        "\n",
        "> $\\begin{equation}\n",
        "v^{1} = \\epsilon^{1}(\\vec{v})\n",
        "\\end{equation}$\n",
        "\n",
        "And the same goes for $\\begin{equation}\n",
        "\\epsilon^{2}(\\vec{v})\n",
        "\\end{equation}$:\n",
        "\n",
        "$\\begin{equation}\n",
        "\\epsilon^{2}(\\vec{v})=\\epsilon^{2}\\left(v^{1} \\overrightarrow{e_{1}}+v^{2} \\overrightarrow{e_{2}}\\right)=v^{1} \\epsilon^{2}\\left(\\overrightarrow{e_{1}}\\right)+v^{2} \\epsilon^{2}\\left(\\overrightarrow{e_{2}}\\right)=v^{2}\n",
        "\\end{equation}$\n",
        "\n",
        "> $\\begin{equation}\n",
        "v^{2} = \\epsilon^{2}(\\vec{v})\n",
        "\\end{equation}$\n",
        "\n",
        "> The epsilons are projecting out vector components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OeBNnmgbm7K"
      },
      "source": [
        "*Directions of epsilon basis vectors*\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_15.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVFvizXxc-eY"
      },
      "source": [
        "See image below: Write a general covector alpha $\\alpha$ (which can be any covector of our choice) as a linear combination of the epsilon covectors. \n",
        "\n",
        "**This means that epsilon covectors form a basis for the set of all covectors!**\n",
        "\n",
        "> **And for that reason we call these epsilons the dual basis, because they are basis for the dual space $V*$.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDxSfnLKcYhg"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_16.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr3S7uyxgWvy"
      },
      "source": [
        "> **We can't just flip column vectors on their side to get the row vectors! This works only in an orthonormal basis**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUtnP9E-ntye"
      },
      "source": [
        "**Learnings**\n",
        "\n",
        "> **All covectors can be written as the linear combination of the dual basis vectors!**\n",
        "\n",
        "> **Covector components can be obtained by counting how many covector lines that the basis vector pierces**\n",
        "\n",
        "> **Covector components transform in the opposite way that vector components do**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC1-tYOUf73d"
      },
      "source": [
        "https://www.youtube.com/watch?v=rG2q77qunSw&t=10s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ojUj0vComet"
      },
      "source": [
        "**Dual Space**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5oZvc5B7L4m"
      },
      "source": [
        "https://youtu.be/2MC4xMhscjQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_D3664Lonx0"
      },
      "source": [
        "* How can we build the new dual basis out of the old dual basis?\n",
        "\n",
        "Dual Space: How do Covectors transform? (This is open)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyvBZT9Hjmpf"
      },
      "source": [
        "https://www.youtube.com/watch?v=d5da-mcVJ20&list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG&index=9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK0JLD-Vte4G"
      },
      "source": [
        "**Summary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev_Q_GmaeWHd"
      },
      "source": [
        "**Important Differentiation**\n",
        "\n",
        "> $\\begin{equation}\n",
        "\\left[\\begin{array}{cc}\n",
        "\\overrightarrow{e_{i}} \\text{Old Basis V with Vectors} \\quad \\vec{v} &  \\widetilde{e_{i}} \\text{New Basis V with Vectors} \\quad \\widetilde{v}\\\\\n",
        "\\overrightarrow{\\epsilon_{i}} \\text{Old Dual Basis V* with Covectors} \\quad \\vec{\\alpha} & \\widetilde{\\epsilon_{i}} \\text{New Dual Basis V* with Covectors} \\quad \\widetilde{\\alpha}\n",
        "\\end{array}\\right]\n",
        "\\end{equation}$\n",
        "\n",
        "**Rules not to forget:**\n",
        "\n",
        "* Vector Space $V$ to get from old to new: Forward Transform in Basis Vectors (covariant) and Backward Transform in Vector Components (contravariant)\n",
        "\n",
        "* Vector Space $V*$ to get from old to new: Backward Transform in Basis Vectors (contravariant) and Forward Transform in Vector Components (covariant)\n",
        "\n",
        "**Fun facts**\n",
        "\n",
        "* Covectors are functions $\\begin{equation}\n",
        "\\alpha: V \\rightarrow \\mathbb{R}\n",
        "\\end{equation}$ (Linearformen, Funktionale etc)\n",
        "\n",
        "* **Covectors don't live in vector space $V$. They take vectors in $V$ as inputs.** (and then spit out scalar number etc, like integral or differential)\n",
        "\n",
        "* **We use can't basis vectors in $V$ like $\\left\\{\\overrightarrow{e_{1}}, \\overrightarrow{e_{2}}\\right\\}$ to measure covectors !!** We need Epsilon $\\epsilon^{n}$ as dual basis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7d1L8xsVyN"
      },
      "source": [
        "\n",
        "* **Basis Vector in $V$ - Upper-left**: we started with the transformation rules for basis vectors = covariant: from old to new with the forward transform.\n",
        "\n",
        "* **Vector Components in $V$ - Bottom-left**: The transformation rules for vector components are the opposite compared to the basis vectors (from old to new with the backward transform). So they are contra variant.\n",
        "\n",
        "* **Basis Covector in $V*$ - Upper-right (Dual Space)**: Transformation rules for basis covectors are also opposite compared to basis vectors. So basis covectors also transform by the contra variant rule.\n",
        "\n",
        "\n",
        "* **Covector Components in $V*$ - Bottom-right (Dual Space)**: Covector components transform in the same way that basis vectors do = This means that covectors transform covariantly. (and contravariant to vectors components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5BJVzT0rK-8"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_18.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvBfI24Gim8D"
      },
      "source": [
        "> **Wie man sieht: man konstruiert (neue) basisvektoren aus (alten) basisvektoren und (neue) vektorkomponenten aus (alten) vektorkomponenten**\n",
        "\n",
        "> Man kann nicht (neue) basisvektoren in $V*$ aus (alten) basisvektoren in $V$ konstruieren ????????"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke7HSuNXXf01"
      },
      "source": [
        "##### **Examples**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE_pme6sWcF4"
      },
      "source": [
        "![ff](https://raw.githubusercontent.com/deltorobarba/repo/master/covariant_transformation.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Njwa-3lQWpnx"
      },
      "source": [
        "* In the shown example, a vector $\\mathbf{v}=\\sum_{i \\in\\{x, y\\}} v^{i} \\mathbf{e}_{i}=\\sum_{j \\in\\{r, \\phi\\}} v^{\\prime j} \\mathbf{e}_{j}^{\\prime} .$ is described by two different coordinate\n",
        "systems:\n",
        "  * a rectangular coordinate\n",
        "system (the black grid), \n",
        "  * and a radial\n",
        "coordinate system (the red grid). \n",
        "\n",
        "* Basis vectors have been chosen for both\n",
        "coordinate systems: $\\mathbf{e}_{x}$ and $\\mathbf{e}_{\\mathbf{y}}$ for the rectangular coordinate system, and $\\mathbf{e}_{\\mathrm{r}}$\n",
        "and $\\mathbf{e}_{\\phi}$ for the radial coordinate system. \n",
        "\n",
        "* The radial basis vectors $\\mathbf{e}_{\\mathrm{r}}$ and $\\mathbf{e}_{\\phi}$ appear\n",
        "rotated anticlockwise with respect to the\n",
        "rectangular basis vectors $\\mathbf{e}_{\\mathrm{x}}$ and $\\mathbf{e}_{\\mathrm{y}}$.\n",
        "\n",
        "> **The covariant transformation, performed to the basis vectors, is thus an anticlockwise rotation, rotating from the first basis vectors to the second basis vectors**.\n",
        "\n",
        "* The coordinates of $v$ must be transformed into the new coordinate system, **but the vector $v$ itself, as a mathematical object, remains independent of the basis chosen, appearing to point in the same direction and with the same magnitude, invariant to the change of coordinates**. \n",
        "\n",
        "* The contravariant transformation ensures this, by compensating for the rotation between the different bases. If we view $v$ from the context of the radial coordinate system, it appears to be rotated more clockwise from the basis vectors $\\mathbf{e}_{\\mathbf{r}}$ and $\\mathbf{e}_{\\Phi}$. compared to how it appeared relative to the rectangular basis vectors $\\mathbf{e}_{x}$ and $\\mathbf{e}_{y}$. \n",
        "\n",
        "* **Thus, the needed contravariant transformation to $v$ in this example is a clockwise rotation.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jrvlp3ueUCgE"
      },
      "source": [
        "*Example*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csV3YgIuUBJK"
      },
      "source": [
        "* Consider the example of moving along a curve $\\gamma(t)$ in the Euclidean plane. In polar coordinates, $\\gamma$ may be written in terms of its radial and angular coordinates by $\\gamma(t)=(r(t), \\theta(t))$. \n",
        "\n",
        "* A vector at a particular time $t$ (for instance, the acceleration of the curve) is expressed in terms of $\\left(\\mathbf{e}_{r}, \\mathbf{e}_{\\theta}\\right),$ where $\\mathbf{e}_{r}$ and $\\mathbf{e}_{\\theta}$ are unit tangent vectors for the polar coordinates, serving as a basis to decompose a vector in terms of radial and [tangential components](https://en.wikipedia.org/wiki/Tangential_and_normal_components). \n",
        "\n",
        "* At a slightly later time, the new basis in polar coordinates appears slightly rotated with respect to the first set. The covariant derivative of the basis vectors (the [Christoffel symbols](https://en.wikipedia.org/wiki/Christoffel_symbols)) serve to express this change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac75knXWUsEa"
      },
      "source": [
        "*Another Example*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD41dbkiUmLi"
      },
      "source": [
        "* In a curved space, such as the surface of the Earth (regarded as a sphere), the translation is not well defined and its analog, parallel transport, depends on the path along which the vector is translated.\n",
        "\n",
        "* A vector e on a globe on the equator at point Q is directed to the north. Suppose we parallel transport the vector first along the equator until at point P and then (keeping it parallel to itself) drag it along a meridian to the pole N and (keeping the direction there) subsequently transport it along another meridian back to Q. \n",
        "\n",
        "* **Then we notice that the parallel-transported vector along a closed circuit does not return as the same vector**; instead, it has another orientation. **This would not happen in Euclidean space and is caused by the curvature of the surface of the globe**. The same effect can be noticed if we drag the vector along an infinitesimally small closed surface subsequently along two directions and then back. The infinitesimal change of the vector is a measure of the curvature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlQLeAV2kmMd"
      },
      "source": [
        "### **Linear Map**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjroy83AivLA"
      },
      "source": [
        "###### **Lineare Abbildungen & lineare Operatoren**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwL6cVdSi5w_"
      },
      "source": [
        "> **Linear Maps: Linear combinations of vector-covector-pairs** $L=L_{j}^{i} (\\overrightarrow{e_{i}} \\otimes \\epsilon^{j})$\n",
        "\n",
        "\n",
        "Linear map is a (1,1) tensor, because they transform using one contravariant rule (= vector components) and one covariant rules (= basis components)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn8Stc4CxgIj"
      },
      "source": [
        "**Case 1: Linear Maps for Transformations of vectors within one basis (with linear maps)**\n",
        "\n",
        "* rank 1 tensor (1,0)-tensor, 1 axe\n",
        "\n",
        "**Case 2: Linear Maps for Transformations of vectors across two basis (with linear maps + forward/backward)**\n",
        "\n",
        "* Linear Transformation as a (1,1)-Tensor - rank 2 tensor, which usually is represented as a matrix (e.g. 2 axes)\n",
        "\n",
        "* for example changing the linear map $L$ in one basis (i.e. Euclidean basis) and rotate basis where we define a new linear map $\\widetilde{L}$\n",
        "\n",
        "* we're not just multiplying by the inverse transform (contravariant), nor just the forward transform (covariant), we're doing both, which hints that this is a (1,1)-tensor!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H34_iJ9Kgi8T"
      },
      "source": [
        "Linear Maps = [Lineare Abbildung](https://de.wikipedia.org/wiki/Lineare_Abbildung): Eine lineare Abbildung (auch lineare Transformation oder Vektorraumhomomorphismus genannt) ist in der linearen Algebra ein wichtiger Typ von **Abbildung zwischen zwei Vektorräumen über demselben Körper**. Bei einer linearen Abbildung ist es unerheblich, ob man zwei Vektoren zuerst addiert und dann deren Summe abbildet oder zuerst die Vektoren abbildet und dann die Summe der Bilder bildet. Gleiches gilt für die Multiplikation mit einem Skalar aus dem Grundkörper.\n",
        "\n",
        "In der Funktionalanalysis, bei der Betrachtung unendlichdimensionaler Vektorräume, die eine Topologie tragen, spricht man meist von [linearen Operatoren](https://de.wikipedia.org/wiki/Linearer_Operator) statt von linearen Abbildungen. Formal gesehen sind die Begriffe gleichbedeutend."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgXc0af4gnv3"
      },
      "source": [
        "![ggg](https://upload.wikimedia.org/wikipedia/commons/3/33/Reflection_of_a_triangle_about_the_y_axis.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmMfdiSJhoHA"
      },
      "source": [
        "Bildung des Vektorraums L(V,W):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHS-OB5fhqts"
      },
      "source": [
        "![gg](https://upload.wikimedia.org/wikipedia/commons/4/49/Vektorraum_linearer_Abbildungen.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYOvCxaDiEU-"
      },
      "source": [
        "[**Besondere lineare Abbildungen:**](https://de.wikipedia.org/wiki/Lineare_Abbildung#Besondere_lineare_Abbildungen)\n",
        "\n",
        "* Monomorphismus\n",
        "Ein Monomorphismus zwischen Vektorräumen ist eine lineare Abbildung $f: V \\rightarrow W$, die injektiv ist. Dies trifft genau dann zu, wenn die Spaltenvektoren der Darstellungsmatrix linear unabhängig sind. \n",
        "\n",
        "* Epimorphismus\n",
        "Ein Epimorphismus zwischen Vektorräumen ist eine lineare Abbildung $f: V \\rightarrow W$, die surjektiv ist. Das ist genau dann der Fall, wenn der Rang der Darstellungsmatrix gleich der Dimension von $W$ ist.\n",
        "\n",
        "\n",
        "* Isomorphismus\n",
        "Ein Isomorphismus zwischen Vektorräumen ist eine lineare Abbildung $f: V \\rightarrow W$, die bijektiv ist. Das ist genau der Fall, wenn die Darstellungsmatrix regulär ist. Die beiden Räume $V$ und $W$ bezeichnet man dann als isomorph.\n",
        "\n",
        "* Endomorphismus\n",
        "Ein Endomorphismus zwischen Vektorräumen ist eine lineare Abbildung, bei der die Räume $V$ und $W$ gleich sind: $f: V \\rightarrow V$. Die Darstellungsmatrix dieser Abbildung ist eine quadratische Matrix. \n",
        "\n",
        "* Automorphismus\n",
        "Ein Automorphismus zwischen Vektorräumen ist eine bijektive lineare Abbildung, bei der die Räume $V$ und $W$ gleich sind. Er ist also sowohl ein Isomorphismus als auch ein Endomorphismus. Die Darstellungsmatrix dieser\n",
        "Abbildung ist eine reguläre Matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhDVtEXnAQXx"
      },
      "source": [
        "###### **Linear Maps as Tensor Product $\\otimes$ (Vector-Covector-Pairs) (Case 1: Transformations of vectors within one basis)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i92vw13lg8TO"
      },
      "source": [
        "*Challenges of working with row vectors & column vectors to get matrices (and reverse)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj3C_5xycQ5Z"
      },
      "source": [
        "https://www.youtube.com/watch?v=YK2zVcWpROA&list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG&index=14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNbSN-N3Tx53"
      },
      "source": [
        "> **Tensor: a collection of vectors and covectors combined together using the tensor product**.\n",
        "\n",
        "* All other tensors are just vectors and covectors combined together! \n",
        "\n",
        "* **They are the fundamental building blocks of all other tensors.**\n",
        "\n",
        "* **This means linear maps and bilinear forms can be built out of vectors and covectors** (for exmaple linear maps are Vector-Covector Pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w3zsZSsUcN2"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_35.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTBh3IVlZ52B"
      },
      "source": [
        "**When we multiply a row vector and a column vector in this order we get a scalar:**\n",
        "\n",
        "$\\begin{aligned} &\\left[\\begin{array}{ll}2 & 1\\end{array}\\right]\\left[\\begin{array}{c}3 \\\\ -4\\end{array}\\right] \\\\=&(2)(3)+(1)(-4) \\\\=& 6-4 \\\\=& 2 \\end{aligned}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vSUj51bacoI"
      },
      "source": [
        "**But if we reverse the order we get a matrix (which is basically a linear map):**\n",
        "\n",
        "$\\left[\\begin{array}{c}3 \\\\ -4\\end{array}\\right]\\left[\\begin{array}{ll}2 & 1\\end{array}\\right]$\n",
        "\n",
        "= $\\left[\\begin{array}{cc}6 & 3 \\\\ -8 & -4\\end{array}\\right]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JIbv67gbCeB"
      },
      "source": [
        "**Can we do this the other way around (get the row and column vector from the matrix)?** (Answer: not always so easy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8gI0spfbNzl"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_36.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sky0Kg17b3cL"
      },
      "source": [
        "Here is the proof why it doesn't work for this matrix:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yY8N0IFb2NE"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_37.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrtmd-hngxs-"
      },
      "source": [
        "**Pure & Impure Matrices & how Vector-Covectors-Pairs help**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1kJ_QeAb73Y"
      },
      "source": [
        "**There are some matrices that can be broken up into column vectors and row vectors, and others not. We call them pure and impure matrices!**\n",
        "\n",
        "* Pure matrices are boring when they are used as linear maps, because all the output vectors exist along the same direction. \n",
        "\n",
        "* The reason behind is that the columns of the matrices are all scalable multiples of each other (as shown below). Output vectors point all to the same direction.\n",
        "\n",
        "* The set of transformations a pure matrix can do as linear map is really limited\n",
        "\n",
        "* Impure matrices as linear maps are more interesting because they can send basis vectors into different directions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1q4rdMsBttd"
      },
      "source": [
        "> **Question: Since impure matrices are more interesting, how can we construct impure matrices using column vector, row vector and products**?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlmjSevIeYNw"
      },
      "source": [
        "> **Solution: We define four special vector-covector-pairs using the old e basis $\\left\\{\\overrightarrow{e_{1}}, \\overrightarrow{e_{2}}\\right\\}$  and the old epsilon dual basis $\\left\\{\\epsilon^{1}, \\epsilon^{2}\\right\\}$** (Hint: this will be the transition from 'classic' linear maps to vector-covector-tensor products with another way of writing them!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pow5ayq-dYve"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_38.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAayaKRjeDz9"
      },
      "source": [
        "For example the 1 on top left can be written using the column and row vector via $\\overrightarrow{e_{1}} \\epsilon_{1}$:\n",
        "\n",
        "> $\\left[\\begin{array}{ll}1 & 0 \\\\ 0 & 0\\end{array}\\right]=\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]\\left[\\begin{array}{ll}1 & 0\\end{array}\\right]=\\overrightarrow{e_{1}} \\epsilon_{1}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nyHdMbHeyfB"
      },
      "source": [
        "And we can do the same for all other 3 matrix components:\n",
        "\n",
        "> $\\left[\\begin{array}{ll}0 & 1 \\\\ 0 & 0\\end{array}\\right]=\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]\\left[\\begin{array}{ll}0 & 1\\end{array}\\right]=\\overrightarrow{e_{1}} \\epsilon_{2}$\n",
        "\n",
        "> $\\left[\\begin{array}{ll}0 & 0 \\\\ 1 & 0\\end{array}\\right]=\\left[\\begin{array}{ll}0 \\\\ 1\\end{array}\\right]\\left[\\begin{array}{ll}1 & 0\\end{array}\\right]=\\overrightarrow{e_{2}} \\epsilon_{1}$\n",
        "\n",
        "> $\\left[\\begin{array}{ll}0 & 0 \\\\ 0 & 1\\end{array}\\right]=\\left[\\begin{array}{ll}0 \\\\ 1\\end{array}\\right]\\left[\\begin{array}{ll}0 & 1\\end{array}\\right]=\\overrightarrow{e_{2}} \\epsilon_{2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwup5NJliBmz"
      },
      "source": [
        "And you’ll notice that these 4 matrices when taking in linear combination, so when we scale each matrix by a different amount and then add them together, we get any general 2x2 matrix $\\left[\\begin{array}{ll}a & b \\\\ c & d\\end{array}\\right]$ that we like, just by picking the right scaling numbers a, b, c and d:\n",
        "\n",
        "> $a\\left[\\begin{array}{ll}1 & 0 \\\\ 0 & 0\\end{array}\\right]+b\\left[\\begin{array}{ll}0 & 1 \\\\ 0 & 0\\end{array}\\right]+c\\left[\\begin{array}{ll}0 & 0 \\\\ 1 & 0\\end{array}\\right]+d\\left[\\begin{array}{ll}0 & 0 \\\\ 0 & 1\\end{array}\\right]=\\left[\\begin{array}{ll}a & b \\\\ c & d\\end{array}\\right]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwW3NlVki387"
      },
      "source": [
        "So this set of 4 products forms a basis for all matrices that are linear maps from the vector space $V \\mapsto V$ to itself\n",
        "\n",
        "> $\\left\\{\\overrightarrow{e_{1}} \\epsilon^{1}, \\overrightarrow{e_{1}} \\epsilon^{2}, \\overrightarrow{e_{2}} \\epsilon^{1}, \\overrightarrow{e_{2}} \\epsilon^{2}\\right\\}$ is a basis for $V \\rightarrow V$\n",
        "\n",
        "So any general linear map $L$ can be written as this linear combination if we pick the coefficients right:\n",
        "\n",
        "> $L=a \\overrightarrow{e_{1}} \\epsilon^{1}+b \\overrightarrow{e_{1}} \\epsilon^{2}+c \\overrightarrow{e_{2}} \\epsilon^{1}+d \\overrightarrow{e_{2}} \\epsilon^{2}$\n",
        "\n",
        "And we can summarize this using the Einstein notation, any linear map $L$ can be written using these components\n",
        "\n",
        "> $L=L_{j}^{i} \\overrightarrow{e_{i}} \\epsilon^{j}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIs8qGJYCBda"
      },
      "source": [
        "> **But this is a vector and a covector written together - how can this be a linear map**?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqOBjcw1f9JR"
      },
      "source": [
        "**Benefit of seeing linear maps as tensor products**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omM8k4eq_LG-"
      },
      "source": [
        "**Benefit of seeing linear maps as linear combinations of vector-covector pairs with the tensor product:**\n",
        "\n",
        "*When we have a linear map acting on a vector, we can get the correct matrix vector component multiplication formula*\n",
        "\n",
        "If you think of some linear map $L$ as a linear combination of these basis linear maps \n",
        "\n",
        "> $L=L_{j}^{i} \\overrightarrow{e_{i}} \\epsilon^{j}$ \n",
        "\n",
        "and we have also a vector $\\vec{v}$ which is a linear combination of these basis vectors \n",
        "\n",
        "> $\\vec{v}=v^{k} \\overrightarrow{e_{k}}$\n",
        "\n",
        "What would we get in $\\vec{w}$ with $L$ acts on the input $\\vec{v}$?\n",
        "\n",
        "> $\\vec{w}=L(\\vec{v})$\n",
        "\n",
        "To find out we substitute the components $L$ and $\\vec{v}$ accordingly:\n",
        "\n",
        "> $\\vec{w}= L_{j}^{i} \\overrightarrow{e_{i}} \\epsilon^{j}\\left(v^{k} \\overrightarrow{e_{k}}\\right)$\n",
        "\n",
        "The $\\epsilon^{j}$ dual basis vector is now acting on the input vector! (and that's what covectors do, they act on vectors). \n",
        "\n",
        "So we use the linearity of $\\epsilon^{j}$ to take out the scaling coefficient $v^{k}$ and put it out in front:\n",
        "\n",
        "> $\\vec{w}= L_{j}^{i} v^{k} \\overrightarrow{e_{i}} \\epsilon^{j}\\left(\\overrightarrow{e_{k}}\\right)$ \n",
        "\n",
        "This leaves us with $\\epsilon^{j}$ acting on $\\left(\\overrightarrow{e_{k}}\\right)$. And by definition this is just a Kronecker delta:\n",
        "\n",
        ">  $\\epsilon^{j}\\left(\\overrightarrow{e_{k}}\\right)$ = $\\delta_{k}^{j}$\n",
        "\n",
        "So we can replace this in the equation:\n",
        "\n",
        "> $\\vec{w}= L_{j}^{i} v^{k} \\overrightarrow{e_{i}} \\delta_{k}^{j}$\n",
        "\n",
        "And by the kronecker delta cancellation rule, we can cancel out the $k$'s and replace it at $v$ with $j$:\n",
        "\n",
        "> $\\vec{w}= L_{j}^{i} v^{j} \\overrightarrow{e_{i}} \\delta^{j}$\n",
        "\n",
        "And this is our output vector written as a linear combination of the $e$ basis vectors:\n",
        "\n",
        "> $\\vec{w}= L_{j}^{i} v^{j} \\overrightarrow{e_{i}}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc9xg5fMe3hW"
      },
      "source": [
        "And we get these coefficients:\n",
        "\n",
        "> $L_{j}^{i} v^{j}$\n",
        "\n",
        "from the standard matrix multiplication rule:\n",
        "\n",
        "> $\\begin{array}{l}\n",
        "\\vec{w}=L(\\vec{v}) \\\\\n",
        "w^{i}=L_{j}^{i} v^{j}\n",
        "\\end{array}$\n",
        "\n",
        "So from our equation above:\n",
        "\n",
        "> $L=L_{j}^{i} \\overrightarrow{e_{i}} \\epsilon^{j}$ \n",
        "\n",
        "**we can see that this product pair is really a linear map**:\n",
        "\n",
        "> $ \\overrightarrow{e_{i}} \\epsilon^{j}$ \n",
        "\n",
        "It took an input vector, transformed it, and gave us an output vector.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfU_PUIDCLfJ"
      },
      "source": [
        "> **Proof: vector-covector-pairs are linear maps - which are tensor products $\\otimes$  !**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_kH2e6iEtvG"
      },
      "source": [
        "**BTW: These are pure matrices, so you get the boring linear maps! To get the more interesting linear maps (the impure matrices!), we need to combine a bunch of pure linear maps together in linear combination, which helps us to get more interesting impure linear maps like $\\left[\\begin{array}{ll}a & b \\\\ c & d\\end{array}\\right]$!**\n",
        "\n",
        "> $a\\left[\\begin{array}{ll}1 & 0 \\\\ 0 & 0\\end{array}\\right]+b\\left[\\begin{array}{ll}0 & 1 \\\\ 0 & 0\\end{array}\\right]+c\\left[\\begin{array}{ll}0 & 0 \\\\ 1 & 0\\end{array}\\right]+d\\left[\\begin{array}{ll}0 & 0 \\\\ 0 & 1\\end{array}\\right]=\\left[\\begin{array}{ll}a & b \\\\ c & d\\end{array}\\right]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OONa2xg5FWx4"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_39.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCRUgbH0FigX"
      },
      "source": [
        "**And finally this vector-covector-pair is actually a tensor product**\n",
        "\n",
        "> $ \\overrightarrow{e_{i}} \\epsilon^{j}$ normally written like this: $\\overrightarrow{e_{i}} \\otimes \\epsilon^{j}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygbeK3OwJsY0"
      },
      "source": [
        "> **Again: Linear maps are linear combinations of vector-covector-pairs $L=L_{j}^{i} \\overrightarrow{e_{i}} \\epsilon^{j}$ with the tensor product $\\overrightarrow{e_{i}} \\epsilon^{j}$ bzw. $L=L_{j}^{i} (\\overrightarrow{e_{i}} \\otimes \\epsilon^{j})$**\n",
        "\n",
        "* **One of 3 benefits: This way we don't need to remember the linear map transformation rules anymore**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY6hUCtPhVPV"
      },
      "source": [
        "**Tensor Product for Linear Maps: Two different ways of multiplying a row vector with a column vector (old and new)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK0j526zBO_6"
      },
      "source": [
        "> **Linear Maps: Linear combinations of vector-covector-pairs** $L=L_{j}^{i} (\\overrightarrow{e_{i}} \\otimes \\epsilon^{j})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro8KDxDMmdOY"
      },
      "source": [
        "!! **The tensor product for linear maps gave a great change of perspective**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "870Y3ekdOzlt"
      },
      "source": [
        "https://www.youtube.com/watch?v=uDRzJIaN2qw&list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG&index=15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBydqknuPEGf"
      },
      "source": [
        "**There are two ways of multiplying a row vector with a column vector (and the second one is much better):**\n",
        "\n",
        "* The $\\otimes$ operator tells us to take the array on the left and distribute it to each of the components inside the array on the right. \n",
        "\n",
        "* This means take the column vector on the left and distribute a copy to each element inside the second array. And you get a row of columns (bottom right), which is basically like a matrix. \n",
        "\n",
        "* **This means that linear maps are rows of columns!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt3u337SQTOV"
      },
      "source": [
        "**On the left is the old way (row vector & column vector both to describe vectors) and on the right side is the new better way with tensor products $\\otimes$**\n",
        "\n",
        "> the coefficients of the linear map are just the entries of an array given by the Kronecker delta of the column vector representing the vector and the row vector representing the covector\n",
        "\n",
        "> (meanwhile combining two covectors using the tensor product can gives us a bilinear form whose coefficients are just the entries of the array given by the Kronecker product of the two row vectors associated with the covectors)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_41.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzoKAmQ1mVn8"
      },
      "source": [
        "> **This idea of distributing arrays into each other will turn out to be very useful later on!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vB2szVrDMqD"
      },
      "source": [
        "> **Repetition & Outlook: With forward and backward transform we modify the vector components when we change from one basis to another, or from one dual basis to another. With linear maps now we modify the vector components when we move a vector around within a given basis! (basis doesn't change)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks7FUzwUeGYe"
      },
      "source": [
        "> **Linear Maps: Linear combinations of vector-covector-pairs** $L=L_{j}^{i} (\\overrightarrow{e_{i}} \\otimes \\epsilon^{j})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xviwJcLdLBLF"
      },
      "source": [
        "> **Linear Maps are transformations that take a vector as an input and produce some new vector as an output** \n",
        "\n",
        "> **Coordinate representations of linear maps end up being matrices!**\n",
        "\n",
        "* Column vectors are coordinate representation of vectors\n",
        "\n",
        "* Row vectors are coordinate representation of covectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXuXV0Q08Vk0"
      },
      "source": [
        "> **When we transform vectors using a linear map, the basis isn’t changing, we aren’t moving the basis. While the output vector might be different than the input vector, we are still measuring the output vector using the same basis.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3WkIqtuKgDi"
      },
      "source": [
        "check also exponential maps!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mVeNbK1K0Yb"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_19.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPi9Rv4yXOvo"
      },
      "source": [
        "**Special Case / Fun fact about how matrices transform vectors:** \n",
        "\n",
        "When you use the column vector (1,0) as an input vector, you get the first column of the matrix as the output (3, -1):\n",
        "\n",
        "> $\\begin{equation}\n",
        "\\left[\\begin{array}{cc}\n",
        "3 & -4 \\\\\n",
        "-1 & 2\n",
        "\\end{array}\\right]\\left[\\begin{array}{l}\n",
        "1 \\\\\n",
        "0\n",
        "\\end{array}\\right]=\\left[\\begin{array}{c}\n",
        "3 \\\\\n",
        "-1\n",
        "\\end{array}\\right]\n",
        "\\end{equation}$\n",
        "\n",
        "When you use the column vector (0,1) as an input vector, you get the second column of the matrix as the output (-4, 2):\n",
        "\n",
        "> $\\begin{equation}\n",
        "\\left[\\begin{array}{cc}\n",
        "3 & -4 \\\\\n",
        "-1 & 2\n",
        "\\end{array}\\right]\\left[\\begin{array}{l}\n",
        "0 \\\\\n",
        "1\n",
        "\\end{array}\\right]=\\left[\\begin{array}{c}\n",
        "-4 \\\\\n",
        "2\n",
        "\\end{array}\\right]\n",
        "\\end{equation}$\n",
        "\n",
        "The column vectors 1, 0 and 0,1 are like copies of the basis vectors e1 and e2. Because: **Linear maps transform input vectors. But linear maps don't transform the basis!**\n",
        "\n",
        "**So when we transform vectors using a linear map, the basis isn’t changing, we aren’t moving the basis**. While the output vector might be different than the input vector, we are still measuring the output vector using the same basis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_FRCZZeMoRp"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_20.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlK0eg3YOIVP"
      },
      "source": [
        "https://www.youtube.com/watch?v=dtvM-CzNe50&list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG&index=10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNer_eOzMwc3"
      },
      "source": [
        "Linear maps:\n",
        "\n",
        "1. maps vectors to vectors $L: V \\mapsto W$, or $L: V \\mapsto V$\n",
        "\n",
        "2. Linearity (addition & scaling)\n",
        "\n",
        "> **Both covectors and linear maps are functions.**\n",
        "\n",
        "> **The only difference is that covectors output is a scalar, and linear maps output vectors.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpwytIe8bZea"
      },
      "source": [
        "**Formula for matrix multiplication**\n",
        "\n",
        "> $\\left[\\begin{array}{ll}a & b \\\\ c & d\\end{array}\\right]\\left[\\begin{array}{l} \\color{red}x \\\\ \\color{blue}y\\end{array}\\right]=\\left[\\begin{array}{l}a \\color{red}x+b \\color{blue}y \\\\ c \\color{red}x+d \\color{blue}y\\end{array}\\right]$\n",
        "\n",
        "This originates in the following abstract algebraic definition:\n",
        "\n",
        "$L: V \\rightarrow W$\n",
        "\n",
        "$L(\\vec{v}+\\vec{w})=L(\\vec{v})+L(\\vec{w})$\n",
        "\n",
        "$L(n \\vec{v})=n L(\\vec{v})$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRItUGHGc-Yc"
      },
      "source": [
        "**How to turn the $\\vec{v}$ coefficients into the $\\vec{w}$ coefficients?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVknHKCkc8Av"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_21.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIWSmO74eUzW"
      },
      "source": [
        "**Proof: Derive the matrix multiplication formulas just from the abstract linearity properties of linear maps**\n",
        "\n",
        "If we have a linear map $L$ that transforms a vector v into another vector w (where w can be written as a linear combination of basis vectors)\n",
        "\n",
        "$\\vec{w}=L(\\vec{v})=w^{1} \\overrightarrow{e_{1}}+w^{2} \\overrightarrow{e_{2}}$\n",
        "\n",
        "and we know how $L$ transforms basis vectors (via the L coefficients)\n",
        "\n",
        "$L\\left(\\overrightarrow{e_{1}}\\right)=L_{1}^{1} \\overrightarrow{e_{1}}+L_{1}^{2} \\overrightarrow{e_{2}}$\n",
        "\n",
        "$L\\left(\\overrightarrow{e_{2}}\\right)=L_{2}^{1} \\overrightarrow{e_{1}}+L_{2}^{2} \\overrightarrow{e_{2}}$\n",
        "\n",
        "this means we can transform the v components into  the w components using the formulas below\n",
        "\n",
        "$w^{1}=L_{1}^{1} v^{1}+L_{2}^{1} v^{2}$\n",
        "\n",
        "$w^{2}=L_{1}^{2} v^{1}+L_{2}^{2} v^{2}$.\n",
        "\n",
        "And if we repeat this argument for any number of dimensions, so if we have a linear map $L$ in n-dimensions \n",
        "\n",
        "$\\vec{w}=L(\\vec{v})=\\sum_{i=1}^{n} w^{i} \\overrightarrow{e_{i}}$\n",
        "\n",
        "We would get all the $L$ coefficients from this formula below\n",
        "\n",
        "$L\\left(\\overrightarrow{e_{i}}\\right)=\\sum_{j=1}^{n} L_{i}^{j} \\overrightarrow{e_{j}}$\n",
        "\n",
        "we can transform the v components into the w components \n",
        "\n",
        "$w^{i}=\\sum_{j=1}^{n} L_{j}^{i} v^{j}$\n",
        "\n",
        "This is the standard matrix multiplication formula for multiplying matrices and vectors together. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "O9lRTsulh3fc",
        "outputId": "6f3e6811-0ca0-4e5a-e267-0c57897c4f67"
      },
      "source": [
        "# Just to play around in the future\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.quiver([0, 1], [0, 2], [1, 4], [2, 3], \n",
        "           angles='xy', scale_units='xy', color=['r','b','g'], scale=1)\n",
        "plt.xlim(0, 5)\n",
        "plt.ylim(0, 5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktuQa-nIDOqo"
      },
      "source": [
        "###### **Case 2: Transformations of vectors across two basis (with linear maps + forward/backward)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_9g_49fGOoC"
      },
      "source": [
        "! Between two vector basis, not between vector basis and dual basis !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54HE1VA6gZTJ"
      },
      "source": [
        "> **We need transformation rules for linear maps when we are moving a vector AND going from one basis to another, because linear maps are only working within one basis (move vectors around within one basis), we need to find the coefficients of the linear map in the new basis when we change basis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_H6yQCaHisk"
      },
      "source": [
        "> **Task: How to get from the new vector components in the old basis to the new vector components in the new basis (via old vector components in old basis, then old vector components in new basis)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siLQN_Pjge6Q"
      },
      "source": [
        "https://www.youtube.com/watch?v=SSSGA6ohkfw&list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG&index=11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC6SbEBgjUTx"
      },
      "source": [
        "**How do we do this?**\n",
        "\n",
        "If you take vector components $\\left[\\begin{array}{l}1 \\\\ 1\\end{array}\\right]_{\\overrightarrow{e_{i}}}$ from the vector $\\vec{v}$ in the original basis $\\overrightarrow{e_{i}}$ \n",
        "\n",
        "1. **apply the linear map** $\\left[\\begin{array}{cc}1 / 2 & 0 \\\\ 0 & 2\\end{array}\\right]_{\\vec{e}_{j}}$, you get the new vector components $L(\\vec{v})$ $=\\left[\\begin{array}{c}1 / 2 \\\\ 2\\end{array}\\right]_{\\overrightarrow{e_{i}}}$ that is still **in the same original basis** $\\overrightarrow{e_{i}}$.\n",
        "\n",
        "2. then **apply the backward transform** with the matrix $\\left[\\begin{array}{cc}1 / 4 & 1 / 2 \\\\ -1 & 2\\end{array}\\right]$, you get the new vector components for $\\vec{v}$ $\\left[\\begin{array}{l}3/4 \\\\ 1\\end{array}\\right]_{\\widetilde{e_{i}}}$ **in the new basis** ${\\widetilde{e_{i}}}$.\n",
        "\n",
        "**We use the backward transform from old to new, since vector components behave contravariant !!**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAJC_FsRjS6l"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_22.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPoUyBocECg8"
      },
      "source": [
        "> **But how do you get the new vector components $L(\\vec{v})$ in the new basis ${\\widetilde{e_{i}}}$?**\n",
        "\n",
        "> **Answer: We need to find the coefficients of the linear map ${\\widetilde{L_{j}^{q}}}$ in the new basis ${\\widetilde{e_{i}}}$.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PijWzQpmoj0p"
      },
      "source": [
        "> **Again: how do you get the new vector components $L(\\vec{v})$ (the transformed vector with the linear map $L$) in the new basis ${\\widetilde{e_{i}}}$, and not only the components of $\\vec{v}$ (the original vector) in the new basis ${\\widetilde{e_{i}}}$?**\n",
        "\n",
        "**Said differently: what are the components of the output vector in the new basis ${\\widetilde{e_{i}}}$?**\n",
        "\n",
        "* we cannot apply the linear map $L$ $\\left[\\begin{array}{cc}1 / 2 & 0 \\\\ 0 & 2\\end{array}\\right]_{\\vec{e}_{j}}$ since it's only valid in the original basis\n",
        "\n",
        "**We need to find a new matrix ${\\widetilde{L}}$ in the new basis ${\\widetilde{e_{i}}}$ that tells us how to build output vectors using the ${\\widetilde{e_{1}}}$ and ${\\widetilde{e_{2}}}$ basis vectors.** \n",
        "\n",
        "* This means we need to find the ${\\widetilde{L_{j}^{q}}}$ coefficients:\n",
        "\n",
        "  * $L\\left(\\color{red}{\\widetilde{e_{1}}}\\right)=\\widetilde{L_{1}^{1}} \\widetilde{e_{1}}+\\widetilde{L_{1}^{2}} \\widetilde{e_{2}}$ \n",
        "\n",
        "  * $L\\left(\\color{red}{\\widetilde{e_{2}}}\\right)=\\widetilde{L_{2}^{1}} \\widetilde{e_{1}}+\\widetilde{L_{2}^{2}} \\widetilde{e_{2}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJkfMlCUuAJ6"
      },
      "source": [
        "**How to get the components of the output vector in the new basis ${\\widetilde{e_{i}}}$:**\n",
        "\n",
        "> $\\sum_{q=1}^{n} \\widetilde{L_{i}^{q}} \\color{red}{\\widetilde{e_{q}}}=L\\left(\\color{red}{\\widetilde{e_{i}}}\\right)$\n",
        "\n",
        "Let's first use the forward transform $\\widetilde{e_{i}}=\\sum_{j=1}^{n} F_{i}^{j} \\overrightarrow{e_{j}}$ to rewrite the new basis vectors in terms of the old basis vectors:\n",
        "\n",
        "> $\\sum_{q=1}^{n} \\widetilde{L_{i}^{q}} \\color{red}{\\widetilde{e_{q}}}=L\\left(\\sum_{j=1}^{n} F_{i}^{j} \\color{blue}{\\overrightarrow{e_{j}}}\\right)$\n",
        "\n",
        "Now we use the linearity of $L$ to take the scale and sum coefficients outside the function:\n",
        "\n",
        "> $\\sum_{q=1}^{n} \\widetilde{L_{i}^{q}} \\color{red}{\\widetilde{e_{q}}}=\\sum_{j=1}^{n} F_{i}^{j} L\\left(\\color{blue}{\\overrightarrow{e_{j}}}\\right)$\n",
        "\n",
        "Now we use this definition $L\\left(\\color{blue}{\\overrightarrow{e_{j}}}\\right)=\\sum_{k=1}^{n} L_{j}^{k} \\color{blue}{\\overrightarrow{e_{k}}}$ to write the output $L\\left(\\color{blue}{\\overrightarrow{e_{j}}}\\right)$ as linear combination of the old basis vectors:\n",
        "\n",
        "> $\\sum_{q=1}^{n} \\widetilde{L_{i}^{q}} \\color{red}{\\widetilde{e_{q}}}=\\sum_{j=1}^{n} F_{i}^{j} \\sum_{k=1}^{n} L_{j}^{k} \\color{blue}{\\overrightarrow{e_{k}}}$\n",
        "\n",
        "Then we re-arrange the sums a bit:\n",
        "\n",
        "> $\\sum_{q=1}^{n} \\widetilde{L_{i}^{q}} \\color{red}{\\widetilde{e_{q}}}=\\sum_{j=1}^{n} \\sum_{k=1}^{n} F_{i}^{j} L_{j}^{k} \\color{blue}{\\overrightarrow{e_{k}}}$\n",
        "\n",
        "Now we write the old basis in terms of the new basis vectors with $\\color{blue}{\\overrightarrow{e_{k}}}=\\sum_{l=1}^{n} B_{k}^{l} \\color{red}{\\widetilde{\\overrightarrow{e_{l}}}}$ using the bckward transform:\n",
        "\n",
        "> $\\sum_{q=1}^{n} \\widetilde{L_{i}^{q}} \\color{red}{\\widetilde{e_{q}}}=\\sum_{j=1}^{n} \\sum_{k=1}^{n} F_{i}^{j} L_{j}^{k} \\sum_{l=1}^{n} B_{k}^{l} \\color{red}{\\widetilde{e_{l}}}$\n",
        "\n",
        "We re-arrange the sums again:\n",
        "\n",
        "> $\\sum_{q=1}^{n} \\widetilde{L_{i}^{q}} \\color{red}{\\widetilde{e_{q}}}=\\sum_{l=1}^{n} \\sum_{j=1}^{n} \\sum_{k=1}^{n} B_{k}^{l} L_{j}^{k} F_{i}^{j} \\color{red}{\\widetilde{e_{l}}}$\n",
        "\n",
        "* So on the left we have a linear combination of ${\\widetilde{e}}$ basis vectors with the summation index $q$.\n",
        "\n",
        "* So on the right we have a linear combination of ${\\widetilde{e}}$ basis vectors again but with the summation index $l$.\n",
        "\n",
        "* So we have a linear combination of ${\\widetilde{e}}$ basis vectors on both sides.\n",
        "\n",
        "But with different summation indexes. But the choice doesn't really matter. So we change all the $q$ with $l$:\n",
        "\n",
        "> $\\sum_{l=1}^{n} \\widetilde{L_{i}^{l}} \\color{red}{\\widetilde{e_{l}}}=\\sum_{l=1}^{n} \\sum_{j=1}^{n} \\sum_{k=1}^{n} B_{k}^{l} L_{j}^{k} F_{i}^{j} \\color{red}{\\widetilde{e_{l}}}$\n",
        "\n",
        "Now we see that the $\\widetilde{L_{i}^{l}}$ coefficients on the left side are equal to this part $\\sum_{j=1}^{n} \\sum_{k=1}^{n} F_{i}^{j} L_{j}^{k} B_{k}^{l}$ in the middle of the right equation:\n",
        "\n",
        "> $\\sum_{l=1}^{n} \\color{pink}{\\widetilde{L_{i}^{l}}} \\widetilde{e_{l}}=\\sum_{l=1}^{n} \\color{pink}{\\sum_{j=1}^{n} \\sum_{k=1}^{n} B_{k}^{l} L_{j}^{k} F_{i}^{j}} \\widetilde{e_{l}}$\n",
        "\n",
        "**This is saying that to transform the matrix coordinates from the old basis to the new basis we multiply the old matrix $L_{j}^{k}$ by the backward transform $B$ on the left and by the forward transform $F$ on the right:**\n",
        "\n",
        "> $\\widetilde{L_{i}^{l}}=\\sum_{j=1}^{n} \\sum_{k=1}^{n} B_{k}^{l} L_{j}^{k} F_{i}^{j}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCXXC0bL3hdu"
      },
      "source": [
        "**This is what we just did (explanation below):**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_23.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXIeoFyV3P8k"
      },
      "source": [
        "**!!! IMPORTANT SUMMARY !!!**\n",
        "\n",
        "> **Task: How to get from the new vector components in the old basis to the new vector components in the new basis (via old vector components in old basis, then old vector components in new basis)**\n",
        "\n",
        "**So, matrices, or linear maps, transform with both the forward transform and the backward transform. Here is why:**\n",
        "\n",
        "* You have two ways to get the new basis vector component: you can use $\\widetilde{L}$ matrix n the bottom to go from left to right directly $\\left[\\begin{array}{l}? \\\\ ?\\end{array}\\right]_{\\widetilde{e_{j}}}$\n",
        "\n",
        "* But it's the same thing as going the other way around: \n",
        "\n",
        "  1. To transform the new vector components into the old vector components you use the forward transform\n",
        "\n",
        "  2. And here to transform the components of the input vector into components of the output vector in the old basis, we just use the matrix $L$\n",
        "\n",
        "  3. And finally to get from the old vector components to the new vector components for the output vector we use the backward transform\n",
        "\n",
        "  4. Now we have the components of the new basis vector $\\left[\\begin{array}{l}? \\\\ ?\\end{array}\\right]_{\\widetilde{e_{j}}}$ with which you can describe any vector in the new vector space.\n",
        "\n",
        "So the idea of transforming matrix components using both the forward and backward transformations makes sense."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2RvlNtvATNG"
      },
      "source": [
        "**Let's check this on our example from above:**\n",
        "\n",
        "This is the equation again to get from the new vector components in the old basis to the new vector components in the new basis (via old vector components in old basis, then old vector components in new basis):\n",
        "\n",
        "> $\\widetilde{L}_{i}^{l}=\\sum_{j=1}^{n} \\sum_{k=1}^{n} B_{k}^{l} L_{j}^{k} F_{i}^{j}$\n",
        "\n",
        "* Backward Transform $B$: $\\left[\\begin{array}{cc}1 / 4 & 1 / 2 \\\\ -1 & 2\\end{array}\\right]$\n",
        "\n",
        "* Linear Map $L$ in old basis ${\\overrightarrow{e_{j}}}$: $\\left[\\begin{array}{cc}1 / 2 & 0 \\\\ 0 & 2\\end{array}\\right]_{\\overrightarrow{e_{j}}}$\n",
        "\n",
        "* Forward Transform $F$: $\\left[\\begin{array}{cc}2 & -1 / 2 \\\\ 1 & 1 / 4\\end{array}\\right]$\n",
        "\n",
        "Now let's place them all in the equation to get the linear map in the new basis:\n",
        "\n",
        "> $L_{\\widetilde{e}_{j}}=\\left[\\begin{array}{cc}1 / 4 & 1 / 2 \\\\ -1 & 2\\end{array}\\right]\\left[\\begin{array}{cc}1 / 2 & 0 \\\\ 0 & 2\\end{array}\\right]_{\\vec{e}_{j}}\\left[\\begin{array}{cc}2 & -1 / 2 \\\\ 1 & 1 / 4\\end{array}\\right]$\n",
        "\n",
        "> $L_{\\widetilde{e}_{j}}=\\left[\\begin{array}{cc}1 / 8 & 1 \\\\ -1 / 2 & 4\\end{array}\\right]\\left[\\begin{array}{cc}2 & -1 / 2 \\\\ 1 & 1 / 4\\end{array}\\right]$\n",
        "\n",
        "We get this matrix the:\n",
        "\n",
        "> $L_{\\widetilde{e}_{j}}=\\left[\\begin{array}{cc}5 / 4 & 3 / 16 \\\\ 3 & 5 / 4\\end{array}\\right]$\n",
        "\n",
        "And this matrix above tells us how to write the outputs of the linear map as linear combination of the new basis:\n",
        "\n",
        "> $L\\left(\\widetilde{e_{1}}\\right)=5 / 4 \\widetilde{e_{1}}+3 \\widetilde{e_{2}}$\n",
        "\n",
        "> $L\\left(\\widetilde{e_{2}}\\right)=3 / 16 \\widetilde{e_{1}}+5 / 4 \\widetilde{e_{2}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLxsfbniFcXT"
      },
      "source": [
        "**Results are correct, the new matrix / linear map in the new basis is converting the vector properly from its original position to the new position (measuring both at the new basis vectors):**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiD1csYcFTSs"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_24.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCSxACu_n_YM"
      },
      "source": [
        "**Forward & Backward Transform of Linear Maps between different basis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhRzSsF1oB70"
      },
      "source": [
        "A tensor is an object that is invariant under a change of coordinates, and **has components that change in a special, predictable way under a change of coordinates**. The way we transform them is by a applying a series of forward and backward transforms!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qCtkB7yojBR"
      },
      "source": [
        "**Forward Transform (going from old $T$ to new $\\widetilde{T}$)**\n",
        "\n",
        "> $\\widetilde{T_{x y z \\ldots}^{a b c \\ldots}}=\\left(B_{\\color{red}i}^{a} B_{\\color{red}j}^{b} B_{\\color{red}k}^{c} \\cdots\\right) T_{\\color{blue}{r s t} \\ldots}^{\\color{red}{i j k} \\ldots}\\left(F_{x}^{\\color{blue}r} F_{y}^{\\color{blue}s} F_{z}^{\\color{blue}t} \\cdots\\right)$\n",
        "\n",
        "* all the upstairs indices $\\color{red}{i, j, k}$ will transform using the **backward transformation** in B on the bottom, because upstairs are the **contravariant components**.\n",
        "\n",
        "* the downstairs indices $\\color{blue}{r, s, t}$ will transform using the **forward transformation**, because downstairs are the **covariant components**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtLtFZJtsHNz"
      },
      "source": [
        "**Backward Transformation (going from new $\\widetilde{T}$ to old $T$)**\n",
        "\n",
        "> $T_{r s t \\ldots}^{i j k \\ldots}=\\left(F_{\\color{red}a}^{i} F_{\\color{red}b}^{j} F_{\\color{red}c}^{k} \\cdots\\right) \\widetilde{T_{\\color{blue}{x y z} \\ldots}^{\\color{red}{a b c} \\ldots}}\\left(B_{r}^{\\color{blue}x} B_{s}^{\\color{blue}y} B_{t}^{\\color{blue}z} \\cdots\\right)$\n",
        "\n",
        "* all the upstairs indices $\\color{red}{i, j, k}$ will transform using the **forward transformation** in B on the bottom, because upstairs are the **contravariant components**.\n",
        "\n",
        "* the downstairs indices $\\color{blue}{r, s, t}$ will transform using the **backward transformation**, because downstairs are the **covariant components**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpzV8kY4vHGZ"
      },
      "source": [
        "**Remember this illustration from the linear maps part that helps to understand the $FTB$ = $\\widetilde{T}$ (oben) bzw. $FLB$ = $\\widetilde{L}$ (unten) transform:**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_23.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHC1c2wNn7ct"
      },
      "source": [
        "> !! **Below: Core Question for the next chapter also, when it gets more complicated with more basis & dual basis** !!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCszL0CpoJy3"
      },
      "source": [
        "> $\\widetilde{T_{x y z \\ldots}^{a b c \\ldots}}=\\left(B_{\\color{red}i}^{a} B_{\\color{red}j}^{b} B_{\\color{red}k}^{c} \\cdots\\right) T_{\\color{blue}{r s t} \\ldots}^{\\color{red}{i j k} \\ldots}\\left(F_{x}^{\\color{blue}r} F_{y}^{\\color{blue}s} F_{z}^{\\color{blue}t} \\cdots\\right)$ (forward transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM39PQiduGjB"
      },
      "source": [
        "**How many contravariant and covariant rules we need to follow during a transformation?**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_32.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g677z2Bunay"
      },
      "source": [
        "> **Tensor: a collection of vectors and covectors combined together using the tensor product**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMIZabpQt3wT"
      },
      "source": [
        "https://youtu.be/C76lWSOTqnc?list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG&t=845"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjjSW-jbttc3"
      },
      "source": [
        "**Summary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2TX1AIgtuva"
      },
      "source": [
        "* Linear map is a (1,1) tensor, because they transform using one contravariant rule (= vector components) and one covariant rules (= basis components)\n",
        "\n",
        "* Metric tensors are (0,2) tensors, because it transforms using tow covariant rules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar4-UQNUtmGR"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_31.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hATTShqPvAS"
      },
      "source": [
        "### **Bilinear Form (inkl. Metric Tensor)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf6OkmW-IYEA"
      },
      "source": [
        "###### **Metric Tensor: Define length of and angle between tangent vectors when basis changes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giCxITBlhpeT"
      },
      "source": [
        "Metric Tensor = \"First Fundamental Form\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OaxbgwaTI2c"
      },
      "source": [
        "> **Bilinear Forms: Generalizations of Metric Tensors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxNaYN1lTw_x"
      },
      "source": [
        "> **Generalisation via tensor product: Bilinear Forms as Covector-Covector-Pairs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTPx6kxjb5rK"
      },
      "source": [
        "**Use Cases: How to measure the length of a vector when we change the vector (with a linear map) as well as when the basis changes?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO5pLVYcJBzc"
      },
      "source": [
        "**In a given basis we compute the output of a metric tensor using this formula**:\n",
        "\n",
        "> $g(\\vec{v}, \\vec{w}) \\mapsto v^{i} w^{j} g_{i j}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvYZQt3eG2iA"
      },
      "source": [
        "https://www.youtube.com/watch?v=C76lWSOTqnc&list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG&index=12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFFvYlWMGxys"
      },
      "source": [
        "* helps to measure lengths and angles in space\n",
        "\n",
        "* we once learnt to measure the length of a vector using the root of c<sup>2</sup> = a<sup>2</sup> + b<sup>2</sup>\n",
        "\n",
        "* in the old basis (orthonormal basis) it would be the following correctly:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xplvl7iqgCb7"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_27.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w00rFU0QgjHW"
      },
      "source": [
        "but that doesn't work in the new basis: We used the side lengths of the triangle $\\vec{v}$ with ${\\widetilde{e_{1}}}$ and ${\\widetilde{e_{2}}}$ and that's not a right-angle triangle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLSh9dCAg6ue"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_28.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQt0JOH5gRPe"
      },
      "source": [
        "> **Pythagoras theorem is only valid in orthonormal bases!**\n",
        "\n",
        "It only works when basis vectors have lengths 1 and and are orthogonal to each other.\n",
        "\n",
        "The real formula for length is given by the dot product:\n",
        "\n",
        "> **$\\|\\vec{v}\\|^{2}=\\vec{v} \\cdot \\vec{v}$**\n",
        "\n",
        "Expanding $v$ out in the old basis we get this:\n",
        "\n",
        "> $\\|\\vec{v}\\|^{2}=\\left(v^{1} \\overrightarrow{e_{1}}+v^{2} \\overrightarrow{e_{2}}\\right) \\cdot\\left(v^{1} \\overrightarrow{e_{1}}+v^{2} \\overrightarrow{e_{2}}\\right)$\n",
        "\n",
        "Which can be re-arrangiert to:\n",
        "\n",
        "> $\\|\\vec{v}\\|^{2} =  v^{1} v^{1}\\left(\\overrightarrow{e_{1}} \\cdot \\overrightarrow{e_{1}}\\right)+v^{1} v^{2}\\left(\\overrightarrow{e_{1}} \\cdot \\overrightarrow{e_{2}}\\right)+v^{2} v^{1}\\left(\\overrightarrow{e_{2}} \\cdot \\overrightarrow{e_{1}}\\right)+v^{2} v^{2}\\left(\\overrightarrow{e_{2}} \\cdot \\overrightarrow{e_{2}}\\right)$\n",
        "\n",
        "And re-arranging again we get this:\n",
        "\n",
        "> $\\|\\vec{v}\\|^{2} =  \\left(v^{1}\\right)^{2}\\left(\\overrightarrow{e_{1}} \\cdot \\overrightarrow{e_{1}}\\right)+2 v^{1} v^{2}\\left(\\overrightarrow{e_{1}} \\cdot \\overrightarrow{e_{2}}\\right)+\\left(v^{2}\\right)^{2}\\left(\\overrightarrow{e_{2}} \\cdot \\overrightarrow{e_{2}}\\right)$\n",
        "\n",
        "And of course the same for the new basis vectors:\n",
        "\n",
        "> $\\|\\vec{v}\\|^{2} =  \\left(\\widetilde{v^{1}}\\right)^{2}\\left(\\widetilde{e_{1}} \\cdot \\widetilde{e_{1}}\\right)+2 \\widetilde{v^{1}} \\widetilde{v^{2}}\\left(\\widetilde{e_{1}} \\cdot \\widetilde{e_{2}}\\right)+\\left(\\widetilde{v^{2}}\\right)^{2}\\left(\\widetilde{e_{2}} \\cdot \\widetilde{e_{2}}\\right)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrxn7i8rkC6X"
      },
      "source": [
        "So checking this on our example above:\n",
        "\n",
        "First remember we can takt the Kronecker delta in this case when we have an orthonormal basis:\n",
        "\n",
        "> $\\overrightarrow{e_{i}} \\cdot \\overrightarrow{e_{j}}=\\delta_{i j}$\n",
        "\n",
        "Which means that we can replace a few terms in our equation:\n",
        "\n",
        "> $\\begin{aligned}\\|\\vec{v}\\|^{2} &=\\left(v^{1}\\right)^{2}\\left(\\overrightarrow{e_{1}} \\cdot \\overrightarrow{e_{1}}\\right) \\\\ &+2 v^{1} v^{2}\\left(\\overrightarrow{e_{1}} \\cdot \\overrightarrow{e_{2}}\\right) \\\\ &+\\left(v^{2}\\right)^{2}\\left(\\overrightarrow{e_{2}} \\cdot \\overrightarrow{e_{2}}\\right) \\end{aligned}$\n",
        "\n",
        "With these using the Kronecker delta:\n",
        "\n",
        "> $\\left(\\overrightarrow{e_{1}} \\cdot \\overrightarrow{e_{1}}\\right)$ = 1\n",
        "\n",
        "> $\\left(\\overrightarrow{e_{2}} \\cdot \\overrightarrow{e_{2}}\\right)$ = 1\n",
        "\n",
        "> $\\left(\\overrightarrow{e_{1}} \\cdot \\overrightarrow{e_{2}}\\right)$ = 0\n",
        "\n",
        "Which leaves us with the special case of Pythagoras theorem on lengths (in orthonormal spaces):\n",
        "\n",
        "> $\\|v\\|^{2}=\\left(v^{1}\\right)^{2}+\\left(v^{2}\\right)^{2}$\n",
        "\n",
        "But to remember: the breal formula is above given by $\\|\\vec{v}\\|^{2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2SIoTX5nSEq"
      },
      "source": [
        "**The Metric Tensor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vkgu1i1jx67"
      },
      "source": [
        "* Is a tensor whose components in a given vector basis are given by the dot products of the basis vectors.\n",
        "\n",
        "> $g_{i j}=\\overrightarrow{e_{i}} \\cdot \\overrightarrow{e_{j}}$\n",
        "\n",
        "* Since the dot products don't care about the order of the input $g_{i j}=g_{j i}$, which means the tensor is symmetric along the diagonal line (spur).\n",
        "\n",
        "> $g_{i j}=\\overrightarrow{e_{i}} \\cdot \\overrightarrow{e_{j}}=\\overrightarrow{e_{j}} \\cdot \\overrightarrow{e_{i}}=g_{j i}$\n",
        "\n",
        "* when we want to get an angle, we put both vectors in\n",
        "\n",
        "* when we want to get a lengths we out the same vector twice in\n",
        "\n",
        "> $\\vec{v} \\cdot \\vec{v}=\\|\\vec{v}\\|^{2}=v^{i} v^{j} g_{i j}$\n",
        "\n",
        "> $\\vec{w} \\cdot \\vec{w}=\\|\\vec{w}\\|^{2}=w^{i} w^{j} g_{i j}$\n",
        "\n",
        "> $\\vec{v} \\cdot \\vec{w}=\\|\\vec{v}\\|\\|\\vec{w}\\| \\cos \\theta=v^{i} w^{j} g_{i j}$\n",
        "\n",
        "Metric tensor is a function $g: V \\times V \\rightarrow \\mathbb{R}$\n",
        "\n",
        "> $g(\\vec{v}, \\vec{w}) \\mapsto v^{i} w^{j} g_{i j}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGw1mdYG35cE"
      },
      "source": [
        "* In differential geometry, one definition of a [metric tensor](https://en.wikipedia.org/wiki/Metric_tensor) is a type of function which takes as input a pair of tangent vectors v and w at a point of a surface (or higher dimensional differentiable manifold) and produces a real number scalar g(v, w) in a way that generalizes many of the familiar properties of the dot product of vectors in Euclidean space.\n",
        "\n",
        "* In the same way as a dot product, **metric tensors are used to define the length of and angle between tangent vectors**. \n",
        "\n",
        "* Through integration, the metric tensor allows one to define and **compute the length of curves on the manifold**.\n",
        "\n",
        "http://walter.bislins.ch/physik/index.asp?page=Metrik%2DTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IkjpUInnz0q"
      },
      "source": [
        "* below you can see the formulas for the squared vector lengths\n",
        "\n",
        "* We can write this formula for the old components as a series of matrix multiplications with the identity matrix $\\left[\\begin{array}{ll}1 & 0 \\\\ 0 & 1\\end{array}\\right]$ in the middle for the orthonormal basis. And if you work this out you still get $\\left(v^{1}\\right)^{2}+\\left(v^{2}\\right)^{2}$\n",
        "\n",
        "* And the same goes for the new coordinate system (with a non-orthonormal basis) with the linear map $\\left[\\begin{array}{cc}5 & -3 / 4 \\\\ -3 / 4 & 5 / 16\\end{array}\\right]$.\n",
        "\n",
        "* These two matrices $\\left[\\begin{array}{ll}1 & 0 \\\\ 0 & 1\\end{array}\\right]$ and $\\left[\\begin{array}{cc}5 & -3 / 4 \\\\ -3 / 4 & 5 / 16\\end{array}\\right]$ are the key to getting the vector lengths in any given corrdinate system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yThnLW1gpzT2"
      },
      "source": [
        "> **These are called metric tensor $g$**\n",
        "\n",
        "> $g_{\\vec{e}_{i}}=\\left[\\begin{array}{ll}1 & 0 \\\\ 0 & 1\\end{array}\\right]_{\\overrightarrow{e_{i}}}$ Metric tensor in the old basis\n",
        "\n",
        "> $g_{\\widetilde{e_{i}}}=\\left[\\begin{array}{cc}5 & -3 / 4 \\\\ -3 / 4 & 5 / 16\\end{array}\\right]_{\\widetilde{e_{i}}}$ Metric tensor in the new basis\n",
        "\n",
        "> **And just like vectors, metric tensors are invariant, but have different components in different coordinate systems!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HR8qlx1nWaI"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_29.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5MBCvriqcTv"
      },
      "source": [
        "> **To get the vector lengths using these formulas we just need to know the basis vector dot products $\\left(\\overrightarrow{e_{n}} \\cdot \\overrightarrow{e_{m}}\\right)$ and $\\left(\\widetilde{e_{n}} \\cdot \\widetilde{e_{m}}\\right)$ and we can store these do products in a matrix which represents the metric tensor for that corrdinate system.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qVJXbG_tTFP"
      },
      "source": [
        "**How do you get the numbers in each metric tensor?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKIweVqetSin"
      },
      "source": [
        "> **Metric tensor components are given by the dot products of the basis vectors (as shown below).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMfKAShpqwac"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_30.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o609HQY_5r4v"
      },
      "source": [
        "**Scaling and Addition with Metric Tensors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk7zu-rH5zWF"
      },
      "source": [
        "Metric tensor is a function $g: V \\times V \\rightarrow \\mathbb{R}$\n",
        "\n",
        "> $g(\\vec{\\color{red}v}, \\vec{\\color{blue}w}) \\mapsto \\color{red}{v^{i}} \\color{blue}{w^{j}} g_{i j}$\n",
        "\n",
        "This is the formula for computing the output of a metric tensor when it acts on two vectors\n",
        "\n",
        "> $\\left[\\begin{array}{ll}\\color{red}{v^{1}} & \\color{red}{v^{2}}\\end{array}\\right]\\left[\\begin{array}{ll}g_{11} & g_{12} \\\\ g_{21} & g_{22}\\end{array}\\right]\\left[\\begin{array}{l}\\color{blue}{w^{1}} \\\\ \\color{blue}{w^{2}}\\end{array}\\right]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENfxZQFB5mdN"
      },
      "source": [
        "**Scaling inputs** \n",
        "\n",
        "(note that you can either scale with v or w but NOT with all together!)\n",
        "\n",
        "> $a\\left(\\left[\\begin{array}{ll}v^{1} & v^{2}\\end{array}\\right]\\left[\\begin{array}{ll}g_{11} & g_{12} \\\\ g_{21} & g_{22}\\end{array}\\right]\\left[\\begin{array}{l}w^{1} \\\\ w^{2}\\end{array}\\right]\\right)$\n",
        "\n",
        "> Option 1 = $\\left.\\left(\\begin{array}{ll}a\\left[v^{1}\\right. & v^{2}\\end{array}\\right]\\right)\\left[\\begin{array}{ll}g_{11} & g_{12} \\\\ g_{21} & g_{22}\\end{array}\\right]\\left[\\begin{array}{c}w^{1} \\\\ w^{2}\\end{array}\\right]=\\left[\\begin{array}{ll}a {v}^{1} & a v^{2}\\end{array}\\right]\\left[\\begin{array}{ll}g_{11} & g_{12} \\\\ g_{21} & g_{22}\\end{array}\\right]\\left[\\begin{array}{l}w^{1} \\\\ w^{2}\\end{array}\\right]$\n",
        "\n",
        "> Option 2 = $\\left[\\begin{array}{ll}v^{1} & v^{2}\\end{array}\\right]\\left[\\begin{array}{ll}g_{11} & g_{12} \\\\ g_{21} & g_{22}\\end{array}\\right]\\left(a\\left[\\begin{array}{l}w^{1} \\\\ w^{2}\\end{array}\\right]\\right)=\\left[\\begin{array}{ll}v^{1} & v^{2}\\end{array}\\right]\\left[\\begin{array}{ll}g_{11} & g_{12} \\\\ g_{21} & g_{22}\\end{array}\\right]\\left[\\begin{array}{l}a w^{1} \\\\ a w^{2}\\end{array}\\right]$\n",
        "\n",
        "Faciliate it by writing in summation notation:\n",
        "\n",
        "> $a\\left(v^{i} w^{j} g_{i j}\\right)=\\left(av^{i}\\right) w^{j} g_{i j}=v^{i}\\left(a w^{j}\\right) g_{i j}$\n",
        "\n",
        "Which brings you to:\n",
        "\n",
        "> $a g(\\vec{v}, \\vec{w})=g(a \\vec{v}, \\vec{w})=g(\\vec{v}, a \\vec{w})$\n",
        "\n",
        "But never multiply it on both sides:\n",
        "\n",
        "> $a g(\\vec{v}, \\vec{w}) \\neq g(a \\vec{v}, a \\vec{w})$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61U4ciYe6VzY"
      },
      "source": [
        "**So the metric tensor properties are**:\n",
        "\n",
        "> $g: V \\times V \\rightarrow \\mathbb{R}$\n",
        "\n",
        "> $a g(\\vec{v}, \\vec{w})=g(a \\vec{v}, \\vec{w})=g(\\vec{v}, a \\vec{w})$\n",
        "\n",
        "> $g(\\vec{v}+\\vec{u}, \\vec{w})=g(\\vec{v}, \\vec{w})+g(\\vec{u}, \\vec{w})$\n",
        "\n",
        "> $g(\\vec{v}, \\vec{w}+\\vec{t})=g(\\vec{v}, \\vec{w})+g(\\vec{v}, \\vec{t})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7XotQTY62rg"
      },
      "source": [
        "**In a given basis we compute the output of a metric tensor using this formula**:\n",
        "\n",
        "> $g(\\vec{v}, \\vec{w}) \\mapsto v^{i} w^{j} g_{i j}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tmdbtu9sy0G"
      },
      "source": [
        "**Transformation of metric tensor components (under a change of the coordinate system)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We09EDn6TqZA"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHymNPa47OYB"
      },
      "source": [
        "###### **Metric Tensor: Raising & Lowering Indexes with $g$ and $\\mathfrak{g}$ metric tensors ($\\flat$ and $\\sharp$ operators)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv1fKrMLHIlz"
      },
      "source": [
        "> **Problem Statement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oboKr8vvucNq"
      },
      "source": [
        "https://www.youtube.com/watch?v=_z9R7OMpxhY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWYgMkiM8GCq"
      },
      "source": [
        "$V$ vector space where vector lives: $\\vec{v}=v^{i \\overrightarrow{e_{i}}}$\n",
        "\n",
        "\n",
        "$V^{*}$ dual vector space where corresponding covector live: $\\alpha=\\alpha_{j} \\epsilon^{j}$ \n",
        "\n",
        "> **Is there any way to create a correspondence between the vectors of $V$ and the covectors of $V^{*}$?**\n",
        "\n",
        "* Means: is there a way to take a vector like $\\vec{v}$ and find its covector like $\\alpha$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSp_HSmMUsZf"
      },
      "source": [
        "...so not between vector in basis 1 vs vector in basis 2, but between vector in basis 1 and covector in basis 2?? (isn't that the same?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c799RYKQBu5N"
      },
      "source": [
        "> **A column vector $\\begin{equation}\n",
        "\\left[\\begin{array}{l}\n",
        "x \\\\\n",
        "y\n",
        "\\end{array}\\right]\n",
        "\\end{equation}$ represents the components of a <u>vector</u>.**\n",
        "\n",
        "> **A row vector $\\begin{equation}\n",
        "\\left[\\begin{array}{ll}\n",
        "2 & 1\n",
        "\\end{array}\\right]\n",
        "\\end{equation}$ represents the components of a <u>covector</u>.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxAWRVAlVq5F"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4UxifDQ91mk"
      },
      "source": [
        "> **Using basis vectors and their limitations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0h5CXPu91Gu"
      },
      "source": [
        "* One way to create a correspondence would be to take the basis vector  $\\overrightarrow{e_{i}}$ in $V$ and pair it up with the basis covector $\\epsilon^{i}$ in $V^{*}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75MryrnlCFGu"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_73.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1uARC2QCJ_x"
      },
      "source": [
        "It works in what matter dimension the space is: \n",
        "\n",
        "* If we want to find the covector partner of any arbitrary vector $\\vec{v}$ we can expand it as a linear combination of basis vectors \n",
        "* turn the basis vectors into covectors \n",
        "* And we can say the covector $\\alpha$ which is equal to the linear combination of $v^{1} \\epsilon^{1}$, $v^{2} \\epsilon^{2}$ etc. is the partner of the vector $\\vec{v}$ in $V^{*}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwfcRgcsDXVt"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_74.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW27H8EWD9W3"
      },
      "source": [
        "> **This doesn't always work well when there is a change of basis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuddij5nEIqi"
      },
      "source": [
        "If you for example we expand the original basis in $V$ by factor 2, it's like using a forward transform (matrix), and the backward transform would be the opposite 1/2 with the accrding matrices:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD30faKsEkoz"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_75.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8kJmpvBGDce"
      },
      "source": [
        "The problem is now following:\n",
        "\n",
        "* Basis vectors are covariant, so when we go from the old basis to the new basis we transform the basis vectors using the forward transform\n",
        "* But with basis covectors, covectors are contra variant, so when we go from the old basis to the new basis we use the backward coefficients\n",
        "* And that means to get the new basis of covectors we would multiply the old covector basis by 1/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr936mHeGBQT"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_76.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad7TD9bNG5C9"
      },
      "source": [
        "So the method of assigning partners doesn’t work well because the correspondence might look nice in one basis, it starts to be wrong in another choice of basis. The coefficients don’t match up\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQzG8kIMJo-_"
      },
      "source": [
        "Because in this case growing the vectors causes the covectors to shrink"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Prb2H-HKG6XL"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_77.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDQlkfoYVet6"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svyC4h9BHDu8"
      },
      "source": [
        "> **Using metric tensor (and no basis vectors at all)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJg_TYERHz6W"
      },
      "source": [
        "Basic idea: To get the partner covector in $V^{*}$ from of a vector $\\vec{v}$ in $V$ to its  we introduce the covector ($\\vec{v}$ * __) in $V^{*}$\n",
        "\n",
        "* any vector can go in there\n",
        "\n",
        "* the result of the multiplication would be a scalar\n",
        "\n",
        "* linearity rules (scale and addition) work well, so it's a member of $V^{*}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chlj25A4Hymp"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_78.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjz-WYa6J7Q_"
      },
      "source": [
        "Image below:\n",
        "\n",
        "* Looking back on our previous example when using basis vectors: the vector-covector-partners might look nice in one basis, but a change of basis makes things ugly because growing the vectors $2 \\overrightarrow{e_{i}}$ causes the covectors to shrink $1 / 2 \\epsilon^{i}$\n",
        "\n",
        "* This breaks the rule of establishing partners by replacing basis vectors $2 \\overrightarrow{e_{i}}$ with basis covectors $2 \\epsilon^{i}$\n",
        "\n",
        "* on the other hand: the new correspondence where we partner the vector $\\vec{v}$ in $V$ with the covector ($\\vec{v}$ * __) in $V^{*}$ doesn't depend on a basis at all (so we don't run into any problems when we change basis)\n",
        "\n",
        "* moreover when we scale the vector by 2 we also scale it's covector partner by 2 (since the linearity rules are valid!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFEbqdtBKOGp"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_79.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7KWjWyQML7m"
      },
      "source": [
        "> $\\vec{v} \\cdot \\text{__} \\quad{\\in} V^{*}$\n",
        "\n",
        "If $\\vec{v}$ really lives in $V^{*}$ that means should be able to build it out of basis covectors $\\epsilon^{i}$:\n",
        "\n",
        "> $\\vec{v} \\cdot \\text{__} \\quad{=} \\quad x_{i} \\epsilon^{i}$ where $\\epsilon^{i}$ is the  basis covector\n",
        "\n",
        "**What are the $x_{i}$ coefficients that we can use to build it as a linear combination of the $\\epsilon^{i}$ epsilon covectors?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bWA1TmENlPD"
      },
      "source": [
        "**The metric tensor $g$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGH-LxUwOZlb"
      },
      "source": [
        "Recall that the results of the dot product of vectors $\\vec{v}$ and $\\vec{w}$ is given by passing the vectors the metric tensor $g$ with \n",
        "\n",
        "> $\\vec{v} \\cdot \\vec{w}=g(\\vec{v}, \\vec{w})$.\n",
        "\n",
        "And to compute the output of this we just expand the metric tensor $g_{i j} \\epsilon^{i} \\epsilon^{j}$ and both vectors as linear combinations $v^{k} \\overrightarrow{e_{k}}$ and $w^{l} \\overrightarrow{e_{l}}$:\n",
        "\n",
        "> $\\vec{v} \\cdot \\vec{w}= g_{i j} \\epsilon^{i} \\epsilon^{j}\\left(v^{k} \\overrightarrow{e_{k}}, w^{l} \\overrightarrow{e_{l}}\\right)$\n",
        "\n",
        "And now we are going to pass these vectors to these covectors like this (and the order doesn't matter because the metric tensor is symmetric: $g(\\vec{v}, \\vec{w})=g(\\vec{w}, \\vec{v})$)\n",
        "\n",
        "> $\\vec{v} \\cdot \\vec{w}= g_{i j} \\epsilon^{i}\\left(v^{k} \\overrightarrow{e_{k}}\\right) \\epsilon^{j}\\left(w^{l} \\overrightarrow{e_{l}}\\right)$\n",
        "\n",
        "We bring the coefficients out in front\n",
        "\n",
        "> $\\vec{v} \\cdot \\vec{w}=g_{i j} v^{k} w^{l} \\epsilon^{i}\\left(\\overrightarrow{e_{k}}\\right) \\epsilon^{j}\\left(\\overrightarrow{e_{l}}\\right)$\n",
        "\n",
        "and we can rewrite these $\\epsilon^{i}\\left(\\overrightarrow{e_{k}}\\right)\\epsilon^{j}\\left(\\overrightarrow{e_{l}}\\right)$ as kronecker deltas:\n",
        "\n",
        "> $\\vec{v} \\cdot \\vec{w}= g_{i j} v^{k} w^{l} \\delta_{k}^{i} \\delta_{l}^{j}$\n",
        "\n",
        "And finally using the index cancellation rule for $k$ and $l$ we get this:\n",
        "\n",
        "> $\\vec{v} \\cdot \\vec{w}= g_{i j} v^{i} w^{j}$\n",
        "\n",
        "And that’s the familiar summation formula we use to get the output of the metric tensor. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbEFx12-T6pd"
      },
      "source": [
        "**How to get the components now?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP5GmQPzP4z1"
      },
      "source": [
        "Now to get the component of ($\\vec{v} \\cdot \\text{__}$),  \n",
        "\n",
        "$\\vec{v} \\cdot \\vec{w}=g(\\vec{v}, \\vec{w})=g_{i j} v^{i} w^{j}$\n",
        "\n",
        "we will do the exact same thing again except we are going to pass a single vector $\\vec{v}$ to the metric tensor as the input and leave the the second inout slot empty:\n",
        "\n",
        "> $\\vec{v} \\cdot{ }_{-}=g(\\vec{v},{ }_{-})$\n",
        "\n",
        "We expand $g$ and $\\vec{v}$ out as linear combinations \n",
        "\n",
        "> $\\vec{v} \\cdot{ }_{-}=g(\\vec{v},{ }_{-}) = g_{i k} \\epsilon^{i} \\epsilon^{k}\\left(\\vec{v}^{j} \\cdot \\overrightarrow{e_{j}}\\right)$\n",
        "\n",
        "And we can pass this vector $\\overrightarrow{e_{j}}$ to one of these covectors (doesn't matter which one, because metric tensor is symmetric) \n",
        "\n",
        "> $\\vec{v} \\cdot{ }_{-}=g(\\vec{v},{ }_{-}) = g_{i k} v^{j} \\epsilon^{i} \\epsilon^{k}\\left(\\overrightarrow{e_{j}}\\right)$\n",
        "\n",
        "And that gives us a Kronecker delta:\n",
        "\n",
        "> $\\vec{v} \\cdot{ }_{-}=g(\\vec{v},{ }_{-}) = g_{i k} v^{j} \\epsilon^{i} \\delta_{j}^{k}$\n",
        "\n",
        "So we can cancel out the indexes $k$, here we have the components $g_{i j} v^{j}$ of ($\\vec{v} \\cdot{ }_{-}$) in the epsilon basis $\\epsilon^{i}$:\n",
        "\n",
        "> $g_{i j} v^{j} \\epsilon^{i}$\n",
        "\n",
        "And we can do the same in another basis and we would get that the components of ($\\vec{v} \\cdot{ }_{-}$) in the $\\widetilde{\\epsilon^{i}}$ basis are the components $\\widetilde{g_{i j}} \\widetilde{v^{j}}$ in here:\n",
        "\n",
        "> $\\widetilde{g_{i j}} \\widetilde{v^{j}} \\widetilde{\\epsilon^{i}}$\n",
        "\n",
        "Because remember this equation from above:\n",
        "\n",
        "> $\\vec{v} \\cdot \\text{__} \\quad{=} \\quad x_{i} \\epsilon^{i}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd9JzmTvSK3I"
      },
      "source": [
        "**Now we are just lowering the index:**\n",
        "\n",
        "* if we drop $g_{i j}$ we can write $v_{j}$ instead of $v^{j}$\n",
        "\n",
        "* it's as if the metric tensor components are lowering the index of the components of $\\vec{v}$ to give the covector components of ($\\vec{v} \\cdot \\text{__}$)\n",
        "\n",
        "> $g_{i j} v^{j}=v_{i}$\n",
        "\n",
        "* and the same thing can be done in any basis (see right side of image)\n",
        "\n",
        "> $\\widetilde{g_{i j}} \\widetilde{v_{j}^{j}}=\\tilde{v_{i}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2WnZMfLU6Zb"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_80.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QTbXmTnWQRV"
      },
      "source": [
        "**In summary:**\n",
        "\n",
        "* [first row] a vector $\\vec{v}$ can be written with the upstairs version of of $\\vec{v}$ components (like ${v}^{j}$) \n",
        "\n",
        "* [second row] and it's partner covector ($\\vec{v} \\cdot \\text{__}$) can be written downstairs versions of the $\\vec{v}$ components (like ${v}_{j}$)\n",
        "\n",
        "* [third row] the way we convert between the upstairs and downstairs version of $\\vec{v}$ is by doing a summation with the metric tensor components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UicCVHgWHys"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_81.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZzPYr-0X2ix"
      },
      "source": [
        "**And one more important thing:**\n",
        "\n",
        "> ${v}_{j}$ ≠ ${v}^{j}$\n",
        "\n",
        "If we have to switch between them we have to use the metric tensor components and do a summation:\n",
        "\n",
        "> ${v}_{j}$ = $\\color{red}{g_{i j}}$ ${v}^{j}$\n",
        "\n",
        "The only way the equality is true is in the extremely special case of an **orthonormal coordinate system**, which means that the **metric tensor components are given by the Kronecker delta**:\n",
        "\n",
        "> ${v}_{j}$ = ${v}^{j}$, only when: $g_{i j}$ = $\\delta_{i j}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws-WjrnhVV49"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOQuX9o0YvVB"
      },
      "source": [
        "> **Inverse metric tensor $\\mathfrak{g}$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1ZRLgCyZCwN"
      },
      "source": [
        "* So we found a way to partner up vectors and covectors by pairing the vector $\\vec{v}$ with the covector ($\\vec{v} \\cdot \\text{__}$)\n",
        "\n",
        "* And we way we get from the vector to the covector is by using the metric tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYeM9JXsfmo3"
      },
      "source": [
        "**Important learning**\n",
        "\n",
        "* We normally think of a metric tensor as a function from a pair of vectors to scalars\n",
        "\n",
        "> $g: V x V \\rightarrow \\mathbb{R}$\n",
        "\n",
        "* But we can also think of it as a function from a single vector in $V$ to a covector in $V^{*}$\n",
        "\n",
        "> $g: V  \\rightarrow V^{*}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cus7qvxvfkzS"
      },
      "source": [
        "**But what would be the reverse direction?** \n",
        "\n",
        "* So from a covector to its vector partner\n",
        "\n",
        "* From the metric tensor we know its components have 2 lower indices, so it’s a member of $V^{*}$ tensor $V^{*}$ bzw.  \n",
        "\n",
        "> $g \\in V^{*} \\otimes V^{*}$\n",
        "\n",
        "* Now we introduce what's called the inverse metric tensor\n",
        "\n",
        "> $\\mathfrak{g} \\in V \\otimes V$\n",
        "\n",
        "* The combination between both in a summation gives you the Kronecker delta:\n",
        "\n",
        "> $\\mathfrak{g}^{k i} g_{i j}=\\delta_{j}^{k}$\n",
        "\n",
        "This is how we define the inverse metric tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QW7MG0lhMRE"
      },
      "source": [
        "**Proof that this definition is right**\n",
        "\n",
        "We see that if we take the standardad \"lowering index equation\":\n",
        "\n",
        "> $v_{i}=g_{i j} v^{j}$\n",
        "\n",
        "And multiply on both sides by the inverse metric tensor:\n",
        "\n",
        "> $\\mathfrak{g}^{k i} v_{i}= \\mathfrak{g}^{k i} g_{i j}v^{j}$\n",
        "\n",
        "This $\\mathfrak{g}^{k i} g_{i j}$ on the right side will cancel out and give a Kronecker delta:\n",
        "\n",
        "> $\\mathfrak{g}^{k i} v_{i}= \\delta^{k}_{j}v^{j}$\n",
        "\n",
        "And then we use the index cancellation rule:\n",
        "\n",
        "> $\\mathfrak{g}^{k i} v_{i}=v^{k}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_baEsMJi_2-"
      },
      "source": [
        "> **So the ordinary metric tensor ('covariant metric tensor') lowers indexes, but the inverse metric tensor raises the indexes, because it goes in the other direction.**\n",
        "\n",
        "> **The ordinary metric tensor $g_{i j}$ is also called 'covariant metric tensor' because its components are covariant.**\n",
        "\n",
        "> **The inverse metric tensor $\\mathfrak{g}^{k i}$ is also called 'contravariant metric tensor' because its components are contravariant.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BYszojnjomL"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_82.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctfOjgXsVX_c"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE4mjAVXj_BE"
      },
      "source": [
        "**Sharp and Flat Operator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvS8iNxBkBnj"
      },
      "source": [
        "Sharp & Flat Operator: https://de.wikipedia.org/wiki/Äußere_Ableitung#Be-_und_Kreuz-_(Flat-_und_Sharp-)_Isomorphismus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvEkEpWmlw5m"
      },
      "source": [
        "* So the ordinary metric tensor lowers indexes meanwhile the inverse metric tensor raises indexes. \n",
        "* But these raising and lowering operations don’t just apply to vector and covector components. \n",
        "* We can also raise and lower the indexes on the components of other tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8yXvn3Zk9O9"
      },
      "source": [
        "So take this tensor $Q$ which is the member of the following vector space:\n",
        "\n",
        "> $Q \\in V \\otimes V^{*} \\otimes V^{*}$\n",
        "\n",
        "Which has the following components $Q_{j k}^{I}$:\n",
        "\n",
        "> $Q=Q_{j k}^{i} \\vec{e}_{i} \\epsilon^{j} \\epsilon^{k}$\n",
        "\n",
        "So if we multiply it but the inverse metric tensor and sum over $j$ like this\n",
        "\n",
        "> $Q^{i}{ }_{j k} \\mathfrak{g}^{j x}$\n",
        "\n",
        "**then we can raise the index upward**:\n",
        "\n",
        "> $=Q^{i x}{ }_{k}$\n",
        "\n",
        "**And we get this new tensor Q prime**\n",
        "\n",
        "> $Q^{\\prime}=Q_{k}^{i x} \\overrightarrow{e_{i} {e}_{x}} \\epsilon^{k}$\n",
        "\n",
        "Which is a member of this vector space:\n",
        "\n",
        "> $Q^{\\prime} \\in V \\otimes \\color{red}{V} \\otimes V^{*}$\n",
        "\n",
        "And notice how that changed in the middle to before taking the inverse, corresponding with the raising of the middle index:\n",
        "\n",
        "> $Q \\in V \\otimes \\color{red}{V^{*}} \\otimes V^{*}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuvZRORjmTfh"
      },
      "source": [
        "**Likewise you can also lowering the index**\n",
        "\n",
        "> $D \\in V \\otimes V$\n",
        "\n",
        "> $D=D^{a b} \\overrightarrow{e_{a} e_{b}}$\n",
        "\n",
        "> $D^{a b} g_{a x}$\n",
        "\n",
        "> $=D_{x}^{b}$\n",
        "\n",
        "> $D^{\\prime}=D_{x}^{b} \\epsilon^{x} \\overrightarrow{e_{b}}$\n",
        "\n",
        "> $D^{\\prime} \\in V^{*} \\otimes V$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieI0Nt6knMSU"
      },
      "source": [
        "**Raising and lowering the index can be done on the component of any tensor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNqFivW2oGYF"
      },
      "source": [
        "All these vector spaces on this slide can be traveled between using the ordinary metric tensor to lower indexes (we travel in the direction of the blue arrow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1fxHn8jnppv"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_83.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CAKsk2xoPAm"
      },
      "source": [
        "Or we can use the inverse metric tensor to raise indexes (direction of the red arrow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj0bAGOpnquA"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_84.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FipArx6BoQZr"
      },
      "source": [
        "And that really between all vector spaces:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPfDCNgTnrvq"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_85.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-teSPx4FpQJd"
      },
      "source": [
        "**Last thing: alternate notation for converting between vector and covector partners**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jciWyVDto4ML"
      },
      "source": [
        "**The flat $\\flat$ operator**\n",
        "\n",
        "\n",
        "We know that this ($\\vec{v} \\cdot _{-}$) is also equal to the metric tensor $g\\left(\\vec{v},_{-}\\right)$ with just one input slot filled with the vector $\\vec{v}$:\n",
        "\n",
        "\n",
        "> $\\vec{v} \\cdot _{-}=g\\left(\\vec{v},_{-}\\right)$\n",
        "\n",
        "An alternative notation for writing this covector is following:\n",
        "\n",
        "> $=\\flat \\vec{v}$\n",
        "\n",
        "The flat operator $\\flat$ lowers the index\n",
        "\n",
        "So the upstairs ${v}$ components of the vector $\\vec{v}$, but the downstairs ${v}$ components are the components of the covector $\\flat$:\n",
        "\n",
        "> $\\vec{v}=v^{i} \\overrightarrow{e_{i}}$\n",
        "\n",
        "> $\\flat \\vec{v}=v_{i} \\epsilon^{i}$\n",
        "\n",
        "So you can see how the flat operator (on the left side) lowers the indexes (on the right side) from $v^{i}$ to $v_{i}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHAyh5kaq1s4"
      },
      "source": [
        "Another way to think of it: the $\\flat$ operator is transforming a vector arrow into a covector stack (like flatteing the pointy arrow into a flat stack)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awg-Xa6SrTTQ"
      },
      "source": [
        "**For the reverse one uses the sharp operator $\\sharp$**\n",
        "\n",
        "* On the other hand if we have a covector $\\alpha$ defined like this as a vector $\\vec{a}$ dot something:\n",
        "\n",
        "> $\\alpha=\\vec{a} \\cdot$\n",
        "\n",
        "which is btw the same thing as the inverse metric tensor taking the covector alpha in the first input slot\n",
        "\n",
        "> $=\\mathfrak{g}(\\alpha,\\text{__})$\n",
        "\n",
        "We can go from the covector alpha to the vector $\\vec{a}$ using the sharp operator:\n",
        "\n",
        "> $\\sharp \\alpha \\mapsto \\vec{a}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBM2a76WuDBO"
      },
      "source": [
        "So the covector alpha has components with downstairs indexes \n",
        "\n",
        "> $\\alpha=\\alpha_{i} \\epsilon^{i}$\n",
        "\n",
        "and the vector alpha sharp has components with upstairs indexes\n",
        "\n",
        "> $\\sharp \\alpha=\\alpha^{i} \\overrightarrow{e_{i}}$\n",
        "\n",
        "So the sharp operator is basically raising the index.\n",
        "\n",
        "Also the sharp operator is basically turning a flat covector stack into a sharp pointy arrow vector (as seen in the image below)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7woRV6ErteN"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_86.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6buU0Nz5-Ik"
      },
      "source": [
        "###### **Bilinear Forms: Generalizations of Metric Tensors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U33bBZndB2jK"
      },
      "source": [
        "**A form is a function that takes vectors as inputs and outputs a number:**\n",
        "\n",
        "> $V \\times V \\times \\cdots \\times V \\rightarrow \\mathbb{R}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-0zUIrUCm8m"
      },
      "source": [
        "**Covectors are linear forms (=1-forms)**\n",
        "\n",
        "* they take one vector as input to output a number (scalar):\n",
        "\n",
        ">  $\\alpha: V \\rightarrow \\mathbb{R}$\n",
        "\n",
        "* and they follow the linearity properties:\n",
        "\n",
        "  * $\\alpha(\\vec{v}+\\vec{w})=\\alpha(\\vec{v})+\\alpha(\\vec{w})$\n",
        "\n",
        "  * $\\alpha(n \\vec{v})=n \\alpha(\\vec{v})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAoS_sV_CvBp"
      },
      "source": [
        "**Bilinear Forms (=2-Forms)**\n",
        "\n",
        "* they take two vectors as input to output a number (scalar):\n",
        "\n",
        "> $\\mathcal{B}: V \\times V \\rightarrow \\mathbb{R}$\n",
        "\n",
        "* and they follow the linearity properties:\n",
        "\n",
        "  * $a \\mathcal{B}(\\vec{v}, \\vec{w})=\\mathcal{B}(a \\vec{v}, \\vec{w})=\\mathcal{B}(\\vec{v}, a \\vec{w})$\n",
        "\n",
        "  * $\\mathcal{B}(\\vec{v}+\\vec{u}, \\vec{w})=\\mathcal{B}(\\vec{v}, \\vec{w})+\\mathcal{B}(\\vec{u}, \\vec{w})$\n",
        "\n",
        "  * $\\mathcal{B}(\\vec{v}, \\vec{w}+\\vec{t})=\\mathcal{B}(\\vec{v}, \\vec{w})+\\mathcal{B}(\\vec{v}, \\vec{t})$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPugrQ--u8ll"
      },
      "source": [
        "* **Bilinear Forms another type of tensor**\n",
        "\n",
        "* the metric tensor is a special bilinear form"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33brAvKczZn8"
      },
      "source": [
        "https://www.youtube.com/watch?v=jLiBCaBEB3o&list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG&index=13"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0GdQAQVOvNl"
      },
      "source": [
        "**Relationship between linear and bilinear forms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xcxRm5xOgwX"
      },
      "source": [
        "If look at the bilinear form rules and focus only on the rules that involve the first input and pretend the second input $\\vec{w}$ is fixed, $\\mathcal{B}$ looks very much like a covector or a linear form (scale input linearly and addition is linear):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpUH5SaBHBGk"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_33.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V8djXRPPUdS"
      },
      "source": [
        "Alternatively if we focus only on the rules that involve the second input and pretend the first input is fixed $\\vec{v}$ also looks like a covector or linear form:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7-ZviIHHBXf"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_34.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW99LuNaPskY"
      },
      "source": [
        "> **So if we say that $\\mathcal{B}$ is a bilinear form, it's because it's a form where each individual input is linear while the other input is held constant!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_EyzSTTGM0K"
      },
      "source": [
        "**Relationship between Metric Tensor and Bilinear Forms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vIuD3g0E3wi"
      },
      "source": [
        "The properties of a bilinear form look very similar to the metric tensor properties:\n",
        "\n",
        "* it takes two vectors as input to output a number (scalar like angle or length):\n",
        "\n",
        "> $g: V \\times V \\rightarrow \\mathbb{R}$\n",
        "\n",
        "* and it follows the linearity properties:\n",
        "\n",
        "  * $a g(\\vec{v}, \\vec{w})=g(a \\vec{v}, \\vec{w})=g(\\vec{v}, a \\vec{w})$\n",
        "\n",
        "  * $g(\\vec{v}+\\vec{u}, \\vec{w})=g(\\vec{v}, \\vec{w})+g(\\vec{u}, \\vec{w})$\n",
        "\n",
        "  * $g(\\vec{v}, \\vec{w}+\\vec{t})=g(\\vec{v}, \\vec{w})+g(\\vec{v}, \\vec{t})$\n",
        "\n",
        "To compute the output of a function in a given basis where ${\\mathcal{B}_{i j}}$ are the components of a matrix:\n",
        "\n",
        "> $\\mathcal{B}(\\vec{v}, \\vec{w}) \\mapsto v^{i} w^{j} \\mathcal{B}_{i j}$\n",
        "\n",
        "The same goes for the metric tensor compute the output of a metric tensor in a given basis:\n",
        "\n",
        "> $g(\\vec{v}, \\vec{w}) \\mapsto v^{i} w^{j} g_{i j}$\n",
        "\n",
        "And just like the metric tensor bilinear forms are (0,2) tensors (so they transform using 2 covariant rules when we change coordinate systems):\n",
        "\n",
        "> $\\widetilde{\\mathcal{B}_{i j}}=F_{i}^{k} F_{j}^{l} \\mathcal{B}_{k l}$\n",
        "\n",
        "> $\\mathcal{B}_{k l}=B_{k}^{i} B_{l}^{j} \\widetilde{\\mathcal{B}_{i j}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAgfvC_2uKzY"
      },
      "source": [
        "**So what is the difference between metric tensor and bilinear form?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9Zz2NHBGQDG"
      },
      "source": [
        "\n",
        "\n",
        "* the metric tensor is a bilinear form, but it's a very specific example of a bilinear form\n",
        "\n",
        "* the metric tensor has 2 additional properties that other bilinear forms might not have:\n",
        "\n",
        "  1. Metric tensor components are symmetric so we can swap i and j (commutative), hwich means that the order of the input vectors in the metric tensor doesn't matter: $\\color{red}{g_{i j}} = \\color{red}{g_{j i}}$ in here: $g(\\vec{v}, \\vec{w})=v^{i} w^{j} \\color{red}{g_{i j}}=v^{i} w^{j} \\color{red}{g_{j i}}=g(\\vec{w}, \\vec{v})$\n",
        "\n",
        "  2. Metric tensor output must be positive (because it measures length): $g(\\vec{v}, \\vec{v})=\\|\\vec{v}\\|^{2} \\geq 0$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE7C17CAR_Jg"
      },
      "source": [
        "Examples of valid metric tensors (they have symmetric matrices and when we put the vector input twice in, we'll always get answers that are non-negativ):\n",
        "\n",
        "> $\\left[\\begin{array}{ll}1 & 0 \\\\ 0 & 1\\end{array}\\right]\\|\\vec{v}\\|^{2}=\\left(v^{1}\\right)^{2}+\\left(v^{2}\\right)^{2}$\n",
        "\n",
        "> $\\left[\\begin{array}{cc}5 & -3 / 4 \\\\ -3 / 4 & 5 / 16\\end{array}\\right]$ = $\\|\\vec{v}\\|^{2}=5\\left(v^{1}\\right)^{2}+(-6 / 4) v^{1} v^{2}+5 / 16\\left(v^{2}\\right)^{2}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLPEJcstSrt1"
      },
      "source": [
        "Non-metric bilinear forms:\n",
        "\n",
        "> $\\left[\\begin{array}{ll}1 & 2 \\\\ 3 & 4\\end{array}\\right]$ because it's not symmetric\n",
        "\n",
        "> $\\left[\\begin{array}{cc}1 & -5 \\\\ -5 & 1\\end{array}\\right]$ = $\\|\\vec{v}\\|^{2}=\\left(v^{1}\\right)^{2}+(-10) v^{1} v^{2}+\\left(v^{2}\\right)^{2}$, this is symmetric, but i.e. $\\left[\\begin{array}{l}1 \\\\ 1\\end{array}\\right]$ would give a result of -8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-CrRniyTtsG"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbaXlKJSTUPQ"
      },
      "source": [
        "**Generalization: Bilinear Forms as Covector-Covector-Pairs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y_hm2F-JNjl"
      },
      "source": [
        "**Bilinear Form (Bilinearform)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVjPHy70IEZI"
      },
      "source": [
        "Als [Bilinearform](https://de.wikipedia.org/wiki/Bilinearform) bezeichnet man in der linearen Algebra eine Funktion, welche zwei Vektoren einen Skalarwert zuordnet und die linear in ihren beiden Argumenten ist.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeV7U_F_IS8W"
      },
      "source": [
        "A [bilinear form](https://en.m.wikipedia.org/wiki/Bilinear_form) on a vector space V is a bilinear map V × V → K, where K is the field of scalars. In other words, a bilinear form is a function B : V × V → K that is linear in each argument separately:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-VlKyY2JW7L"
      },
      "source": [
        "> **Bilinear forms are linear combinations of covector-covector-pairs** (including the metric tensor)\n",
        "\n",
        "> $\\mathcal{B}=\\mathcal{B}_{i j} \\epsilon^{i} \\epsilon^{j}=\\mathcal{B}_{i j}\\left(\\epsilon^{i} \\otimes \\epsilon^{j}\\right)$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud5Zs7xQnvJU"
      },
      "source": [
        "*Why not vector-vector-pairs or so? - Bilinear forms take two vector inputs and since covectors take one vector each, a pair of covectors would take two vector inputs.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4f-5DtdtRXH"
      },
      "source": [
        "**Benefit 1: write out any bilinear form as a linear combination of covector-covector pairs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49QjDsHaoBJ6"
      },
      "source": [
        "*Look at our classic transformation rules*:\n",
        "\n",
        "> $\\widetilde{\\mathcal{B}_{i j}}=F_{i}^{k} F_{j}^{l} \\mathcal{B}_{k l}$\n",
        "\n",
        "> $\\mathcal{B}_{i j}=B_{i}^{k} B_{j}^{l} \\widetilde{\\mathcal{B}_{k l}}$\n",
        "\n",
        "and\n",
        "\n",
        "> $\\widetilde{e_{j}}=F_{j}^{i} \\overrightarrow{e_{i}}$\n",
        "\n",
        "> $\\overrightarrow{e_{j}}=B_{j}^{i} \\widetilde{e_{i}}$\n",
        "\n",
        "and \n",
        "\n",
        "> $\\widetilde{\\epsilon}^{i}=B_{j}^{i} \\epsilon^{j}$\n",
        "\n",
        "> $\\epsilon^{i}=F_{j}^{i} \\epsilon^{j}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QekWLPfpA-d"
      },
      "source": [
        "**Proof**\n",
        "\n",
        "If we can assume we can write out any bilinear form as a linear combination of covector-covector pairs **to get the transformation rule for these components** we just transform the basis covectors individually:\n",
        "\n",
        "> $\\mathcal{B}=\\mathcal{B}_{k l} \\epsilon^{k} \\epsilon^{l}$\n",
        "\n",
        "Basis covectors are contra variant, so to build old from the new we use the forward transform $F$ \n",
        "\n",
        "> $\\mathcal{B}=\\mathcal{B}_{k l}\\left(F_{i}^{k} \\widetilde{\\epsilon}^{i}\\right)\\left(F_{j}^{l} \\widetilde{\\epsilon}^{j}\\right)$\n",
        "\n",
        "and putting these in front gives us this:\n",
        "\n",
        "> $\\mathcal{B}=\\left(F_{i}^{k} F_{j}^{l} \\mathcal{B}_{k l}\\right) \\widetilde{\\epsilon}^{i}\\widetilde{\\epsilon}^{j}$\n",
        "\n",
        "which as we can see is the correct one:\n",
        "\n",
        "> $\\widetilde{B_{i j}}=F_{i}^{k} F_{j}^{l} \\mathcal{B}_{k l}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v7IAgYzqiW_"
      },
      "source": [
        "**Benefit 2: We can also get the correct component multiplication formula when a bilinear form acts on two vector inputs:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-QrTQXdq3dx"
      },
      "source": [
        "Given:\n",
        "\n",
        "> $\\mathcal{B}=\\mathcal{B}_{i j} \\epsilon^{i} \\epsilon^{j}$\n",
        "\n",
        "> $\\vec{v}=v^{k} \\overrightarrow{e_{k}}$\n",
        "\n",
        "> $\\vec{w}=w^{l} \\overrightarrow{e_{l}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWzl92c3rAnG"
      },
      "source": [
        "**Proof:** replace components with equations above:\n",
        "\n",
        "> $s=\\mathcal{B}(\\vec{v}, \\vec{w})$\n",
        "\n",
        "Replace the bilinear form and the vectors with their linear combination expansions in some basis \n",
        "\n",
        "> $s=\\mathcal{B}_{i j} \\epsilon^{i} \\epsilon^{j}\\left(v^{k} \\overrightarrow{e_{k}}, w^{l} \\overrightarrow{e_{l}}\\right)$\n",
        "\n",
        "Now we pass each of these vector inputs to their corresponding covectors \n",
        "\n",
        "> $s=\\mathcal{B}_{i j} \\epsilon^{i}\\left(v^{k} \\overrightarrow{e_{k}}\\right) \\epsilon^{j}\\left(w^{l} \\overrightarrow{e_{l}}\\right)$\n",
        "\n",
        "\n",
        "$v$ and $w$ come out in front:\n",
        "\n",
        "> $s=\\mathcal{B}_{i j} v^{k} w^{l} \\epsilon^{i}\\left(\\overrightarrow{e_{k}}\\right) \\epsilon^{j}\\left(\\overrightarrow{e_{l}}\\right)$\n",
        "\n",
        "Replace ($\\overrightarrow{e_{k}}$) and ($\\overrightarrow{e_{l}}$) with Kronecker deltas\n",
        "\n",
        "> $s=\\mathcal{B}_{i j} v^{k} w^{l} \\delta_{k}^{i} \\delta_{l}^{j}$\n",
        "\n",
        "Finally using the index cancellation rules for $k$ and $l$ we get the correct component multiplication formula ends up giving us a single number as a result:\n",
        "\n",
        "> $s=\\mathcal{B}_{i j} v^{i} w^{j}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC0jk1jPtnM2"
      },
      "source": [
        "**Benefit 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40EhTBYeuU_9"
      },
      "source": [
        "Remember with linear maps, the new way of writing with the tensor product makes a lot more tensors (with a row of rows): Even though we had two vector inputs we needed to write one as a column and one as a row  flipped on its side to make the multiplication work correctly. Which is awkward, because vectors should always be written as columns and not as rows!\n",
        "\n",
        "When we write the bilinear forms as a row of rows the matrix multiplication formula makes a lot more sense. We can write out both vectors as columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaK3-XOTvb29"
      },
      "source": [
        "**Above is the old way (row vector & column vector both to describe vectors, and the transition matrix in the middle) and on the bottom is the new better way with tensor products $\\otimes$**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_42.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZXXW06swLD9"
      },
      "source": [
        "**Summary of the tensor product for bilinear maps:**\n",
        "\n",
        "So we can write bilinear forms as linear combinations of covector covector pairs and this\n",
        "\n",
        "* immediately gives us the transformation rules $\\begin{aligned} \\widetilde{\\epsilon}^{i} &=B_{j}^{i} \\epsilon^{j} & \\widetilde{\\mathcal{B}_{i j}} &=F_{i}^{k} F_{j}^{l} \\mathcal{B}_{k l} \\\\ \\epsilon^{i} &=F_{j}^{i} \\widetilde{\\epsilon}^{j} & \\mathcal{B}_{i j} &=B_{i}^{k} B_{j}^{l} \\widetilde{B_{k l}} \\end{aligned}$\n",
        "\n",
        "* the component multiplication formula: $\\mathcal{B}_{i j} \\epsilon^{i} \\epsilon^{j} \\Rightarrow \\mathcal{B}_{i j} v^{i} w^{i}$\n",
        "\n",
        "* and the correct array shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_v9lB3NlHTE"
      },
      "source": [
        "**Combining two covectors using the tensor product can gives us a bilinear form whose coefficients are just the entries of the array given by the Kronecker product of the two row vectors (and not a row and a column vwector like for the Kronecker delta) associated with the covectors**\n",
        "\n",
        "* Meanwhile the coefficients of the linear map are just the entries of an array given by the Kronecker delta of the column vector representing the vector and the row vector representing the covector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Gysu23vwIX"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_43.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vunhuJeZRQoi"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXKHNs4SNpaD"
      },
      "source": [
        "**EXTENSION: Any Vector-Covector-Combination as Tensor Product $\\otimes$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnLXk7ijQQ4W"
      },
      "source": [
        "https://www.youtube.com/watch?v=9R4vhqvE_jw&list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG&index=17"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-HzE6R8Nqow"
      },
      "source": [
        "> **Linear Maps: Linear combinations of vector-covector-pairs** $L=L_{j}^{i} (\\overrightarrow{e_{i}} \\otimes \\epsilon^{j})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XepAaVOPO9Rj"
      },
      "source": [
        "> **Bilinear Forms: Linear combinations of covector-covector-pairs** $\\mathcal{B}=\\mathcal{B}_{i j} \\epsilon^{i} \\epsilon^{j}=\\mathcal{B}_{i j}\\left(\\epsilon^{i} \\otimes \\epsilon^{j}\\right)$ (including metric tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjDPJfpWPgwA"
      },
      "source": [
        "**Let's take two new tensor**\n",
        "\n",
        "This is a (2,0) tensor\n",
        "\n",
        "> $D=D^{a b} \\overrightarrow{e_{a}} \\overrightarrow{e_{b}}$ \n",
        "\n",
        "This is a (1,2) tensor\n",
        "\n",
        "> $Q=Q_{j k}^{i} \\overrightarrow{e_{i}} \\epsilon^{j} \\epsilon^{k}$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihXGqHHlQLzL"
      },
      "source": [
        "**Now we can ask the same questions:**\n",
        "\n",
        "1. What are the coordinate transform rules?\n",
        "2. What is the multiplication formula for $Q$ ($D$)?\n",
        "3. What are the array shapes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjH3REydQ9ZC"
      },
      "source": [
        "**1. How to $D$ and $Q$ under a change of basis?**\n",
        "\n",
        "Transforming tensor components is not hard, long as you have the transformation rules for basis vectors and covectors (plug backward transform in here for example twice on the left side)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6BCtxaGRPXn"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_50.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G3Dxm03RdSn"
      },
      "source": [
        "**2. What is the formula for $Q$ acting on the input $D$ = $Q(D)$**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xOhA35vRjZa"
      },
      "source": [
        "This is tricky because there is no one way to do that. Some examples are:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjpikBsBSbf0"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_51.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8PgKRmcSdHh"
      },
      "source": [
        "> **The challenge is now that: As we make these tensors bigger and bigger with more and more covariant and contravariant parts, we end up with more and more ways to do the summations, and more and more ways to compute functions.**\n",
        "\n",
        "* Writing $D$ = $Q(D)$ is ambuguous as it doesn't tell us exactly what to do\n",
        "\n",
        "* so we need to write it out in the Einstein notation like on the left side, for example $Q_{j k}^{i} D^{j k}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwMyGD2OTbXr"
      },
      "source": [
        "**3. What is the array shape?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shWdxhbeTm1s"
      },
      "source": [
        "It's like the Kronecker product between two column vectors:\n",
        "\n",
        "* like this part $\\overrightarrow{e_{a}} \\overrightarrow{e_{b}}$  in this here: $D=D^{a b} \\overrightarrow{e_{a}} \\overrightarrow{e_{b}}$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRXZVNc3Ub_G"
      },
      "source": [
        "*We can do this for the first example from above*:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkSgY4moUaCT"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_52.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7I_zNIhU28N"
      },
      "source": [
        "*For the other example it would look like this*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaNIpel8U0Yd"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_53.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCTxIaLMU7kM"
      },
      "source": [
        "*One could use the 3d visualisation, but it's better in the matrix array way. Because looking at this you can see it’s a (1,2) tensor with one column aspect and two row aspects*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GZg16KPU1WK"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_54.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMi5BlFyVheg"
      },
      "source": [
        "**Array Multiplication**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KkaJsiIWZei"
      },
      "source": [
        "*Easy for smaller tensors*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTyF-2vsVut3"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_55.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCa0iC8UWBsT"
      },
      "source": [
        "*That's not so easier for larger tensors that have high type numbers, because there are several possible multiplication rules (as discussed earlier):*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXFZ_OH-Wctm"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_56.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqPaeTDUWoc9"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_57.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Btxo7SfVjfS"
      },
      "source": [
        "*For much more complex tensors, it's the easiest to just stick with the Einstein notation and also not do the array representation.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj9k3XnrX_bt"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_58.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyGsVdBzXtPV"
      },
      "source": [
        "So with high type tensors the abstract notation and the array notation have their limitations. When trying to express tensor multiplication formulas it’s usually easier just to stick with the Einstein component notation. For this reason a lot of sources just write tensors like this and leave out basis vector and covectors completely:\n",
        "\n",
        "> $Q_{j k}^{i} \\overrightarrow{e_{i}} \\epsilon^{j}$ $\\mapsto$ $Q_{j k}^{i}$\n",
        "\n",
        "> $D^{a b} \\overrightarrow{e_{a}} \\overrightarrow{e_{b}}$ $\\mapsto$ $D=D^{a b}$\n",
        "\n",
        "**But it's important to remember that tensor components always come from a choice of basis, and the same tensor can have different components if we choose to represent it in a different basis.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v00kN_dfYtuV"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_59.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIuY9yDaZEns"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_60.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww0H7zQfNLwS"
      },
      "source": [
        "**Exkurs: Tensor Product $\\otimes$ vs Kronecker Product $\\otimes$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAAC6oIJOROe"
      },
      "source": [
        "They are technically different things, but highly related to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYBZgAraNfLf"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_40.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aot4DpBgN_Fl"
      },
      "source": [
        "https://www.youtube.com/watch?v=qp_zg_TD0qE&list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG&index=16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuCoDKzBKdQh"
      },
      "source": [
        "**Here are examples on how the tensor products works:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-a5jHatF-a-"
      },
      "source": [
        "Basis for Vector Space $V$\n",
        "\n",
        "> $\\overrightarrow{e_{1}}, \\overrightarrow{e_{2}} \\in V$\n",
        "\n",
        "Basis for Dual Space $V*$\n",
        "\n",
        "> $\\epsilon^{1}, \\epsilon^{2} \\in V^{*}$\n",
        "\n",
        "And the covectors are linear functions that are defined by these rules here, where the covector $\\epsilon^{i}$ is acting on the vector $\\overrightarrow{e_{j}}$ gives the Kronecker delta $\\delta_{j}^{i}$ as the result (=we get 1 if i and j are the same and 0 if not).\n",
        "\n",
        "> $\\epsilon^{i}\\left(\\overrightarrow{e_{j}}\\right)=\\delta_{j}^{i}=\\left\\{\\begin{array}{l}1, i=j \\\\ 0, i \\neq j\\end{array}\\right.$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLyH8vIyGe2n"
      },
      "source": [
        "**A tensor product takes two tensors and produces a new tensor:**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_44.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuUqmshEHGAi"
      },
      "source": [
        "**To demonstrate that this is a linear map, we can pass in an input vector $\\overrightarrow{v}$**\n",
        "\n",
        "To get the output we can just we pass $v$ to the covector $\\epsilon$ first\n",
        "\n",
        "> $\\left(\\overrightarrow{e_{i}} \\otimes \\epsilon^{j}\\right)(\\vec{v})$\n",
        "\n",
        "Pass v to the covector:\n",
        "\n",
        "> $=\\overrightarrow{e_{i}} \\otimes\\left(\\epsilon^{j}(\\vec{v})\\right)$\n",
        "\n",
        "Then we expand v as a linear combination of the basis vectors\n",
        "\n",
        "> $=\\overrightarrow{e_{i}} \\otimes\\left(\\epsilon^{j}\\left(v^{k} \\overrightarrow{e_{k}}\\right)\\right)$\n",
        "\n",
        "The we bring the components outside since covectors are linear functions (we can scale before or after):\n",
        "\n",
        "> $=v^{k} \\overrightarrow{e_{i}} \\otimes\\left(\\epsilon^{j}\\left(\\overrightarrow{e_{k}}\\right)\\right)$\n",
        "\n",
        "And the covector acting on a vector becomes a Kronecker delta:\n",
        "\n",
        "> $=v^{k} \\overrightarrow{e_{i}} \\delta_{k}^{j}$\n",
        "\n",
        "Then Kronecker index cancellation rule we can remove the $k$ indexes and get j:\n",
        "\n",
        "> $=v^{j} \\overrightarrow{e_{i}}$\n",
        "\n",
        "So this is a function that takes a vector input and produces a vector output\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cxCtxWNKVNc"
      },
      "source": [
        "**Here are examples on how the Kronecker products works:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqbmpOz9JpKW"
      },
      "source": [
        "Here you get a row of columns when you take the first array on the left and distribute every element to the second array on the right:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_46.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7PsreLrKTas"
      },
      "source": [
        ".. and multiplying this with another column vector we get the same thing (here you get a column of rows of columns)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_47.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8-qZXEnL7Pv"
      },
      "source": [
        "**Summary**\n",
        "\n",
        "> $=v^{j} \\overrightarrow{e_{i}}$ \n",
        "\n",
        "* these coefficient are the entries of a matrix (on the tensor product side)\n",
        "\n",
        "* on the Kronecker delta side you can see this matrix !!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KNp8526L8HP"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_48.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYefxE5vNAUg"
      },
      "source": [
        "* Tensor product and Kronecker product are doing basically the same kind of thing\n",
        "\n",
        "* It’s just the tensor product is combining the abstract vector and the abstract covector in the land of algebraic symbols\n",
        "\n",
        "* And the Kronecker product is combining the the vector array and the covector array  in the land of arrays\n",
        "\n",
        "* But the components that we get from the tensor are just the components of the matrix that we get from Kronecker product\n",
        "\n",
        "* So they are sort of the same operation they just do the work in different contexts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpAZH1mnNESo"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_49.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WbQkWdCA0rW"
      },
      "source": [
        "### **Bilinear Map**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU2x63gHJKId"
      },
      "source": [
        "**Bilinear Map (bilineare Abbildung)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsQ4y_sbcCqo"
      },
      "source": [
        "Matrix multiplication is an example. (in contrast: linear map war eine matrix als map von vector zu vector, das hier ist eine matrix als map zw matrix und matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvUhNvbMI2uk"
      },
      "source": [
        "[Bilinearen Abbildungen](https://de.m.wikipedia.org/wiki/Bilineare_Abbildung) verallgemeinern die verschiedensten Begriffe von Produkten (im Sinne einer Multiplikation). Die Bilinearität entspricht dem Distributivgesetz $a \\cdot (b + c) = a \\cdot b + a \\cdot c$ bei der normalen Multiplikation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdQ5G1UYJFap"
      },
      "source": [
        "[A bilinear map](https://en.m.wikipedia.org/wiki/Bilinear_map) is a function combining elements of two vector spaces to yield an element of a third vector space, and is linear in each of its arguments. Matrix multiplication is an example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YntIti2fNbT1"
      },
      "source": [
        "### **Multilinear Form**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RftwOpvNd1P"
      },
      "source": [
        "Kovariante Tensoren sind Multilinearformen [Source](https://de.m.wikipedia.org/wiki/Multilinearform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsu9zP1cO7vX"
      },
      "source": [
        "In abstract algebra and multilinear algebra; a [multilinear form](https://en.m.wikipedia.org/wiki/Multilinear_form) on a vector space $V$ over a field $K$ is a map\n",
        "$f: V^{k} \\rightarrow K$\n",
        "that is separately $K$ -linear in each of its $k$ arguments. More generally, one can define multilinear forms on a module over a commutative ring. The rest of this article, however, will only consider multilinear forms on finite-dimensional vector spaces.\n",
        "\n",
        "A multilinear $k$ -form on $V$ over $\\mathbf{R}$ is called a (covariant) $k$ -tensor, and the vector space of such forms is usually denoted $\\mathcal{T}^{k}(V)$ or $\\mathcal{L}^{k}(V) \\cdot$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkQusr_NeYUX"
      },
      "source": [
        "bilinear form"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhXNxLbbeVeT"
      },
      "source": [
        "exterior product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "385OlLlWeRSS"
      },
      "source": [
        "Differential form"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnYI3QTIefG3"
      },
      "source": [
        "pullback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K27Uu3jNoqI"
      },
      "source": [
        "### **Multilinear Map - from Tensors to Tensor Spaces (Product Spaces & Vector Spaces $\\otimes$)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI7tQJHncdOn"
      },
      "source": [
        "Linear map: matrix als map von vektor zu vektor\n",
        "\n",
        "bilinear map: matrix als map zw matrix und matrix\n",
        "\n",
        "multilinear map: matrix (tensor) als map zw tensor und tensor (mehr als bilinear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly9YH7kJ6JkP"
      },
      "source": [
        "**Multilinear Maps: So the strongest kind of linearity we could reasonably impose is that $m$ is linear in each coordinate when all else is fixed**. \n",
        "\n",
        "https://jeremykun.com/2014/01/17/how-to-conquer-tensorphobia/\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Matrix_multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofQKNYh5cMwx"
      },
      "source": [
        "**Tensor Product Spaces $\\otimes$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7sbTMXCNp45"
      },
      "source": [
        "Im mathematischen Teilgebiet der linearen Algebra und verwandter Gebiete wird durch die [multilineare Abbildung](https://de.m.wikipedia.org/wiki/Multilineare_Abbildung) der Begriff der linearen Abbildung verallgemeinert. Ein wichtiges Beispiel einer multilinearen Abbildung ist die Determinante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1EvHHn3Ny7X"
      },
      "source": [
        "In linear algebra, a [multilinear map](https://en.m.wikipedia.org/wiki/Multilinear_map) is a function of several variables that is linear separately in each variable. More precisely, a multilinear map is a function\n",
        "\n",
        "> $\n",
        "f: V_{1} \\times \\cdots \\times V_{n} \\rightarrow W\n",
        "$\n",
        "\n",
        "where $V_{1}, \\ldots, V_{n}$ and $W$ are vector spaces (or modules over a commutative\n",
        "ring), with the following property: for each $i$, if all of the variables but $v_{i}$ are held constant, then $f\\left(v_{1}, \\ldots v_{i}, \\ldots v_{n}\\right)$ is a linear function of $v_{i} .$\n",
        "\n",
        "A multilinear map of one variable is a linear map, and of two variables is a bilinear map. More generally, a multilinear map of k variables is called a k-linear map. **If the codomain of a multilinear map is the field of scalars, it is called a multilinear form**. Multilinear maps and multilinear forms are fundamental objects of study in multilinear algebra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd3wTfP0OhR0"
      },
      "source": [
        "For multilinear maps used in cryptography, see [Cryptographic multilinear map](https://en.m.wikipedia.org/wiki/Cryptographic_multilinear_map)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhMNVZbYaAHG"
      },
      "source": [
        "**Tensor Product Rules**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfbZg37RZNi6"
      },
      "source": [
        "https://www.youtube.com/watch?v=M-OLmxuLdbU&list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG&index=18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2woa-ljmzkt"
      },
      "source": [
        "**Tensor Product Operation Rules - which gives us a (Tensor) Vector Space**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UaQY3DMb5dJ"
      },
      "source": [
        "Tensor product: Combining tensors that follow these scaling and adding rules:\n",
        "\n",
        "> $n(\\vec{v} \\alpha)=(n \\vec{v}) \\alpha=\\vec{v}(n \\alpha)$ (*Note the scaling rule: scale only with one side, not both at the same time!*)\n",
        "\n",
        "> $\\vec{v} \\alpha+\\vec{v} \\beta=\\vec{v}(\\alpha+\\beta)$\n",
        "\n",
        "> $\\vec{v} \\alpha+\\vec{w} \\alpha=(\\vec{v}+\\vec{w}) \\alpha$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEFMjK9NhTVY"
      },
      "source": [
        "And written in proper tensor notation:\n",
        "\n",
        "> $n(\\vec{v} \\otimes \\alpha)=(n \\vec{v}) \\otimes \\alpha=\\vec{v} \\otimes(n \\alpha)$\n",
        "\n",
        "> $\\vec{v} \\otimes \\alpha+\\vec{v} \\otimes \\beta=\\vec{v} \\otimes(\\alpha+\\beta)$\n",
        "\n",
        "> $\\vec{v} \\otimes \\alpha+\\vec{u} \\otimes \\alpha=(\\vec{v}+\\vec{u}) \\otimes \\alpha$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwRSebqVmrX7"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_63.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrPaGbNbnNaL"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_64.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hSO435um4gW"
      },
      "source": [
        "**Tensor Vector Spaces**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FRkhB9koQ_c"
      },
      "source": [
        "These vectors are element of the vector space ${V}$\n",
        "\n",
        "> $\\vec{v}, \\vec{w}, \\overrightarrow{e_{1}}, \\overrightarrow{e_{2}}$ $\\in {V}$\n",
        "\n",
        "These covectors are element of the dual vector space ${V^{*}}$\n",
        "\n",
        "> $\\alpha, \\beta, \\epsilon^{1}, \\epsilon^{2}$ $\\in {V^{*}}$\n",
        "\n",
        "We can make following vector-covector-pairs:\n",
        "\n",
        "> $\\vec{v} \\alpha, \\vec{v} \\beta, \\vec{w} \\alpha, \\vec{w} \\beta, \\overrightarrow{e_{1}} \\epsilon^{2}, L_{j}^{i} \\overrightarrow{e_{i}} \\epsilon^{j}$\n",
        "\n",
        "And we can add them and scale with them with the tensor product rules which forms a vector space:\n",
        "\n",
        "> $n(\\vec{v} \\otimes \\alpha)=(n \\vec{v}) \\otimes \\alpha=\\vec{v} \\otimes(n \\alpha)$\n",
        "\n",
        "> $\\vec{v} \\otimes \\alpha+\\vec{v} \\otimes \\beta=\\vec{v} \\otimes(\\alpha+\\beta)$\n",
        "\n",
        "> $\\vec{v} \\otimes \\alpha+\\vec{u} \\otimes \\alpha=(\\vec{v}+\\vec{u}) \\otimes \\alpha$\n",
        "\n",
        "So we know that these must be vectors in a vectors space:\n",
        "\n",
        "> $\\vec{v} \\alpha, \\vec{v} \\beta, \\vec{w} \\alpha, \\vec{w} \\beta, \\overrightarrow{e_{1}} \\epsilon^{2}, L_{j}^{i} \\overrightarrow{e_{i}} \\epsilon^{j}$\n",
        "\n",
        "But in which vector space do they live in? In this one:\n",
        "\n",
        "> $\\in V \\otimes V^{*}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v5QUEo_qX2Q"
      },
      "source": [
        "**Now this is a new use case of $\\otimes$, because so far we used it for combining vectors or tensors. Here we use it to combine entire vector spaces.** (more about it below in a short separat chapter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v_LAxNx9XsT"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzYepuNl9gie"
      },
      "source": [
        "**So what are the elements of $V \\otimes V^{*}$?** (1,1)-tensors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjQxDkDs9fnK"
      },
      "source": [
        "\n",
        "> **(1,1)-Tensors**: $L_{j}^{i} \\overrightarrow{e_{i}} \\epsilon^{j} \\in V \\otimes V^{*}$\n",
        "\n",
        "Remember: vectors have an upstairs index (because they transform contravariant):\n",
        "\n",
        "> $\\vec{v}=v^{i} \\overrightarrow{e_{i}}$\n",
        "\n",
        "and covectors habe a downstairs index (because they transform covariant):\n",
        "\n",
        "> $\\alpha=\\alpha_{i} \\epsilon^{i}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_MDlJujqpQA"
      },
      "source": [
        "\n",
        "\n",
        "So if we do a summation with vector components like this over $j$, we end up with vector components as the output (because we have one upstairs $i$ index that's left):\n",
        "\n",
        "> $L_{j}^{i} v^{j}=w^{i}$\n",
        "\n",
        "In this case $L$ ist acting as a map from $V$ to $V$, or essentially a linear map.\n",
        "\n",
        "> $V \\mapsto V$ \n",
        "\n",
        "> **This is a (1,1)-Tensor and a member of the vector space $V \\otimes V^{*}$**\n",
        "\n",
        "But we can also do a summation with covector components like this with sum over $i$, and our outout would have $j$ as the dowstairs index:\n",
        "\n",
        "> $L_{j}^{i} \\alpha_{i}=\\beta_{j}$\n",
        "\n",
        "We would end up with covector components as the output. So covector in, covector out:\n",
        "\n",
        "> $V^{*} \\mapsto V^{*}$ \n",
        "\n",
        "> **This is also a (1,1)-Tensor and a member of the vector space $V \\otimes V^{*}$**\n",
        "\n",
        "Also we can provide $L$ with both vector components and covector components and we do two summations over $i$ and $j$, and that would give us a scalar as the output since there are no indices left to sum over.\n",
        "\n",
        "> $L_{j}^{i} v^{j} \\alpha_{i}=s$\n",
        "\n",
        "So in this case $L$ can be viewed as a function from a pair of vectors and covectors to scalars.\n",
        "\n",
        "> $V \\times V^{*} \\rightarrow \\mathbb{R}$ \n",
        "\n",
        "> **This is also a (1,1)-Tensor and a member of the vector space $V \\otimes V^{*}$**\n",
        "\n",
        "And finally we can do the same thing but reverse the order of the inputs:\n",
        "\n",
        "> $L_{j}^{i} \\alpha_{i} v^{j}=s$\n",
        "\n",
        "And in this case $L$ is a function from a covector-vector-pair to scalar:\n",
        "\n",
        "> $V^{*} \\times V \\rightarrow \\mathbb{R}$\n",
        "\n",
        "> **This is also a (1,1)-Tensor and a member of the vector space $V \\otimes V^{*}$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-L-L-XQsk9q"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aalLVt5GFfx"
      },
      "source": [
        "**So what are the elements of $V^{*} \\otimes V^{*}$?** (0,2)-tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vot5kh9i9T6Z"
      },
      "source": [
        "**Now what if we use the tensor product to combine two covectors together?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3YRm0hA9l-i"
      },
      "source": [
        "Those covectors life in $V^{*}$:\n",
        "\n",
        "> $\\alpha, \\beta, \\gamma, \\delta, \\epsilon^{1}, \\epsilon^{2}$ $\\in V^{*}$\n",
        "\n",
        "So when we have covector-covector-pairs like following it turns out that they all life in the vector space **$V^{*} \\otimes V^{*}$**\n",
        "\n",
        "> $\\alpha \\beta, \\alpha \\gamma, \\delta \\beta, \\epsilon^{1} \\epsilon^{2}, \\mathcal{B}_{i j} \\epsilon^{i} \\epsilon^{j}$ **$\\in V^{*} \\otimes V^{*}$**\n",
        "\n",
        "**So elements of the $V^{*} \\otimes V^{*}$are (0,2)-tensors**\n",
        "\n",
        "> $\\mathcal{B}_{i j} \\epsilon^{i} \\epsilon^{j} \\in V^{*} \\otimes V^{*}$\n",
        "\n",
        "> **This is a (0,2)-Tensor and a member of the vector space $V^{*} \\otimes V^{*}$** \n",
        "\n",
        "(Covector-covector-pairs and their linear combinations)\n",
        " \n",
        "If we take these $B$ components and do two summations with two sets of vector components (via $i$ and $j$), then we end up with a scalar:\n",
        "\n",
        "> $\\mathcal{B}_{i j} v^{i} w^{j}=s$\n",
        "\n",
        "And this of course is a bilinear form (which takes a pair of vectors and outputs a scalar):\n",
        "\n",
        "> $V \\times V \\rightarrow \\mathbb{R}$\n",
        "\n",
        "> **This is a (0,2)-Tensor and a member of the vector space $V^{*} \\otimes V^{*}$**\n",
        "\n",
        "But we can also do a single summation over $i$ with a set of vector components and we’d be left with the index $j$ downstairs. So the output would be a set of covector components\n",
        "\n",
        "> $\\mathcal{B}_{i j} v^{i}=\\alpha_{j}$\n",
        "\n",
        "So in this case $B$ is a map from vectors to covectors:\n",
        "\n",
        "> $V \\rightarrow V^{*}$\n",
        "\n",
        "> **This is a (0,2)-Tensor and a member of the vector space $V^{*} \\otimes V^{*}$**\n",
        "\n",
        "Also we could choose to do summation with vector components over the $j$ index and then end up with covector components $i$\n",
        "\n",
        "> $\\mathcal{B}_{i j} v^{j}=\\beta_{i}$\n",
        "\n",
        "This would be another map from $V$ to $V^{*}$, but it would be a different map than the previous one, because we’re doing the summation differently.\n",
        "\n",
        "> $V \\rightarrow V^{*}$\n",
        "\n",
        "> **This is a (0,2)-Tensor and a member of the vector space $V^{*} \\otimes V^{*}$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXVPc1kP9ikY"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7pJFmnBGP8a"
      },
      "source": [
        "**Create even larger vector spaces from basic building blocks $V$ and $V^{*}$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PJjyl4GChTa"
      },
      "source": [
        "**So we can create larger and larger vector spaces out of the two basic building blocks $V$ and $V^{*}$**:\n",
        "\n",
        "* starting with two vector spaces $V$ and $V^{*}$ (basic building blocks)\n",
        "\n",
        "  * they contain tensors $v_{i}$ and $\\alpha_{j}$\n",
        "  \n",
        "  * with vector components with upstairs index and covector components with downstairs index\n",
        "\n",
        "* we can combine these 2 vector spaces into new vector spaces using the tensor product $V \\otimes V$, $V \\otimes V^{*}$, $V^{*} \\otimes V$ and $V^{*} \\otimes V^{*}$\n",
        "\n",
        "  * and these vectors spaces have following vector components: $\\mathcal{A}^{i j}$, $L_{j}^{I}$, $L_{j}{ }^{i}$ and $\\mathcal{B}_{i j}$\n",
        "\n",
        "  * Indexes from $V$ go upstairs and index from $V^{*}$ go downstairs\n",
        "\n",
        "* And we can continue to make larger and larger vector spaces using the tensor product like $V \\otimes V \\otimes V$, $V^{*} \\otimes V \\otimes V$ etc\n",
        "\n",
        "  * And all these vector spaces contain tensors like $T^{i j k}$, $T_{i}^{j k}$, $T_{j}^{i k}$ etc.\n",
        "  \n",
        "  * with components that have different combinations of upstairs and downstairs indexes depending on whether they are constructed using $V$ or $V^{*}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0tSrWkPDA5Z"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_65.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsYx7SyXHUWU"
      },
      "source": [
        "**So if we have some new tensor $T$ from a vector space we’ve never seen before, we can easily get the correct component indexes just by looking at the vector spaces.**\n",
        "\n",
        "> $T \\in V^{*} \\otimes V \\otimes V^{*} \\otimes V^{*}$\n",
        "\n",
        "Looking at these vector spaces we see that the basis would be made up of a covector, a vector, a covector and another covector in combination\n",
        "\n",
        "> $T={\\epsilon}^{i}  \\overrightarrow{e_{j}} \\epsilon^{k} {\\epsilon}^{l}$\n",
        "\n",
        "And we get the components just by **placing the indexes in the opposite position that we see in the basis**, so that all the summations work out properly.\n",
        "\n",
        "**And now we can ask: How can this tensor $T$ act on other tensors?**\n",
        "\n",
        "> $T_{i}^{j}{ }_{k l}$\n",
        "\n",
        "examples of other tensors to be acted on:\n",
        "\n",
        "> $u^{c} \\quad \\begin{array}{cc}D^{f g} & \\beta_{s} \\\\ Q_{u v}^{t} & L_{y}^{x} & w^{b} & U^{m n o}\\end{array}$\n",
        "\n",
        "**Well, we can basically do any summations we like as long as the upstairs indexes are matched with downstairs indexes and downstairs indexes are matched with upstairs indexes.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smQJnOTCJg8Y"
      },
      "source": [
        "We could do something like this with four summations and you can see that all the indexes are positioned properly:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tjMvHRaJjfE"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensors_69.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEjc1eZWKIsd"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_68.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL7-mwyDKwII"
      },
      "source": [
        "**This is how the result for each would look like** [see explanation](https://youtu.be/M-OLmxuLdbU?list=PLJHszsWbB6hrkmmq57lX8BV-o-YIOFsiG&t=683)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uY9giwXKsy5"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_70.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk-lP8UuhhKa"
      },
      "source": [
        "The tensors we get from these tensor product form new vector spaces:\n",
        "\n",
        "> $V \\otimes V$\n",
        "\n",
        "> $V \\otimes V^{*}$\n",
        "\n",
        "> $V^{*} \\otimes V$\n",
        "\n",
        "> $V^{*} \\otimes V^{*}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8gaaOp9OFGV"
      },
      "source": [
        "**Tensor Products as Multilinear Maps**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1wLBTdMLN0x"
      },
      "source": [
        "**What do all these functions have in common?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyQ3RuV6Svzb"
      },
      "source": [
        "* If you make all inputs constant except one, we can scale the input before or scale the output after and we get the same result\n",
        "\n",
        "* And also if we replace these inout vector components with a sum of two sets of vector components I can just distribute these out and get this sum here (red line under equation in image), so basically I can add the inputs or I can add the outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dXVTv2KTOMu"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_73.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIOSifyzRNqC"
      },
      "source": [
        "> **Multilinear Map: A function that is linear when all inputs except one are held constant** (they are linear in each input variable)\n",
        "\n",
        "* when we scale the input variable by $n$ (and all other are held constant) that's the same as scaling the ouput of the function by $n$\n",
        "\n",
        "* when we hold all input constant except one, and we do a sum in the input slot, that's the same thing as doing the sum of the outputs (in image below)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8QXFQ2gSZs0"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_71.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imgqV653iHLI"
      },
      "source": [
        "And all tensors are **multilinear maps** which means they are functions that take some number of inputs and they are linear in each input variable while all other input variables are held constant (kind of ceteris paribus in economics!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6xrhw0z55OY"
      },
      "source": [
        "### **From Single Vectors to Vector Fields (Transformations)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vwd9ycMPnGaj"
      },
      "source": [
        "##### **Basis Vectors = Partial Derivatives (Jacobian)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hv-xB6F59Hr"
      },
      "source": [
        "A vector can be re-interpreted as a partial derivative (see image below):\n",
        "\n",
        "> $\\overrightarrow{e_{x}} \\equiv \\frac{\\partial \\vec{R}}{\\partial x}$\n",
        "\n",
        "https://www.youtube.com/watch?v=rr5qEb_kT6c&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kxt7ncBEwbj"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_112.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwemvVT6gKCQ"
      },
      "source": [
        "The forward matrix for example is constructed from the scaling coefficients (=basis vector coiefficients) in this case from the new basis * the old basis coefficients:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_89.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFyd9JCijfTB"
      },
      "source": [
        "https://www.youtube.com/watch?v=OMCguyCnTQk&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip6TceKegLxJ"
      },
      "source": [
        "* Now if you want to get the coefficients when your old basis in Cartesian and your new basis is Polar coordinates, then you have another forward map at every point in the polar coordinate system\n",
        "\n",
        "* if you now think of the basis vectors as partial derivatives, it makes things much easier. Use mutlivariable chain rules:\n",
        "\n",
        "  * the first old basis vector $\\overrightarrow{e_{x}}$ can be thought of as the partrial derivative in the x direction: $\\frac{\\partial \\vec{R}}{\\partial x}=\\overrightarrow{e_{x}}$\n",
        "\n",
        "  * the second old basis vector $\\overrightarrow{e_{y}}$ can be thought of as the partrial derivative in the y direction: $\\frac{\\partial \\vec{R}}{\\partial y}=\\overrightarrow{e_{x}}$\n",
        "\n",
        "  * same goes for the new basis vector (polar coordinates) as partial derivaties into r and $\\theta$ directions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moAomB7pgxPy"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_90.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bjXpN2bhHQ2"
      },
      "source": [
        "The underlined part are the coefficients to move from one basis (cartesian) to another (polar) (Achtung: not normalised):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UONFMjnDhCSd"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_91.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib8lMPatiAiu"
      },
      "source": [
        "The forward matrix = the Jacobian matrix:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIcAyhrZh_he"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_92.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2pyxTmVlHea"
      },
      "source": [
        "Example of that it works:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O07XWpbTlT_q"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_95.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VbFuNYDkrWa"
      },
      "source": [
        "And you can do the same the other way around to get the Backward transform, which is the inverse Jacobian:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9csAls1Tkh9J"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_93.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf5WRU1IlD4B"
      },
      "source": [
        "Example of that it works:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t2vli-nk-2-"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_94.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r11g-gHWly33"
      },
      "source": [
        "It total it looks likes this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zGVDgYKl0aZ"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_96.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMeh1englkIb"
      },
      "source": [
        "And we can store the (forward & backward) coefficients in matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s6K_Cijl2Nn"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_97.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9kuqV7wnL0t"
      },
      "source": [
        "##### **Vectors = Derivatives in Vector Fields (vector fields of tangent vectors along curves)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqNgTmz7npYF"
      },
      "source": [
        "> Task: Figure out vector components in a new basis, **but instead of one vector, we consider vector fields**.\n",
        "\n",
        "We consider vectors along a curve (=tangent vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1bToWKvnRrW"
      },
      "source": [
        "https://www.youtube.com/watch?v=9yOb9gHnLUk&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6s7zP7zo8Os"
      },
      "source": [
        "The cases are both the same: \n",
        "\n",
        "* on we have a single vector in a new basis constructed from the basis vectors in the old basis and its components\n",
        "\n",
        "* on the bottom we have a whole vector field constructed from the old basis (using the chain rule!) and the vectir components ar derivates!\n",
        "\n",
        "* Framed in red is the vector we want to expand, in blue framed the basis vectors and in green framed the vector components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXMGN1yko079"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_98.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--mPorKKqCNh"
      },
      "source": [
        "Example: in the cartesian coordinate system the basis vectors are every where the same. Just components are everywhere different. But it’s easy using the multivariable chain rule when you take the vector field:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD4bX2eFpmrQ"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_99.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOLSkW3zqmKs"
      },
      "source": [
        "Other example iof tangents on a circle in a cartesian coordinate system:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhD5dXs0qklx"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_100.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uGzwjLoq-BO"
      },
      "source": [
        "Do these component make sense? Let's check with an example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv-H1Ly5rCla"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_101.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF5EIC6ern1-"
      },
      "source": [
        "Also works in the polar coordinate system:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8PSF7Ahrk1b"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_103.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMBmDl65sS47"
      },
      "source": [
        "Checking if it's true, and it works:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj5JcehUsR3z"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_104.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmDhjARH8C1l"
      },
      "source": [
        "##### **Vectors: Contravariance of Vector Field Components**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Tc8R17R_lZm"
      },
      "source": [
        "https://www.youtube.com/watch?v=zKuyaQ4JRs8&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=6&t=154s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAcAsEz08KYj"
      },
      "source": [
        "* Vector components are contravariant\n",
        "\n",
        "* We can follow the same reasoning for vector fields of tangent vectors along curves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPMbmj-m9E4B"
      },
      "source": [
        "In this example, the polar components have two be equal to the Cartesian components multiplied by the backward transform. So we get this transformation formula for the components of the tangent vectors (the box on the bottom right):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFcbjIaU9t-s"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_104.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t9ZyZK2-Yph"
      },
      "source": [
        "Partial derivative basis vectors transform one way and the vector component derivatives transform the other way, the vector components are contravariant. (Dervative coefficients are opposites) But don't memorize them! Simply use multivariable chain rules for the four formulas on the bottom and you get the transformation (chain rules over cartesian frames in purple, chain rule sover polar coordinates framed in green)::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNULyN8G-XE6"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_105.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yomB0uS5A3zX"
      },
      "source": [
        "Remember when we used for forward and backward transforms with single vectors the following formula:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEN9QhB6A9q7"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_107.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47IqpEmoAnJB"
      },
      "source": [
        "**This is similar for Vector Fields: basis vectors transform one way, and the vector components transform the other wa, using the Jacobian $J$ and the Jacobian inverse $J^-1$ as the forward and backward transforms:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVrXW2OPAPM7"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_106.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8O5diWqBadM"
      },
      "source": [
        "..and this is for the specific example we had for the circular curve with radius 2:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93-kyqArBQxm"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_108.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJiw1Hi8CIOS"
      },
      "source": [
        "**One important last thing: we remove the position vector $R$ and leave the <u>derivative operators = (basis) vector</u>, and they will be considered basis vectors from now on:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozESJ841CbLp"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_109.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd32Sd8mC6X3"
      },
      "source": [
        "And this makes sense: The partial derivative with respect to x points in the x direction (and so on):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lmPKkD-CyyL"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_110.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7t0L81pDV2J"
      },
      "source": [
        "This is useful becasue position vectors $R$ rely on an origin, and as we will see later, on manifolds on curved surfaces we cannot rely on the existnce of an origin point:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZxCanO8DfgJ"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_111.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN0JHv-YFbJK"
      },
      "source": [
        "##### **Vectors: Extrinsic (Exterior) Geometry**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ZJpK-SH7n5"
      },
      "source": [
        "https://www.youtube.com/watch?v=VHkL5HpL0HY&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdGhxdPhGh6N"
      },
      "source": [
        "* Let's take a 2D surface like earth, and someone drives along it\n",
        "\n",
        "* we want to get the velocity of the car. We need position vectors, where we need an origin point (center of earth), then we get 2 vectors, take their limit to compute velocity\n",
        "\n",
        "* There are 2 issues with this:\n",
        "\n",
        "  1. Firstly the origin point that we've chosen doesn't live o the earth's 2D surface. We picked an origin point that was exterior to the surface. \n",
        "  \n",
        "  2. Secondly the target velocity actually leaves the surface that we are studying and goes off into the outside space - **Remember here Lie algreba and Lie group**: the tangent is outside the 2D surface and the tangent point is the Lie algebra. All on the 2D surface however is part of the Lie group.\n",
        "\n",
        "* So here, both the origin point and the velocity vector are both defined using the 3 dimensional space, even though we are only studying 2 dimensional spherical surface\n",
        "\n",
        "* **This is why it's all called exterior geometrty and exterior product** - studying something outside"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfjrMWg3Fgf-"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_113.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykHcxOIqIINd"
      },
      "source": [
        "If we try to find the distance between 2 points on a map of earth, it's called \"intrinsiv geometry\" when we are not allowed to leave the surface (and hence cannot draw a straight line, but need to find a geodesic on the flat map)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpJ5-pmUIfv4"
      },
      "source": [
        "And that gets even more complicated in General Relativity:\n",
        "\n",
        "1. 4D spacetime is curved space, so we cannot draw a straight line int he curved space. So that means we cant draw poisiton vectors. \n",
        "\n",
        "2. And we cannot pick an origin outside the 4D spacetime, because that would mean picking a point outside of the universe\n",
        "\n",
        "That's why its called intrinsic geometry: you need to stay inside! **But how do we study velocity if we are not allowed to use position vectors?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1iBLH11JZ7n"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_114.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfAIY2xeJeih"
      },
      "source": [
        "**Solution: we cannot draw straight lines, but we can draw curved paths on a 2D on a map for exmaple**.\n",
        "\n",
        "> **So we can't use normal position vectors to talk about directions on a surface, but we can use derivative operators to talk about different directions:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M69DFKc5L-qF"
      },
      "source": [
        "* If have have some path that's traveling around in our curved space $(x(\\lambda), y(\\lambda))$, we can still consider the direction that the path is pointing in using the derivative with respect to the curve parameter $\\frac{d}{d \\lambda}$\n",
        "\n",
        "* And we can break this direction up into its x and y components using the multivariable chain rules that we have for derivative operators $\\frac{d}{d \\lambda}=\\frac{d x}{d \\lambda} \\frac{\\partial}{\\partial x}+\\frac{d y}{d \\lambda} \\frac{\\partial}{\\partial y}$\n",
        "\n",
        "* But Achtung: you shouldn't think of this direction vector as actually connecting the two points on the earth (origin and destination of yellow arrow). The derivative just gives the general direction that the curve is traveling in at a given point.\n",
        "\n",
        "* So derivatives with us a way to talk about directions on a curved surface in a way that is complete intrinsic to the surface and doesn't require an outside space in any way. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9fCf-xxKdTJ"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_115.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9z9hAO2MkLy"
      },
      "source": [
        "We can use the same approach in 4 D space: we can't draw straight lines, but we can still draw curved paths. And that means we can take derivatives with respect to the paths parameters to get a sense of different directions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7PHcRymMlt-"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_116.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohLBzSDpNl_K"
      },
      "source": [
        "> So the old notation uses actual vectors from the **vector spaces R2 and R3** to define directions. But the new notation use the **vector space of derivative operators**.\n",
        "\n",
        "> **The vector space of derivative operators is formally known the \"Tangent Vector Space\" and is denoted: $T_{p}M$**, which is the vector space of derivatives at some point p on a surface $M$. And keep in mind that the vectors on the left and the vectors on the right are in fact from different vector spaces!! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfnBYAbGM4Aq"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_117.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzWeBGovN87H"
      },
      "source": [
        "And they do form a vector space because we can scale and add them linearly! So these partial derivatives are vectors in the tangent space $T_{p}M$:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbQcbjcLN77s"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_118.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbty_KKPgF9o"
      },
      "source": [
        "##### **Covectors: Differential Forms = Covectors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmNLuDcQhgaw"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_119.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQZSDQKtgofg"
      },
      "source": [
        "https://www.youtube.com/watch?v=XGL-vpk-8dU&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=8&t=201s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxLGFuVfhMX_"
      },
      "source": [
        "Re-interprete $d$ from $df$ as being an operator that takes a scalar field and outputs a covector field:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKFJ2cjMhrRd"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_120.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6mdNkf4jwKa"
      },
      "source": [
        "Example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5thTrbTmjt9D"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_126.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O0ehbWbh4PT"
      },
      "source": [
        "The way to get the covector fields is by tracing out the level sets of the scalar function: **Skalarfeld links mit Temperaturen, Kovektorfeld rechts mit den Konturen, wo überall die gleichen Konturen existieren (Äquivalenzen)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnYIWkB_iBwM"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_125.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSB8i_p3iy7V"
      },
      "source": [
        "Another example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTCmMB3Ji1nO"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_124.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21G88huhiz_L"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_122.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DzDkj-2jydq"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_127.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xOUNNBEl0Ca"
      },
      "source": [
        "*Example: If we think of x as a scalar field, it would look like this: it’s a scalar field where each point is given the x value at that point. And the covector field $dx$ would like like the other picture on top right: Covector fields $dx$ with level set curves being vertical lines and orientation to the right (because all x values are the same along this line, whcih aligns with the definition of a [**Level Set (Niveaumenge)**](https://de.wikipedia.org/wiki/Niveaumenge): \"die Menge aller Punkte des Definitionsbereichs einer Funktion, denen ein gleicher Funktionswert zugeordnet ist\".\n",
        "\n",
        "Covector fields $dy$ with level set curves being horizontal lines and orientation upwards:*\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_128.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EczRt2MFnSbY"
      },
      "source": [
        "Another examples: Circles with constant radius are along the same lines:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_129.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAYlahXAoiAS"
      },
      "source": [
        "**How to calculate now? - How do covector fields like $df$ act on $\\vec{v}$ to give us output values?**\n",
        "\n",
        "> Count the number of tangent lines to the curve at p (where the vector originates at point p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGWNs_Orojfu"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_130.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSuiZQQWpm3s"
      },
      "source": [
        "**But what's the geometrical meaning of $df$ ($\\vec{v}$)?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGpD60_Epskx"
      },
      "source": [
        "On a map we can draw out curves of constant elevation (which is the same thing as level sets). We can think of this level set drawing of a mountain as a covector field associated with the mountain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63_xK5mqrNAp"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_131.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3EvUH3GrOjy"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_132.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV2T7TkGsH8-"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_133.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIGdClC-sUu2"
      },
      "source": [
        "> $d f(\\vec{v})$ tells us the rate of change of $f$ when moving at velocity $\\vec{v}$. **$d f(\\vec{v})$ is the directional derivative of $f$ in direction $\\vec{v}$**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkLExJb5u9MP"
      },
      "source": [
        "**Covector Field Components: The following are the basis covectors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfsAMSGPuwo7"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_134.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZKsHpZlwxlz"
      },
      "source": [
        "So just as we can expand individual covectors into linear combinations of dual basis vectors (and of course we get different components depending on which basis we use (all on top), we can also expand differential forms - also callee covector fields - into linear combinations of other covector fields where we get different components depending o which basis we use (on the bottom)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5u522WPxJKW"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_135.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iruX41TXvgM8"
      },
      "source": [
        "https://www.youtube.com/watch?v=r_20yXBdhJk&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwW3Euv-xnRw"
      },
      "source": [
        "**Transformation Rules of Differential Forms (Covector Fields)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZH72aDVyEKX"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_136.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5Xgb_Z4y_oX"
      },
      "source": [
        "Same logic applies for covector fields: if we for example want to build the Cartesian basis covector fields our of the polar basis covector fields (from new to old), we use the following coefficients, which are the entries of the Jacobian matrix (=forward transform, because covector basis components act contravariant)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLbJFfUKzvDo"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_137.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP5zUYGD1Mmi"
      },
      "source": [
        "**Summary of all transformations (between 2 basis of covector fields, for example between Cartesian and polar coordinate system):**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_138.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JX8syZ0xpwT"
      },
      "source": [
        "https://www.youtube.com/watch?v=4doR1XCXzKU&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRa8wC482caL"
      },
      "source": [
        "##### **Integration with Differential Forms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qbv54XyvNf3u"
      },
      "source": [
        "* With the following interpretation of differential forms we can create the integration and it doesn't depend on coordinate systms at all\n",
        "\n",
        "* Also we **just need start point and end point** and count the number of pierced covector components instead of computing the integral at each point on the line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csUdCGmrOU_D"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_147.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2frufUJPvvb"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_149.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p2OXzQuPhSy"
      },
      "source": [
        "Since the covector fields and the paths are the same in both following cases, the result of the integral which is negative 4, is also the same in both cases:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6-Qxt65PNpV"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_148.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULhEP5GBQVeM"
      },
      "source": [
        "> **Covector fields are invariant of the choice of coordinates. Covector field components depend on the choice if coordinate.*And that's why when we change the variable in an integral we still get the same answer.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dylyiDr82fAh"
      },
      "source": [
        "https://www.youtube.com/watch?v=kyzSofggsqg&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97_2iyEaH_Ur"
      },
      "source": [
        "https://www.youtube.com/watch?v=PzrGGbX-_54&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56qtcwg5IAo2"
      },
      "source": [
        "##### **Metric Tensor to compute arc length of a curve in Flat & Curved Space**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4uxma59K9mz"
      },
      "source": [
        "**In Flat Space**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVcqlsicTpFU"
      },
      "source": [
        "So in summary the equation for calculating the arc length of a curve is an integral that depends on the magnitude of the curves tangent vectors $\\left\\|\\frac{d \\vec{R}}{d \\lambda}\\right\\|$ in this:\n",
        "\n",
        "> $\\operatorname{arclength}=\\int\\left\\|\\frac{d \\vec{R}}{d \\lambda}\\right\\| d \\lambda$\n",
        "\n",
        "And to calculate the squared magnitude of the tangent vectors we need to use the dot product\n",
        "\n",
        "> $\\left\\|\\frac{d \\vec{R}}{d \\lambda}\\right\\|^{2}=\\frac{d \\vec{R}}{d \\lambda} \\cdot \\frac{d \\vec{R}}{d \\lambda}$\n",
        "\n",
        "And we end up with this equation in Cartesian coordinates:\n",
        "\n",
        "> $=\\frac{d c^{i}}{d \\lambda} \\frac{d c^{j}}{d \\lambda}\\left(\\frac{\\partial \\vec{R}}{\\partial c^{i}} \\cdot \\frac{\\partial \\vec{R}}{\\partial c^{j}}\\right)$\n",
        "\n",
        "And this equation in polar coordinates:\n",
        "\n",
        "> $=\\frac{d p^{i}}{d \\lambda} \\frac{d p^{j}}{d \\lambda}\\left(\\frac{\\partial \\vec{R}}{\\partial p^{i}} \\cdot \\frac{\\partial \\vec{R}}{\\partial p^{j}}\\right)$\n",
        "\n",
        "And the basis vector dot products $\\left(\\frac{\\partial \\vec{R}}{\\partial c^{i}} \\cdot \\frac{\\partial \\vec{R}}{\\partial c^{j}}\\right)$ and $\\left(\\frac{\\partial \\vec{R}}{\\partial p^{i}} \\cdot \\frac{\\partial \\vec{R}}{\\partial p j}\\right)$ give us the components of the metric tensor:\n",
        "\n",
        "> $=\\frac{d c^{i}}{d \\lambda} \\frac{d c^{j}}{d \\lambda} g_{i j}$\n",
        "\n",
        "> $=\\frac{d p^{i}}{d \\lambda} \\frac{d p^{j}}{d \\lambda} \\widetilde{g_{i j}}$\n",
        "\n",
        "\n",
        "**So the key to getting the arc length of a curve is the tangent vector magnitude. And the key to getting the tangent vector magnitude is the metric tensor components $g_{i j}$ and $\\widetilde{g_{i j}}$**. \n",
        "\n",
        "And remember: the metric tensor is a (0,2) tensor because its components obey 2 covariant transformation laws:\n",
        "\n",
        "> $\\begin{aligned} \\widetilde{g_{i j}} &=\\frac{\\partial c^{k}}{\\partial p^{i}} \\frac{\\partial c^{l}}{\\partial p^{j}} g_{k l} \\\\ g_{k l} &=\\frac{\\partial p^{i}}{\\partial c^{k}} \\frac{\\partial p^{j}}{\\partial c^{l}} \\widetilde{g_{i j}} \\end{aligned}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJhzyopCRcpY"
      },
      "source": [
        "In flat space there is only 1 metric tensor with which you can calculate the arc length of any curve as long as we can do this integral."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OanUBO2gQpre"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_150.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEyO9rlkIMO1"
      },
      "source": [
        "https://www.youtube.com/watch?v=BbQmTmSzUCI&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=13"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikzbu9etK69-"
      },
      "source": [
        "**In Curved Space**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vduae7TNLCQ6"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_142.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtIqF9otUKcN"
      },
      "source": [
        "In curved space: Vector field: vector changes from point to point. Covector fields have covectors that change from point to point. And now a metric tensor field involves a different metric tensor being placed everywhere in space that change from point to point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJOXS0zNUHv8"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_151.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVD5ECk6UyAp"
      },
      "source": [
        "Every curved space has its own metric tensor field that gives you the rules for measuring distance on it:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHlpysnyU9p8"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_152.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smxFOwPMLX5r"
      },
      "source": [
        "Metric tensors:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGRj9JUmLvRD"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_143.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwhkLmE6MLC4"
      },
      "source": [
        "Simplify them:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suMk4ZEwMX9h"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_144.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfV4j9QwMZeU"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_145.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BczFLxe1MiRs"
      },
      "source": [
        "For the intrinsic view (left side only) we can remove $R$ vectors completely and treat derivative operators themselves as the vectors:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79cCI6smNACE"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_146.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2UfZTNyIPrG"
      },
      "source": [
        "https://www.youtube.com/watch?v=SmjbpIgVKFs&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adud22GGIRQb"
      },
      "source": [
        "##### **Gradient $\\nabla$ vs $d$ operator (exterior derivative/differential)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXnfJkJmIcqS"
      },
      "source": [
        "https://www.youtube.com/watch?v=nJpONHO_X5o&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixJeOlq8IgFI"
      },
      "source": [
        "https://www.youtube.com/watch?v=Do5vzLJRWRE&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcJcHsPjI8Jn"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_139.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvXamrXPJNod"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_141.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYNetSMmIhcB"
      },
      "source": [
        "##### **Geodesics and Christoffel Symbols (extrinsic geometry) & Second Fundamental Form**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN8xiSNU9o5Y"
      },
      "source": [
        "> **A geodesic is the straightest possible path on a curved surface / in curved space** (note: not the shortest path necessarily!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQYVNBKRImT1"
      },
      "source": [
        "https://www.youtube.com/watch?v=1CuTNveXJRc&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=17"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7XXgjUKVz_A"
      },
      "source": [
        "> **Geodesic curve: In curved space, a straight path has zero tangential acceleration when we travel along it at constant speed.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUAcA2YqVaMr"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_153.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwiT3eI3zKtl"
      },
      "source": [
        "**Tangential component of the acceleration vector has to be zero**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfB4ZsrSy-RY"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_154.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0E1CnOc0zJS"
      },
      "source": [
        "To get acceleration vector, we take the derivative of the velocity vector (like second derivative of position)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkp0iSyb2d50"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_155.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou0AZpi02fFD"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_156.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6mWZr1S6vPV"
      },
      "source": [
        "How to get the second fundamental form:\n",
        "\n",
        "> $\\frac{\\partial^{2} \\vec{R}}{\\partial u^{i} \\partial u^{j}} \\cdot \\hat{n}=L_{i j}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg4z_yjH2rTn"
      },
      "source": [
        "**And the Christoffel symbols (capital gamma) give us the tangential components of the second order derivative vector = acceleration (at a point in a curved space), so how much of each of the basis vectors $u$ we need:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73yk-dme2gJW"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_157.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaoRvkrz5cej"
      },
      "source": [
        "We can make our Gamma component even easier using Einstein notation:\n",
        "\n",
        "> $\\frac{\\partial^{2} \\vec{R}}{\\partial u^{i} \\partial u^{j}}=\\Gamma_{i j}^{k} \\frac{\\partial \\vec{R}}{\\partial u^{k}}+L_{i j} \\hat{n}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLDnJJ0n6Eo5"
      },
      "source": [
        "How to get the Christoffel:\n",
        "\n",
        "> $\\Gamma_{i j}^{m}=\\frac{\\partial^{2} \\vec{R}}{\\partial u^{i} \\partial u^{j}} \\cdot \\frac{\\partial \\vec{R}}{\\partial u^{l}} \\mathfrak{g}^{l m}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP5XsK4e35av"
      },
      "source": [
        "Here is our 3D vector bases with the surface normal vector and two tangent vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLb-7YWO38Bf"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_158.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r5Lm6if3Z82"
      },
      "source": [
        "This is the second order derivative $\\frac{\\partial^{2} \\vec{R}}{\\partial u^{i} \\partial u^{j}}$ that we want (lila vector) and the three component $\\Gamma_{i j}^{1}$, $\\Gamma_{i j}^{2}$ and $L_{i j}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM--IsMe3d7B"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_159.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hkfnz7C9KCgQ"
      },
      "source": [
        "> **The equator is a geodesic curve, and the shortest one at any given point there:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peRTz1coKBCx"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_178.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGWuoX4pJ74-"
      },
      "source": [
        "This makes sense: if we travel around thr equator our acceleration vector points directly inward towards the center of the circle which is also the center of the sphere (because remember: **To compute geodesic curves, we need to find curves where the acceleration vector is normal to the surface.**):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI5OrcJjKQTu"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_179.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQS6b7eZ7Vdw"
      },
      "source": [
        "**So setting the following framed part on the bottom to zero is an effective way to detect whether a curve is a geodesic**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3tyO0rz7rRy"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_160.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8-IPVoq8h7a"
      },
      "source": [
        "**So setting the tangential component equal to zero gives us the geodesic equation. Any curve parameterized by lambda which satisfies this geodesic equation is in fact a geodesic curve. And geodesic curves are the paths that beams of light will follow in curved spacetime.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXCxLt0l8Bj3"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_161.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_zDFUhx9BjY"
      },
      "source": [
        "To summarize this all:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wkijdv29FJ5"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_162.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th2re53x-OIS"
      },
      "source": [
        "**And summary of how to proceed when computing the geodesic:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1tP_arf-Q6_"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_163.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klVh1jXP9U_t"
      },
      "source": [
        "Further information: https://www.youtube.com/watch?v=8sVDceI70HM&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-spr-G2USI37"
      },
      "source": [
        "##### **Covariant Derivative: Flat Space Definition**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPHfXZVrSLXh"
      },
      "source": [
        "https://www.youtube.com/watch?v=U5iMpOn5IHw&t=4s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjxVhFlLScig"
      },
      "source": [
        "> **Covariant Derivative = understanding the rate of change of vector (tensor) fields that takes changing basis vectors into account**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVGYOMq-SqKp"
      },
      "source": [
        "Challenge: different sources define covariant derivative in different ways."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTyfzP67TFBa"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_164.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD3j9AnhTv0s"
      },
      "source": [
        "**Reminder about Cartesian and polar coordinate system: the basis vectors in each system are equivalent to the partial derivatives of a position vector $R$ with respect to the coordinate variables (x and y, and r and $\\theta$) (see blue and orange box)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh0NGf8FTZFT"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_165.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7SunUSMUW7E"
      },
      "source": [
        "**Another reminder: x and y are for example replaced with $c^1$ and $c^2$ because it simplifies the equation (which makes it easier to write expressions with summations, here $c^i$). And when $i$ is on top and bottom we can even leave the summation $\\sum_i$ sign away according to Einstein**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJlW-3sEUhXK"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_166.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-6nZhB8Ya7R"
      },
      "source": [
        "**Consider following two examples:**\n",
        "\n",
        "* the in the first picture the vector field is constant everywhere. hence the deriative of this vector field is zero in the x and y direction.\n",
        "\n",
        "* in the second image below the vector field is moving. So the vector field is NOT zero in the $r$ and $\\theta$ direction. The components 2 and 1 are constant, but the basis vectors $e_r$ and $e_\\theta$ are changing from point to point that causes the vectors in the vector field to change length and direction. \n",
        "\n",
        "> **Constant Components ≠ Constant Vector Field**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f09TbXoHYXdd"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_167.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWfjGcHcYZc5"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_168.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDuLSJUwaISG"
      },
      "source": [
        "**Summary for calculating covariant derivative in flat space**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1OWjN1gaMlS"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_169.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ych-SJZzao2R"
      },
      "source": [
        "**Replace with Christoffel symbol, it goes to zero in cartesian flat space**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR6Ao6TUam6R"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_170.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9boDSglaycD"
      },
      "source": [
        "**In polar coordinates, some Christoffel symbols go to zero, others not:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QedF1D--a2rF"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_171.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSpwUJjTbdqR"
      },
      "source": [
        "**Final summary for covariant derivatives in flat space:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq-oPGCtbcwI"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_172.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYEN7gQIyVkn"
      },
      "source": [
        "##### **Extension: Covariant Derivative (Component Definition)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh-G0Q5kyGv3"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_173.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLDlxhsO0IJH"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_174.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfMzb6fr2bjX"
      },
      "source": [
        "> **The covariant derivative of a vector field is a new vector field that depends on the direction of differentiation.** \n",
        "\n",
        "So if we look at the two main directions in 2D space, we get actually 2 vector fields for the covariant derivative (one for each covariant derivative in the main coordinate directions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn3TkpAu2gtN"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_175.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLAB_kIB4ppO"
      },
      "source": [
        "* And we can write the components of these vector fields using the semicolon notation „;i“ \n",
        "* These would be the $k$‘s components of the covariant derivative vector field we get when differentiating in the direction of the i’th cooedinate.\n",
        "* And to convert between these components we use one covariant transformation rule with the Jacobian matrix $\\frac{\\partial c^{a}}{\\partial p^{i}}$  and one contravariant transformation rule with the inverse Jacobian matrix $\\frac{\\partial p^{k}}{\\partial c^{b}}$\n",
        "* So the covariant derivative components with the semicolon form a (1,1) tensor: one contravatiant transformation rule and one covariant transformation rule (where the inverse Jacobian transforms the contravariant index, and the Jacobian transforms the covariant index.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OU9YxyC2_TJ"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_177.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saqBBtf76glo"
      },
      "source": [
        "> **Christoffel Symbols are NOT Tensors**\n",
        "\n",
        "> $\\widetilde{\\Gamma_{i j}^{k}}=\\frac{\\partial p^{k}}{\\partial c^{b}}\\left[\\frac{\\partial c^{a}}{\\partial p^{i}} \\frac{\\partial c^{r}}{\\partial p^{j}} \\Gamma_{a r}^{b}+\\frac{\\partial^{2} c^{b}}{\\partial p^{i} \\partial p^{j}}\\right]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0DbmdY474cs"
      },
      "source": [
        "##### **Covariant Derivative: Curved Space Definition (extrinsic) and Parallel Transport**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSmI7cdt7_5u"
      },
      "source": [
        "https://youtu.be/Af9JUiQtV1k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLSSaOUGi9O7"
      },
      "source": [
        "> **Objective: Dealing with rates of change of vector fields on curved surfaces**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Oq9jRaflm6g"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_180.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbhwPKrfmiQ1"
      },
      "source": [
        "On a flat surface it's clear: the first vector field is constant (because all arrows have the same length and direction) and the covariant derivative is zero, and the second vector field  is not constant and the covariant derivative is non-zero (because the arrows change length and direction):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cH_Pg9JmK7d"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_181.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmaYZvmknEPN"
      },
      "source": [
        "When we say it's constant, we mean all vectors are the same. But how we know they are the same? We can out them on top:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MUejLyDmL5D"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_182.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTuumeu3nJuS"
      },
      "source": [
        "That unfortunately doesn't work on curved space: arrows that seems to point in the same direction (red and blue) are in fact pointing in different directions. The two blue arrows are the same, but look like pinting into different directions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLlJMuLbmMwQ"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_183.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG4M5nuUnaMc"
      },
      "source": [
        "You could paralle transport them, but there is one issue: if you transport them around, they end up showing in different directions. This means:\n",
        "\n",
        "> **A constant vector field on a curved surface makes no sense from the perspective of someone living on it.**\n",
        "\n",
        "We need to live with it, that it changes direction afetr a parallel transport. It's the best we can do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOSYtYJFmOGx"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_184.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPQjO9i0kBaO"
      },
      "source": [
        "Look at this nice visualisation of parallel transport: https://math.stackexchange.com/questions/2215084/parallel-transport-equations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmzX4BacnuXQ"
      },
      "source": [
        "Paralle transport means we keep the arrow as constant as possible. But how do we describe this constance mathematically? Look at the green arrows that show the difference: \n",
        "\n",
        "> **When we paralle transport a vector, the rate of change of that vector always points at a direction that;s normal to a surface.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_DpA51omPCk"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_185.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hyjWIuCoqpT"
      },
      "source": [
        "Recall: normal vectors are perpendicular to the tangent plan pointing outward to the surface:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTa3SZBlmQF-"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_186.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkAJOwrVpSx8"
      },
      "source": [
        "> **So if we parallel transport this vector along a path on the curved surface, we end up with a vector field defined at every point on the curve.**\n",
        "\n",
        "The rate of change if the vector field will always be some normal vector $\\vec{n}$ pointing out of the surface. \n",
        "\n",
        "> $\\frac{d \\vec{v}}{d \\lambda}=\\vec{n}$\n",
        "\n",
        "In other words: if we take the rate of change of the vector field and subtract the normal part we'll always get zero:\n",
        "\n",
        "> $\\frac{d \\vec{v}}{d \\lambda}-\\vec{n}=\\overrightarrow{0}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_LkkvU_pgk7"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_187.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kJ5vEm3qzEG"
      },
      "source": [
        "And here come the covariant derivatives:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyeyzrxAqs6E"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_188.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5XTuLWwrHvj"
      },
      "source": [
        "**Example: Curve parameter $\\lambda$ (in yellow) with a vector field (lila) along this curve, and we want to find the rate of change of the vector as we travel along the curve.** \n",
        "\n",
        "> $\\nabla_{\\vec{w}} \\vec{v}=\\overrightarrow{0}$ means the vector $\\vec{v}$ is parallel transported in the direction $\\vec{W}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAfyCawarwk2"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_189.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQEEBIgDuAPT"
      },
      "source": [
        "Following image show how we did it so far:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A73e9JNattIc"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_191.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwtHP1V4uFKL"
      },
      "source": [
        "Now with the exception that we change v and w with u1 and u2, where u1 and u2 mean different things:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOF278-ftuIg"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_192.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m2JwWhNtDAh"
      },
      "source": [
        "U1 curves: Longitude from north to south\n",
        "\n",
        "U2 curves: Latitudes from west to east"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKKS2_uitv-8"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_193.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lJ0XUoIumUn"
      },
      "source": [
        "The tangent basis vectors of the sphere are given by these two partial derivatives of a position vector (which are sometimes written as the basis vectors e1 and e2). Where the e1 basis vectors are just the tangent vectors along the u1 curves, and the e2 basis vectors are just the tangent vectors along the u2 curves:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luyYlAB6spCt"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_190.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12GXUqhuCux3"
      },
      "source": [
        "> **The covariant derivative is just the ordinary derivative with the normal component substratected!**\n",
        "\n",
        "> $\\nabla \\frac{\\partial}{\\partial u^{i}} \\vec{v}=\\frac{\\partial \\vec{v}}{\\partial u^{i}}-\\vec{n}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efy-04p1DH4d"
      },
      "source": [
        "**Let's work on an example: Let's take some tangent vector field V on the sphere in the direction of the $u^I$ coordinate (and we deal with a vector field where all the vectors are tangent to the surface -0 happens in physics very often).**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as4-LdboJMde"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_197.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PCxTpWjHm4S"
      },
      "source": [
        "* Since the $\\vec{v}$ are always tangent to the sphere, we can always expand it as a linear combination of the $e_1$ and $e_2$ basis tangent vectors\n",
        "\n",
        "* Product rule: so this derivative $\\left[\\begin{array}{l}v^{j} \\overrightarrow{e_{j}}\\end{array}\\right]$ becomes two terms: $\\frac{\\partial v^{j}}{\\partial u^{i}} \\overrightarrow{e_{j}}+v j \\frac{\\partial \\overrightarrow{e_{j}}}{\\partial u^{i}}$\n",
        "\n",
        "\t* $\\frac{\\partial v^{j}}{\\partial u^{i}} \\overrightarrow{e_{j}}$  where we differentiate the vector field components\n",
        "\n",
        "\t* $v j \\frac{\\partial \\overrightarrow{e_{j}}}{\\partial u^{i}}$ where we differentiate the basis vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEzPosYhIklh"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_196.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5zsZmYkIqUy"
      },
      "source": [
        "And we can rewrite it as following:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IL5jAbHEmQq"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_195.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG4tPgcPLQti"
      },
      "source": [
        "How to get the Christoffel is in the video, here the formula: \n",
        "\n",
        "> $\\Gamma_{i j}^{k}=\\left(\\frac{\\partial \\overrightarrow{e_{j}}}{\\partial u^{i}} \\cdot \\overrightarrow{e_{l}}\\right) \\mathfrak{g}^{l k}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EmMUeIxE8iZ"
      },
      "source": [
        "**See the following image:** \n",
        "\n",
        "* 3D basis consisting of 2 tangent basis vectors $e$ and the normal vector $n$ to the surface\n",
        "\n",
        "* Lila is the derivative vector that we want to  expand in a linear combination\n",
        "\n",
        "* the two Christoffel symbols tell us how much of the $e_1$ and $e_2$ basis vectors we need\n",
        "\n",
        "* the second fundamental form $L_{ij}$ tells us how much of the normal vector we need"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xfbwehVE6j6"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_194.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xzzbf4AoKyuP"
      },
      "source": [
        "*How to get the details of the formula (the Christoffel elements for example) see the video!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6dlX3lYJr2_"
      },
      "source": [
        "**Summary** \n",
        "\n",
        "ps: The normal component $\\vec{n}$ is always zero in flat space!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_6qqcctKyRB"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_198.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1Zf-UHKPUCN"
      },
      "source": [
        "**Summary**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G4m2If7PSqQ"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_199.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhj2ieePzubb"
      },
      "source": [
        "##### **Covariant Derivative: Curved Space Definition (Intrinsic) and Geodesics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7CmJIC0zsq-"
      },
      "source": [
        "https://www.youtube.com/watch?v=EFKBp52LtDM&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=22"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D88KUEOMjNDI"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_200.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hv4BaWckaw6"
      },
      "source": [
        "We can't compute the Christoffel symbol like this anymore on instrinsic space, because we expanded the basis vectors and the basis vectors derivatives in terms of the x,y,z basis. And this let us compute the dot products to get the Christoffel.\n",
        "\n",
        "But now we have to pretend the x,y,z variables don't exist and we can only see the coordinate lines directly on the surface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q8suWTplRm1"
      },
      "source": [
        "**This is what we have to give up now on instrinsic space**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re7LMDbwlrw2"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_201.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT4VHQIXl3NI"
      },
      "source": [
        "We don't have an origin that we can use to extend position vectors from since space is curved. **So we can no longer think of basis vectors as derivatives of a position vector $R$. Instead in instrinsic geometry the basis vectors we are using are the partial derivative operators themselves (they point in a specific direction)** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maWzjdkhmjPT"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_202.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVh7600omy5g"
      },
      "source": [
        "> **And these new basis vectors live in the called \"Tangent Vector Space $T_pM$ at some given point p. And there is a different Tangent Vector Space at every point p on the surface:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ttxs39SnSKB"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_203.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrzHG_jJnchV"
      },
      "source": [
        "So how we calculate the covariant derivative for intrinsically curved space?\n",
        "\n",
        "* We can't use the normal vector anymore to substract it from the ordinary derivative ($\\nabla \\frac{\\partial}{\\partial u^{i}} \\vec{v}=\\frac{\\partial \\vec{v}}{\\partial u^{i}}-\\vec{n}$) so we get the covariant derivative. Because there is no outside anymore.\n",
        "\n",
        "* which means we ignore the normal part (just like in the flat space exmaple before)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WcJrjbHpAZA"
      },
      "source": [
        "So we can compute the formula for the covariant derivative but at the end we have the Christoffel symbols, that we cannot calculate with 'external' coordinates:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCo3O1yFo_cu"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_204.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8R8EF80pYMB"
      },
      "source": [
        "We can try to get the intrinsic Christoffel symbol (image below with the part on top). \n",
        "\n",
        "Remember: the metric tensor components are just the dot products of the basis vectors! And since the order of the dot product doesn't matter. So the metric tensor components are symmetric in the i and j indexes. Below you can see the derivative operator notation as well. \n",
        "\n",
        "But now: how do we compute the dot product, if we can't expand the vectors in the x,y,z space?\n",
        "\n",
        "**The metric tensor is so important, it needs to be given to us** (like with the Einstein field equation in General Relativity):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrWSlaR_pkUb"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_205.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee0FJ_Heq1P3"
      },
      "source": [
        "The derivative of the $e_j$ in the direction of the $u^I$ coordinate $\\frac{\\partial}{\\partial u^{i}}\\left(\\overrightarrow{e_{j}}\\right)$\n",
        ", really just means the second order derivative here: $\\frac{\\partial}{\\partial u^{i}}\\left(\\frac{\\partial}{\\partial u^{j}}\\right)$. \n",
        "\n",
        "And since the order of differentiation doesn't matter, it means that it's equivalent to $\\frac{\\partial}{\\partial u^{j}}\\left(\\overrightarrow{e_{i}}\\right)$.\n",
        "\n",
        "So the derivatives in the green boxes are equivalent to the ones in purple, it means that also the two Christoffel symbols are the same. \n",
        "\n",
        "The Christoffel symbols are symmetric in their lower indexes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y8TBYR_qzkh"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_206.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpIdj7nQsA02"
      },
      "source": [
        "So given that we can't solve the Christoffel symbols:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jgmdl4wsCQ1"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_207.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndukPv1Vs9lM"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_208.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le38rBzLtml9"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_209.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cExIrT-dt8Ze"
      },
      "source": [
        "and we get this as our new formula for the Christoffel symbol:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4WehrAit_iN"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_210.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5GlZ1IMuQY0"
      },
      "source": [
        "**This completes our definition of covariant derivative for any intrinsically curved space as long as we are given the metric tensor:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey2b-UwZuSZ7"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_211.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjOLNdsRzlz4"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_215.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyy1EiN0w6wp"
      },
      "source": [
        "**Finally new way to define Geodesics (instrinsic definition):**\n",
        "\n",
        "* Geodesic = straightest possible way between two points on a curved surface\n",
        "\n",
        "* Equal to paralle transporting a vector along itself: $\\nabla_{\\vec{w}} \\vec{v}=\\overrightarrow{0}$\n",
        "\n",
        "* And parallel transport means that the covariant derivative of a vector is equal to zero\n",
        "\n",
        "* So when we say a vector is parallel transported itself we mean that the vector that we're taking the covariant derivative of and the direction that we choose are the same. \n",
        "\n",
        "* So when the covariant derivative of a vector in the direction of itself is equal to zero, the resulting curve that we get is a **geodesic curve**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ohQlLpy2z5"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_212.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEs2mB6fzCYI"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_213.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhBmmN2GzXAA"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_214.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0fWrfCiRpNV"
      },
      "source": [
        "##### **Covariant Derivative: Abstract Definition**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4VGUwYbz_3_"
      },
      "source": [
        "https://www.youtube.com/watch?v=cEEahoUUGyc&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=23&t=422s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53iALgJV0IOL"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_164.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ryGjKvO06ad"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_216.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz9FWHE11bPL"
      },
      "source": [
        "Before we come to defining the abstract definition of covariant derivatives, let's remember the abstract definition of a vector space:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NinsLCzg1jbn"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_217.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9AKGjp512II"
      },
      "source": [
        "With that definition we can take an example of a vector, generalize it to a vector space with above rules, and out of those rules form other vector spaces that obey the same rules:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD9CaT0-2Dcj"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_219.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcgMkNyo2d1k"
      },
      "source": [
        "**Same is for covariant derivatives: we look at the properties and then check other examples of covariant derivatives that follow the same rules**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03erQtEf2w-m"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_220.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sabhiduy3DcQ"
      },
      "source": [
        "**Property: Linearity (Addition and Scaling). Covariant derivative is also additive for the vector field part**:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJQZCLSY3OTf"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_222.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBnjbXcT4qy3"
      },
      "source": [
        "So a covariant derivative is an operator with 2 input slots: one for direction and one for input field. Output is rate of change, which is a new field.\n",
        "\n",
        "> **Sometimes the covariant derivative operator is also called \"Connection\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpuqtcKM5KH8"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_223.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh5W8LG-5xHu"
      },
      "source": [
        "**What parallel transport is doing it is connecting the tangent vector space at red point p to tangent vector space at blue point q. So parallel transport gives us a way to map vectors from TpS to TqS. And since parallel transport is defined using the covariant derivative, it's really the covariant derivative that's providing the connection between the tangent spaces in this curved space**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKcN1qUD6dt4"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_224.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7QXNLfZ7JZf"
      },
      "source": [
        "Christoffel symbols are **not unique**, which results that there are many ways to define these connection coefficients. \n",
        "\n",
        "But there is ba way to get a unique solution for the Christoffel symbols. And that's by introducing 2 new properties called the **Torsian free** property and the **Metric Compatibility** property. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgzSwy607YDw"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_225.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu01__-XPZEG"
      },
      "source": [
        "**First new property: Torsion Free (with Lie Bracket)**\n",
        "\n",
        "The torsion free property says that the covariant derivative of each $e^j$ in the $e^i$ direction is the same as the covariant derivative of $e^i$ in the $e^j$  direction (i'ts inspired by the rule of traditional derivatives where the order of partial differention doesn't matter).\n",
        "\n",
        "With it's expansion incl. the Christoffel symbol on the right side: The torsion free property says that are free to swap the lower indexes of the Christoffel symbols without changing their value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8j4zArZPR4j"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_226.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShyxqkGiPgZK"
      },
      "source": [
        "**Second new property: Metric Compatibility**\n",
        "\n",
        "The covariant derivative of the dot product is zero, or in another words: the dot product stays constant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weWI_3U5RmWq"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_227.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZz7uDHkRnR8"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_228.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtEyAB9mSDwM"
      },
      "source": [
        "**Visualized this means following two things:**\n",
        "\n",
        "1. when two vectors are parallel transported along a curve (see below), their angle stays constant (because rate of change of their dot product is zero)\n",
        "\n",
        "2. and also the length of the vector stays constant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK9sdD4lSCL4"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_229.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cV_YsLiuS7oI"
      },
      "source": [
        "**And both together allows us to solve for the Christoffel symbols:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUL8rlNlTGfx"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_230.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMa7-PcNTNGF"
      },
      "source": [
        "> **This means we found one particular version of the covariant derivative.**\n",
        "\n",
        "> **and the covariant derivative that use these Christoffel symbols is called Levi-Civita Connection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKha5G4KTzEj"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_231.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FwXxSWfT2Sb"
      },
      "source": [
        "**And this result is stated by the Fundamental Theorem of Riemannian Geometry**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87oeiDAwUR6j"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_232.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNmDhDCaUgAd"
      },
      "source": [
        "**But there are also other covariant derivatives, for example one where all the Christoffel symnols are zero: $\\widetilde{\\Gamma_{i j}^{k}}=0$**. This is not a  Levi-Civita Connection!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ROrQ6mjVOWc"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_233.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTZLMnjUA7Uc"
      },
      "source": [
        "Both perform parallel transport, but the result is different: end up connecting tangent spaces on the spheres in different ways."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdENOy1iBQ8w"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_234.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_rrwkhnBb-8"
      },
      "source": [
        "We can define all sorts of connections, but the  Levi-Civita Connection is the most important one!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfF3ORx1Bq5W"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_235.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2TNpWHeB68C"
      },
      "source": [
        "> **Now let's move on to extending covariant derivatives to all tensor fields**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfvs7HZECHv1"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_236.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd8HaqiiDcts"
      },
      "source": [
        "> **The covariant derivative of a covector field has basically the same formula as the covariant derivative of a vector field except we have a negative sign:**\n",
        "\n",
        "(ps: here lambda comes from this: $\\nabla_{\\partial_{i}} \\epsilon^{j}=\\Lambda_{i k}^{j} \\epsilon^{k}$. We use the lambda coefficients who play a similar role as the Christoffel symbols, but for covectors instead (to expand the covariant derivative of the basis covectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEOugon3DeaJ"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_237.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPf2WLpDEyto"
      },
      "source": [
        "**And for Covariant Derivatives of a Tensor:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myOakXrSExq2"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_238.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnsjeCW8HSWQ"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_239.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9yyOPqvIRgt"
      },
      "source": [
        "> The metric compatibility property means that the covariant derivative of the metric tensor in any direction is always going to be zero. Another way of writing is on the bottom where we leave out the direction of the covariant derivative because the covariant derivative of the metric tensor is zero in every direction:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_eRca2ZHuxq"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_240.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGWptaqbIoOL"
      },
      "source": [
        "> **SUMMARY**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX5YNrwMIqKu"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_241.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A03smo9SI1L2"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_242.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkKuGspvJioN"
      },
      "source": [
        "Using the torsion free and metric compatibility properties we can derive a unique set of Christoffel symbols which define a unique covariant derivative called the Levi-Civita-connection (which is called Fundamental Theorem of Riemannian geometry):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09QM1UoNJu3N"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_244.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DlM_NYVJHeA"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_243.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GMDGuHNJ_R3"
      },
      "source": [
        "Levi-Civita-connection is the most important one. But we can also define different covariant derivatives by picking different Christoffel symbols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyOio38VKIS7"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_245.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejxNRu4UKa5e"
      },
      "source": [
        "And different covariant derivatives will result in different instructions for parallel transports:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaGJda6IKouq"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_246.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVw0NmmrLT9G"
      },
      "source": [
        "**We have shown the covariant derivative of a (in the image below):**\n",
        "\n",
        "> scalar field\n",
        "\n",
        "> vector field\n",
        "\n",
        "> covector field\n",
        "\n",
        "> metric tensor field\n",
        "\n",
        "> and we can use this property on the bottom in a black box to get the covariant derivative of any general tensor field"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cfxjJzpK3oZ"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_247.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toPWFrsBORvV"
      },
      "source": [
        "##### **Lie Bracket (Commutator in Flow Curves)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VusQwcJwb--3"
      },
      "source": [
        "https://www.youtube.com/watch?v=SfOiOPuS2_U&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=24&t=69s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMz6CrFUcc-U"
      },
      "source": [
        "**Flow Curve (Integral Curve)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJXS5mXtdfz6"
      },
      "source": [
        "In the following image:\n",
        "\n",
        "* The partial derivatives of the coordinate variables are basically like basis vectors (framed in blue)\n",
        "\n",
        "* the derivatives with respect to lambda (framed in red) are the components "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RtdjJ9fdJmu"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_258.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzOb3SSmkZfK"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_271.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDdMinWxdolg"
      },
      "source": [
        "Looking at the components we have 2 partial derivatives to solve with initial position we can choose (here (0,0):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpBOc27fc24d"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_257.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4107ivfcnGK"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_256.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__AVL_FHYs15"
      },
      "source": [
        "**Lie Bracket (the commutator of 2 vector fields $\\vec{u}$ & $\\vec{v}$)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeY7efEoYrfx"
      },
      "source": [
        "* Lie Bracket takes 2 vector fields and tells us if the rectangle of flow curves closes properly\n",
        "\n",
        "* Flow curves do not close properly if Lie bracket is non zero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mZufMmZcJKg"
      },
      "source": [
        "Task of calculating Lie bracket:\n",
        "\n",
        "1. Find change of $\\vec{u}$ in the direction of $\\vec{v}$\n",
        "\n",
        "2. Find change of $\\vec{v}$ in the direction of $\\vec{u}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6qXxGq_ajDC"
      },
      "source": [
        "> **Lie Bracket (Commutator) = measures how much vector field flow curves fail to close.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdzzKm7vegPV"
      },
      "source": [
        "> $[\\vec{u}, \\vec{v}]=\\vec{u}(\\vec{v})-\\vec{v}(\\vec{u})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAS5bQjrZatX"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_248.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWkrTH1hbKpl"
      },
      "source": [
        "In this example the two derivatives are not the same:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtDiTaaMbYst"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_253.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Frg3TK37a1Xd"
      },
      "source": [
        "...and this has geometrical meaning: the separation vector is the $e_y$ vector measured by the Lie bracket:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzxD5C5Ba2_7"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_252.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRF-e9lfZbA0"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_249.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLD7WsNNbvN4"
      },
      "source": [
        "We can also calculate the result:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7lBvsz-bx8_"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_255.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuAibkYabw1P"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_254.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSGa0zUuZumj"
      },
      "source": [
        "**Coordinate lines are just flow curves along basis vectors**\n",
        "\n",
        "Because coordinate curves always close without a curve, so Lie bracket always has to be zero for them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD4DgFX9ZvC3"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_250.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0lz7cnvaLMF"
      },
      "source": [
        "Like in polar coordinates the Lie bracket goes to zero where it's not totally obvious:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OY01lGMaLsC"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_251.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bAiY-Ljk4aH"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_272.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiLlXNGqlMJZ"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_273.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FMTtABgb7i6"
      },
      "source": [
        "##### **Torsion Tensor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaRHhYwxcABo"
      },
      "source": [
        "https://www.youtube.com/watch?v=SfOiOPuS2_U&list=PLJHszsWbB6hpk5h8lSfBkVrpjsqvUGTCx&index=24&t=69s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2xp1gzwe0JL"
      },
      "source": [
        "To define the Torsion Tensor we need to define the derivative of V in the direction of u and the derivative of U in the direction of V:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4AGrxZjeO2Z"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_259.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn-If37Cfnd5"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_260.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icGAmeK6foj_"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_261.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6Ki9FSlf4Qa"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_262.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCrTiRQxgMTZ"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_263.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJqxzlihgT6Q"
      },
      "source": [
        "Different definition of the connection coefficients will give us different instructions for performing parallel transport:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaX7Usr0gjwr"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_264.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI16kwW7g0Og"
      },
      "source": [
        "**Difference between Lie Bracket and Torsion tensor**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8omppJtOg4xh"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_264.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBJs7LZqhXBa"
      },
      "source": [
        "In the following image:\n",
        "\n",
        "* With proper parallel transport the covariant derivative is zero. \n",
        "\n",
        "* The arrows framed in red (the difference vectors) tell us how much the vector fields u and v deviate aways from parallel transport\n",
        "\n",
        "* So when the covariant derivative are non zero it means that the vector fields are deviating away from the dashed lines (parallel transport)\n",
        "\n",
        "* And remember: the separation between the tips of the vectors is the Lie bracket (in black)\n",
        "\n",
        "* The blue separation vector: this is the torsion tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Tc0ZKERhahc"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_265.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6FxOg6niLxz"
      },
      "source": [
        "If it's zero, then the vectors match, and we get a completely closed 4 sided shape:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pqj4D5SeiuIX"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_267.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0nTMzYRidzK"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_266.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ba3Ikgqi0P2"
      },
      "source": [
        "And how do we get the Torsion tensor components?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd57zfHrjL4x"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_268.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETqxx6Z_jl31"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_269.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaKkCe35juSK"
      },
      "source": [
        "So when a connection is Torsion free, we mean that we can swap the lower indexes of the connection coefficients:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU-K7mWSkFGq"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_270.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXhpli7klhP5"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_274.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkAdYJWPlvoz"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/tensor_275.png)"
      ]
    }
  ]
}