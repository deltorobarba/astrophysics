{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spaces.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qYW5u_0Oi7l5",
        "tQRaw6wfNOpR",
        "bt1ud5jc4UUB",
        "1k-wmgpkP8lv",
        "SHXnaFUeQBL6",
        "xU32us9ZQouN",
        "nwOcv6tLTkxl",
        "2KesWFfaTmuu",
        "iVuurd_GTqys",
        "bHE_58TCK5mP",
        "zI1toWT6AZet",
        "7oaxbCPG0PUB",
        "g2VqyxFgIRLt",
        "dfT-0QZZm8VW",
        "hDrk6VPEtOU2",
        "rXt3-c9EhID7",
        "gD8HZ1Q1giLt",
        "15ok6ieBgYkv",
        "BmZFI8hdhy1u",
        "-59nC3Yih3Gm",
        "DhwL39dIoAR5",
        "HN2Dn3F0iAzD",
        "TSRliOMMiHC-",
        "CXBpZ1M8zNi5",
        "cxTnwP8u5YD2",
        "oAf4sna4hQMg",
        "deNJWcC3hUSX",
        "jtmj4FOHq6ht",
        "ZT8FPvZ3hi1N",
        "rYLc2b-qsm8N",
        "lydB1B0oq-VJ",
        "O1hoL_o6Zh_H",
        "mISGLzNFniMx",
        "HbZOslj1eRla",
        "fFzrPn6HYJt9",
        "rZlz94XCYE8Q",
        "ug1sNzCsdMGh",
        "D1mImehPm69J",
        "X1tE5YQRlE54",
        "iFheGZB5u2fk"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deltorobarba/machinelearning/blob/master/spaces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Aoj2PpxvDQV",
        "colab_type": "text"
      },
      "source": [
        "# **Spaces**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U5_6xH7tAQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ostHcxEvNZ5r",
        "colab_type": "text"
      },
      "source": [
        "![Normed Vector Space](https://upload.wikimedia.org/wikipedia/en/7/74/Mathematical_Spaces.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkYQO6LE2R1b",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Space_(mathematics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYW5u_0Oi7l5",
        "colab_type": "text"
      },
      "source": [
        "## **Inner product space (Prähilbertraum bzw. Skalarprodukt)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtcOpkYQjFKx",
        "colab_type": "text"
      },
      "source": [
        "* Vektorraum, auf dem ein inneres Produkt definiert ist\n",
        "\n",
        "* In linear algebra, an inner product space is a vector space with an additional structure called an inner product. This additional structure associates each pair of vectors in the space with a scalar quantity known as the inner product of the vectors\n",
        "\n",
        "* Geometric interpretation of the angle between two vectors defined using an inner product. Inner products allow the rigorous introduction of intuitive geometrical notions such as the length of a vector or the angle between two vectors. They also provide the means of defining orthogonality between vectors (**zero inner product**). \n",
        "\n",
        "* Inner product spaces generalize Euclidean spaces (in which the inner product is the **dot product**, also known as the scalar product) to vector spaces of any (possibly infinite) dimension, and are studied in functional analysis. \n",
        "\n",
        "* An inner product **naturally induces an associated norm**, (|x| and |y| are the norms of x and y, in the picture) thus an inner product space is also a normed vector space. A complete space with an inner product is called a Hilbert space. \n",
        "\n",
        "* An (incomplete) space with an inner product is called a pre-Hilbert space, since its completion with respect to the norm induced by the inner product is a Hilbert space. Inner product spaces over the field of complex numbers are sometimes referred to as unitary spaces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1QQh9gFi-WB",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Inner_product_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQRaw6wfNOpR",
        "colab_type": "text"
      },
      "source": [
        "## **Normed Vector Spaces (Vektornormen)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt1ud5jc4UUB",
        "colab_type": "text"
      },
      "source": [
        "### **Overview & p-Norm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3Ek_c4p1Ldn",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Norm_(Mathematik)#Vektornormen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y23TBwgQXJuY",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Norm_(mathematics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUGbZ9CqNRHn",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Normed_vector_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-LnUvriVm4a",
        "colab_type": "text"
      },
      "source": [
        "A normed vector space or normed space is a vector space over the real or complex numbers, on which a norm is defined. A norm is the formalization and the generalization to real vector spaces of the intuitive notion of \"length\" in the real world. A norm is a real-valued function defined on the vector space that is commonly denoted x ↦ ‖ x ‖, and has the **following properties**:\n",
        "\n",
        "1. It is **nonnegative**, that is for every vector x, one has ‖x‖ ≥ 0.\n",
        "\n",
        "2. It is **positive on nonzero vectors**, that is, ‖x‖ = 0 ⟺ x = 0.\n",
        "\n",
        "3. For every vector x, and every **scalar α**, one has ‖ α x ‖ = | α | ‖ x ‖.\n",
        "\n",
        "4. The **triangle inequality** holds; that is, for every vectors x and y, one has ‖ x+y ‖ ≤ ‖ x ‖ + ‖ y ‖.\n",
        "\n",
        "A norm induces a distance by the formula d (x,y) = ‖ y-x ‖.\n",
        "\n",
        "Therefore, a normed vector space is a metric space, and thus a topological vector space. An [inner product space](https://en.m.wikipedia.org/wiki/Inner_product_space) is a normed space, where the norm of a vector is the square root of the inner product of the vector by itself. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFf8p5SVJn2V",
        "colab_type": "text"
      },
      "source": [
        "**P-Norm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUReq39VTPQM",
        "colab_type": "text"
      },
      "source": [
        "For all p ≥ 1, the p-norms and maximum norm as defined above indeed satisfy the properties of a \"length function\" (or norm), which are that:\n",
        "\n",
        "1. only the zero vector has zero length,\n",
        "\n",
        "2. lhe length of the vector is positive homogeneous with respect to multiplication by a scalar (positive homogeneity), and\n",
        "\n",
        "3. the length of the sum of two vectors is no larger than the sum of lengths of the vectors (triangle inequality).\n",
        "\n",
        "Abstractly speaking, this means that **Rn together with the p-norm is a Banach space**. This Banach space is the Lp-space over Rn. \n",
        "\n",
        "**Any normed vector space is a metric space** by defining d(x, y) = ‖ y - x ‖, see also metrics on vector spaces. (If such a space is complete, we call it a Banach space.) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeSMyh0-FK2I",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/P-Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQlHR9FKyapX",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Norm_(Mathematik)#Vektornormen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMXH_RxXRDkr",
        "colab_type": "text"
      },
      "source": [
        "![alternativer Text](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Vector-p-Norms_qtl1.svg/480px-Vector-p-Norms_qtl1.svg.png)\n",
        "\n",
        "*Illustrations of unit circles (see also superellipse) in different p-norms (every vector from the origin to the unit circle has a length of one, the length being calculated with length-formula of the corresponding p).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k-wmgpkP8lv",
        "colab_type": "text"
      },
      "source": [
        "### **Von der p1-Norm (Summennorm) zur L1 Norm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqKbtCMiB61r",
        "colab_type": "text"
      },
      "source": [
        "> $\\|x\\|_{1}=\\sum_{i=1}^{n}\\left|x_{i}\\right|$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4dl2ZASP_kc",
        "colab_type": "text"
      },
      "source": [
        "* Summennorm, Betragssummennorm oder 1-Norm ist in der Mathematik eine **Vektornorm**. Sie ist definiert als die Summe der Beträge der Vektorkomponenten und ist eine spezielle p-Norm für die Wahl von p=1.\n",
        "\n",
        "* Die Einheitssphäre der reellen Summennorm ist ein Kreuzpolytop mit minimalem Volumen über alle p-Normen. **Daher ergibt die Summennorm für einen gegebenen Vektor den größten Wert aller p-Normen**. Die von der Summennorm abgeleitete Metrik ist die Manhattan-Metrik.\n",
        "\n",
        "* Die Summennorm ist im Gegensatz zur euklidischen Norm (2-Norm) **nicht von einem Skalarprodukt induziert.**\n",
        "\n",
        "* Die von der Summennorm abgeleitete Metrik ist die **Manhattan-Metrik** oder Taxi-Metrik.\n",
        "\n",
        "* Die von der Summennorm [induzierte Matrixnorm](https://de.m.wikipedia.org/wiki/Natürliche_Matrixnorm) ist die [Spaltensummennorm](https://de.m.wikipedia.org/wiki/Spaltensummennorm).\n",
        "\n",
        "* Techniques which use an L1 penalty, like LASSO, encourage solutions where many parameters are zero. \n",
        "\n",
        "* The Manhattan norm gives rise to the Manhattan distance, where the distance between any two points, or vectors, is the sum of the differences between corresponding coordinates.\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Taxicab_geometry\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Lasso_(statistics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v2FUVhEND-B",
        "colab_type": "text"
      },
      "source": [
        "![alternativer Text](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Euclid_Octahedron_3.svg/240px-Euclid_Octahedron_3.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69gd5KqRNHzc",
        "colab_type": "text"
      },
      "source": [
        "*Der Einheitssphäre der Summennorm ist in drei Dimensionen ein Oktaeder*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4MyKCvxQKCl",
        "colab_type": "text"
      },
      "source": [
        "**Beispiel (reeller Vektor):**\n",
        "\n",
        "Die Summennorm des reellen Vektors $x=(3,-2,6) \\in \\mathbb{R}^{3}$ ist gegeben als\n",
        "\n",
        "$\\|x\\|_{1}=|3|+|-2|+|6|=11$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ozv2tPIOKQr",
        "colab_type": "text"
      },
      "source": [
        "**Die wichtigsten Verallgemeinerungen der Summen-Norm:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T_E2UeNOdOW",
        "colab_type": "text"
      },
      "source": [
        "$\\ell^{1}-$ Norm (**Folgenraum**)\n",
        "\n",
        "* Die $\\ell^{1}$ -Norm ist die Verallgemeinerung der Summennorm auf den Folgenraum $\\ell^{1}$ der **betragsweise summierbaren Folgen** $\\left(a_{n}\\right)_{n} \\in \\mathbb{K}^{N} .$ Hierbei wird lediglich **die endliche Summe durch eine unendliche ersetzt** und die $\\ell^{\\text {t }}$ -Norm ist dann gegeben als\n",
        "\n",
        "> $\\left\\|\\left(a_{n}\\right)\\right\\|_{\\ell^{1}}=\\sum_{n=1}^{\\infty}\\left|a_{n}\\right|$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpfpULLzPBb8",
        "colab_type": "text"
      },
      "source": [
        "$L^{1}$ -Norm (**Funktionenraum**)\n",
        "\n",
        "* Weiter kann die Summennorm auf den Funktionenraum $L^{1}(\\Omega)$ der auf einer Menge $\\Omega$ betragsweise integrierbaren Funktionen verallgemeinert werden, was in zwei Schritten geschieht. Zunächst wird die $\\mathcal{L}^{1}$ Norm einer betragsweise Lebesgue-integrierbaren Funktion $f: \\Omega \\rightarrow \\mathbb{K}$ als\n",
        "\n",
        "> $\\|f\\|_{\\mathcal{L}^{1}(\\Omega)}=\\int_{\\Omega}|f(x)| d x$\n",
        "\n",
        "* definiert, wobei im Vergleich zur $\\ell^{1}$ -Norm lediglich die Summe durch ein Integral ersetzt wurde. Dies ist zunächst nur eine Halbnorm, da nicht nur die Nullfunktion, sondern auch alle Funktionen, die sich nur an einer Menge mit Lebesgue-Maß Null von der Nullfunktion unterscheiden, zu Null integriert werden. \n",
        "\n",
        "* Daher betrachtet man die Menge der Äquivalenzklassen von Funktionen $[f] \\in L^{1}(\\Omega)$, die fast überall gleich sind, und erhält auf diesem $L^{1}$ -Raum die $L^{1}$ -Norm durch\n",
        "\n",
        "> $\\|[f]\\|_{L^{1}(\\Omega)}=\\|f\\|_{\\mathcal{L}^{1}(\\Omega)}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQOMzI3RBEU2",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Summennorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHXnaFUeQBL6",
        "colab_type": "text"
      },
      "source": [
        "### **Von der p2-Norm (Euklidische Norm) zur L2 Norm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3yL08xkQGbj",
        "colab_type": "text"
      },
      "source": [
        "* Die euklidische Norm, Standardnorm oder 2-Norm ist eine in der Mathematik häufig verwendete Vektornorm. Im zwei- und dreidimensionalen euklidischen Raum entspricht die euklidische Norm der anschaulichen Länge oder dem Betrag eines Vektors und kann mit dem Satz des Pythagoras berechnet werden. \n",
        "\n",
        "* Die euklidische Norm ist eine **von einem Skalarprodukt induzierte Norm** (im Ggs zur p1-Norm)\n",
        "\n",
        "* Techniques which use an L2 penalty, like ridge regression, encourage solutions where most parameter values are small.\n",
        "\n",
        "* Exkurs: [Elastic Net](https://en.m.wikipedia.org/wiki/Elastic_net_regularization) regularization uses a penalty term that is a combination of the L1 norm and the L2 norm of the parameter vector.\n",
        "\n",
        "* The length of a vector x = (x1, x2, ..., xn) in the n-dimensional real vector space Rn is usually given by the **Euclidean norm**:\n",
        "\n",
        "> $\\|x\\|_{2}=\\left(x_{1}^{2}+x_{2}^{2}+\\cdots+x_{n}^{2}\\right)^{1 / 2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSVhAEwxB_hW",
        "colab_type": "text"
      },
      "source": [
        "> $\\|x\\|_{2}=\\sqrt{\\sum_{i=1}^{n}\\left|x_{i}\\right|^{2}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4u2sHf11vdf",
        "colab_type": "text"
      },
      "source": [
        "Die Euclidean Norm besitzt als eine von einem Skalarprodukt [induzierte Norm](https://de.m.wikipedia.org/wiki/Skalarproduktnorm) **neben den [drei Normaxiomen](https://de.m.wikipedia.org/wiki/Norm_(Mathematik)#Definition) eine Reihe weiterer Eigenschaften**:\n",
        "\n",
        "* die Gültigkeit der [Cauchy-Schwarz-Ungleichung](https://de.m.wikipedia.org/wiki/Cauchy-Schwarzsche_Ungleichung)\n",
        "* der [Parallelogrammgleichung](https://de.m.wikipedia.org/wiki/Parallelogrammgleichung)\n",
        "* sowie eine Invarianz unter unitären Transformationen (Die euklidische Norm ändert sich also unter unitären Transformationen nicht. Für reelle Vektoren sind solche Transformationen beispielsweise Drehungen des Vektors um den Nullpunkt. Diese Eigenschaft wird zum Beispiel bei der numerischen Lösung linearer Ausgleichsprobleme über die **Methode der kleinsten Quadrate mittels QR-Zerlegungen genutzt**.)\n",
        "\n",
        "Für orthogonale Vektoren erfüllt die euklidische Norm selbst eine allgemeinere Form des Satzes des Pythagoras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbyU4goN2tS_",
        "colab_type": "text"
      },
      "source": [
        "* Von der euklidischen Norm werden Begriffe wie der euklidische Abstand und die euklidische Topologie abgeleitet. \n",
        "\n",
        "* Sie **kann auf unendlichdimensionale Vektorräume verallgemeinert werden**, beispielsweise auf **Folgenräume durch die ℓ2-Norm** und auf **Funktionenräume durch die [L2-Norm](https://de.m.wikipedia.org/wiki/Lp-Raum#Der_Hilbertraum_L2) (Hilbertraum L2)**.\n",
        "\n",
        "* Sieht man eine Matrix mit reellen oder komplexen Einträgen als entsprechend langen Vektor an, so kann die euklidische Norm auch für Matrizen definiert werden und heißt dann [**Frobeniusnorm**](https://de.m.wikipedia.org/wiki/Frobeniusnorm). Die euklidische Norm kann auch auf unendlichdimensionale Vektorräume über den reellen oder komplexen Zahlen verallgemeinert werden und hat dann zum Teil eigene Namen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6av7qXO0_rf",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Euklidische_Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewZ2VXEjESYA",
        "colab_type": "text"
      },
      "source": [
        "See also: https://en.m.wikipedia.org/wiki/Non-Euclidean_geometry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_25QFIacwWAd",
        "colab_type": "text"
      },
      "source": [
        "**Euklidische Norm und Einheitskreis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQufRHsJx6AL",
        "colab_type": "text"
      },
      "source": [
        "Für einen gegebenen Vektor $x_{0} \\in V$ und einen Skalar $r \\in \\mathbb{K}$ mit $r>0$ heißt die Menge\n",
        "\n",
        "> $\\left\\{x \\in V:\\left\\|x-x_{0}\\right\\|<r\\right\\}$\n",
        "\n",
        "bzw. $\\quad\\left\\{x \\in V:\\left\\|x-x_{0}\\right\\| \\leq r\\right\\}$\n",
        "offene bzw. abgeschlossene Normkugel und die Menge\n",
        "\n",
        "> $\\left\\{x \\in V:\\left\\|x-x_{0}\\right\\|=r\\right\\}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC_GtMMcwt1e",
        "colab_type": "text"
      },
      "source": [
        "Normsphäre um $x_{0}$ mit Radius $r .$ \n",
        "\n",
        "* Die Begriffe $_{n}$ Kugel\" bzw. Sphäre\" sind dabei sehr allgemein zu sehen - beispielsweise kann eine Normkugel auch Ecken und Kanten besitzen - und **fallen nur im Spezialfall der euklidischen Vektornorm mit dem aus der Geometrie bekannten Kugelbegriff zusammen**. \n",
        "\n",
        "* Wählt man in der Definition $x_{0}=0$ und $r=1,$ so nennt man die entstehenden Mengen Einheitskugel bzw. Einheitssphäre. \n",
        "\n",
        "* Jede Normkugel bzw. Normsphäre entsteht aus der entsprechenden Einheitskugel\n",
        "bzw. Einheitssphäre durch Skalierung mit dem Faktor $r$ und Translation um den Vektor $x_{0}$. \n",
        "\n",
        "* Ein Vektor der Einheitssphäre heißt Einheitsvektor; zu jedem Vektor $x \\neq 0$ erhält man durch Normierung $\\frac{x}{\\|x\\|}$ den zugehörigen Einheitsvektor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf2dS7qAxmxu",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Norm_(Mathematik)#Normkugeln"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsTnah-j5XPW",
        "colab_type": "text"
      },
      "source": [
        "**Die wichtigsten Verallgemeinerungen der Euklidischen Norm:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRax0LTq5PpT",
        "colab_type": "text"
      },
      "source": [
        "$\\ell^{2}-$ Norm (**Folgenraum**)\n",
        "\n",
        "* Die $\\ell^{2}-$ Norm ist die Verallgemeinerung der euklidischen Norm auf den [Folgenraum](https://de.m.wikipedia.org/wiki/Folgenraum) $\\ell^{2}$ der quadratisch summierbaren Folgen $\\left(a_{n}\\right)_{n} \\in \\mathbb{K}^{\\mathrm{N}} .$ Hierbei wird lediglich die endliche Summe durch eine unendliche ersetzt und die $\\ell^{2}$ -Norm ist dann gegeben als\n",
        "\n",
        "> $\\left\\|\\left(a_{n}\\right)\\right\\|_{\\ell^{2}}=\\left(\\sum_{n=1}^{\\infty}\\left|a_{n}\\right|^{2}\\right)^{1 / 2}$\n",
        "\n",
        "* Die ℓ-p -Räume sind ein Spezialfall der allgemeineren Lp-Räume, wenn man das Zählmaß auf dem Raum N betrachtet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Peq0MPwB6WKs",
        "colab_type": "text"
      },
      "source": [
        "$L^{2}-$ Norm (**Funktionenraum**)\n",
        "\n",
        "* Weiter kann die euklidische Norm auf den [Funktionenraum](https://de.m.wikipedia.org/wiki/Funktionenraum) $L^{2}(\\Omega)$ der auf einer Menge $\\Omega$ quadratisch integrierbaren Funktionen verallgemeinert werden, was in zwei Schritten geschieht. Zunächst wird die $\\mathcal{L}^{2}$ Norm einer quadratisch Lebesgue-integrierbaren Funktion $f: \\Omega \\rightarrow \\mathbb{K}$ als\n",
        "\n",
        "> $\\|f\\|_{\\mathcal{L}^{2}(\\Omega)}=\\left(\\int_{\\Omega}|f(x)|^{2} d x\\right)^{1 / 2}$\n",
        "\n",
        "* definiert, wobei im Vergleich zur $\\ell^{2}$ -Norm lediglich die Summe durch ein Integral ersetzt wurde. Dies ist zunächst nur eine Halbnorm, da nicht nur die Nullfunktion, sondern auch alle Funktionen, die sich nur an einer Menge mit Lebesgue-Maß Null von der Nullfunktion unterscheiden, zu Null integriert werden. Daher betrachtet man die Menge der Äquivalenzklassen von Funktionen $[f] \\in L^{2}(\\Omega),$ die fast überall gleich sind, und erhält auf diesem $L^{2}$ -Raum die $L^{2}$ -Norm durch\n",
        "\n",
        "> $\\|[f]\\|_{L^{2}(\\Omega)}=\\|f\\|_{\\mathcal{L}^{2}(\\Omega)}$\n",
        "\n",
        "* Der Raum $L^{2}(\\Omega)$ ist ein Hilbertraum mit dem Skalarprodukt zweier Funktionen\n",
        "\n",
        "> $\\langle f, g\\rangle_{L_{2}(\\Omega)}=\\int_{\\Omega} \\overline{f(x)} \\cdot g(x) d x$\n",
        "\n",
        "* Er lässt sich von dem Lebesgue-Maß auch auf allgemeine Maße verallgemeinern."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU32us9ZQouN",
        "colab_type": "text"
      },
      "source": [
        "### **Von der p∞-Norm (Maximumsnorm) zu L∞-Norm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwOcv6tLTkxl",
        "colab_type": "text"
      },
      "source": [
        "#### **Maximumsnorm (Unendlich-Norm)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwl3Y9ZtTUDj",
        "colab_type": "text"
      },
      "source": [
        "* Die Maximumsnorm, Maximumnorm oder Tschebyschew-Norm ist eine spezielle Norm für Funktionen beziehungsweise für Vektoren oder Matrizen. Sie ist ein Spezialfall der [Supremumsnorm](https://de.m.wikipedia.org/wiki/Supremumsnorm).\n",
        "\n",
        "* Anschaulich gesprochen ist der aus der Maximumsnorm abgeleitete Abstand immer dann relevant, wenn man sich in einem mehrdimensionalen Raum in alle Dimensionen gleichzeitig und unabhängig voneinander gleich schnell bewegen kann. (zB Rochade beim Schach)\n",
        "\n",
        "* Allgemeiner kann die Maximumsnorm benutzt werden, um zu bestimmen, wie schnell man sich in einem zwei- oder dreidimensionalen Raum bewegen kann, wenn angenommen wird, dass die Bewegungen in x-, y- (und z-)Richtung unabhängig, gleichzeitig und mit gleicher Geschwindigkeit erfolgen.\n",
        "\n",
        "\n",
        "* Noch allgemeiner kann man ein System betrachten, dessen Zustand durch n unabhängige Parameter bestimmt wird. An allen Parametern können gleichzeitig und ohne gegenseitige Beeinflussung Änderungen vorgenommen werden. Dann „misst“ die Maximumsnorm in Rn die Zeit, die man benötigt, um das System von einem Zustand in einen anderen zu überführen. Voraussetzung hierfür ist allerdings, dass man die Parameter so normiert hat, dass gleiche Abstände zwischen den Werten auch gleichen Änderungszeiten entsprechen. Andernfalls müsste man eine gewichtete Version der Maximumsnorm verwenden, die die unterschiedlichen Änderungsgeschwindigkeiten der Parameter berücksichtigt.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3CFgJHJVYZO",
        "colab_type": "text"
      },
      "source": [
        "Für einen Vektor $x=\\left(x_{1}, \\ldots, x_{n}\\right) \\in \\mathbb{R}^{n}$ nennt man\n",
        "\n",
        "> $\\|x\\|_{\\max }:=\\max \\left(\\left|x_{1}\\right|, \\ldots,\\left|x_{n}\\right|\\right)$ \n",
        "\n",
        "die Maximumsnorm von x. \n",
        "\n",
        "* Die **Maximumsnorm kann auch als Grenzfall der $p$ -Normen** $\\|x\\|_{p}:=\\left(\\sum_{i=1}^{n}\\left|x_{i}\\right|^{p}\\right)^{1 / p}$ aufgefasst werden. Lässt man $p$ gegen unendlich laufen, so erhält man\n",
        "aus der $p$ -Norm die Maximumsnorm.\n",
        "\n",
        "* **Aus diesem Grund wird die Maximumsnorm für Vektoren auch als $\\infty$ -Norm (Unendlich-Norm) bezeichnet.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar8qLNfnCi8_",
        "colab_type": "text"
      },
      "source": [
        "Für den Grenzwert p→ ∞ erhält man die ∞-Norm (Unendlich-Norm), die oft auch zu den p-Normen gezählt wird. Sie wird auch **Maximumsnorm oder Tschebyschow-Norm** genannt und ist definiert durch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioRBlq9ICFf6",
        "colab_type": "text"
      },
      "source": [
        "> $\\|x\\|_{\\infty}=\\max _{i=1, \\ldots, n}\\left|x_{i}\\right|$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hpZp3hzCXku",
        "colab_type": "text"
      },
      "source": [
        "Dass die Maximumsnorm tatsächlich als Grenzwert der $p$ -Normen für $p \\rightarrow \\infty$ entsteht, folgt für $x \\neq 0$\n",
        "aus\n",
        "\n",
        "> $\\lim _{p \\rightarrow \\infty}\\|x\\|_{p}=\\lim _{p \\rightarrow \\infty}\\left(\\sum_{i=1}^{n}\\left|x_{i}\\right|^{p}\\right)^{1 / p}=\\|x\\|_{\\infty} \\cdot \\lim _{p \\rightarrow \\infty}\\left(\\sum_{i=1}^{n}\\left(\\frac{\\left|x_{i}\\right|}{\\|x\\|_{\\infty}}\\right)^{p}\\right)^{1 / p}=\\|x\\|_{\\infty} \\cdot \\lim _{p \\rightarrow \\infty} S^{1 / p}=\\|x\\|_{\\infty}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIA4-xLTSKoB",
        "colab_type": "text"
      },
      "source": [
        "* For a real number p ≥ 1, the p-norm or Lp-norm of x is defined by\n",
        "\n",
        "> $\\|x\\|_{p}=\\left(\\left|x_{1}\\right|^{p}+\\left|x_{2}\\right|^{p}+\\cdots+\\left|x_{n}\\right|^{p}\\right)^{1 / p}$\n",
        "\n",
        "* The absolute value bars are unnecessary when p is a rational number and, in reduced form, has an even numerator.\n",
        "\n",
        "* The L∞-norm or maximum norm (or uniform norm) is the limit of the Lp-norms for p → ∞. It turns out that this limit is equivalent to the following definition:\n",
        "\n",
        "> $\\|x\\|_{\\infty}=\\max \\left\\{\\left|x_{1}\\right|,\\left|x_{2}\\right|, \\ldots,\\left|x_{n}\\right|\\right\\}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbrnlkWOBNEE",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Maximumsnorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KesWFfaTmuu",
        "colab_type": "text"
      },
      "source": [
        "#### **Supremumsnorm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0mN6eYZT6rC",
        "colab_type": "text"
      },
      "source": [
        "* Im Gegensatz zur Maximumsnorm wird die Supremumsnorm $\\|f\\|_{\\text {sup }}:=\\sup _{t \\in X}|f(t)|$ nicht für stetige, sondern für beschränkte Funktionen $f$ definiert. \n",
        "\n",
        "* In diesem Fall ist es nicht notwendig, dass $X$ kompakt ist; $X$ kann eine beliebige Menge sein. Da stetige Funktionen auf kompakten Räumen beschränkt sind, ist die Maximumsnorm ein Spezialfall der Supremumsnorm.\n",
        "\n",
        "* Die Supremumsnorm (auch Unendlich-Norm genannt) ist in der Mathematik eine Norm auf dem Funktionenraum der beschränkten Funktionen. Im einfachsten Fall einer reell- oder komplexwertigen beschränkten Funktion ist die Supremumsnorm das Supremum der Beträge der Funktionswerte. Allgemeiner betrachtet man Funktionen, deren Zielmenge ein normierter Raum ist, und die Supremumsnorm ist dann das Supremum der Normen der Funktionswerte. Für stetige Funktionen auf einer kompakten Menge ist die Maximumsnorm ein wichtiger Spezialfall der Supremumsnorm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrQFlg6EWE26",
        "colab_type": "text"
      },
      "source": [
        "![alternativer Text](https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Graf_arctg.svg/260px-Graf_arctg.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9WdCWwbWJVf",
        "colab_type": "text"
      },
      "source": [
        "*Die Supremumsnorm der reellen Arkustangens-Funktion ist π/2. Auch wenn die Funktion diesen Wert betragsmäßig nirgendwo annimmt, so bildet er dennoch die kleinste obere Schranke.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIHI-jmUWwUr",
        "colab_type": "text"
      },
      "source": [
        "Supremumsnorm vs Maximumsnorm:\n",
        "\n",
        "* So ist etwa die **Supremumsnorm** der linearen Funktion $f(x)=x$ in diesem Intervall gleich $1 .$ Die Funktion nimmt diesen Wert zwar innerhalb des Intervalls nicht an, kommt inm jedoch beliebig nahe. \n",
        "\n",
        "* Wählt man stattdessen das abgeschlossene Einheitsintervall $M=[0,1]$, dann wird der Wert 1 angenommen und die Supremumsnorm entspricht der **Maximumsnorm**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDKcUEhwTZKC",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Supremumsnorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3OOjvbpXuEt",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Wesentliches_Supremum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVuurd_GTqys",
        "colab_type": "text"
      },
      "source": [
        "#### **L-Infinity**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4x8mIupEplw",
        "colab_type": "text"
      },
      "source": [
        "* The vector space ℓ∞ is a **sequence space** (Folgenraum) whose elements are the bounded sequences. The vector space operations, addition and scalar multiplication, are applied coordinate by coordinate. \n",
        "\n",
        "* L∞ is a **function space** (Funktionenraum). Its elements are the essentially bounded measurable functions. More precisely, L∞ is defined based on an underlying measure space, (S, Σ, μ). Start with the set of all measurable functions from S to R which are essentially bounded, i.e. bounded up to a set of measure zero. Two such functions are identified if they are equal almost everywhere. Denote the resulting set by L∞(S, μ)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIMWHQgyXYiA",
        "colab_type": "text"
      },
      "source": [
        "* $\\ell^{\\infty},$ the (real or complex) vector space of bounded sequences with the **[supremum norm](https://de.m.wikipedia.org/wiki/Supremumsnorm)**, and $L^{\\infty}=L^{\\infty}(X, \\Sigma, \\mu)$, the vector space of essentially bounded measurable functions with the **[essential supremum norm](https://de.m.wikipedia.org/wiki/Wesentliches_Supremum)**, are two closely related Banach spaces. \n",
        "\n",
        "* In fact the former is a special case of the latter. As a Banach space they are the continuous dual of the Banach spaces $\\ell_{1}$ of absolutely summable sequences, and $L^{1}=L^{1}(X, \\Sigma, \\mu)$ of absolutely integrable measurable functions (if the measure space fulfills the conditions of being localizable and therefore\n",
        "semifinite). \n",
        "\n",
        "* Pointwise multiplication gives them the structure of a Banach algebra, and in fact they are the standard examples of abelian Von Neumann algebras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHSE1UbcYFEP",
        "colab_type": "text"
      },
      "source": [
        "**The sequence space (Folgenraum) is a special case of the function space (Funktionenraum): $\\ell_{\\infty}=L_{\\infty}(\\mathbb{N})$ where the natural numbers are equipped with the counting measure.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trPSIZzFS6uw",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/L-infinity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHE_58TCK5mP",
        "colab_type": "text"
      },
      "source": [
        "### **Von den L<sup>p</sup> Normen zu den L<sup>p</sup> Spaces**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYn1j_U9lfis",
        "colab_type": "text"
      },
      "source": [
        "Der **normierte Vektorraum** $L^{p}$ ist [vollständig](https://de.m.wikipedia.org/wiki/Vollständiger_Raum) und damit ein [Banachraum](https://de.m.wikipedia.org/wiki/Banachraum), die Norm $\\|\\cdot\\|_{L} p$ wird **$L^{p}$ Norm** genannt.\n",
        "\n",
        "Auch wenn man von sogenannten $L^{p}$ -Funktionen spricht, handelt es sich dabei um die gesamte Äquivalenzklasse einer klassischen Funktion. Allerdings liegen im Falle des Lebesgue-Maßes auf dem $\\mathbb{R}^{n}$ zwei verschiedene stetige Funktionen nie in der gleichen Äquivalenzklasse, so dass der $L^{p}$\n",
        "-Begriff eine natürliche Erweiterung des Begriffs stetiger Funktionen darstellt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S725bXUeKYmW",
        "colab_type": "text"
      },
      "source": [
        "* The Lp spaces are [function spaces](https://en.m.wikipedia.org/wiki/Function_space) defined using a natural **generalization of the p-norm for finite-dimensional vector spaces**. They are sometimes called **Lebesgue spaces**.\n",
        "\n",
        "* A normed vector space is automatically a metric space, by defining the metric in terms of the norm in the natural way. But a metric space may have no algebraic (vector) structure — i.e., it may not be a vector space — so the concept of a **metric space is a generalization of the concept of a normed vector space**.\n",
        "\n",
        "* Lp spaces form an important class of [Banach spaces](https://en.m.wikipedia.org/wiki/Banach_space) in functional analysis, and of topological vector spaces.\n",
        "\n",
        "* In statistics, measures of central tendency and statistical dispersion, such as the mean, median, and standard deviation, are defined in terms of Lp metrics, and measures of central tendency can be characterized as [solutions to variational problems](https://en.m.wikipedia.org/wiki/Central_tendency#Solutions_to_variational_problems)\n",
        "\n",
        "* An Lp space may be defined as a space of measurable functions for which the p-th power of the absolute value is Lebesgue integrable, where functions which agree almost everywhere are identified. \n",
        "\n",
        "* More generally, let 1 ≤ p < ∞ and (S, Σ, μ) be a [measure space](https://en.m.wikipedia.org/wiki/Measure_space). Consider the set of all measurable functions from S to C or R whose absolute value raised to the p-th power has a finite integral, or equivalently, that\n",
        "\n",
        "> $\\|f\\|_{p} \\equiv\\left(\\int_{S}|f|^{p} \\mathrm{d} \\mu\\right)^{1 / p}<\\infty$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdACuRMye29o",
        "colab_type": "text"
      },
      "source": [
        "The **space Lp for 0 < p < 1 is an [F-space](https://en.m.wikipedia.org/wiki/F-space)**: it admits a complete translation-invariant metric with respect to which the vector space operations are continuous. It is also locally bounded, much like the case p ≥ 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikJhQfzmlAP1",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Lp-Raum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI1toWT6AZet",
        "colab_type": "text"
      },
      "source": [
        "### **Exkurs: Sequence Space (Folgenraum) vs Function Space (Funktionenraum)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEBy-NHOAgJ_",
        "colab_type": "text"
      },
      "source": [
        "* Ein Folgenraum ist ein in der Mathematik betrachteter Vektorraum, dessen Elemente Zahlenfolgen sind. Viele in der Funktionalanalysis auftretende Vektorräume sind Folgenräume oder können durch solche repräsentiert werden. Zu den Beispielen zählen u. a. die wichtigen Räume wie ℓ∞ aller beschränkten Folgen oder c0 aller gegen 0 konvergenten Folgen.\n",
        "\n",
        "* **Werden Normen bzw. Systeme von Normen oder Halbnormen auf Folgenräumen definiert, erhält man normierte Räume bzw. lokalkonvexe Räume.**\n",
        "\n",
        "* A **sequence space** (Folgenraum) is a vector space whose elements are infinite sequences of real or complex numbers. \n",
        "\n",
        "* Equivalently, it is a **function space** (Funktionenraum) whose elements are functions from the natural numbers to the field K of real or complex numbers. \n",
        "\n",
        "* The set of all such functions is naturally identified with the set of all possible infinite sequences with elements in K, and can be turned into a vector space under the operations of pointwise addition of functions and pointwise scalar multiplication. All sequence spaces are linear subspaces of this space. Sequence spaces are typically equipped with a norm, or at least the structure of a topological vector space.\n",
        "\n",
        "* The **most important sequence spaces in analysis are the ℓp spaces**, consisting of the p-power summable sequences, with the p-norm. These are special cases of Lp spaces for the counting measure on the set of natural numbers. \n",
        "\n",
        "* Other important classes of sequences like convergent sequences or null sequences (Nullfolgen) form sequence spaces, respectively denoted c and c0, with the sup norm. Any sequence space can also be equipped with the topology of pointwise convergence, under which it becomes a special kind of Fréchet space called FK-space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O9pC39wDsQ4",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Folgenraum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bmbh-1CIDuKZ",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Funktionenraum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oaxbCPG0PUB",
        "colab_type": "text"
      },
      "source": [
        "### **Weitere Normen: Matrixnorm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_AGvxsw-HqD",
        "colab_type": "text"
      },
      "source": [
        "* Eine Matrixnorm ist in der Mathematik eine Norm auf dem Vektorraum der reellen oder komplexen Matrizen. \n",
        "\n",
        "* Neben den drei Normaxiomen Definitheit, absolute Homogenität und Subadditivität wird bei Matrixnormen teilweise die Submultiplikativität als vierte definierende Eigenschaft gefordert. Submultiplikative Matrixnormen besitzen einige nützliche Eigenschaften, so ist beispielsweise der Spektralradius einer quadratischen Matrix, also der Betrag des betragsgrößten Eigenwerts, niemals größer als ihre Matrixnorm.\n",
        "\n",
        "* Es gibt mehrere Möglichkeiten, Matrixnormen zu definieren, unter anderem direkt über eine Vektornorm, als Operatornorm oder über die Singulärwerte der Matrix. Matrixnormen werden insbesondere in der linearen Algebra und der numerischen Mathematik verwendet.\n",
        "\n",
        "Wichtige Matrixnormen:\n",
        "* Über Vektornormen definierte Matrixnormen\n",
        "* Über Operatornormen definierte Matrixnormen\n",
        "* Über Singulärwerte definierte Matrixnormen\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Matrixnorm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7u1GiAGVvzL",
        "colab_type": "text"
      },
      "source": [
        "## **Metric Spaces (Distances & Metrics)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVZMwFV4sD33",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Metrischer_Raum#Einordnung_in_die_Hierarchie_mathematischer_Strukturen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbxCak1TsHDa",
        "colab_type": "text"
      },
      "source": [
        "Metriken geben einem Raum eine globale und eine lokale mathematische Struktur. Die globale Struktur kommt in geometrischen Eigenschaften wie der Kongruenz von Figuren zum Ausdruck. Die lokale metrische Struktur, also die Definition kleiner Abstände, ermöglicht unter bestimmten zusätzlichen Voraussetzungen die Einführung von Differentialoperationen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2VqyxFgIRLt",
        "colab_type": "text"
      },
      "source": [
        "### **From Divergences to Metric Spaces**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfT-0QZZm8VW",
        "colab_type": "text"
      },
      "source": [
        "#### **Properties**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HScpxU3gCkB",
        "colab_type": "text"
      },
      "source": [
        "1. $d(x, y) \\geq 0 \\quad$ (**non-negativity**)\n",
        "\n",
        "2. $d(x, y)=0$ if and only if $x=y$ (**identity of indiscernibles**. Note that condition 1 and 2 together produce **positive definiteness**)\n",
        "\n",
        "3. $d(x, y)=d(y, x)$ (**symmetry**)\n",
        "\n",
        "4. $d(x, z) \\leq d(x, y)+d(y, z)$ (**subadditivity / triangle inequality**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGoqrlNKgEo8",
        "colab_type": "text"
      },
      "source": [
        "* **Divergence** fullfills property of positive definiteness (1 + 2)\n",
        "\n",
        "* **Distance** fullfills property of positive definiteness and symmetrie (1 + 2+ 3)\n",
        "\n",
        "* **Metric** fullfills property of positive definiteness, symmetrie and triangle inequality (1 + 2 + 3 + 4)\n",
        "\n",
        "* Metric Space: Together with the set, a metric makes up a metric space.\n",
        "\n",
        "* (*Jede Norm induziert eine Metrik, aber nicht jede Metrik wird durch eine Norm induziert*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbyK2erJfiMZ",
        "colab_type": "text"
      },
      "source": [
        "Given a set $X$ of points, a distance function on $X$ is a map $d: X \\times X \\rightarrow \\mathbb{R}_{+}$ that is symmetric, and satisfies $d(i, i)=0$ for all $i \\in X .$ \n",
        "\n",
        "* Eine Metrik (auch Abstandsfunktion) ist eine Funktion, die je zwei Elementen des Raums einen nicht negativen reellen Wert zuordnet, der als Abstand der beiden Elemente voneinander aufgefasst werden kann. \n",
        "\n",
        "* The metric is a function that defines a concept of distance between any two members of the set, which are usually called points. The metric satisfies a few simple properties.\n",
        "\n",
        "* Unter einem [metrischen Raum](https://de.m.wikipedia.org/wiki/Metrischer_Raum) (metric space) versteht man in der Mathematik eine Menge, auf der eine Metrik definiert ist. \n",
        "\n",
        "* A metric on a space induces topological properties like open and closed sets, which lead to the study of more abstract topological spaces. Der Begriff „topologischer Raum“ verallgemeinert den Begriff „metrischer Raum“: Jeder metrische Raum ist ein topologischer Raum mit der Topologie, die durch die Metrik induziert wird (siehe dazu [Umgebung](https://de.m.wikipedia.org/wiki/Umgebung_(Mathematik))). Jeder metrische Raum ist ein [Hausdorff-Raum](https://de.m.wikipedia.org/wiki/Hausdorff-Raum)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_8BD2qlqkKE",
        "colab_type": "text"
      },
      "source": [
        "Falls die Funktion d zusätzlich die Dreiecksungleichung erfüllt, ist sie eine Metrik. Häufig wird auch eine Metrik als Distanzfunktion bezeichnet.\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Distanzfunktion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1zsesz3sQZl",
        "colab_type": "text"
      },
      "source": [
        "Eine [Isometrie](https://de.m.wikipedia.org/wiki/Isometrie) ist eine Abbildung, die zwei metrische Räume aufeinander abbildet und dabei die Metrik – also die Abstände zwischen je zwei Punkten – erhält. ps: [Isometrische Isomorphie](https://de.m.wikipedia.org/wiki/Isometrische_Isomorphie) beschreibt in der Funktionalanalysis einen Zusammenhang zwischen zwei unterschiedlichen Räumen, die geometrisch identisch sind."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7d7_An6wMZW",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Continuous_function#Continuous_functions_between_metric_spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMMYN7ReV1TC",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Metric_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A0RiFz6sHZ-",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Distance#General_metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDrk6VPEtOU2",
        "colab_type": "text"
      },
      "source": [
        "#### **Exkurs: Norms vs Metrics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGuci0L-l6c3",
        "colab_type": "text"
      },
      "source": [
        "**Instead of distance between points, a norm gives us the length of a vector, as measured from the origin.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pdUxKjtgFkR",
        "colab_type": "text"
      },
      "source": [
        "Metrics and norms are related, and they can both convey a notion of distance.\n",
        "\n",
        "If we have a set 𝑋, then we say that the function  𝑑:𝑋×𝑋→ℝ≥0 is a metric on 𝑋 if it satisfies the following for all points  𝑥,𝑦,𝑧∈𝑋: \n",
        "\n",
        ">  𝑑(𝑥,𝑦)=0⟹𝑥=𝑦\n",
        "\n",
        "> 𝑑(𝑥,𝑦)=𝑑(𝑦,𝑥)\n",
        "\n",
        "> 𝑑(𝑥,𝑦)≤𝑑(𝑥,𝑧)+𝑑(𝑦,𝑧).\n",
        "\n",
        "* **We call the function 𝑑 a metric or distance function. (Without the triangle inequality it's just a distance, but not a metric!)**\n",
        "\n",
        "* What do these properties say though? First, if the distance between two points is 0, then they are actually the same point. Second, the distance doesn't change if you swap where you start and end. The third property is called the triangle inequality, and is motivated by the corresponding property for real numbers.\n",
        "\n",
        "* The **problem with a metric is that sometimes, they can be too general**.\n",
        "\n",
        "* For example, take  𝑋=ℚ  and let  𝑑(𝑥,𝑦)=0 if  𝑥=𝑦, and  𝑑(𝑥,𝑦)=1 if  𝑥≠𝑦. I'll let you check it is indeed a metric. This metric sucks. I mean, **it doesn't give you any geometrical interpretation of “distance”,** and our metric space (ℚ,𝑑) is very hard to visualize, even though ℚ is a nice and familiar set. On a graph (the combinatorial object) this metric may be useful, but I digress.\n",
        "\n",
        "* On the other hand, **a norm must be defined on a vector space**, which inherently have a lot of structure!\n",
        "\n",
        "* Let  𝑉 be a vector space over the field  𝑘. A norm is a function  ‖•‖:𝑉→ℝ≥0 that satsfies the following for all 𝜆∈𝑘 and 𝑥,𝑦∈𝑉:\n",
        "\n",
        "* ‖𝑥‖=0⟹𝑥=0\n",
        "* ‖𝜆𝑥‖=|𝜆|‖𝑥‖\n",
        "* ‖𝑥+𝑦‖≤‖𝑥‖+‖𝑦‖\n",
        " \n",
        "* <u>**Instead of distance between points, a norm gives us the length of a vector, as measured from the origin**</u>. Property 3 is also called the triangle inequality, but now it has a nice geometric interpretation (unlike in a general metric space). Also you can give necessary and sufficient conditions on when the triangle inequality is actually an equailty. Not so in a metric space.\n",
        "\n",
        "* It is easy to see that **a norm is a metric on  𝑉, because length is the same as “distance from 0.”** To check, simply replace  𝑥 by  𝑣−𝑤 in the definition of a norm and say  ‖𝑣−𝑤‖=𝑑(𝑣,𝑤). (Note that 𝑣−𝑤∈𝑉 because  𝑉 is a linear space, so we can take it's norm).\n",
        "\n",
        "* This does not hold conversely because we may not even have addition of elements in a general set  𝑋.\n",
        "\n",
        "* To sum up: **All norms are metrics, and normed spaces** (vector spaces with a norm) have a lot more structure than general metric spaces. Anything that holds in a metric space will also hold for a normed space. Metric spaces are more general, but can be ugly!\n",
        "\n",
        "[Source Quora](https://www.quora.com/What-is-the-difference-between-a-metric-and-a-norm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXt3-c9EhID7",
        "colab_type": "text"
      },
      "source": [
        "### **Divergences**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD8HZ1Q1giLt",
        "colab_type": "text"
      },
      "source": [
        "#### **Divergence & 'Statistical Distance'**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqH4VD9zgjtm",
        "colab_type": "text"
      },
      "source": [
        "In statistics and information geometry, divergence or a contrast function is a function which establishes the **\"distance\" of one probability distribution to the other** on a statistical manifold. In statistics, probability theory, and information theory, **a statistical distance** quantifies the distance between two statistical objects, which can be\n",
        "\n",
        "* two random variables, or \n",
        "* two probability distributions or \n",
        "* two samples, or \n",
        "* the distance can be between an individual sample point and a population or \n",
        "* a wider sample of points.\n",
        "\n",
        "A distance between populations can be interpreted as **measuring the distance between two probability distributions** and hence they are essentially measures of distances between probability measures. \n",
        "\n",
        "* Where statistical distance measures relate to the differences between random variables, these may have statistical dependence, and hence these distances are not directly related to measures of distances between probability measures. \n",
        "\n",
        "* Again, a measure of distance between random variables may **relate to the extent of dependence between them, rather than to their individual values.**\n",
        "\n",
        "**<u>Many statistical distances are not metrics</u>** (and some types are regerred to as divergence), because they lack one or more properties of proper metrics. For example, \n",
        "\n",
        "* [pseudometrics](https://en.m.wikipedia.org/wiki/Pseudometric_space) violate the \"positive definiteness\" (alternatively, \"identity of indescernibles\") property (1 & 2 above); \n",
        "\n",
        "* [quasimetrics](https://en.m.wikipedia.org/wiki/Metric_(mathematics)#Quasimetrics) violate the symmetry property (3); and semimetrics violate the triangle inequality (4). \n",
        "\n",
        "* Statistical distances that satisfy (1) and (2) are referred to as divergences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y2GffaHgpYZ",
        "colab_type": "text"
      },
      "source": [
        "* In statistics and information geometry, there are many kinds of statistical distances, notably divergences, especially Bregman divergences and f-divergences. These include and generalize many of the notions of \"difference between two probability distributions\", and allow them to be studied geometrically, as statistical manifolds. \n",
        "\n",
        "* The **most elementary** is the **squared Euclidean distance**, which forms the basis of least squares; this is the most basic Bregman divergence (-> is this a metric then ???)\n",
        "\n",
        "* The **most important** in information theory is the relative entropy (**Kullback–Leibler divergence**), which allows one to analogously study maximum likelihood estimation geometrically; this is the most basic f-divergence, and is also a Bregman divergence (and is the only divergence that is both). \n",
        "\n",
        "* Statistical manifolds corresponding to Bregman divergences are flat manifolds in the corresponding geometry, allowing an analog of the Pythagorean theorem (which is traditionally true for squared Euclidean distance) to be used for linear inverse problems in inference by optimization theory.\n",
        "\n",
        "* Other important statistical distances include the Mahalanobis distance, the energy distance, and many others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_6VnI9tgsJe",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Information_geometry\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Statistical_distance\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Divergence_(statistics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15ok6ieBgYkv",
        "colab_type": "text"
      },
      "source": [
        "#### **Meaning of 'no symmetry' in divergences**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFglF2QTgaEc",
        "colab_type": "text"
      },
      "source": [
        "* The Kullback-Leibler divergence is not symmetric. Roughly speaking, it's because you should think of the two arguments of the KL divergence as different kinds of things: the first argument is empirical data, and the second argument is a model you're comparing the data to. \n",
        "\n",
        "* Take a bunch of independent random variables $X_{1}, \\ldots, X_{n}$ whose possible values lie in a finite set.* Say these variables are identically distributed, with $\\operatorname{Pr}\\left(X_{i}=x\\right)=p_{x}$. Let $F_{n, x}$ be the number of variables whose values are equal to $x$. The list $F_{n}$ is a random variable, often called the \"empirical frequency distribution\" of the $X_{i} .$ What does $F_{n}$ look like when $n$ is very large?\n",
        "\n",
        "* More specifically, let's try to estimate the probabilities of the possible values of $F_{n} .$ since the set of possible values is different for different $n$, take a sequence of frequency distributions $f_{1}, f_{2}, f_{3}, \\ldots$ approaching a fixed frequency distribution $f$. It turns out $^{* *}$ that\n",
        "\n",
        "> $\\lim _{n \\rightarrow \\infty} \\frac{1}{n} \\ln \\operatorname{Pr}\\left(F_{n}=f_{n}\\right)=-\\mathrm{KL}(f, p)$ \n",
        "\n",
        "* In other words, the Kullback-Leibler divergence of $f$ from $p$ lets you estimate the probability of getting an empirical frequency distribution close to $f$ from a large number of independent random variables with distribution $p$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEE5LAAygcf-",
        "colab_type": "text"
      },
      "source": [
        "Excellent article \"Information Theory, Relative Entropy and Statistics,\" by [François Bavaud](https://link.springer.com/chapter/10.1007/978-3-642-00659-3_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1geLcP8Pgut9",
        "colab_type": "text"
      },
      "source": [
        "List of Distances Types\n",
        "\n",
        "'braycurtis': hdbscan.dist_metrics.BrayCurtisDistance\n",
        "\n",
        "'canberra': hdbscan.dist_metrics.CanberraDistance\n",
        "\n",
        "'chebyshev': hdbscan.dist_metrics.ChebyshevDistance\n",
        "\n",
        "'cityblock': hdbscan.dist_metrics.ManhattanDistance\n",
        "\n",
        "'dice': hdbscan.dist_metrics.DiceDistance\n",
        "\n",
        "'euclidean': hdbscan.dist_metrics.EuclideanDistance\n",
        "\n",
        "'hamming': hdbscan.dist_metrics.HammingDistance\n",
        "\n",
        "'haversine': hdbscan.dist_metrics.HaversineDistance\n",
        "\n",
        "'infinity': hdbscan.dist_metrics.ChebyshevDistance\n",
        "\n",
        "'jaccard': hdbscan.dist_metrics.JaccardDistance\n",
        "\n",
        "'kulsinski': hdbscan.dist_metrics.KulsinskiDistance\n",
        "\n",
        "'l1': hdbscan.dist_metrics.ManhattanDistance\n",
        "\n",
        "'l2': hdbscan.dist_metrics.EuclideanDistance\n",
        "\n",
        "'mahalanobis': hdbscan.dist_metrics.MahalanobisDistance\n",
        "\n",
        "'manhattan': hdbscan.dist_metrics.ManhattanDistance\n",
        "\n",
        "'matching': hdbscan.dist_metrics.MatchingDistance\n",
        "\n",
        "'minkowski': hdbscan.dist_metrics.MinkowskiDistance\n",
        "\n",
        "'p': hdbscan.dist_metrics.MinkowskiDistance\n",
        "\n",
        "'pyfunc': hdbscan.dist_metrics.PyFuncDistance\n",
        "\n",
        "'rogerstanimoto': hdbscan.dist_metrics.RogersTanimotoDistance\n",
        "\n",
        "'russellrao': hdbscan.dist_metrics.RussellRaoDistance\n",
        "\n",
        "'seuclidean': hdbscan.dist_metrics.SEuclideanDistance\n",
        "\n",
        "'sokalmichener': hdbscan.dist_metrics.SokalMichenerDistance\n",
        "\n",
        "'sokalsneath': hdbscan.dist_metrics.SokalSneathDistance\n",
        "\n",
        "'wminkowski': hdbscan.dist_metrics.WMinkowskiDistance\n",
        "\n",
        "https://hdbscan.readthedocs.io/en/latest/basic_hdbscan.html\n",
        "\n",
        "https://reference.wolfram.com/language/guide/DistanceAndSimilarityMeasures.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAdXAeihnHMA",
        "colab_type": "text"
      },
      "source": [
        "#### **Types of Divergences**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmZFI8hdhy1u",
        "colab_type": "text"
      },
      "source": [
        "##### **f-Divergence**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9smhem9wh0x8",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/F-divergence\n",
        "\n",
        "The Hellinger distance is a type of f-divergence\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Hellinger_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-59nC3Yih3Gm",
        "colab_type": "text"
      },
      "source": [
        "##### **Bregman Divergence**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXaFiel6h7Fl",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Bregman_divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnDfoUM_h5VG",
        "colab_type": "text"
      },
      "source": [
        "The squared Euclidean divergence is a Bregman divergence (corresponding to the function x<sup>2</sup>, but not an f-divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vvhq-zZ2h9Ae",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Euclidean_distance#Squared_Euclidean_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhwL39dIoAR5",
        "colab_type": "text"
      },
      "source": [
        "##### **Squared Euclidean Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mHVqq2toEeh",
        "colab_type": "text"
      },
      "source": [
        "* Squared Euclidean distance is of central importance in estimating parameters of statistical models, where it is used in the method of least squares, a standard approach to regression analysis. \n",
        "\n",
        "* The corresponding loss function is the squared error loss (SEL), and places progressively greater weight on larger errors. The corresponding risk function (expected loss) is mean squared error (MSE).\n",
        "\n",
        "* **Squared Euclidean distance is not a metric**, as it does not satisfy the triangle inequality. However, **it is a more general notion of distance, namely a divergence** (specifically a Bregman divergence), and can be used as a statistical distance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjoet-ldoMGv",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Euclidean_distance#Squared_Euclidean_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN2Dn3F0iAzD",
        "colab_type": "text"
      },
      "source": [
        "##### **Kullback–Leibler divergence**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OWsTyvziEce",
        "colab_type": "text"
      },
      "source": [
        "The only divergence that is both an f-divergence and a Bregman divergence is the Kullback–Leibler divergence\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Kullback–Leibler_divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSRliOMMiHC-",
        "colab_type": "text"
      },
      "source": [
        "##### **Jensen–Shannon divergence**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AgQmDiLiJW_",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Jensen–Shannon_divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO5uuQMehFZD",
        "colab_type": "text"
      },
      "source": [
        "### **Similarity & Distances**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXBpZ1M8zNi5",
        "colab_type": "text"
      },
      "source": [
        "#### **Similarity Learning & Similarity Measures**\n",
        "\n",
        "*Ähnlichkeitsmaße werden für nominal oder ordinal skalierte Variablen genutzt*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxTnwP8u5YD2",
        "colab_type": "text"
      },
      "source": [
        "##### **Overview**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdhCXyrkgLB0",
        "colab_type": "text"
      },
      "source": [
        "In der Statistik, insbesondere der Multivariaten Statistik, interessiert man sich für die Messung der Ähnlichkeit zwischen verschiedenen Objekten und definiert dazu Ähnlichkeits- und Distanzmaße. **Es handelt sich dabei nicht um Maße im mathematischen Sinn**, der Begriff bezieht sich ausschließlich auf die Messung einer bestimmten Größe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez_pHYiXgPcu",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Ähnlichkeitsanalyse\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Distanzfunktion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu_3BJSrgnoi",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Distance_(graph_theory)\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VyoAh5jw5zd",
        "colab_type": "text"
      },
      "source": [
        "**Similarity Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3kMumcau1jK",
        "colab_type": "text"
      },
      "source": [
        "Similarity learning is an area of supervised machine learning in artificial intelligence. It is closely related to regression and classification, but the goal is to learn a similarity function that measures how similar or related two objects are. It has applications in ranking, in recommendation systems, visual identity tracking, face verification, and speaker verification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbKu0ozEiQxS",
        "colab_type": "text"
      },
      "source": [
        "other approaches to learn a distance metric from examples.\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Similarity_learning\n",
        "\n",
        "Triplet Loss (a loss function for machine learning algorithms) is often used for learning similarity for the purpose of learning embeddings, like word embeddings and even thought vectors, and metric learning.\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Triplet_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL8yx8TPwzxd",
        "colab_type": "text"
      },
      "source": [
        "**Similarity Measure**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YROdjwerw1vn",
        "colab_type": "text"
      },
      "source": [
        "* In statistics and related fields, a similarity measure or similarity function is a real-valued function that quantifies the similarity between two objects. \n",
        "\n",
        "* Although no single definition of a similarity measure exists, usually such measures are in some sense the inverse of distance metrics: they take on large values for similar objects and either zero or a negative value for very dissimilar objects.\n",
        "\n",
        "* Cosine similarity is a commonly used similarity measure for real-valued vectors, used in (among other fields) information retrieval to score the similarity of documents in the vector space model. In machine learning, common kernel functions such as the RBF kernel can be viewed as similarity functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iXAC70pwnTo",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Similarity_measure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g_7L7g3ny7G",
        "colab_type": "text"
      },
      "source": [
        "**Ranking & Learning to Rank**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97toBWqunbiF",
        "colab_type": "text"
      },
      "source": [
        "Ranking.. (triplet loss mit similarity learning wird im ranking verwendet, weil es ordinal ist im ggs zu distance learning..)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdpLZzSioAhS",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Ranking_(information_retrieval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOWwPfO4nxxY",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Learning_to_rank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke2u6tb3nq5P",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Ranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LntGnKsfn38Z",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Information_retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAf4sna4hQMg",
        "colab_type": "text"
      },
      "source": [
        "##### **Jaccard-Koeffizient**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYu5h2eLhR-N",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Jaccard-Koeffizient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deNJWcC3hUSX",
        "colab_type": "text"
      },
      "source": [
        "##### **Yules Index**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGeN7197hXMA",
        "colab_type": "text"
      },
      "source": [
        "Yules Index ist ein statistischer Messwert, der die Uniformität oder Diversität des Wortschatzes bestimmt. Er wurde vom schottischen Statistiker George Udny Yule entwickelt und misst die Wahrscheinlichkeit, mit der zwei zufällig ausgewählte Wörter eines Textes identisch sind – und zwar weitgehend unabhängig vom Umfang des Textes.Diesen Index hat Herdan aufgegriffen und weiterentwickelt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-YLY8Q4hZmk",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Yules_Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtmj4FOHq6ht",
        "colab_type": "text"
      },
      "source": [
        "##### **Pearson Korrelationskoeffizient**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W0A6wTO22MZ",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Korrelationskoeffizient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrVKpOHIzWHG",
        "colab_type": "text"
      },
      "source": [
        "#### **Distance Metric Learning & Distance Measures**\n",
        "\n",
        "*Distanzmaße werden für metrisch skalierte Variablen (d. h. für Intervall- und Verhältnisskala) genutzt.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UfyDobq5cXp",
        "colab_type": "text"
      },
      "source": [
        "##### **Overview**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRiPX5ymiOQB",
        "colab_type": "text"
      },
      "source": [
        "**Distance Metric Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcYq501LwPx2",
        "colab_type": "text"
      },
      "source": [
        "**Distanzmaße** werden für metrisch skalierte Variablen (d. h. für Intervall- und Verhältnisskala) genutzt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g5n2_2QuXGU",
        "colab_type": "text"
      },
      "source": [
        "Similarity learning is closely related to distance metric learning. Metric learning is the task of learning a distance function over objects. A metric or distance function has to obey four axioms: non-negativity, identity of indiscernibles, symmetry and subadditivity (or the triangle inequality). **In practice, metric learning algorithms ignore the condition of identity of indiscernibles and learn a pseudo-metric**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecLaHQ8EiXyP",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Similarity_learning#Metric_learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fW7iOU1uAvm",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AepjAni7x_g9",
        "colab_type": "text"
      },
      "source": [
        "**Exkurs**: [Distance measures](https://en.m.wikipedia.org/wiki/Distance_measures_(cosmology)) in cosmology are complicated by the [expansion of the universe](https://en.m.wikipedia.org/wiki/Expansion_of_the_universe), and by effects described by the [theory of relativity](https://en.m.wikipedia.org/wiki/Theory_of_relativity) such as [length contraction](https://en.m.wikipedia.org/wiki/Length_contraction) of moving objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvctBykzhmbB",
        "colab_type": "text"
      },
      "source": [
        "##### **Mahalanobis distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-TZ_CmyyVV-",
        "colab_type": "text"
      },
      "source": [
        "* The Mahalanobis distance is a measure of the distance between a point P and a distribution D\n",
        "\n",
        "* If each of these axes is re-scaled to have unit variance, then the Mahalanobis distance corresponds to standard Euclidean distance in the transformed space. The Mahalanobis distance is thus unitless and scale-invariant, and takes into account the correlations of the data set.\n",
        "\n",
        "* In statistics, the covariance matrix of the data is sometimes used to define a distance metric called Mahalanobis distance.\n",
        "\n",
        "* Bregman divergence: **the Mahalanobis distance is an example of a Bregman divergence**\n",
        "\n",
        "* **Bhattacharyya distance related, for measuring similarity between data sets (and not between a point and a data set** - Mahalanobis distance is a particular case of the Bhattacharyya distance when the standard deviations of the two classes are the same.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guFweB6AhoJs",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Mahalanobis_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYZzNeN0mJJ2",
        "colab_type": "text"
      },
      "source": [
        "* Mahalanobis distance is an effective multivariate distance metric that measures the distance between a point and a distribution. \n",
        "\n",
        "* It is an extremely useful metric having, excellent applications **in multivariate anomaly detection, classification on highly imbalanced datasets and one-class classification**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCC_7jqmo0rN",
        "colab_type": "text"
      },
      "source": [
        "![alternativer Text](https://raw.githubusercontent.com/deltorobarba/machinelearning/master/mahalanobis.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAydAR1XqBN_",
        "colab_type": "text"
      },
      "source": [
        "* If the dimensions (columns in your dataset) are correlated to one another, which is typically the case in real-world datasets, the Euclidean distance between a point and the center of the points (distribution) can give little or misleading information about how close a point really is to the cluster.\n",
        "\n",
        "* The two points above are equally distant (Euclidean) from the center. But only one of them (blue) is actually more close to the cluster, even though, technically the Euclidean distance between the two points are equal.\n",
        "\n",
        "* This is because, Euclidean distance is a distance between two points only. It does not consider how the rest of the points in the dataset vary. So, it cannot be used to really judge how close a point actually is to a distribution of points.\n",
        "\n",
        "* **What we need here is a more robust distance metric that is an accurate representation of how distant a point is from a distribution.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdi3fJK7pK-O",
        "colab_type": "text"
      },
      "source": [
        "So computationally, how is Mahalanobis distance different from Euclidean distance?\n",
        "\n",
        "1. It transforms the columns into uncorrelated variables\n",
        "2. Scale the columns to make their variance equal to 1\n",
        "3. Finally, it calculates the Euclidean distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzlk1JzZmQRz",
        "colab_type": "text"
      },
      "source": [
        "https://www.machinelearningplus.com/statistics/mahalanobis-distance/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40Jv2Z1mmUFw",
        "colab_type": "text"
      },
      "source": [
        "The Mahalanobis distance has the following properties:\n",
        "\n",
        "* It accounts for the fact that the variances in each direction are different.\n",
        "\n",
        "* It accounts for the covariance between variables.\n",
        "\n",
        "* It reduces to the familiar Euclidean distance for uncorrelated variables with unit variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0Hwd5cNpl_c",
        "colab_type": "text"
      },
      "source": [
        "Distance in standard units\n",
        "\n",
        "In statistics, we sometimes measure \"nearness\" or \"farness\" in terms of the scale of the data. **Often \"scale\" means \"standard deviation.\"** For univariate data, we say that an observation that is one standard deviation from the mean is closer to the mean than an observation that is three standard deviations away. (You can also specify the distance between two observations by specifying how many standard deviations apart they are.)\n",
        "\n",
        "**For many distributions, such as the normal distribution, this choice of scale also makes a statement about probability**. Specifically, it is more likely to observe an observation that is about one standard deviation from the mean than it is to observe one that is several standard deviations away. Why? Because the probability density function is higher near the mean and nearly zero as you move many standard deviations away.\n",
        "\n",
        "**For normally distributed data, you can specify the distance from the mean by computing the so-called z-score**. For a value x, the z-score of x is the quantity z = (x-μ)/σ, where μ is the population mean and σ is the population standard deviation. This is a dimensionless quantity that you can interpret as the number of standard deviations that x is from the mean.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIjjqmwLmY0F",
        "colab_type": "text"
      },
      "source": [
        "https://blogs.sas.com/content/iml/2012/02/15/what-is-mahalanobis-distance.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT8FPvZ3hi1N",
        "colab_type": "text"
      },
      "source": [
        "##### **Bhattacharyya distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1YoJ42mx-xb",
        "colab_type": "text"
      },
      "source": [
        "* In statistics, the Bhattacharyya distance measures the similarity of two probability distributions. It is closely related to the Bhattacharyya coefficient which is a measure of the amount of overlap between two statistical samples or populations. \n",
        "\n",
        "* The coefficient can be used to determine the relative closeness of the two samples being considered. It is used to measure the separability of classes in classification and it is considered to be more reliable than the Mahalanobis distance, as the ***Mahalanobis distance is a particular case of the Bhattacharyya distance** when the standard deviations of the two classes are the same. \n",
        "\n",
        "* Consequently, when two classes have similar means but different standard deviations, the Mahalanobis distance would tend to zero, whereas the Bhattacharyya distance grows depending on the difference between the standard deviations.\n",
        "\n",
        "* under certain conditions does not obey the triangle inequality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AVM3T1Dhkld",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Bhattacharyya_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYLc2b-qsm8N",
        "colab_type": "text"
      },
      "source": [
        "##### **Hellinger Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEGZl1OtyhBy",
        "colab_type": "text"
      },
      "source": [
        "*  the Hellinger distance (closely related to, although different from, the Bhattacharyya distance) is used to **quantify the similarity between two probability distributions**. \n",
        "\n",
        "* **It is a type of f-divergence.**\n",
        "\n",
        "* (?) ist vielleicht sogar eine metric weil es triangle inequality erfüllt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owVHpnpSywyW",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Hellinger_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lydB1B0oq-VJ",
        "colab_type": "text"
      },
      "source": [
        "##### **Euclidean L1 and Manhatten Distance L2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGE57oYk2smE",
        "colab_type": "text"
      },
      "source": [
        "Sinde it fullfills all 4 properties, it is not only a distance but also a metric (see details below)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1hoL_o6Zh_H",
        "colab_type": "text"
      },
      "source": [
        "### **Metrics I: Durch Normen induzierte Metriken (L<sup>p</sup> Distances)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mISGLzNFniMx",
        "colab_type": "text"
      },
      "source": [
        "#### **Oberview**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN_4QgtRm6rR",
        "colab_type": "text"
      },
      "source": [
        "**Jede Norm induziert eine Metrik, aber nicht jede Metrik wird durch eine Norm induziert** (?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBQAQ6GOZlg7",
        "colab_type": "text"
      },
      "source": [
        "Jede Norm auf einem Vektorraum induziert durch die Festlegung\n",
        "\n",
        "> $d(x, y) \\equiv\\|x-y\\|$\n",
        "\n",
        "eine Metrik. Somit ist jeder normierte Vektorraum (und erst recht jeder Innenproduktraum, Banachraum oder Hilbertraum) ein metrischer Raum.\n",
        "\n",
        "**Eine Metrik, die aus einer $p$ -Norm abgeleitet ist, heißt auch Minkowski-Metrik**. Wichtige Spezialfälle sind die\n",
        "\n",
        "* Manhattan-Metrik zu $p=1$, \n",
        "* euklidische Metrik zu $p=2$\n",
        "* Maximum-Metrik zu $p=\\infty$\n",
        "\n",
        "Weitere Beispiele für Normen (und damit auch für Metriken) finden sich im Artikel [Norm (Mathematik)](https://de.m.wikipedia.org/wiki/Norm_(Mathematik)). Aus einer $p$ -Norm abgeleitet sind zum Beispiel die Metriken der folgenden wichtigen Räume:\n",
        "der eindimensionale Raum der reellen oder komplexen Zahlen mit dem absoluten Betrag als Norm (mit beliebigem $p$ ) und der dadurch gegebenen Betragsmetrik\n",
        "\n",
        "> $d(x, y)=|x-y|$\n",
        "\n",
        "or euklidische Raum mit seiner durch den Satz des Pythagoras gegebenen euklidischen Metrik (zur euklidischen Norm für $p=2$ )\n",
        "\n",
        "> $d(x, y)=\\sqrt{\\left(x_{1}-y_{1}\\right)^{2}+\\cdots+\\left(x_{n}-y_{n}\\right)^{2}}$\n",
        "\n",
        "Als eine [**Fréchet-Metrik**](https://de.m.wikipedia.org/wiki/Fréchet-Metrik) wird gelegentlich eine Metrik\n",
        "\n",
        "> $d(x, y)=\\rho(x-y)$\n",
        "\n",
        "bezeichnet, die von einer Funktion $\\rho$ induziert wird, welche die meisten Eigenschaften einer Norm besitzt, aber nicht homogen ist. **Sie stellt eine Verbindung zwischen Metrik und Norm her.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbZOslj1eRla",
        "colab_type": "text"
      },
      "source": [
        "#### **L<sup>p</sup> Distances (Minkowski Distances / Metrics)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7Sd3MWyW5V6",
        "colab_type": "text"
      },
      "source": [
        "* **The Minkowski distance is a metric in a normed vector space** which can be considered as a generalization of both the Euclidean distance and the Manhattan distance.\n",
        "\n",
        "* Minkowski distance is typically used with p being 1 or 2, which correspond to the **Manhattan distance and the Euclidean distance**, respectively. In the limiting case of p reaching infinity, we obtain the **Chebyshev distance**\n",
        "\n",
        "* p need not be an integer, but it cannot be less than 1, because otherwise the triangle inequality does not hold (which is possible, but then it's not a metric anymore)\n",
        "\n",
        "* **In physical space the Euclidean distance is in a way the most natural one, because in this case the length of a rigid body does not change with rotation.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqKAYkW2oE2Z",
        "colab_type": "text"
      },
      "source": [
        "![alternativer Text](https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/2D_unit_balls.svg/800px-2D_unit_balls.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRP4WSD9oLvm",
        "colab_type": "text"
      },
      "source": [
        "*The figure shows unit circles (the set of all points that are at the unit distance from the centre) with various values of p*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t8p1rGbdPx1",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Minkowski_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFzrPn6HYJt9",
        "colab_type": "text"
      },
      "source": [
        "#### **L1 - Manhattan Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO0nqUI8m_fA",
        "colab_type": "text"
      },
      "source": [
        "* **ist eine topologische Distanz**\n",
        "\n",
        "* The Manhattan norm gives rise to the Manhattan distance, where the distance between any two points, or vectors, is the sum of the differences between corresponding coordinates.\n",
        "\n",
        "* **Die Manhattan-Metrik ist die von der Summennorm (1-Norm) eines Vektorraums erzeugte Metrik. Aber: Die Summennorm ist nicht von einem Skalarprodukt induziert.**\n",
        "\n",
        "* Die Manhattan-Metrik (auch Manhattan-Distanz, Mannheimer Metrik, Taxi- oder Cityblock-Metrik) ist eine Metrik, in der die Distanz d zwischen zwei Punkten a und b als die Summe der absoluten Differenzen ihrer Einzelkoordinaten definiert wird:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oL_J1fZIqT8",
        "colab_type": "text"
      },
      "source": [
        "> $d(a, b)=\\sum_{i}\\left|a_{i}-b_{i}\\right|$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0_E7Gu4IbbP",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Manhattan-Metrik"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZlz94XCYE8Q",
        "colab_type": "text"
      },
      "source": [
        "#### **L2 - Euclidean Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1bl59wtmyYn",
        "colab_type": "text"
      },
      "source": [
        "* The **euclidean distance** is the L2-norm of the difference, **a special case of the Minkowski distance with p=2**. It is the natural distance in a geometric interpretation.\n",
        "\n",
        "> $d_{2}:(x, y) \\mapsto\\|x-y\\|_{2}=\\sqrt{d_{\\mathrm{SSD}}}=\\sqrt{\\sum_{i=1}^{n}\\left(x_{i}-y_{i}\\right)^{2}}$\n",
        "\n",
        "* Together with the Euclidean distance the Euclidean space is a metric space (x element R, d). http://theanalysisofdata.com/probability/B_4.html\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Euclidean_distance\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Tikhonov_regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug1sNzCsdMGh",
        "colab_type": "text"
      },
      "source": [
        "#### **L ∞ - Chebyshev Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QdrlGVRmlmx",
        "colab_type": "text"
      },
      "source": [
        "* The maximum norm gives rise to the **Chebyshev distance** or chessboard distance, the minimal number of moves a chess king would take to travel from x to y. The Chebyshev distance is the L∞-norm of the difference, a special case of the Minkowski distance where p goes to infinity. It is also known as Chessboard distance.\n",
        "\n",
        "> $d_{\\infty}:(x, y) \\mapsto\\|x-y\\|_{\\infty}=\\lim _{p \\rightarrow \\infty}\\left(\\sum_{i=1}^{n}\\left|x_{i}-y_{i}\\right|^{p}\\right)^{\\frac{1}{p}}=\\max _{i}\\left|x_{i}-y_{i}\\right|$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjWVKu82npHV",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Chebyshev_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1mImehPm69J",
        "colab_type": "text"
      },
      "source": [
        "### **Metrics II: Nicht durch Normen erzeugte Metriken**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1tE5YQRlE54",
        "colab_type": "text"
      },
      "source": [
        "#### **Overview**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUnISc3anLSR",
        "colab_type": "text"
      },
      "source": [
        "* Auf jeder Menge lässt sich eine triviale Metrik, die sogenannte gleichmäßig diskrete Metrik (die sogar eine Ultrametrik ist) definieren durch \n",
        "\n",
        "> $d(x, y)=\\left\\{\\begin{array}{ll}0 & \\text { für } x=y \\\\ 1 & \\text { für } x \\neq y\\end{array}\\right.$\n",
        "\n",
        "Sie induziert die diskrete Topologie.\n",
        "\n",
        "* Auf $\\mathbb{R}$ wird durch $\\delta(x, y)=|\\arctan (x)-\\arctan (y)|$ eine Metrik definiert. Bezüglich dieser Metrik ist $\\mathbb{R}$ nicht vollständig. So ist $z .$ B. die Folge $(n)_{n \\in \\mathbb{N}}$ eine $\\delta$ -Cauchy-Folge, die nicht in $\\mathbb{R}$ konvergiert. Die von dieser Metrik erzeugte Topologie stimmt zwar mit der Standardtopologie auf IR überein, aber die von den beiden Metriken induzierten uniformen Strukturen sind offensichtlich\n",
        "verschieden.\n",
        "\n",
        "Im Allgemeinen **nicht durch eine Norm induziert ist die riemannsche Metrik**, die aus einer differenzierbaren Mannigfaltigkeit eine [riemannsche Mannigfaltigkeit](https://en.m.wikipedia.org/wiki/Riemannian_manifold) macht. \n",
        "\n",
        "Beispiele dafür:\n",
        "\n",
        "* die natürliche Metrik auf einer Kugeloberfläche, in der der Großkreis die kürzeste Verbindung ([Geodäte](https://en.m.wikipedia.org/wiki/Geodesic)) zwischen zwei Punkten ist;\n",
        "\n",
        "* die uneigentliche Metrik im Minkowski-Raum $\\mathbb{R} \\times \\mathbb{R}^{3}$ der speziellen Relativitätstheorie, in der zeitähnliche Abstände durch $\\left[(\\Delta t)^{2}-(\\Delta x / c)^{2}-(\\Delta y / c)^{2}-(\\Delta z / c)^{2}\\right]^{1 / 2}$ und ortsähnliche Abstände $\\operatorname{durch}\\left[(\\Delta x)^{2}+(\\Delta y)^{2}+(\\Delta z)^{2}-(\\Delta c t)^{2}\\right]^{1 / 2}$ gegeben sind\n",
        "\n",
        "* die von der Materieverteilung abhängige Verallgemeinerung dieser Metrik in der allgemeinen Relativitätstheorie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbhUmt563M6H",
        "colab_type": "text"
      },
      "source": [
        "Die riemannsche Metrik ist keine Metrik im Sinne der Theorie der metrischen Räume, sondern ein Skalarprodukt. Man kann jedoch ähnlich wie in der Theorie der Skalarprodukträume aus dem Skalarprodukt eine Metrik gewinnen. Somit können riemannsche Mannigfaltigkeiten als metrische Räume verstanden werden. Auf riemannschen Mannigfaltigkeiten sind also im Gegensatz zu differenzierbaren Mannigfaltigen Begriffe wie Abstand, Durchmesser oder Vollständigkeit definiert."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUzTHdhL3PTo",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Riemannsche_Mannigfaltigkeit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taLU82-Xn0xm",
        "colab_type": "text"
      },
      "source": [
        "* Die [französische Eisenbahnmetrik](https://de.m.wikipedia.org/wiki/Französische_Eisenbahnmetrik) ist ein beliebtes Übungsbeispiel für eine nicht durch eine Norm induzierte Metrik. Sie wird unter Bezugnahme auf einen ausgezeichneten Punkt $P($, Paris\") wie folgt definiert: Der Abstand zweier verschiedener Punkte, deren Verbindungsgerade durch $P$ verläuft, ist inr Abstand unter der gewöhnlichen euklidischen Metrik. Der Abstand zweier\n",
        "verschiedener Punkte, deren Verbindungsgerade nicht durch $P$ verläuft, ist die Summe ihrer Abstände von $P$\n",
        "\n",
        "* Die [Hausdorff-Metrik](https://de.m.wikipedia.org/wiki/Hausdorff-Metrik) misst den Abstand zwischen Teilmengen, nicht Elementen, eines metrischen Raums; man könnte sie als Metrik zweiten Grades bezeichnen, denn sie greift auf eine Metrik ersten Grades zwischen den Elementen des metrischen Raums zurück.\n",
        "\n",
        "* Der [Hamming-Abstand](https://de.m.wikipedia.org/wiki/Hamming-Abstand) ist eine Metrik auf dem Coderaum, die die Unterschiedlichkeit von (gleich langen) Zeichenketten angibt. Siehe auch [Levenshetin Distance](https://de.m.wikipedia.org/wiki/Levenshtein-Distanz) - Die Levenshtein-Distanz kann als Erweiterung des Hamming-Abstands angesehen werden, welcher sich auf Ersetzungen beschränkt und daher nur Zeichenketten gleicher Länge bemessen kann. Eine Phonetische Suche kann die Levenshtein-Distanz verwenden, um Fehler zu erlauben. [Dynamic Time Warpening](https://de.m.wikipedia.org/wiki/Dynamic-Time-Warping). Die Levenshtein-Distanz kann als Sonderform der Dynamic-Time-Warping-Distanz (DTW) betrachtet werden."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFheGZB5u2fk",
        "colab_type": "text"
      },
      "source": [
        "#### **Edit Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh03tQ74ulO-",
        "colab_type": "text"
      },
      "source": [
        "In computer science, there is the notion of the \"edit distance\" between two strings. For example, the words \"dog\" and \"dot\", which vary by only one letter, are closer than \"dog\" and \"cat\", which differ by three letters. This idea is used in spell checkers and in coding theory, and is mathematically formalized in several different ways, such as:\n",
        "\n",
        "[Levenshtein distance](https://en.m.wikipedia.org/wiki/Levenshtein_distance)\n",
        "\n",
        "[Hamming distance](https://en.m.wikipedia.org/wiki/Hamming_distance)\n",
        "\n",
        "[Lee distance](https://en.m.wikipedia.org/wiki/Lee_distance)\n",
        "\n",
        "[Jaro–Winkler distance](https://en.m.wikipedia.org/wiki/Jaro–Winkler_distance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJpF7K2iugN3",
        "colab_type": "text"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Edit_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mbesBmkiMUh",
        "colab_type": "text"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Metrischer_Raum"
      ]
    }
  ]
}