{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vLLaN6mPXKth",
        "efzpvSJocU3I",
        "Gj-d2EYc2e7s",
        "gNGVQC0OENoM",
        "hlzi59BP8aqU",
        "2rAAm4JiTDN3",
        "2Xmk4oUjXRHh",
        "D9VH8cY6Ia40",
        "KR_qJb-WbsTp",
        "Zd3SbuXPo-mz",
        "DA5HMxDY9iHT",
        "8APTJDua9uNY",
        "OQhOPkypmczT",
        "ypsYD62SW6N9",
        "HX_Y0zpTYD8b",
        "T3lxJ4d7BriG",
        "jBlZmRcPPd8C",
        "c1GtjXg4e2yE",
        "Oz7oDSQ5Bm6H",
        "La_aZKRrBaXe",
        "-wgjwv48EPNF",
        "pgvi8Yztfy7j",
        "XyPztHZDog1j",
        "mUfHuBR4Nhcn",
        "ql8hl9HHzAOe",
        "-OrLJOuEP4GO",
        "qOXTdQWbu6wm",
        "GwAZXBb_beZP",
        "8fYo65BMPmqp",
        "P4NJL0kOLbfi",
        "Dgy31jigwHId",
        "DOOx_crf83HT",
        "I2xPw5u9vGWI",
        "y4YO0LQ4A4IX",
        "aZ3xS4t7CWRV",
        "gj5tJ7BnBLC0",
        "XW6H46KpBVW-",
        "nMRTXb5a56Aq",
        "AbTRWe0r27UX",
        "fP_EL_HY_Xew",
        "RcixBlEjhSch",
        "wagDIGtWD_f9",
        "uxq8EP-8YIIc",
        "U2lhywuKYNRw",
        "GZOmqj0cJlVg",
        "-91jSrDIX7jC",
        "g9-cNnkyYxVk",
        "hNQBtp95w2Di",
        "LRIi-9lWbiAt",
        "fSOCv2LsgeIu",
        "AXGHc7oUfx_p",
        "A90mbGhcftHI",
        "GXXGNyygfl3B",
        "w9lDedY3fgnk",
        "2VU6BC9nYCGr",
        "a1VNgmJMpYSL",
        "_ZLCspR7YR3z",
        "Fv5NjSY6wPmt",
        "dRx4Wa1NZjf_",
        "s9R2XXEqZeYH",
        "dDeahAqJZZUs",
        "dLcMEj-iZUWy",
        "nzm9UioSZQMr",
        "yIEGR7ZtZKfS",
        "RbnAnPCJZDh4",
        "SfaztpziY2sb",
        "mL9gnsMGYrOZ",
        "pqNjjLBMYen-",
        "KMsbZlxPt-Ec",
        "MZO0odc6qWrf",
        "Bs0vbHxkhFvU",
        "vysHiG6QtWbx",
        "Apl61SPnakw3",
        "bIfbMtM1Y-7c",
        "ZVxXcD-mYYhA",
        "91Gi3EMaYlBw",
        "GL1iMe8igraR",
        "UQgau4E3u8MF",
        "y7r0yPBYKf60",
        "iptu2LVks6If",
        "jBh1Tr-vn_4f",
        "cqdowsM5oHEP",
        "1fAAZcgWoiJB",
        "cyrUknMLo8bl",
        "M0kD-s4t82ez",
        "9GXuS8c94Iay",
        "gXZXzSSsrrUL",
        "VHiwFI7ovP7J",
        "dcFMdt_xthGK",
        "cPAo7HRV06Ol",
        "3hazOulegQat",
        "EBxdSfTogMN6",
        "RscthBMzOLUM",
        "7sf5tauFtttx",
        "jdJ5yNTZibYy",
        "AZ-w7Fv4O91T",
        "k5rk1UYyjFyF",
        "xdsgEUJ4jW7d",
        "Y5obzMR9bSTS",
        "_wegxQZg6Cql",
        "6IeXoanHRwy3",
        "GjKhUGg9zYhs",
        "EOjTIfBF5mfO",
        "zXJ4KIadIPuy",
        "5_P1_6vvyHEc",
        "HPFi-nppjRQA",
        "gPeePps2begU",
        "uM9V1BBQGHTy",
        "crQgUFkRk-XB",
        "6uUn645o-PmN",
        "EkdQBmsWyXyQ",
        "NpX_msD1vmi-",
        "-bgPYHGr1kCz",
        "86rBYa_u4urx",
        "JgPN5UHup5lH",
        "CBU1tb4vs16v",
        "WikX85R-r4I2",
        "bkXljK6xhBPG",
        "Cqusdv76O-Bx",
        "0MXqdUuKJZ37",
        "PFZKZOdMPBfF",
        "0IdZ1gStv7HP",
        "3cyZhA5TuEuW",
        "l_kkJp3mtIyD",
        "qoluFPb7O8Vv",
        "JC96LcJUvxwY",
        "w4FmSc4QvQsY",
        "ON5x3x5CPe7d",
        "jK7vTB6GIQpe",
        "QaGfSVYXp_gy",
        "Y7EMAgb2PJDH",
        "6Z0vHScrO3Nw",
        "ut_14zjENSyM",
        "QFiC9iq1uchk",
        "KcuadzY1rHe3",
        "hrYb8_OIPhhO",
        "r2-fNN88Cb7S",
        "NxI60357-N2l",
        "J4ZBVKqKqAbk",
        "vOqtFAy5GKtG",
        "EV6x8bY7pvDP",
        "WnAvpRxbPSwU",
        "1Amg0O9YxNcY",
        "dEY-ynaCNWkJ",
        "YY-9SFOGdbPy",
        "L_xE9c7WKnUU",
        "qMfQjLMqmzuw",
        "Az7EjhgzgTLq",
        "m_M1o-kVjMZ1",
        "0md9DQ34gkax",
        "jRi0tikbgikC",
        "02eilyDPlFh8",
        "Cmqnes9brFPk",
        "LOnEwXajSzfL",
        "ijtvzpIDxEzV",
        "ThL-AmiaxI8J",
        "8SsJmnB0xNNN",
        "l-DiG5X3xTfp",
        "oKvbzZ8cxOS1",
        "eLjOkdyQxLeb",
        "V36uKfvAxRCm",
        "hiezBxLBxVLy",
        "IJCykPfwxdQn",
        "zXCXyX9DxfdE"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deltorobarba/sciences/blob/master/complexity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"blue\">**Complexity**"
      ],
      "metadata": {
        "id": "xEVSiuftty-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0000.png)"
      ],
      "metadata": {
        "id": "YiqcrmGetjeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color=\"Blue\">**Computational Complexity**"
      ],
      "metadata": {
        "id": "vLLaN6mPXKth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"Blue\">*Computational Complexity*"
      ],
      "metadata": {
        "id": "efzpvSJocU3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [**Computational complexity theory**](https://en.m.wikipedia.org/wiki/Computational_complexity_theory) = <u>**Is it possible to compute a function efficiently?**</u>\n",
        "\n",
        "* Read: [A Short History of Computational Complexity](https://www.uni-ulm.de/fileadmin/website_uni_ulm/iui.inst.190/Mitarbeiter/toran/beatcs/column80.pdf)\n",
        "\n",
        "* **Definition**: Computational complexity theory asks \"How efficiently can a problem be solved\"? (NP-complete, NP-hard, P problems, etc. on Turing machine). It studies the resources (time, space, etc.) required to solve different computational problems. For **Quantum Computing: understand the ultimate physical limits to computation**\n",
        "\n",
        "* **Origin**: Hartmanis and Stearns showed that computational problems have an inherent complexity, which can be quantified in terms of the number of steps needed on a simple model of a computer, the multi-tape Turing machine. efficient reductions... collapse in equivalent classes, to natural complexity classes. motion of reducability. [Yablonsky](https://en.m.wikipedia.org/wiki/Sergey_Yablonsky) one of first to raise issues of potentially **inherent unavoidability of brute force search for some problems**, precursor of P = NP problem\n",
        "\n",
        "* **Special - Quantum**: [Quantum circuit complexity](https://en.m.wikipedia.org/wiki/Quantum_complexity_theory): subfield of computational complexity theory that deals with complexity classes defined using quantum computers. Studies hardness of computational problems and relationship between complexity classes. Two important: BQP and QMA.\n",
        "\n",
        "* **Ausgangspunkt**: [Quantum many body problem](https://en.m.wikipedia.org/wiki/Many-body_problem): seems exponentially difficult for classical computers to simulate quantum systems ([Source](https://en.m.wikipedia.org/wiki/Quantum_threshold_theorem#Notes)). Quantum computers can simulate many Hamiltonians in [polynomial time with bounded errors](https://en.m.wikipedia.org/wiki/BQP) (BQP): chemical simulations, drug discovery, energy production, [climate modeling](https://en.m.wikipedia.org/wiki/Climate_model) and [FeMoco](https://en.m.wikipedia.org/wiki/FeMoco). [Finally, a Problem That Only Quantum Computers Will Ever Be Able to Solve](https://www.quantamagazine.org/finally-a-problem-that-only-quantum-computers-will-ever-be-able-to-solve-20180621/). **Iterative improvements in classical algorithm are not enough**. Quantum computing: an “easy” problem can be solved on QC in polynomial time is class BQP (Bounded-error Quantum Polynomial time), and a hard problem which can only be verified in polynomial time is class QMA (the playfully named [Quantum Merlin Arthur](https://en.m.wikipedia.org/wiki/QMA)).  Hope in field is that there is overlap between NP and BQP: a hard problem can be transformed into an easy one.\n",
        "\n",
        "* **Limitations**: [\"The Limits of Quantum Computers\"](https://www.scientificamerican.com/article/the-limits-of-quantum-computers/): Quantum computers may provide a massive speedup for problems in the BQP complexity class. Nothing more. They are no more powerful than a Turing machine (in terms of the problems that can be solved). [The_Limits_of_Quantum_Computers](https://www.cs.virginia.edu/~robins/The_Limits_of_Quantum_Computers.pdf). [How Big are Quantum States?](https://www.scottaaronson.com/democritus/lec13.html).\n",
        "\n",
        "\n",
        "* **Computational Problems**: Decision, Sampling, Counting, Verifying, Optimization, Function etc. [Decision Problems](https://en.m.wikipedia.org/wiki/Decision_problem) see also [Search Problem](https://en.m.wikipedia.org/wiki/Search_problem) wie PH oder RP, Sampling Problem wie RP oder Boson Sampling, Proof Verifier Problems wie P, IP oder MIP* = RE, [Counting Problems](https://en.m.wikipedia.org/wiki/Counting_problem_(complexity)), wie Sharp-P oder P#P.\n",
        "\n",
        "* **Further reading:**\n",
        "  * Wiki: [Quantum complexity theory](https://en.m.wikipedia.org/wiki/Quantum_complexity_theory). [Quantum_supremacy: Computational_complexity](https://en.m.wikipedia.org/wiki/Quantum_supremacy#Computational_complexity). [Computational_problem](https://en.m.wikipedia.org/wiki/Computational_problem).\n",
        "  * Five worlds of Hardness: [Which Computational Universe Do We Live In?](https://www.quantamagazine.org/which-computational-universe-do-we-live-in-20220418/)\n",
        "  * [A Short Guide to Hard Problems](https://www.quantamagazine.org/a-short-guide-to-hard-problems-20180716/). [A New Map Traces the Limits of Computation](https://www.quantamagazine.org/edit-distance-reveals-hard-computational-problems-20150929/).\n",
        "  * Diagonalization remains one of key tools in complexity theorists’ arsenal [Alan Turing and the Power of Negative Thinking](https://www.quantamagazine.org/alan-turing-and-the-power-of-negative-thinking-20230905/).\n",
        "  * [Complexity Theory’s 50-Year Journey to the Limits of Knowledge](https://www.quantamagazine.org/complexity-theorys-50-year-journey-to-the-limits-of-knowledge-20230817/)."
      ],
      "metadata": {
        "id": "E-jqmAnSXhmi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Meta-complexity**](https://simons.berkeley.edu/programs/Meta-Complexity2023) (Example: Minimum Circuit Size Problem)\n",
        "\n",
        "* Video: [How Complex Is Complexity? Or What’s a ‘Meta’ for?](https://www.youtube.com/watch?v=7cgcPNUNgxQ) by Eric Allender at Somons Institute\n",
        "\n",
        "* **Meta-complexity**: [Complexity Theory’s 50-Year Journey to the Limits of Knowledge](https://www.quantamagazine.org/complexity-theorys-50-year-journey-to-the-limits-of-knowledge-20230817/). It is concerned with difficulty of computational problems, both directly and indirectly. **How hard is it to prove that problems are hard to solve?**\n",
        "\n",
        "  * **Computational complexity theory**:\tDifficulty of computational problems\n",
        "  * **Meta-complexity theory**:\tDifficulty of determining the difficulty of computational problems\n",
        "\n",
        "* Example: [Minimum Circuit Size Problem](https://en.m.wikipedia.org/wiki/Circuit_complexity) (MCSP - Circuit Complexity), is concerned with complexity of Boolean functions. Bit string $2^n$ is a truth table of a function, and a number s. Does that function has a small circuit (of size at most s)?\n",
        "\n",
        "  * (f,s) : f has a circuit of size ≤ s, where f is represented by a bit string of length $2^n$ (seems intractable, is hard)\n",
        "\n",
        "  * **Complexity question**: Show f is hard\n",
        "\n",
        "  * **Meta-Complexity question**: show that it is hard to show that f is hard\n",
        "\n",
        "* Difference between computational complexity and algorithmic information theory on MCSP:\n",
        "\n",
        "  * In **computational complexity theory**, MCSP asks whether a given Boolean function can be computed by a circuit of a certain size (NP-hard, but not known whether NP-complete) - Is it possible to **compute efficiently** a given Boolean function?\n",
        "\n",
        "  * In **algorithmic information theory**, MCSP asks for Kolmogorov complexity of a given Boolean function (how difficult it is to describe object using a computer program?) - How difficult it is to **describe concisely** a given Boolean function?\n",
        "\n"
      ],
      "metadata": {
        "id": "_h99ix-0Tshq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Circuit Complexity**\n",
        "* Quantum circuit complexity is a measure of the minimum number of quantum gates needed to implement a given unitary transformation\n",
        "* circuit complexity is a lower bound on computational capacity.\n",
        "* (run)time complexity of a quantum algorithm depends on a number of factors, **including the circuit complexity of the algorithm**, the architecture of the quantum computer, and the error rate of the quantum computer.\n",
        "* For [quantum circuit complexity](https://en.m.wikipedia.org/wiki/Circuit_complexity) see also:\n",
        "  * [Linear growth of quantum circuit complexity](https://arxiv.org/abs/2106.05305): Consider constructing deeper and deeper circuits for an n-qubit system, by applying random two-qubit gates. At what rate does the circuit complexity increase?\n",
        "  * [Quantum Computation as Geometry](https://arxiv.org/abs/quant-ph/0603161): Determining the quantum circuit complexity of a unitary operation is closely related to the problem of finding minimal length paths in a particular curved geometry.\n",
        "  * [The geometry of quantum computation](https://arxiv.org/abs/quant-ph/0701004)\n",
        "  * [Quantum Computation as Geometry](https://arxiv.org/abs/quant-ph/0603161) (Nielsen geometry)\n",
        "* [Quantum circuit complexity](https://en.m.wikipedia.org/wiki/Circuit_complexity) is a fundamental concept in quantum computation: widespread applications ranging from determining the running time of quantum algorithms to understanding the physics of black holes. By understanding the complexity of quantum circuits, we can develop more efficient quantum algorithms and better understand the capabilities of quantum computers.\n",
        "  * **Circuit complexity is a measure of the difficulty of computing a function using a Boolean circuit.** A Boolean circuit is a network of logic gates that computes a Boolean function, which is a function that takes a Boolean input vector and produces a Boolean output. The size of a circuit is the number of gates it contains, and its depth is the longest path from an input gate to an output gate.\n",
        "  * Quantum circuit complexity is a **measure of the minimum number of quantum gates needed to implement a given unitary transformation**. However, it is important to note that not all gates are created equal. Some gates are more complex than others, and it may take multiple gates to implement a single unitary transformation.\n",
        "  * Measure the complexity of a quantum gate:\n",
        "    * by its depth: The depth of a gate is the longest path from the input to the output of the gate.\n",
        "    * by its size: The size of a gate is the number of qubits it acts on.\n",
        "  * Quantum circuits are a graphical representation of quantum algorithms. They consist of a sequence of quantum gates, which are unitary operations that act on quantum qubits. The output of a quantum circuit is a unitary transformation on the input state. Here are some examples of quantum circuit complexity:\n",
        "  * The quantum Fourier transform can be implemented with a circuit of depth O(log n), where n is the number of qubits. The quantum Fourier transform can be implemented with a circuit of depth O(log n), where n is the number of qubits. However, the time complexity of the quantum Fourier transform depends on the architecture of the quantum computer. For example, if the quantum computer can implement the quantum Fourier transform using a parallel circuit, then the time complexity will be O(log n). However, if the quantum computer can only implement the quantum Fourier transform using a sequential circuit, then the time complexity will be O(n log n).\n",
        "  * Shor's algorithm for factoring integers can be implemented with a circuit of depth O(log n). Shor's algorithm for factoring integers can be implemented with a circuit of depth O(log n). However, the time complexity of Shor's algorithm depends on the error rate of the quantum computer. If the error rate is low enough, then the time complexity of Shor's algorithm will be polynomial in the size of the integer being factored.\n",
        "  * Grover's algorithm for searching unsorted databases can be implemented with a circuit of depth O(sqrt(N)), where N is the size of the database. Grover's algorithm for searching unsorted databases can be implemented with a circuit of depth O(sqrt(N)), where N is the size of the database. However, the time complexity of Grover's algorithm depends on the number of queries that can be made to the database. If the number of queries is limited, then the time complexity of Grover's algorithm will be higher than O(sqrt(N))\n",
        "* Research papers:\n",
        "  * [Complexity and order in approximate quantum error-correcting codes](https://arxiv.org/abs/2310.04710): We establish rigorous connections between quantum circuit complexity and approximate quantum error correction (AQEC) properties, covering both all-to-all and geometric scenarios including lattice systems. Approximate quantum error correction is a mostly unexplored land, of which we know only a few landmarks. Here they give us a map, and show interesting connections to other areas of physics.\n",
        "  * [Linear growth of quantum circuit complexity](https://arxiv.org/abs/2106.05305): Consider constructing deeper and deeper circuits for an n-qubit system, by applying random two-qubit gates. At what rate does the circuit complexity increase?\n",
        "  * [Quantum Computation as Geometry](https://arxiv.org/abs/quant-ph/0603161): Determining the quantum circuit complexity of a unitary operation is closely related to the problem of finding minimal length paths in a particular curved geometry.\n",
        "  * [The geometry of quantum computation](https://arxiv.org/abs/quant-ph/0701004)\n",
        "  * [Quantum Computation as Geometry](https://arxiv.org/abs/quant-ph/0603161) (Nielsen geometry)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EKpQ47BNMI_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Complexity Classes**](https://en.m.wikipedia.org/wiki/Complexity_class)\n",
        "\n",
        "The relationship of BQP to essential classical complexity classes [(Source)](https://en.m.wikipedia.org/wiki/Quantum_complexity_theory):\n",
        "\n",
        "> ${\\mathsf {P\\subseteq BPP\\subseteq BQP\\subseteq PP\\subseteq PSPACE}}$\n",
        "\n",
        "Relationships between fundamental time and space complexity classes [(S1)](https://en.m.wikipedia.org/wiki/PSPACE) and [(S2)](https://en.m.wikipedia.org/wiki/Complexity_class):\n",
        "\n",
        "> ${\\mathsf {NL\\subseteq P\\subseteq NP\\subseteq PH\\subseteq PSPACE\\subseteq EXPTIME\\subseteq EXPSPACE}}$\n",
        "\n",
        "\n",
        "* [P](https://en.m.wikipedia.org/wiki/P_(complexity)): Can be solved by a deterministic classical computer in polynomial time. P $\\subseteq$ BQP (i.e. anything you can do with a classic computer you can do with a quantum computer). We don't know if that is a strict inequality! [Source](https://quantumcomputing.stackexchange.com/questions/16506/can-quantum-computer-solve-np-complete-problems)\n",
        "\n",
        "* [RP](https://en.m.wikipedia.org/wiki/RP_(complexity)) und [ZPP](https://en.m.wikipedia.org/wiki/ZPP_(complexity)). Unsolved problem in computer science: $\\displaystyle {\\mathsf {P}}{\\overset {?}{=}}{\\mathsf {RP}}$. [RP](https://en.m.wikipedia.org/wiki/RP_(complexity)): Sampling Problem. Randomized polynomial time (RP) is the complexity class of problems for which a [probabilistic Turing machine](https://en.m.wikipedia.org/wiki/Probabilistic_Turing_machine) exists with these properties. Class of problems for which a randomized algorithm can give the correct answer in polynomial time, with a probability of at least 1/2 for \"yes\" instances. Ask for samples from probability distributions. [Source](https://en.m.wikipedia.org/wiki/Quantum_supremacy).\n",
        "  * [Boson sampling](https://en.m.wikipedia.org/wiki/Boson_sampling) Boson sampling is believed to be an RP complexity problem (randomized polynomial time - not proven): solve it in polynomial time with a high probability of success. Randomized algorithm is quantum computer that sample from Boson sampling distribution, which exponentially hard to sample from classically, but maybe polynomial for QC. Showing that Boson sampling is RP -> demonstrate quantum supremacy.\n",
        "  * [Sampling the output distribution of random quantum circuits\n",
        "  ](https://en.m.wikipedia.org/wiki/Quantum_supremacy#Sampling_the_output_distribution_of_random_quantum_circuits) (Google experiment)\n",
        "  * [Solving the sampling problem of the Sycamore quantum circuits](https://arxiv.org/abs/2111.03011)\n",
        "  * [Quantum Sampling Problems, Boson Sampling and Quantum Supremacy](https://arxiv.org/abs/1702.03061)\n",
        "  * [Computational advantage of quantum random sampling](https://arxiv.org/abs/2206.04079)\n",
        "  \n",
        "* [BPP](https://de.m.wikipedia.org/wiki/BPP_(Komplexitätsklasse)): Decision problems, that can be solved by a probabilistic classical computer in polynomial time\n",
        "\n",
        "* [BQP](https://en.m.wikipedia.org/wiki/BQP): Decision problems, that can be solved by a quantum computer in polynomial time (with quantum probability).\n",
        "  * BQP are not in [BPP](https://de.m.wikipedia.org/wiki/BPP_(Komplexitätsklasse)): [Factorization](https://de.m.wikipedia.org/wiki/Faktorisierung) with [Shor's algorithm](https://de.m.wikipedia.org/wiki/Shor-Algorithmus). BQP = P? - Open Question. Dequantized algorithms for such problems – high-rank matrix inversion, for example – would imply that classical computers can efficiently simulate quantum computers, i.e., BQP = P, which is **not** currently considered to be likely. [Source](https://arxiv.org/abs/1905.10415)\n",
        "\n",
        "* [PP](https://de.m.wikipedia.org/wiki/Probabilistische_Polynomialzeit) - Decision problems, die in von einer probabilistischen Turingmaschine in Polynomialzeit lösbar ist und die Antwort in mindestens der Hälfte der Fälle richtig ist. [PostBQP](https://en.m.wikipedia.org/wiki/PostBQP) = [PP](https://de.m.wikipedia.org/wiki/Probabilistische_Polynomialzeit).\n",
        "\n",
        "* [PSPACE](https://de.m.wikipedia.org/wiki/PSPACE) - Problems that can be solved using a polynomial amount of memory, and possibly exponential time.\n",
        "\n",
        "* [IP](https://en.m.wikipedia.org/wiki/IP_(complexity)) interactive proof) is the class of problems solvable by an interactive proof system. It is equal to the class PSPACE.\n",
        "\n",
        "* [NP](https://en.m.wikipedia.org/wiki/NP_(complexity)): Solution can be checked by a deterministic classical computer in polynomial time. [List of NP problems](https://en.m.wikipedia.org/wiki/List_of_NP-complete_problems).\n",
        "  * [NP-Hard](https://en.m.wikipedia.org/wiki/NP-hardness): [travelling salesman](https://en.m.wikipedia.org/wiki/Travelling_salesman_problem). [Sign Problem](https://en.m.wikipedia.org/wiki/Numerical_sign_problem), zB [Sign-Problem-Free Fermionic Quantum Monte Carlo](https://arxiv.org/pdf/1805.08219.pdf)\n",
        "    * [PCP theorem](https://en.m.wikipedia.org/wiki/PCP_theorem): states that every decision problem in the NP complexity class has probabilistically checkable proofs (proofs that can be checked by a randomized algorithm) of constant query complexity and logarithmic randomness complexity (uses a logarithmic number of random bits). The PCP theorem is the cornerstone of the theory of computational [hardness of approximation](https://en.m.wikipedia.org/wiki/Hardness_of_approximation), which investigates the inherent difficulty in designing efficient [approximation algorithms](https://en.m.wikipedia.org/wiki/Approximation_algorithm) for various [optimization problems](https://en.m.wikipedia.org/wiki/Computational_problem).\n",
        "  * [NP-Complete](https://en.m.wikipedia.org/wiki/NP-completeness): hardest of problems to which solutions can be verified quickly, like [Halting problem](https://en.m.wikipedia.org/wiki/Halting_problem) or [3SAT](https://en.m.wikipedia.org/wiki/Boolean_satisfiability_problem) (except, one manages to create a reduction of Grovers algorithm on this NP-Complete algorithm). Can quantum computer solve NP-complete problems? - if you solve any NP-complete problem, all other NP problems come as a 'freebie' (not just the NP-complete ones). In that sense, it would be a huge milestone. It is widely believed that quantum computers cannot solve NP-complete problems, but it has never been proven [Source](https://quantumcomputing.stackexchange.com/questions/16506/can-quantum-computer-solve-np-complete-problems)\n",
        "  * [Co-NP](https://de.m.wikipedia.org/wiki/Co-NP): Complement of NP. Problems for which a \"no\" answer can be verified in polynomial time\n",
        "  * [P versus NP](https://en.m.wikipedia.org/wiki/P_versus_NP_problem): Open question, [video1](https://youtu.be/EHp4FPyajKQ), [video2](https://youtu.be/YX40hbAHx3s)\n",
        "  * [BQNP: The quantum analogue of NP](https://medium.com/mit-6-s089-intro-to-quantum-computing/bqnp-the-quantum-analogue-of-np-486ed2469c1d) and [What is the relationship between BQP and NP?](https://www.quora.com/What-is-the-relationship-between-BQP-and-NP-1)\n",
        "  * Kolmogorov suggested, even before the notions of P, NP, and NP-completeness existed, that lower bound efforts might best be focused on sets that are relatively devoid of simple structure. That is, the NP-complete problems are probably too structured to be good candidates for separating P from NP. One should rather focus on the intermediate less-structured sets that somehow are complex enough to prove separations. As a candidate of such a set he proposed to look at the set of what we call nowadays the **resource-bounded Kolmogorov random strings.** His student Levin looked at \"Time-bounded Kolmogorov Complexity\"\n",
        "\n",
        "* [PH](https://en.m.wikipedia.org/wiki/PH_(complexity)) union of all complexity classes in polynomial hierarchy. Generalizations of NP.\n",
        "\n",
        "\n",
        "* [QMA](https://en.m.wikipedia.org/wiki/QMA): Solution can be checked by a quantum computer in polynomial time.\n",
        "  * QMA is the quantum analog of the NP complexity class.\n",
        "  * HeurBQP/qpoly ⊆ HeurQMA/poly (The Learnability of Quantum States, 2004)\n",
        "  * Many interesting classes are contained in QMA, such as P, BQP and NP, all problems in those classes are also in QMA. However, there are problems that are in QMA but not known to be in NP or BQP. A [list of known QMA-complete problems](https://arxiv.org/abs/1212.6312)\n",
        "    * Quantum circuit/channel property verification (V)\n",
        "    * Hamiltonian ground state estimation (H), icl. Quantum k-SAT (S)\n",
        "    * Density matrix consistency (C)\n",
        "  * The **Local Hamiltonian problem** is a complexity class in quantum computing. It is the problem of determining the ground state energy of a local Hamiltonian. It is QMA-complete, which means that there exists a quantum algorithm that can solve the problem with a polynomial number of queries to a quantum oracle, and no classical algorithm can solve the problem with a polynomial number of queries to a classical oracle, unless P=BQP. The Local Hamiltonian problem is a fundamental problem in quantum computing. It is a key problem in the study of quantum algorithms for solving optimization problems.\n",
        "* [RE](https://en.m.wikipedia.org/wiki/RE_(complexity)) recursively enumerable, is the class of decision problems for which a 'yes' answer can be verified by a Turing machine in a finite amount of time. RE-complete problem: Halting problem.\n",
        "* [MIP* = RE ?](https://medium.com/mit-6-s089-intro-to-quantum-computing/mip-re-6e903720c82f), bzw [MIP* = RE (arXiv)](https://arxiv.org/abs/2001.04383) (aus Spektrum der Wissenschaft 7/20): enthält MIP* sämtliche berechenbaren Probleme der Informatik! Dem Beweis zufolge ist MIP identisch mit der riesigen Komplexitätsklasse RE. Sie umfasst alle Entscheidungsprobleme (solche, deren Antwort Ja oder Nein lautet), die ein Computer in endlicher Zeit bejahen kann. Darunter fällt unter anderem die hartnäckigste aller Aufgaben, das berühmte Halteproblem. Dabei geht es darum, zu bestimmen, ob ein Computer bei einer Berechnung jemals anhalten kann – oder für immer weiterrechnet.\n",
        "\n",
        "*Further important complexity classes*\n",
        "\n",
        "* [DQC1](https://en.m.wikipedia.org/wiki/One_Clean_Qubit): Deterministic quantum computation with one clean qubit is the class of decision problems solvable by a one clean qubit machine in polynomial time, upon measuring the first qubit, with an error probability of at most 1/poly(n) for all instances\n",
        "* [Optimization problems](https://en.m.wikipedia.org/wiki/Optimization_problem), see [Complexity Classes for Optimization Problems](https://home.in.tum.de/~kugele/files/JoBSIS.pdf): [PLS](https://en.m.wikipedia.org/wiki/PLS_(complexity)): a local optimal solution can be found in polynomial time, but it might not be the global optimal solution. **NPO** is the optimization equivalent to NP (candidate solution can be checked in polynomial time). [APX](https://en.m.wikipedia.org/wiki/APX) for problems that can be approximated within a constant factor in polynomial time.\n",
        "* [Function problems](https://en.m.wikipedia.org/wiki/Function_problem): [FP](https://en.m.wikipedia.org/wiki/FP_(complexity)): The function problem equivalent of P, where the task is to compute a specific output rather than just deciding yes/no.\n",
        "* [Sharp-P](https://de.m.wikipedia.org/wiki/Sharp-P) How many solutions are there? Sharp P complete problems: #SAT oder Anzahl der perfekten Matchings eines bipartiten Graphen\n",
        "* More: https://complexityzoo.net/Complexity_Zoo\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B8Sn02WrzXmF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1684.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1655.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1646.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1274.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1646.jpg)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1647.png)\n",
        "\n",
        "*Source [here](https://www.researchgate.net/figure/Computability-hierarchy-and-computational-complexity-classes_fig5_341817215)*"
      ],
      "metadata": {
        "id": "vQZjqUGyNu2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Computer Efficiency & Spacetime Complexity**\n",
        "\n",
        "*How to calculate Computer Performance?*: [Frontier supercomputer](https://en.m.wikipedia.org/wiki/Frontier_(supercomputer)) is capable of making 1,102,000 [TFLOPs](https://en.m.wikipedia.org/wiki/FLOPS) (1.1 quintillion calculations per second).  [Exascale_computing](https://en.m.wikipedia.org/wiki/Exascale_computing). [Floating-point_arithmetic](https://en.m.wikipedia.org/wiki/Floating-point_arithmetic). [Instructions_per_second](https://en.m.wikipedia.org/wiki/Instructions_per_second). [Gleitkommazahl](https://de.m.wikipedia.org/wiki/Gleitkommazahl) (floating point). [Floating_point_numbers](https://en.wikibooks.org/wiki/A-level_Computing/AQA/Paper_2/Fundamentals_of_data_representation/Floating_point_numbers). [Double-precision_floating-point_format](https://en.m.wikipedia.org/wiki/Double-precision_floating-point_format)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1273.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1683.jpg)\n",
        "\n",
        "New Breakthrough Brings Matrix Multiplication Closer to Ideal: https://www.quantamagazine.org/new-breakthrough-brings-matrix-multiplication-closer-to-ideal-20240307/\n",
        "\n",
        "\n",
        "[Researchers Approach New Speed Limit for Seminal Problem](https://www.quantamagazine.org/researchers-approach-new-speed-limit-for-seminal-problem-20240129/): Integer linear programming can help find the answer to a variety of real-world problems. Now researchers have found a much faster way to do it.\n",
        "\n",
        "Source: [Youtube](https://youtu.be/A5QTukT1VS8?si=tpAqnNWsgS9aWAEm), https://wires.onlinelibrary.wiley.com/doi/epdf/10.1002/wcms.1481\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1630.png)\n",
        "\n",
        "* Examples: [Computational complexity of mathematical operations](https://en.m.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations#Matrix_algebra) and [Computational complexity of matrix multiplication](https://en.m.wikipedia.org/wiki/Computational_complexity_of_matrix_multiplication)\n",
        "\n",
        "* **Time complexity vs Space complexity**: [Time Complexity](https://en.m.wikipedia.org/wiki/Time_complexity): Big O notation.\n",
        "  * The time complexity is the [computational complexity](https://en.m.wikipedia.org/wiki/Computational_complexity) that describes the amount of computer time it takes to run an algorithm. Time complexity is commonly estimated by counting the number of elementary operations performed by the algorithm. See also [Time hierarchy theorem](https://en.m.wikipedia.org/wiki/Time_hierarchy_theorem). [Space complexity](https://en.m.wikipedia.org/wiki/Space_complexity) is generally expressed as the amount of memory required by an algorithm on an input of size n. See also [Space hierarchy theorem](https://en.m.wikipedia.org/wiki/Space_hierarchy_theorem).\n",
        "  * [Time complexity](https://en.m.wikipedia.org/wiki/Time_complexity), Space Complexity = Auxiliary Space + Space used for input values, [Space time tradeoff](https://en.m.wikipedia.org/wiki/Space–time_tradeoff), [Garbage collection](https://de.m.wikipedia.org/wiki/Garbage_Collection), [Time and Space Complexity Analysis of Algorithm](https://afteracademy.com/blog/time-and-space-complexity-analysis-of-algorithm), [How to compute Time Complexity or Order of Growth of any program](https://www.rookieslab.com/posts/how-to-compute-time-complexity-order-of-growth-of-any-program)\n",
        "\n",
        "* Time Complexity: The amount of time it takes a learning algorithm to learn a concept. **\"quantum time complexity, defined as the total number of gates used by the algorithm**\". (Source: Survey on the complexity of learning quantum states)\n",
        "  * low sample complexity is a necessary condition for efficient learning, but information-theoretic sufficiency of a small sample is not much help in practice if finding a good hypothesis still takes much time (time complexity of best quantum learner vs best known classical learner)\n",
        "  * \"despite several distribution-specific speedups, quantum examples do not signifi- cantly reduce sample complexity if we require our learner to work for all distributions D. This should be contrasted with the situation when considering the time complexity of learning\"\n",
        "  * \"Exponential sample complexity when data is from quantum sensors. Time complexity is more subtle.\"\n",
        "\n",
        "* **Worst-case vs Average-case complexity**: [Worst-case_complexity](https://en.m.wikipedia.org/wiki/Worst-case_complexity) and [Average-case_complexity](https://en.m.wikipedia.org/wiki/Average-case_complexity)\n",
        "\n",
        "* [Big O notation (Landau)](https://en.m.wikipedia.org/wiki/Big_O_notation): Big (O) worste case / Big Ω (Omega) best case / Big θ (Theta), [Examples of runtime with big O](https://stackoverflow.com/questions/2307283/what-does-olog-n-mean-exactly), [Brilliant: Complexity Theory](https://brilliant.org/wiki/complexity-theory/), [Theory of computation](https://en.m.wikipedia.org/wiki/Theory_of_computation)"
      ],
      "metadata": {
        "id": "m13Q5iLjReWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Beispiele:**\n",
        "\n",
        "Video: [The Complexity of Dynamic Least-Squares Regression](https://www.youtube.com/watch?v=GLE3hjDRbQw) by Shunhua Jiang (Columbia University)\n",
        "\n",
        "Video: [Fast Algorithms for Regression Problems](https://www.youtube.com/watch?v=FqLCImQNpeg)\n",
        "\n",
        "\n",
        "* Does the complexity increase with larger p-norms, or not?*\n",
        "\n",
        "The complexity of linear regression with regularization using different p-norms (such as in Ridge regression for \\( p = 2 \\) or Lasso for \\( p = 1 \\)) does indeed vary, but not necessarily in a direct relationship with the value of \\( p \\).\n",
        "\n",
        "1. **L2 Norm (Ridge Regression - \\( p = 2 \\)):**\n",
        "   - Ridge regression adds a regularization term equal to the square of the magnitude of the coefficients (L2 norm) to the loss function. The computational complexity of ridge regression is similar to ordinary linear regression. The solving process involves matrix operations that are computationally intensive (like inversion), but these operations don't significantly increase in complexity with the addition of the L2 term.\n",
        "\n",
        "2. **L1 Norm (Lasso Regression - \\( p = 1 \\)):**\n",
        "   - Lasso regression uses the absolute value of the coefficients (L1 norm) as the regularization term. The main computational challenge with Lasso is that the absolute value function is not differentiable at zero, which complicates the optimization process. Specialized algorithms like coordinate descent are used, and the complexity can be higher compared to ridge regression, especially for high-dimensional data. However, this increased complexity is more due to the nature of the L1 norm rather than its size.\n",
        "\n",
        "3. **Higher p-norms:**\n",
        "   - In practice, norms higher than L2 are rarely used in linear regression. Theoretically, as \\( p \\) increases beyond 2, the optimization problem can become more challenging due to the increasing non-linearity and non-convexity of the norm. This could potentially lead to higher computational complexity, but such cases are not common in standard linear regression problems.\n",
        "\n",
        "In summary, the increase in computational complexity with different p-norms in linear regression is less about the size of \\( p \\) and more about the mathematical and computational characteristics of the norms themselves. L1 and L2 norms are the most commonly used, with L1 (Lasso) generally posing more computational challenges due to its non-differentiability at zero. Higher p-norms are not standard in linear regression and could potentially introduce more complex optimization challenges.\n",
        "\n",
        "*Why do higher p-norms show increasing non-linearity and non-convexity of the norm?*\n",
        "\n",
        "Higher p-norms exhibit increasing non-linearity and non-convexity due to the mathematical properties of the norms themselves. To understand this, let's first define the p-norm for a vector \\( \\mathbf{x} \\) in \\( \\mathbb{R}^n \\):\n",
        "\n",
        "\\[ \\|\\mathbf{x}\\|_p = \\left( \\sum_{i=1}^{n} |x_i|^p \\right)^{\\frac{1}{p}} \\]\n",
        "\n",
        "As \\( p \\) increases, the behavior of this norm changes:\n",
        "\n",
        "1. **Increasing Non-Linearity:**\n",
        "   - For \\( p < 1 \\), the p-norm is non-convex. As \\( p \\) approaches 1, the function becomes linear in nature (the L1 norm or Manhattan norm). Beyond \\( p = 1 \\), including the commonly used \\( p = 2 \\) (Euclidean norm), the function is convex but exhibits increasing non-linearity as \\( p \\) increases.\n",
        "   - The non-linearity arises because higher powers increasingly magnify larger components of the vector more than smaller ones. For instance, in the case of \\( p = 2 \\), squaring each component treats all components equally in terms of their sign but not in terms of their magnitude. As \\( p \\) increases further, this effect becomes more pronounced, leading to a function that responds very non-linearly to changes in the input vector.\n",
        "\n",
        "2. **Non-Convexity for \\( p > 1 \\):**\n",
        "   - For \\( p > 1 \\), the p-norms are always convex. This convexity is a crucial property for many optimization problems, including those in machine learning, as it ensures that any local minimum is also a global minimum.\n",
        "   - However, as \\( p \\) increases, the shape of the function becomes more \"peaky\" or \"sharp\" around the axes. This can be intuitively understood: for very large \\( p \\), the p-norm is heavily influenced by the largest component of the vector, almost ignoring the smaller components. This behavior can lead to a function that, while still convex, has very steep gradients near the axes, making optimization more challenging.\n",
        "\n",
        "3. **Practical Implications:**\n",
        "   - In optimization problems, such as those in machine learning, these properties have significant implications. Non-linear, sharp functions can lead to optimization challenges, such as difficulty in finding the global minimum due to steep gradients or flat regions.\n",
        "   - Moreover, the computational cost of evaluating higher p-norms can be significant, as it involves raising each component of the vector to a high power and then taking a root, operations that are more computationally intensive than those required for lower p-norms.\n",
        "\n",
        "In summary, the increase in non-linearity and the specific convexity shape of higher p-norms are inherent to their mathematical definition. These properties influence their practical use in fields like machine learning, where lower p-norms (like L1 and L2) are preferred due to their balance of computational feasibility and desirable optimization properties. Higher p-norms, while theoretically interesting, often present practical challenges for optimization.\n",
        "\n",
        "*How can you quantify the computational cost?*\n",
        "\n",
        "Quantifying the computational cost of an algorithm or a computational process involves assessing several factors, such as time complexity, space complexity, and the actual execution time and memory usage in practice. Here's a breakdown of how these are typically quantified:\n",
        "\n",
        "1. **Time Complexity:**\n",
        "   - Time complexity is a theoretical measure of the execution time of an algorithm as a function of the size of the input data. It's usually expressed in Big O notation (like O(n), O(n^2), O(log n)), which describes the upper limit of the growth rate of the runtime.\n",
        "   - This measure helps to understand how the execution time will increase as the input size grows. It's crucial for comparing different algorithms, especially in terms of their scalability.\n",
        "\n",
        "2. **Space Complexity:**\n",
        "   - Space complexity measures the amount of memory an algorithm needs in terms of the size of the input data. Like time complexity, it's also expressed in Big O notation.\n",
        "   - This aspect is important in scenarios where memory is a limiting factor, such as in embedded systems or when dealing with extremely large data sets.\n",
        "\n",
        "3. **Actual Execution Time:**\n",
        "   - The actual execution time is the real-time an algorithm takes to complete. This can be measured by running the algorithm and timing its execution.\n",
        "   - The actual execution time can vary based on several factors, including the hardware used, the efficiency of the implementation, and the specific characteristics of the input data.\n",
        "\n",
        "4. **Actual Memory Usage:**\n",
        "   - This is a practical measurement of the amount of memory used by an algorithm when it runs. It can be measured using profiling tools.\n",
        "   - Actual memory usage can vary from the theoretical space complexity due to factors like the efficiency of the memory allocation in the implementation and overheads imposed by the system or the programming environment.\n",
        "\n",
        "5. **Algorithmic Efficiency:**\n",
        "   - Efficiency takes into account both time and space complexity. An efficient algorithm is one that has both a lower time complexity and a lower space complexity.\n",
        "   - In practice, there's often a trade-off between time and space efficiency (known as the time-space trade-off). Optimizing for one can lead to increased usage of the other.\n",
        "\n",
        "6. **Profiling and Benchmarking:**\n",
        "   - In practice, profiling and benchmarking are used to quantify the computational cost of an algorithm. Profiling involves running the algorithm with specific tools to measure various performance metrics like execution time and memory usage.\n",
        "   - Benchmarking involves comparing these performance metrics under different conditions or against other algorithms to assess relative performance.\n",
        "\n",
        "In summary, quantifying computational cost involves a mix of theoretical analysis (time and space complexity) and practical measurements (actual execution time and memory usage). This assessment helps in understanding the efficiency of an algorithm and its suitability for a particular application, especially when resources are limited or when dealing with large-scale problems.\n",
        "\n",
        "*could you quantify the Time Complexity in advance without running the function?*\n",
        "\n",
        "Yes, you can quantify the time complexity of an algorithm in advance without actually running the function. This is typically done through theoretical analysis based on the algorithm's structure and operations. Here's how you might approach this:\n",
        "\n",
        "1. **Understand the Algorithm's Operations:**\n",
        "   - Analyze each part of the algorithm and identify the basic operations (like comparisons, assignments, arithmetic operations) and how often they are performed relative to the input size.\n",
        "   - Pay special attention to loops and nested loops, as they often play a significant role in determining time complexity.\n",
        "\n",
        "2. **Counting Basic Operations:**\n",
        "   - For each line of code or each operation, estimate how many times it will be executed in terms of the size of the input. For instance, a single loop from 1 to \\( n \\) suggests \\( n \\) iterations, while a nested loop might suggest \\( n^2 \\) iterations.\n",
        "\n",
        "3. **Big O Notation:**\n",
        "   - Express the total number of basic operations in Big O notation. This involves finding the term with the fastest-growing rate and ignoring constants and less significant terms. For example, if the total operations are \\( 5n^2 + 3n + 8 \\), the time complexity is \\( O(n^2) \\).\n",
        "\n",
        "4. **Consider the Worst, Average, and Best Cases:**\n",
        "   - Analyze the time complexity for different scenarios: worst-case (upper bound), average case (expected complexity for a random input), and best case (lower bound). Sometimes, the complexity might be the same for all cases, but often it varies.\n",
        "\n",
        "5. **Comparing Different Parts of the Algorithm:**\n",
        "   - If the algorithm has different components or phases, analyze each part separately and then combine the results. The overall complexity is dominated by the part with the highest complexity.\n",
        "\n",
        "6. **Recursion:**\n",
        "   - For recursive algorithms, establish the recurrence relation describing the algorithm and solve it to find the time complexity.\n",
        "\n",
        "7. **Amortized Analysis:**\n",
        "   - In some cases, especially with algorithms that have occasional expensive operations, an amortized analysis might be more appropriate. This looks at the time complexity over a sequence of operations, providing an average time per operation.\n",
        "\n",
        "8. **Empirical Validation (Optional):**\n",
        "   - While not necessary for theoretical analysis, sometimes running the algorithm with different input sizes and measuring the execution time can validate your theoretical complexity analysis.\n",
        "\n",
        "It's important to note that this analysis provides an upper bound on the growth rate of the execution time and does not give the exact execution time, which can depend on factors like hardware, compiler optimizations, and specifics of the input data.\n",
        "\n",
        "*for linear regression using L2 norm the time complexity is n^2, or not?*\n",
        "\n",
        "The time complexity of linear regression using the L2 norm (Ridge Regression) isn't simply \\( n^2 \\); it depends on various factors including the number of features (denoted as \\( m \\)) and the number of training samples (denoted as \\( n \\)). Let's break it down:\n",
        "\n",
        "1. **Using the Normal Equation:**\n",
        "   - The normal equation for Ridge Regression is \\((X^TX + \\lambda I)^{-1}X^Ty\\), where \\( X \\) is the feature matrix, \\( y \\) is the target vector, \\( \\lambda \\) is the regularization parameter, and \\( I \\) is the identity matrix.\n",
        "   - The computationally intensive step here is the matrix multiplication \\( X^TX \\) and the matrix inversion \\((X^TX + \\lambda I)^{-1}\\).\n",
        "   - The multiplication \\( X^TX \\) has a complexity of \\( O(m^2n) \\), as it involves multiplying an \\( n \\times m \\) matrix with its transpose \\( m \\times n \\).\n",
        "   - Matrix inversion typically has a complexity of \\( O(m^3) \\) using standard algorithms like Gaussian elimination.\n",
        "   - So, the overall complexity would be dominated by the higher of \\( O(m^2n) \\) and \\( O(m^3) \\).\n",
        "\n",
        "2. **Using Gradient Descent:**\n",
        "   - If Ridge Regression is solved using gradient descent, the time complexity per iteration is \\( O(mn) \\), since each update requires computing gradients over all \\( n \\) samples and \\( m \\) features.\n",
        "   - However, the total number of iterations needed to converge can vary widely depending on the learning rate and the specifics of the dataset.\n",
        "\n",
        "In conclusion, the time complexity of linear regression using the L2 norm is not simply \\( n^2 \\); it depends on the method used for solving the regression and the relationship between the number of features \\( m \\) and the number of samples \\( n \\). For the normal equation method, it's generally the higher of \\( O(m^2n) \\) and \\( O(m^3) \\), while for gradient descent, it's \\( O(mn) \\) per iteration."
      ],
      "metadata": {
        "id": "JkiTC1xozlAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"Blue\">*Algorithmic Complexity*"
      ],
      "metadata": {
        "id": "Gj-d2EYc2e7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [Algorithmic Information (Algorithmic Complexity)](https://en.m.wikipedia.org/wiki/Algorithmic_information_theory) = <u>**How difficult is it to describe a function concisely?**</u>\n",
        "\n",
        "* Rayo's number is the smallest number that cannot be expressed anymore- an example??\n",
        "\n",
        "* One motivation: Boltzmann's famous example of monkeys typing on typewriters will eventually end up writing a book by Shakespear - but chances are vanishing small, much longer than our universe.\n",
        "  * Same is for chance that monkey type first x digits of Pi correct - very small\n",
        "  * But going down to program level: what's the chance of writing a program / function that spits out all numbers of Pi? That is much more likely by monkeys.\n",
        "  * Then you can also ask: what things you can NOT describe with short programs anymore? where you need an instruction that is the same size of it's output (Kolmogorof complexity)? Example: Any real number!\n",
        "\n",
        "* [Mathematical Simplicity May Drive Evolution’s Speed](https://www.quantamagazine.org/computer-science-and-biology-explore-algorithmic-evolution-20181129/): for some outputs, it’s computationally easier to describe how to generate something than to actually generate it. The probability of producing some types of outputs is far greater when randomness operates at the level of the program describing it rather than at the level of the output itself, because that program will be short.\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1679.png)\n",
        "\n",
        "* Algorithmic Information Theory (AIT) (Algorithmic Complexity): minimum amount of information, or minimum size of algorithm that you need to express a problem or function unambigously. AIT is study of relationship between computation and information, and is concerned with [Kolmogorov Complexity](https://en.m.wikipedia.org/wiki/Kolmogorov_complexity) of objects (Algorithmic Complexity or Solomonoff–Kolmogorov–Chaitin complexity)\n",
        "  * Is a measure of complexity of a particular string in terms of all algorithms that generate it.\n",
        "  * Kolmogorov Complexity is **the length of the shortest computer program that can generate the object**.\n",
        "  * Complexity of X is the length of the shortest description d such that if you feed it into the universal Turing machine, it spits out the string X.\n",
        "  * When a string has no short description (means the complexity is about the length of X and I need to feed the entire string into a universal Turing machine), that means the string is random.\n",
        "  * So Kolmogorov complexity is equal to their length = shortest program that can solve a problems is just as long as the input to the problem.\n",
        "* AIT is typically concerned with the complexity of individual objects, such as strings or Turing machines (as opposed to Computational Complexity Theory which looks at entire classes of problems)\n",
        "\n",
        "\n",
        "> <font color=\"Blue\">**Algorithmic Complexity Theory and Algorithmic Information Theory: It‘s useful to talk about complexity of models or structures in terms of minimum amount of information, or minimum size of algorithm that you need to express that unambigously.**</font>\n",
        "\n",
        "* **Example 1: What is simpler: a single integer or the set of all integers?** (from Kolmogorov complexity)\n",
        "  * Answer is counter-intuitive: it’s not a single integer, because the vast majority of all integers are way more complicated than the set of all possible integers.\n",
        "  * Because you can write down a simple algorithm, rule or mathematical expression that unambigously defines the set of all possible integers. But a single integer can require an arbitrarily large amount of information to express.\n",
        "  * So from a Kolmogorov complexity standpoint or algorithmic information complexity standpoint most integers are more complicated than the set of all integers.\n",
        "  * **This is been used as an argument in favor of the multiverse**. As an ontology: what‘s simpler: just our un universe exists, or the space of all possible universes exist? The latter is more plausible [Source](https://youtu.be/DaKR-UiYd6k?si=hZ-qbpiRU4gDxt9E)\n",
        "\n",
        "* **Example 2:  Is the universe predictable and definable by a finite set of symbols (Computational Irreducability)?**\n",
        "  * Assuming universe is computable, is it also predictable (=computationally reducable), or you need to run it?\n",
        "  * [Computational Irreducability](https://en.m.wikipedia.org/wiki/Computational_irreducibility) theory: no model can predict using only initial conditions, exactly what will occur in a given physical system before an experiment is conducted. It is a topic in both computational complexity theory (=problems cannot be solved efficiently by any algorithm) and algorithmic information theory (=how difficult it is to describe the object using a computer program).\n",
        "  * **Wolfram argues that many natural systems are computationally irreducible, which means that they cannot be simulated efficiently by any computer program**. Examples of problems that are thought to be computationally irreducible:\n",
        "    * The halting problem: determining whether a given computer program will halt or run forever. The factoring problem: factoring a large number into its prime factors.\n",
        "    * <font color=\"Blue\">These problems are thought to be computationally irreducible **because their Kolmogorov complexity is equal to their length. In other words, the shortest program that can solve these problems is just as long as the input to the problem**.</font>\n",
        "  * Universe: It seems that **there is no simplification that you can make. you just have to do the computation from beginning to end to work it out how the universe is going to evolve** (we have to explicitely simulate every step, there is no equation that spits out the answer, because it‘s fundamentally irredusable). Examples fluid mechanics: where is every molecule? We have to simulate it, e.g. position of individual molecules, that is completely unknown, would require arbitrary amounts of computational effort to determine. You need to use Coarse grain to make bulk statements: navier stokes or euler equation, Partition functions, Boltzmann equatio, Ergodicity: there is no net movement of particles in any direction. One particle distribution function, chapman-enskog expansion. From [Video 1](https://youtu.be/EIyjaCwbYXQ?si=-rmxgdj7Bpz945Fm) and [Video 2](https://youtu.be/DaKR-UiYd6k?si=pOSreHgxonkg4Wr9).\n",
        "  * Parts of universe seem to be computable and definable with a finite set of symbols, at least based on our current understanding of physics and mathematics. However, the complete computability and definability of the universe remain open questions, subject to ongoing scientific and philosophical inquiry. It is an area where new discoveries and insights can potentially reshape our understanding in fundamental ways.\n",
        "\n",
        "* **Further problems and examples in AIT**\n",
        "\n",
        "  * **Assembly Theory**: [Assembly theory](https://en.m.wikipedia.org/wiki/Assembly_theory) is a hypothesis that characterizes object complexity - molecules produced by biological processes must be more complex than those produced by non-biological processes. [Article](https://www.quantamagazine.org/a-new-theory-for-the-assembly-of-life-in-the-universe-20230504/). It studies complexity of constructing objects from smaller components and is **based on idea that complexity of an object is equal to minimum number of steps required to construct it from a set of primitive components**. (AT is more focused on construction of objects, while AIT is more focused on description of objects)\n",
        "\n",
        "  * **Constructor Theory** (Chiara Marletto and David Deutsch). [Constructor_theory](https://en.m.wikipedia.org/wiki/Constructor_theory). [How to Rewrite the Laws of Physics in the Language of Impossibility](https://www.quantamagazine.org/with-constructor-theory-chiara-marletto-invokes-the-impossible-20210429/). [Physicists Rewrite the Fundamental Law That Leads to Disorder](https://www.quantamagazine.org/physicists-trace-the-rise-in-entropy-to-quantum-information-20220526/). It studies complexity of constructing objects from smaller components and is **based on idea that complexity of an object is equal to minimum number of steps required to construct it from a set of primitive components**. (CT is more focused on construction of objects, while AIT is more focused on the description of objects)\n",
        "\n",
        "  * Quantamagazine: [Mathematical Simplicity May Drive Evolution’s Speed](https://www.quantamagazine.org/computer-science-and-biology-explore-algorithmic-evolution-20181129/)\n",
        "\n",
        "* **Difference to Computational Complexity Theory (CCT):**\n",
        "\n",
        "  * CCT: **Can a problem be solved** in polynomial time? - Complexity of **classes** of computational problems.\n",
        "\n",
        "  * AIT: **How complex** is a given string? Complexity of **individual objects**.\n",
        "\n",
        "  * Algorithmic complexity (Kolmogorov): Length of the shortest program that can generate a given output. How difficult it is to describe an object using a computer program?\n",
        "\n",
        "* **Connections to Computational Complexity Theory (CCT):**\n",
        "\n",
        "  * AIT provides a theoretical foundation for CCT. CCT is study of amount of resources (time and space) required to solve computational problems. CCT is concerned with complexity of classes of problems (P, NP).\n",
        "\n",
        "  * **AIT can prove lower bounds on time and space complexity**: define complexity classes P and NP (with Kolmogorov complexity) or study computational complexity of certain problems (sorting list of numbers). [Minimum Description Length (MDL) principle](https://en.m.wikipedia.org/wiki/Minimum_description_length) is based on AIT and used in ML."
      ],
      "metadata": {
        "id": "yy8Hru9l28pr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problems at intersection between Computability Theory and Algorithmic Information Theory (Algorithmic Complexity)**\n",
        "\n",
        "> <font color=\"blue\">**Three dimensions of complexity of function or problem:**</font>\n",
        "* **Is it computable (solvable, or undecidable)?** (<font color=\"blue\">computability theory</font>)\n",
        "* **Is it computable efficiently (in finite spacetime)?** (<font color=\"blue\">computational complexity theory</font>)\n",
        "* **Is it describable concisely (with finite set of symbols)?** (<font color=\"blue\">algorithmic complexity / information theory</font>)\n",
        "\n",
        "*Special: **Is it predictable = simulatable efficiently** by any computer program? (computationally irreducibility theorem)  (a topic in computational complexity theory=problems cannot be solved efficiently by any algorithm, and algorithmic information theory=how difficult it is to describe the object using a computer program)*\n",
        "\n",
        "**Example: Number Theory and Computability: Difference between (in)finite value and (in)finite instruction within ZFC?**\n",
        "\n",
        "<font color=\"red\">**Computable and definable with finite set of symbols**\n",
        "* Algorithms for Prime Numbers, Fibonacci sequence\n",
        "* Graham's number is the biggest number used constructively (is not transfinite) - it is definable using a finite set of symbols, as evidenced by its representation in Knuth's up-arrow notation.\n",
        "* Tree3. Loaders number. SCG(13) and SSCG(3)\n",
        "\n",
        "<font color=\"red\">**Not Computable but still definable with finite set of symbols**\n",
        "* **Busy Beaver function**: ZFC can define the Busy Beaver function itself, in less than, say, a billion symbols. But ZFC can't pin down the precise value of even BB(7918) = can not determine specific values of the function. Closely related to undecidable Halting problem.\n",
        "* **Rayo's number**: largest number nameable by an expression in first-order set theory with a given finite number of symbols. The number it represents is so vast that it transcends ordinary concepts of computability and representation in mathematics.\n",
        "* **Chaitin's number**: is transfinite and it is not computable, which means that there is no algorithm to compute its digits exactly. Closely related to undecidable Halting problem.\n",
        "* **Transfinite numbers**: are numbers that are greater than any finite number. They represent different \"sizes\" of infinity. The concept was introduced by Georg Cantor. Two most well-known transfinite numbers are ℵ₀ (aleph-null) and ℵ₁ (aleph-one). Transfinite numbers are not computable in the traditional sense because they represent infinite values. Despite their infinite nature, transfinite numbers can be defined using a finite set of symbols. For example, ℵ₀ is defined as the cardinality (size) of the set of natural numbers, and ℵ₁ is defined as the next larger infinite cardinal number.\n",
        "\n",
        "<font color=\"red\">**Not Computable and not definable with finite set of symbols**\n",
        "* **Most real numbers**: Fast alle reelle Zahlen sind nicht berechenbar, [gehorchen nicht einmal einer Rechenvorschrift](https://www.spektrum.de/kolumne/die-meisten-reellen-zahlen-sind-nicht-berechenbar/2133762), there are uncountably many real numbers, but only countably many finite strings of symbols with which to define numbers. This means that almost all real numbers are not definable with a finite set of symbols.\n",
        "* Computing **very large and precise value of the busy beaver function** can be either undefinable by finite set of symbols, or not practically / efficently feasible but still possible with a very very large, finite set of symbols. This isn't cut-clear.\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1631.png)\n",
        "\n",
        "Source: [All the Numbers - Numberphile](https://www.youtube.com/watch?v=5TkIe60y2GI&t=458s). See also: [Large_numbers](https://en.m.wikipedia.org/wiki/Large_numbers), [Names of large numbers](https://en.m.wikipedia.org/wiki/Names_of_large_numbers), [Liste besonderer Zahlen](https://de.m.wikipedia.org/wiki/Liste_besonderer_Zahlen), [Constructible numbers](https://en.m.wikipedia.org/wiki/Constructible_number), [Algebraic numbers](https://en.m.wikipedia.org/wiki/Algebraic_number), [Transcendental numbers](https://en.m.wikipedia.org/wiki/Transcendental_number), [Computable numbers](https://en.m.wikipedia.org/wiki/Computable_number). **Non-Computable numbers**: [Chaitin constant](https://en.m.wikipedia.org/wiki/Chaitin%27s_constant). [Die meisten reellen Zahlen kennen wir nicht](https://www.spektrum.de/kolumne/die-meisten-reellen-zahlen-sind-nicht-berechenbar/2133762) (gehorchen nicht einmal einer Rechenvorschrift). **Special cross-section**: [Normal numbers](https://en.m.wikipedia.org/wiki/Normal_number): [Champernowne’s constant](https://en.m.wikipedia.org/wiki/Champernowne_constant) (whole numbers) - normal and transendental. [Copeland-Erdös-number](https://de.m.wikipedia.org/wiki/Copeland-Erdős-Zahl) (primes). **Empty section: normal and Non-Computable numbers (we have no examples)**: We have no examples. But proofs have shown: this is the greatest amount of numbers: most numbers are normal and most numbers are uncomputable. So this section should be full, but we have no example."
      ],
      "metadata": {
        "id": "6431aTWzeYh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"Blue\">*Computability Theory*"
      ],
      "metadata": {
        "id": "gNGVQC0OENoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [Computability_theory](https://en.m.wikipedia.org/wiki/Computability_theory) = <u>**Can a function be computed (solved) on a Turing machine?**</u>\n",
        "\n",
        "* What problems can be solved? (Halting, Entscheidungsproblem, etc. with Turing machine, finite automata..)\n",
        "\n",
        "* [An Easy-Sounding Problem Yields Numbers Too Big for Our Universe](https://www.quantamagazine.org/an-easy-sounding-problem-yields-numbers-too-big-for-our-universe-20231204/) - Researchers prove that navigating certain systems of vectors is among the most complex computational problems.\n",
        "\n",
        "* Video: [Extended Church Turing thesis](https://youtu.be/gs2Pv2vHqn8?si=bkcy04UGegfa7_yd)\n",
        "\n",
        "* COMPUTABILITY: [How to Build an Origami Computer](https://www.quantamagazine.org/how-to-build-an-origami-computer-20240130/) (quantamagazine)\n",
        "\n",
        "* Computability_theory **studies the theoretical limits of what can be computed by an idealized computing device**, such as a [Turing machine](https://en.m.wikipedia.org/wiki/Turing_machine). [Church Turing Thesis](https://en.m.wikipedia.org/wiki/Church%E2%80%93Turing_thesis): all algorithms may be thought of as Turing machines. apply to all function. you cannot short cut computation: Halting problem.\n",
        "\n",
        "  * **Turing**: functions that can be computed by Turing machine is computable by humans using paper and pencil\n",
        "\n",
        "  * **Gödel**: there are certain statements that cannot be proven or disproven within any formal system (incompleteness theorem). Implications for computability theory: **there are some functions that cannot be computed by any Turing machine (Halting problem, Collatz conjecture, Turing degrees)**\n",
        "\n",
        "* Video: [Church-Turing Thesis Cannot Possibly Be True\n",
        "](https://www.youtube.com/watch?v=egK4xhuWsVY&t=61s):\n",
        "  * The thesis asserts this: If an algorithm A computes a partial function f from natural numbers to natural numbers then f is partially recursive, i.e., the graph of f is recursively enumerable.\n",
        "  * The thesis has been formulated in 1930s. The only algorithms at the time were sequential algorithms. Sequential algorithms were axiomatized in 2000. This axiomatization was used in 2008 to prove the thesis for sequential algorithms, i.e., for the case where A ranges over sequential algorithms.\n",
        "  * These days, in addition to sequential algorithms, there are parallel algorithms, distributed algorithms, probabilistic algorithms, quantum algorithms, learning algorithms, etc.\n",
        "  * The question whether the thesis is true in full generality is actively discussed from 1960s. We argue that, in full generality, the thesis cannot possibly be true.\n",
        "\n",
        "* Computability theory provides the theoretical foundation for computational complexity theory (CCT), and many of the problems studied in CCT are motivated by questions in computability theory.\n",
        "\n",
        "* A computable **number** a real number that can be calculated to any desired precision by finite, terminating algorithm. But: almost no real numbers are computable.\n",
        "* A computable **function** requires a finite number of steps to produce the output. The Busy Beaver function Σ(n) grows faster than any computable function. Hence, it is not computable; only a few values are known.\n",
        "\n",
        "*See [Computability (Berechenbarkeit)](https://en.m.wikipedia.org/wiki/Computability), [Analysis of algorithms](https://en.m.wikipedia.org/wiki/Analysis_of_algorithms), [Model of Computation](https://en.m.wikipedia.org/wiki/Model_of_computation), [Theory of Computation](https://en.m.wikipedia.org/wiki/Theory_of_computation), [Algorithmic Information Theory](https://en.m.wikipedia.org/wiki/Algorithmic_information_theory), [Undecidable problem](https://en.m.wikipedia.org/wiki/Undecidable_problem), [List of undecidable problems](https://en.m.wikipedia.org/wiki/List_of_undecidable_problems), [Limits of Computation](https://en.m.wikipedia.org/wiki/Limits_of_computation), [Pfeilschreibweise](https://de.m.wikipedia.org/wiki/Pfeilschreibweise), [Hyper-Operator](https://de.m.wikipedia.org/wiki/Hyper-Operator), [Potenzturm](https://de.m.wikipedia.org/wiki/Potenzturm), [Long_and_short_scales](https://en.m.wikipedia.org/wiki/Long_and_short_scales)*"
      ],
      "metadata": {
        "id": "ERjGs_IMvI3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum Extended Church Turing thesis (qECTT)**\n",
        "* Quantum Extension: The qECTT proposes that any physically realizable computational device can be efficiently simulated by a quantum Turing machine. **In essence, it posits that quantum computers, though vastly more powerful than classical computers, still operate within limits that can be, in principle, simulated**.\n",
        "* Most researchers think it's valid. If yes, it would forbid \"supertasks\" like solving the halting problem (Quantum computers remain fundamentally powerful but seem unlikely to enable true hypercomputation).\n",
        "* Open Question: However, the door isn't fully closed. Exotic models of quantum mechanics or yet-undiscovered physics could offer surprises, and philosophical debates over the definition of computation itself contribute to the ongoing discussion.\n",
        "\n",
        "* The **quantum extended Church-Turing thesis** (qECTT) states that any physical system that can compute any function computable by a quantum Turing machine can be efficiently simulated by a quantum Turing machine.\n",
        "\n",
        "> **In other words, the qECTT asserts that quantum computers are the most powerful physical computers possible, and that no other physical system can compute any function that a quantum computer cannot efficiently compute.**\n",
        "\n",
        "The qECTT is based on the following two premises:\n",
        "\n",
        "1. Quantum computers are more powerful than classical computers, in the sense that they can efficiently solve certain problems that are intractable for classical computers.\n",
        "  * The first premise is well-established, and has been demonstrated by the development of quantum algorithms that can efficiently solve certain problems that are intractable for classical computers, such as Shor's algorithm for factoring large numbers and Grover's algorithm for searching unsorted databases.\n",
        "2. Any physical system that can compute any function can be efficiently simulated by a quantum Turing machine.\n",
        "  * The second premise is more speculative, but it is supported by the fact that quantum Turing machines are a universal model of computation, meaning that they can simulate any other physical system of computation.\n",
        "\n",
        "> <font color=\"blue\">**The qECTT is still an open question**, but it is a very important one, as it has **implications for the limits of what is computable in the physical world**</font>. If the qECTT is true, then it means that quantum computers are the most powerful physical computers possible, and that there are certain problems that cannot be efficiently solved by any physical computer.\n",
        "\n",
        "* Interesting example and contradiction of the qECTT:\n",
        "\n",
        "  * Suppose that there is a physical system, such as a black hole, that can compute some function that cannot be efficiently computed by a quantum Turing machine. Then, the qECTT predicts that there is a quantum Turing machine that can efficiently simulate the black hole, and thus also compute the function.\n",
        "\n",
        "  * This is a very powerful prediction, and it is still not known whether it is true. However, <font color=\"blue\">**if the qECTT is true, then it would have implications for our understanding of the nature of computation and the limits of what is possible in the universe**</font>.\n",
        "\n",
        "  * This is a contradiction because it implies that there is a quantum Turing machine that can compute any function, which is not possible. The Church-Turing thesis states that there are some functions that cannot be computed by any Turing machine, and the qECTT is an extension of the Church-Turing thesis to quantum computers.\n",
        "\n",
        "  * So, the contradictory example of the qECTT shows that the qECTT itself is not a valid thesis. However, it is still an interesting and important question to ask whether there are any physical systems that can compute functions that cannot be efficiently computed by quantum computers.\n",
        "\n",
        "* ***One possible resolution to the contradiction is to say that the qECTT only applies to physical systems that are consistent with the laws of physics***. If there is a physical system that can compute a function that cannot be efficiently computed by a quantum Turing machine, then it must be a system that violates the laws of physics.\n",
        "\n",
        "* ***Another possible resolution to the contradiction is to say that the qECTT only applies to physical systems that are efficient***. If there is a physical system that can compute a function that cannot be efficiently computed by a quantum Turing machine, then it must be a system that is very inefficient.\n",
        "\n",
        "> Ultimately, the question of whether the qECTT is valid or not is an open one. It is a very important question, as it has implications for the limits of what is computable in the physical world."
      ],
      "metadata": {
        "id": "zltUffjrn2_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chomsky-Hierarchy and Automata Theory**\n",
        "\n",
        "* [Formal language](https://en.m.wikipedia.org/wiki/Formal_language) consists of words from letters from an alphabet and are well-formed acc. to specific set of rules\n",
        "* Automata theory and [Chomsky hierarchy](https://en.m.wikipedia.org/wiki/Chomsky_hierarchy) are used to **classify the complexity of languages**.\n",
        "* [Automata theory](https://en.m.wikipedia.org/wiki/Automata_theory) is study of abstract machines and automata, and computational problems that can be solved\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1651.png)\n",
        "\n",
        "\n",
        "**Beyond Turing Machines**: [Undecidable function](https://en.m.wikipedia.org/wiki/Undecidable_problem) with [List of undecidable problems](https://en.m.wikipedia.org/wiki/List_of_undecidable_problems)\n",
        "\n",
        "  * Undecidable functions can be used to show that certain languages are not in the Chomsky hierarchy. For example, the language of all strings that encode a Turing machine that halts on its own input is not context-sensitive. This is because if there were a context-sensitive grammar for this language, then we could use it to solve the halting problem by simply constructing a Turing machine from the grammar.\n",
        "\n",
        "  * In general, undecidable functions can be used to show that certain problems are not solvable by any algorithm. This is a powerful tool for understanding the limits of computation.\n",
        "\n",
        "\n",
        "**0. Type:** [Recursively enumerable](https://en.m.wikipedia.org/wiki/Recursively_enumerable_language) grammar = [Turing Machine](https://en.m.wikipedia.org/wiki/Turing_machine)\n",
        "\n",
        "  * Unlimited RAM, Recursively and enumerable are unrestricted, most general grammar and automata and allow general computation, the Turing machines = machines that can remember an unlimited number of states. See also: [Nondeterministic Turing machine](https://en.m.wikipedia.org/wiki/Nondeterministic_Turing_machine) and [Probabilistic_Turing_machine](https://en.m.wikipedia.org/wiki/Probabilistic_Turing_machine). Also: [Quantum Turing Machine (QTM](https://en.m.wikipedia.org/wiki/Quantum_Turing_machine), [quantum circuit](https://en.m.wikipedia.org/wiki/Quantum_circuit) is computationally equivalent. QTM can be related to classical and probabilistic Turing machines with [transition (Stochastic_matrix) matrices](https://en.m.wikipedia.org/wiki/Stochastic_matrix).\n",
        "\n",
        "    *  A quantum Turing machine (QTM) with postselection was defined by Scott Aaronson, who showed that class of polynomial time on such a machine (PostBQP) is equal to classical complexity class PP.\n",
        "    * A way of understanding the Quantum Turing machine (QTM) is that it generalizes the classical Turing machine (TM) in the same way that the quantum finite automaton (QFA) generalizes the deterministic finite automaton (DFA). In essence, the internal states of a classical TM are replaced by pure or mixed states in a Hilbert space; the transition function is replaced by a collection of unitary matrices that map the Hilbert space to itself.\n",
        "\n",
        "  * **Type a**: [Recursively enumerable function](https://en.m.wikipedia.org/wiki/Recursively_enumerable_language): [Busy beaver](https://en.m.wikipedia.org/wiki/Busy_beaver) (does not terminate)for some arguments you put into the function they will stop and give an answer and for others they will go on forever)\n",
        "\n",
        "  * **Type b**: [Recursive](https://en.m.wikipedia.org/wiki/Recursive_language) language and [Recursive functions](https://en.m.wikipedia.org/wiki/General_recursive_function): is [Ackermann function](https://en.m.wikipedia.org/wiki/Ackermann_function) (terminates). Not every total recursive function is a primitive recursive function—the most famous example is the [Ackermannfunktion](https://de.m.wikipedia.org/wiki/Ackermannfunktion): extrem schnell wachsende Funktion, mit deren Hilfe in der theoretischen Informatik Grenzen von Computer- und Berechnungsmodellen aufgezeigt werden können. Die [Sudanfunktion](https://de.wikipedia.org/wiki/Sudanfunktion) ist eine rekursive berechenbare Funktion, die total μ-rekursiv, **jedoch nicht primitiv rekursiv** ist, was sie mit der bekannteren Ackermannfunktion gemeinsam hat.\n",
        "\n",
        "  * **Type c**: [Primitive Recursive function](https://en.m.wikipedia.org/wiki/Primitive_recursive_function), incl. every other program that isn’t recursive, like something going through a Sequence, for loop and nested for loops. 1926 vermutete David Hilbert, dass jede [berechenbare](https://de.m.wikipedia.org/wiki/Berechenbarkeit) Funktion [primitiv-rekursiv](https://de.m.wikipedia.org/wiki/Primitiv-rekursive_Funktion) sei, siehe auch [Berechenbarkeitstheorie](https://de.m.wikipedia.org/wiki/Berechenbarkeitstheorie): **lässt sich jede durch einen Computer berechenbare Funktion aus einigen wenigen, sehr einfachen Regeln zusammensetzen und die Dauer der Berechnung im Voraus abschätzen?**. Ackermann und Sudan haben das widerlegt. Die Sudanfunktion und die Ackermannfunktion waren so die ersten veröffentlichten, nicht primitiv rekursiven Funktionen. ps: [Enumeration algorithm](https://en.m.wikipedia.org/wiki/Enumeration_algorithm). [Recursive function](https://en.m.wikipedia.org/wiki/Recursion_(computer_science)), also [Computable function](https://en.m.wikipedia.org/wiki/Computable_function), calls itself again to repeat code. An [iterative function](https://en.m.wikipedia.org/wiki/Iteration) repeatedly executes set of statements (code) without overhead of function calls and stack memory (simpler, faster).\n",
        "\n",
        "\n",
        "**1. Type:** [Context-sensitive](https://en.m.wikipedia.org/wiki/Context-sensitive_language) grammars =  [Linear bounded automata](https://en.m.wikipedia.org/wiki/Linear_bounded_automaton)\n",
        "\n",
        "  * Limited RAM needed, but you can predict how much RAM (turing machines with predictable and finite amount of RAM). Linear bounded automata can remember a stack of states and a counter. Context-sensitive languages are used to model the set of all strings that are syntactically correct in a programming language.\n",
        "\n",
        "  * On Turing machines the tape has unbounded length (unlimited tape). An LBA can access only a finite portion of the tape by the read/write head. **This makes an LBA a more accurate model of a real-world computer than a Turing machine.** A linear bounded automaton is a [nondeterministic Turing machine](https://en.m.wikipedia.org/wiki/Nondeterministic_Turing_machine)\n",
        "\n",
        "**2. Type:** [Context-free](https://en.m.wikipedia.org/wiki/Context-free_grammar) grammars = [Pushdown Automata](https://en.m.wikipedia.org/wiki/Pushdown_automaton)\n",
        "  \n",
        "  * No RAM needed, for example for parsing. Pushdown automata can recognize context-free languages (e.g. set of all balanced parentheses) because pushdown automata have a stack, which they can use to store information about the input string. This allows them to keep track of the context of the input string, which is necessary for recognizing context-free languages.\n",
        "\n",
        "**3. Type:** [Regular](https://en.m.wikipedia.org/wiki/Regular_language) grammars = [Finite State Machine](https://en.m.wikipedia.org/wiki/Finite-state_machine)\n",
        "\n",
        "  * Finite state automata: machines that can only remember a finite number of states. Regular languages are used to model simple patterns, such as the set of all strings of even length.\n",
        "\n",
        "  * z.B. [Deterministic Finite Automaton](https://en.m.wikipedia.org/wiki/Deterministic_finite_automaton) and [Quantum Finite Automaton](https://en.m.wikipedia.org/wiki/Quantum_finite_automaton). Finite automata: pattern recognition, regular expressions.\n",
        "\n",
        "\n",
        "*Exkurs: Combinational Logic vs Sequential logic (Automata theory): [Sequential logic](https://en.m.wikipedia.org/wiki/Sequential_logic): type of logic circuit whose output depends on present value of its input signals and on sequence of past inputs (history). Sequential logic has state (memory). Sequential logic is used to store the state of the automaton, which is necessary to track the current position of the tape head and the symbols that have been read (more complex, because requires a larger number of memory elements, and the logic to update the state of the automaton can be more complicated). The sequential logic is implemented using flip-flops, which are memory elements that can store a single bit of information. [Combinational Logic](https://en.m.wikipedia.org/wiki/Combinational_logic): output is a function of only the present input. Combinational logic does not have a state (memory). Combinatorial logic is used to determine the next state of the automaton and the output symbol to be written to the tape, based on the current state, the input symbol, and the contents of the tape. Combinational logic is used in computer circuits to perform Boolean algebra on input signals and on stored data. The ALU is constructed using combinational logic, also half adders, full adders, half subtractors, full subtractors, multiplexers, demultiplexers, encoders and decoders, AND, OR, and NOT. The combinational logic is typically much simpler than the sequential logic. This is because the next state of the automaton and the output symbol to be written to the tape can be determined by a relatively small number of input variables.*\n",
        "\n"
      ],
      "metadata": {
        "id": "3cQ2ILoRRcAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Beyond Automata: Computational irreducibility and graphs**\n",
        "\n",
        "https://www.spektrum.de/news/stephen-wolfram-sucht-nach-der-weltformel-der-physik/2203229\n",
        "\n",
        "Die Zoologie der Graphensubstitutionsregeln ist um Klassen schwieriger als die der zellulären Automaten. Vor allem sieht man einer Regel im Allgemeinen nicht an, welche Graphen sie auf die Dauer produzieren wird. Von Ausnahmen abgesehen gibt es keine andere Möglichkeit, das herauszufinden, als die Regel ihre Arbeit machen zu lassen, ein Phänomen, das Wolfram »rechnerische Irreduzibilität« (computational irreducibility) nennt. Das berüchtigte deterministische Chaos (das Verhalten des Systems ist bis in alle Zukunft vorherbestimmt, aber unvorhersagbar) ist die Regel und das, wovon die ganze Physik handelt (Systeme, deren zukünftiges Verhalten man vorhersagen kann), die Ausnahme: einsame Inseln der Reduzibilität im großen Ozean des Chaos."
      ],
      "metadata": {
        "id": "uPH-C3qz4l7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why are most decision problems uncomputable?**  \n",
        "* [Turing and the Halting problem (computerphile)](https://youtu.be/macM_MtS_w4)\n",
        "* Decision problems answer is binary (chess, tetris, halting problem, negative weight cycle detection)\n",
        "* Decision problems are as hard as optimisation problems\n",
        "* Why are most decision problems uncomputable. Proof with theory from [MIT Lecture 23: Computational Complexity](https://youtu.be/moPtwq_cVH8):\n",
        "    * Define a progam: space of all possible programs ≈ you can think of it as binary strings (reduced). You can also think of numbers represented as binary strings ≈ natural number element N\n",
        "    * Define a Decision problem: function that maps inputs to yes (1) or no (0). Input ≈ is a binary string element of N (natural numbers). It‘s a function from N to 0/1. **Every infinite string of bits represents a decision problem.** Output is infite! **A program is a fintie string of bits.**\n",
        "    * You can write down a table of all answers: **a decision problem is an infite string of bits:** =110001010100010111. A program is a finite string of bits.** So they are different.\n",
        "    * One way to see the difference is to add a decimal point: .110001010100010111 - now this infinite string of bits in the output of a decision problem is a real number between 0 and 1 (written in binary). Any real number can be represented by an infinite string of bits.\n",
        "    * A decision problem is element of R, meanwhile a program is element of N (set of all integers).\n",
        "    * But R >> N. R (uncountably infinite) >> N (countable infinite), <font color=\"red\">**there are way more problems than there are programs to solve them**</font>, almost every problem unsolvable by any program.\n"
      ],
      "metadata": {
        "id": "2lw0UapfQk5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Non-computable numbers**\n",
        "* [Large_numbers](https://en.m.wikipedia.org/wiki/Large_numbers), [Names of large numbers](https://en.m.wikipedia.org/wiki/Names_of_large_numbers), [Liste besonderer Zahlen](https://de.m.wikipedia.org/wiki/Liste_besonderer_Zahlen)\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1631.png)\n",
        "\n",
        "* [Constructible numbers](https://en.m.wikipedia.org/wiki/Constructible_number)\n",
        "* [Algebraic numbers](https://en.m.wikipedia.org/wiki/Algebraic_number)\n",
        "* [Transcendental numbers](https://en.m.wikipedia.org/wiki/Transcendental_number)\n",
        "* [Computable numbers](https://en.m.wikipedia.org/wiki/Computable_number)\n",
        "* **Non-Computable numbers**\n",
        "  * [Chaitin constant](https://en.m.wikipedia.org/wiki/Chaitin%27s_constant)\n",
        "  * [Die meisten reellen Zahlen kennen wir nicht](https://www.spektrum.de/kolumne/die-meisten-reellen-zahlen-sind-nicht-berechenbar/2133762) (gehorchen nicht einmal einer Rechenvorschrift)\n",
        "* Special cross-section: [Normal numbers](https://en.m.wikipedia.org/wiki/Normal_number)\n",
        "  * [Champernowne’s constant](https://en.m.wikipedia.org/wiki/Champernowne_constant) (whole numbers) - normal and transendental\n",
        "  * [Copeland-Erdös-number](https://de.m.wikipedia.org/wiki/Copeland-Erdős-Zahl) (primes)\n",
        "\n",
        "Source: [All the Numbers - Numberphile](https://www.youtube.com/watch?v=5TkIe60y2GI&t=458s)\n",
        "\n",
        "**Empty section: normal and Non-Computable numbers (we have no examples)**: We have no examples. But proofs have shown: this is the greatest amount of numbers: <font color=\"blue\">**most numbers are normal and most numbers are uncomputable**</font>. So this section should be full, but we have no example.\n"
      ],
      "metadata": {
        "id": "1f0R8e-ts52g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"Blue\">*Physical Boundaries of Computation*"
      ],
      "metadata": {
        "id": "hlzi59BP8aqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Physical Boundaries of Computation** ([Limits of Computation](https://en.m.wikipedia.org/wiki/Limits_of_computation))\n",
        "\n",
        "> Video: [Quantum Computing](https://youtu.be/gsxeKg41yMw?si=-B5mx5y0jhQGLUpR)\n",
        "\n",
        "*Limits from **Physics** (thermodynamics, quantum mechanics), from **Computer Science** (Computability theory, Complexity theory, Information science) and from **Mathematics** (number theory). Limits are derived from simple questions:*\n",
        "\n",
        "1. <font color=\"blue\">What is the max limit of information capacity?</font> (per given volume and in the observable universe) - [Beckenstein Bound](https://en.m.wikipedia.org/wiki/Bekenstein_bound) 10$^{43}$ bits per kg\n",
        "2. <font color=\"blue\">What is the min amount of heat per erased bit that is dissipated when information is destroyed?</font> - $10^{-21}$ x 2.9 Joule: One limit is the [Landauer’s principle](https://en.m.wikipedia.org/wiki/Landauer%27s_principle), which states that the minimum energy required to perform a single logical operation is equal to the Boltzmann constant times the temperature of the system. This limit implies that the maximum number of computations that can be performed in a given amount of time is limited by the total energy available.\n",
        "2. <font color=\"blue\">What is the max physical speed limit of computation?</font> -\n",
        "  * [Bremermann's Limit](https://en.m.wikipedia.org/wiki/Bremermann%27s_limit) 10$^{50}$ operations per second (speed of light and Planck length > fundamental limit to how fast information can be processed, even in a perfect computer). Bremermann's Limit states that the maximum computational speed of a self-contained system is limited by the speed of light and the Planck length. This limit implies that there is a fundamental limit to how fast information can be processed, even in a perfect computer. **1.3563925 × 10^50 bits per second per kilogram**\n",
        "  * The [Margolus-Levitin theorem](https://de.m.wikipedia.org/wiki/Margolus-Levitin-Theorem) states that the maximum computational speed per unit of energy is limited by the Planck constant. This limit implies that there is a fundamental limit to how much computation can be performed with a given amount of energy. (Margolus-Levitin-Theorem, the processing rate of all forms of computation (including quantum computation) cannot be higher than about **6 × 10^33 operations per second per joule of energy.** 'Black Hole Computers' from Seth Lloyd: Margolus-Levitin theorem: operations take place in the minimum time allowed. The theorem says that the time it takes to flip a bit, t, depends on the amount of energy you apply, E. The more energy you apply, the shorter the time can be. Mathematically, the rule is t h/4E, where h is Planck's constant.\n",
        "3. <font color=\"blue\">What is the physical limit of computation (max number of operations) of the universe in its entire lifetime?</font> - 10$^{229}$ operations (if all matter in the observable would turn into a black hole computer). Calculated combining Margolus-Levitin theorem and Landauer’s principle.\n",
        "4. <font color=\"blue\">What is the max physical time limit of computation?</font> - [Poincare Recurrence time](https://en.m.wikipedia.org/wiki/Poincaré_recurrence_theorem) (universe resets itself, e.g. before finishing Graham's number)\n",
        "5. <font color=\"blue\">What is the max physical resolution limit of the universe?</font> - 10$^{185}$ Planck volume. Anything bigger than this number cannot be explained in physical terms.\n",
        "6. <font color=\"blue\">Can I find another me of myself in this universe?</font> - No! $10^{{10}^{70}}$ is the number of all possible quantum states a person can occupy (roughly a 1 m$^3$ of space) - the same arrangement of atoms that makes you. If you would walk $10^{{10}^{70}}$ meters, you would start to see repetitions of yourself. But the max number of protons of the observable universe is only $10^{80}$ [Eddington number](https://en.m.wikipedia.org/wiki/Eddington_number) and the max resolution is only 10$^{185}$ (Planck volume).\n",
        "\n",
        "Papers: [Ultimate physical limits to computation (Seth Lloyd, 2000)](https://arxiv.org/abs/quant-ph/9908043), [Computational capacity of the universe (Seth Lloyd, 2001)](https://arxiv.org/abs/quant-ph/0110141), [NP-complete Problems and Physical Reality (Scott Aaronson, 2005)](https://arxiv.org/abs/quant-ph/0502072), [Estimation of the information contained in the visible matter of the universe](https://arxiv.org/abs/2112.04473), [The Cost of computation](https://arxiv.org/abs/1905.05669), [Article: From 1,000,000 to Graham’s Number](https://waitbutwhy.com/2014/11/1000000-grahams-number.html), Video: [The Boundary of Computation](https://www.youtube.com/watch?v=kmAc1nDizu0&list=WL&index=7), Video: [The Limits of Computation](https://www.youtube.com/watch?v=ZDfaXJRtOoM), [Amdahl's law](https://en.m.wikipedia.org/wiki/Amdahl%27s_law) predict theoretical speedup when using multiple processors"
      ],
      "metadata": {
        "id": "c1x-N4GYUfEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Selection of physical limits relevant to computation:**\n",
        "\n",
        "> See also [Orders of magnitude (numbers)](https://en.wikipedia.org/wiki/Orders_of_magnitude_(numbers))\n",
        "\n",
        "* <font color=\"blue\">$10^{-44}$ seconds max speed to write a single symbol - [Planck time](https://de.m.wikipedia.org/wiki/Planck-Zeit). Important to know the limits how to compute large numbers: </font>\n",
        "\n",
        "  * if you can write a single symbol only at this time max, then it would take you more time to write down **Graham's number** than one period within **Poincare's recurrence time** = when the universe would reset itself before you finished writing Graham's number\n",
        "\n",
        "  * to write down the **Googol number** you need $10^{56}$ seconds = $10^{48}$ years - Have we enough time to write that down? - Depends on nature of dark energy. In $10^{48}$ years we have the **era of Black Hole dominance** (all matter disappeared and we live in a supermassive black hole or is all matter is unimaginable far apart) [Video](https://www.youtube.com/watch?v=X3l0fPHZja8)\n",
        "\n",
        "* <font color=\"blue\">$10^{-21}$ x 2.9 Joule: [Landauer’s principle](https://en.m.wikipedia.org/wiki/Landauer%27s_principle). Min amount of heat per erased bit that is dissipated when information is destroyed [Source](https://physicsworld.com/a/wiping-data-will-cost-you-energy). See also [Entropy in thermodynamics and information theory](https://en.m.wikipedia.org/wiki/Entropy_in_thermodynamics_and_information_theory)</font>\n",
        "\n",
        "\n",
        "* **1 bit is in quantum communication complexity the communication complexity of the OR problem, even if the parties share entanglement**. It shows that there are some problems that cannot be solved using less communication than their classical counterparts, even if the parties share entanglement. The Quantum OR lemma was first published in 1999 by David Deutsch and Artur Ekert. It has been used to prove lower bounds on the communication complexity of a variety of other problems, including the AND problem, the XOR problem, and the equality problem. **The Quantum OR lemma is a powerful tool for studying the power of quantum communication. It has helped to shed light on the fundamental limits of what can be achieved with quantum communication.**\n",
        "\n",
        "* $10^{11}$ years (100 billion) other galaxies than Andromeda and Milky way are outside of the visible universe\n",
        "\n",
        "* $10^{12}$ years (1 trillion) the galaxies will be depleted of gas clouds, and thus the formation of new stars will be impossible (all hydrogen in stars cores are exhausted)\n",
        "\n",
        "\n",
        "* $12^{12}$ years (1,2 trillion) all stars in the universe will have exhausted (no more stars). [Source](https://www.youtube.com/watch?v=dsWfGzxjs0w), remaining only white dwarfs, neutron stars and black holes.\n",
        "\n",
        "* $10^{14}$ years: In 100 trillion years (100 x 10^12) the last star will die and the universe is ony dominated by dark matter [Source](https://www.youtube.com/watch?v=4Stzj2_Rlo4). Nothing more interesting will happen for next decillions (10^60), vigintillions (10^120) and googols of years dominated by dark matter. Then you have a visible universe of 36 bn light years diameter and is a black hole inside out. But quantum fluctuations at the event horizon will fill the inside up with new particles.\n",
        "\n",
        "* <font color=\"blue\">$10^{15}$ (1 quadrillion) – all planets are detached from their solar systems\n",
        "\n",
        "* <font color=\"blue\">$10^{16}$ bit is the total amount of information a typical human observer can possibly absorb during his lifetime [arXiv:0910.1589](https://arxiv.org/abs/0910.1589)</font>\n",
        "\n",
        "\n",
        "* <font color=\"blue\">$10^{17}$ (100 quadrillion) – The number of seconds since the Big Bang (important to estimate max limit of computation since beginning of universe)\n",
        "\n",
        "* <font color=\"blue\">$10^{18}$ max operations per second in human brain (and floating point operations, flops in 2020)</font>\n",
        "\n",
        "* $10^{18}$ max operations per second in human brain (and floating point operations, flops in 2020)\n",
        "\n",
        "* $10^{23}$ x 6,022 - Avogadro Zahl. Multipliziert mit mol$^{-1}$ ergibt die [Avogadro Konstante](https://de.m.wikipedia.org/wiki/Avogadro-Konstante) - die Anzahl der Teilchen, die in einem Mol eines Stoffes enthalten sind (602 Trilliarden Teilchen pro Mol). For computation: see [Fredkin gate paper](https://cqi.inf.usi.ch/qic/82_Fredkin.pdf), section 5: An isolated physical system consisting of a substantial amount (say, 1 g) of matter possesses an enormous number of degrees of freedom, or modes, of the order of magnitude of Avogadro's number (..).\n",
        "\n",
        "* <font color=\"blue\">$10^{30}$ years: all remnant of stars will have fallen in the central galactic supermassive black hole\n",
        "\n",
        "* <font color=\"blue\">$10^{30}$ x 3 years: if also Protons decay and all atmic nuclei are decayed. Black hole era of the universe starts. Black holes are the only celestial objects in the entire universe.\n",
        "\n",
        "* <font color=\"blue\">$10^{33}$ x 6 : [Margolus-Levitin-Theorem](https://en.m.wikipedia.org/wiki/Margolus–Levitin_theorem), the processing rate of all forms of computation (including quantum computation) cannot be higher than about 6 × 10^33 operations per second per joule of energy. The maximum computational speed per unit of energy is limited by the Planck constant.\n",
        "\n",
        "* <font color=\"blue\">$10^{43}$ = [Beckenstein bound](https://en.m.wikipedia.org/wiki/Bekenstein_bound): maximal amount of information that can be contained within a given volume. Genauer: Using mass–energy equivalence, the informational limit may be reformulated as follows where M is the mass (in kg), and R is the radius (in meter) of the system ${\\displaystyle H\\leq {\\frac {2\\pi cRM}{\\hbar \\ln 2}}\\approx 2.5769082\\times 10^{43}\\ {\\frac {\\text{bit}}{{\\text{kg}}\\cdot {\\text{m}}}}\\cdot M\\cdot R,}$. You can also consider this as $10^{43}$ Hertz: a computer that operated at these operations per second would use so much energy that it would simply collapse to a black hole - Moore’s law: ultimate limits imposed by quantum gravity (min 55:00 [video](https://www.youtube.com/watch?v=uX5t8EivCaM&t=2492s))</font>\n",
        "  * It implies that the information of a physical system, or the information necessary to perfectly describe that system, must be finite if the region of space and the energy are finite.\n",
        "  * In computer science this implies that non-finite models such as [Turing machines](https://en.m.wikipedia.org/wiki/Turing_machine) are not realizable as finite devices.\n",
        "\n",
        "* <font color=\"blue\">$10^{50}$ bits per second per kilogram x 1.3563925 = [Bremermann limits](https://en.m.wikipedia.org/wiki/Bremermann%27s_limit) - Max rate of data processing by isolatad material system. Physical limit of computation. It is derived from Einstein's mass-energy equivalency and the Heisenberg uncertainty principle, and is c2/h.</font>\n",
        "\n",
        "  * A computer at the size of earth and operating at Bremermann's limits could do $10^{74}$ computations per second. It could break a 128 bit cryptographic key in less than $10^{-36}$ of a second and a 256 bit key in 2 minutes. However for 512 bit key working this Bremermann's computational speed limit would ta e$10^{72}$ years. [Source at min 2:30](https://www.youtube.com/watch?v=ZDfaXJRtOoM). Das Universum wird aber vrs “nur” noch max Trillionen (10^12) oder Quadrillionen (10^15) Jahre existieren.\n",
        "\n",
        "* <font color=\"blue\">$10^{50}$ x 5 operations per second. The \"ultimate laptop\": 1 kg black hole with width = 3 x $10^{27}$ meters it would perform 5 x $10^{50}$ operations /sec, but has only a lifetime = $10^{-22}$ sec (due to Hawking radiation). Source: [Seth Lloyd: Black hole computer](https://www.scientificamerican.com/article/black-hole-computers-2007-04/). It's also the **final limit of computation is at Heisenberg uncertainty** at $10^{50}$ operations per second (flops, not clock speed) [Source](https://www.youtube.com/watch?v=jv2H9fp9dT8) even when accounting for a Black Hole</font>\n",
        "\n",
        "* * <font color=\"blue\">$10^{68}$ years: black hole of the size of the sun will have decayed due to Hawking radiation\n",
        "\n",
        "* $10^{80}$ [Eddington number](https://en.m.wikipedia.org/wiki/Eddington_number): Number of protons in the observable universe. genauer: 1.57 × $10^{79}$\n",
        "\n",
        "* <font color=\"blue\">$10^{80}$ x ∼6: number of bits of information stored in all the matter particles of the observable universe (where each particle in the observable universe contains 1.509 bits of information) [arxiv:0110141](https://arxiv.org/abs/quant-ph/0110141) and [arxiv:2112.04473](https://arxiv.org/abs/2112.04473)</font>\n",
        "\n",
        "* $10^{90}$: Fill the universe with grains of sand (.5mm in diameter)\n",
        "\n",
        "* <font color=\"blue\">$10^{90}$ - max number of bits the universe can have processed [arxiv:0110141](https://arxiv.org/abs/quant-ph/0110141), based on the amount of information the Universe can register and the number of elementary operations that it can have performed over its history</font>\n",
        "\n",
        "* <font color=\"blue\">$10^{90}$ operations per second: if all matter in the observable would turned into a black hole computer it could perform $10^{90}$ operations per second but it has a life time of 2.8 x $10^{139}$ seconds before hawking radiation cause it to evaporate. In that time it could perform 2.8 x $10^{229}$ operations. Source: [Seth Lloyd: Black hole computer](https://www.scientificamerican.com/article/black-hole-computers-2007-04/)</font>\n",
        "\n",
        "\n",
        "* $10^{106}$ - $10^{108}$ years it takes for Black holes to evaporate due to Hawking radiation. Source: [The Crazy Future If Protons Don't Decay](https://www.youtube.com/watch?v=5XuBIyGqE1w). The universe enters the dark era.All physical objects have decayed into subatomic particles. If protons don't decay, look at $10^{1500}$ years.\n",
        "\n",
        "\n",
        "* $10^{100}$: [Googol](https://en.wikipedia.org/wiki/Googol), from American mathematician Edward Kasner in 1938\n",
        "\n",
        "* $10^{113}$  The number of hydrogen atoms it would take to pack the universe full of them.\n",
        "\n",
        "* $10^{116}$ x 1.57: possible ways of arrangements a 6x6x6 rubik's cube can have\n",
        "\n",
        "* <font color=\"blue\">$10^{120}$ - max number of operations the universe can have performed [arxiv:0110141](https://arxiv.org/abs/quant-ph/0110141), based on the amount of information the Universe can register and the number of elementary operations that it can have performed over its history</font>\n",
        "\n",
        "* <font color=\"blue\">$10^{120}$ max number of bits of data that could be computes in the amount of time that has elapsed so far in the universe based on the maximum entropy of the universe, the speed of light and the minimum time taken to move information across the Planck length. Anything that requires more than this amount of data cannot have been computed yet [Source, min 2](https://youtu.be/nJObMJLweCs) - Limit on the computational power of the universe (and why Laplace demon cannot exist)</font>\n",
        "\n",
        "* $10^{122}$ The number of protons you could fit in the universe (incl, non-observable universe??) -> for this I need a source\n",
        "\n",
        "* $10^{183}$ number of Planck length' ($10^{-35}$ meters) cubes in the observable universe\n",
        "\n",
        "* <font color=\"blue\">$10^{185}$ x 4: Without being able to go smaller, we’ve reached the largest number where the physical world can be visualize: take a Planck length (10^(-35) meter) and fill it with universe - largest number where the physical world can be used to visualize it. **Anything bigger than this number cannot be explained in physical terms.**</font>\n",
        "\n",
        "* $10^{200}$ pieces to cut a circle and fill with it a square - from circle to square: [Tarski's circle-squaring problem](https://en.m.wikipedia.org/wiki/Tarski%27s_circle-squaring_problem). Achtung: From square to circle: [Squaring the circle](https://en.m.wikipedia.org/wiki/Squaring_the_circle) has been proven to be impossible.\n",
        "\n",
        "* <font color=\"blue\">$10^{229}$ x 2.8: max number of operations if all matter in the observable would turned into a black hole computer Source: [Seth Lloyd: Black hole computer](https://www.scientificamerican.com/article/black-hole-computers-2007-04/)</font>\n",
        "\n",
        "\n",
        "* $10^{495}$ x 6.8: possible proteins the cells in a body can create from the 375 amino acids (but it just unfolds a small subset of all these combinations). Video: [The Most Complex Language in the World](https://www.youtube.com/watch?v=TYPFenJQciw&list=WL&index=13)\n",
        "\n",
        "\n",
        "* $10^{1500}$ years: In case proton decay is not possible, all the particles will have fused together to form iron-56 isotopes, and thus creating something called 'Iron stars'.\n",
        "\n",
        "* 10$^{272.000}$ number of possible universes in string theory [video](https://youtu.be/k_TEoUF12Yk)\n",
        "\n",
        "* $10^{{10}^{7}}$ bits: the amount of information that goes into the Black Hole to build it up for a black hole of the mass of our sun (contradiction because we have only Black Holes observables: mass, electric charge, momentum (no hairs theorem from Bekenstein) = very few bits). Black holes have an enormous number of microstates (hidden configurations - translates to an enormous entropy). Entropy formula from Jacob Bekenstein: $S_{B H}=\\frac{A}{4 L_P^2}=\\frac{c^3 A}{4 G \\hbar}$. Source: [Are Black Holes actually fuzzballs?](https://youtu.be/351JCOvKcYw?si=CtlKQtLkoSx0hRBc)\n",
        "\n",
        "* $10^{{10}^{16}}$: Number of universes that a human observer may distinguish = number of different configurations a typical human brain can have [arXiv:0910.1589](https://arxiv.org/abs/0910.1589)\n",
        "\n",
        "* $10^{{10}^{29}}$ times the size of the observable universe = the chance to meeting an exact copy of yourself (=same constellation of particles) in an infinite universe. Source: [The paradox of an infinite universe](https://youtu.be/isdLel273rQ?si=zvg0qvbC5pAHtssg)\n",
        "\n",
        "* $10^{10^{40}}$ where [Merten‘s Conjecture](https://en.m.wikipedia.org/wiki/Mertens_conjecture) can be disproven\n",
        "\n",
        "* $10^{10^{40}}$ years: all particles will have collapes into black holes (which would evaporate almost instantaneously due to timescale). Now the universe is an absolute void with nothing inside of it. Now, the Universe has reached its final energy state, its maximum entropic value.\n",
        "\n",
        "* $10^{10^{40}}$ years: [Boltzmann brain](https://de.m.wikipedia.org/wiki/Boltzmann-Gehirn), a self-aware entity that appeared due to random quantum fluctuations.\"\n",
        "\n",
        "* <font color=\"blue\">$10^{{10}^{70}}$ - All possible quantum states a person can occupy (roughly a meter ^3 of space). If you would walk $10^{{10}^{70}}$ meters, you would start to see repetitions of yourself.[Source](https://youtu.be/8GEebx72-qs?t=287)</font>\n",
        "\n",
        "* $10^{{10}^{76}}$ years: iron stars will slowly collapse into black holes. Source: [The Crazy Future If Protons Don't Decay](https://www.youtube.com/watch?v=5XuBIyGqE1w)\n",
        "\n",
        "* $10^{{10}^{100}}$ or $10^{Googol}$ - [Googolplex](https://en.m.wikipedia.org/wiki/Googolplex): you cannot write this number in the (observable) universe, since there is not enough space: it has more digits than there are atoms in the observable universe. <font color=\"blue\">**From here start numbers that are incomprehensible. If i walk a googoplex far (the universe is as big as a googolplex meters across), I would see repetitions of myself** (aka same arrangements of atoms like me).</font> if i go further i would see the entire observable universe repeating (size of the universe: $(10^{26})^3$ meters. <font color=\"blue\">**This means there is probably not another me in the universe**.</font> but if you live in a universe that is a googolplex across, then you would by chance run into the same arrangements of atoms that matches you. [numberphile](https://www.youtube.com/watch?v=8GEebx72-qs&t=0s)\n",
        "\n",
        "* $10^{{10}^{{10}^{7}}}$: Number of possible universes, but assume that we are not limited as observers to distinguish more universes. $10^{{10}^{16}}$ is number of universes that a human observer may distinguish [arXiv:0910.1589](https://arxiv.org/abs/0910.1589)\n",
        "\n",
        "* $10^{{10}^{{10}^{34}}}$ bzw. $e^{{e}^{{e}^{79}}}$: untere Schranke der [Skewes Number](https://de.m.wikipedia.org/wiki/Skewes-Zahl)\n",
        "\n",
        "\n",
        "* $10^{{10}^{{10}^{56}}}$ years: random quantum fluctuations and quantum tunneling is predicted to give birth to another universe [Source](https://www.youtube.com/watch?v=dsWfGzxjs0w)\n",
        "\n",
        "* $10^{{10}^{{10}^{76}}}$ years: next checkpoint for a new universe to give birth via a big bang (if protons don't decay), if we are looking at the probability of quantum fluctuations. Source: [The Crazy Future If Protons Don't Decay](https://www.youtube.com/watch?v=5XuBIyGqE1w)\n",
        "\n",
        "* $10^{{10}^{{10}^{100}}}$ - Googolplexian. Number 10 raised to the power of one Googolplex. 10^1000000..... - line is probably trillions of light years long\n",
        "\n",
        "* $10^{{10}^{{10}^{1000}}}$: untere Schranke der [Skewes Number](https://de.m.wikipedia.org/wiki/Skewes-Zahl) unter Nicht-Annahme der Riemann Hypothese. Unter Annahme der Riemann Hypothese: $10^{{10}^{{10}^{961}}}$ bzw. $e^{{e}^{{e}^{7703}}}$\n",
        "\n",
        "* <font color=\"blue\">$10^{{10}^{{10}^{{10}^{{10}^{1.1}}}}}$ **Poincare recurrence time**: Time until a system resets itself (particle of gas go back in the corner, because phase space is finite). you can apply that to the whole universe. Largest finite time ever been calculated by a physicist in a published paper: [arxiv:9411193](https://arxiv.org/abs/hep-th/9411193). He calculated [Poincare recurrence time](https://en.m.wikipedia.org/wiki/Poincar%C3%A9_recurrence_theorem) (for a certain type of universe with a certain cosmological number). [Video](https://www.youtube.com/watch?v=1GCf29FPM4k).</font>\n"
      ],
      "metadata": {
        "id": "6tjmyhKJX2FI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\">**Here we cannot simply write down the numbers anymore $\\downarrow \\downarrow$**\n",
        "\n",
        "> See also: Video: [Numbers too big to imagine](https://youtu.be/u1x_FJZX6Vw?si=4bqa_0_nbdd4DquX)\n",
        "\n",
        "**g64 number [Grahams Zahl](https://de.m.wikipedia.org/wiki/Grahams_Zahl)**\n",
        "\n",
        "* **Graham's number is the biggest number used constructively** = used in a mathematical proof, rather than just being a theoretical concept. There is a specific mathematical problem that can be solved by using Graham's number.\n",
        "\n",
        "* $g_{64}$ [Grahams Zahl](https://de.m.wikipedia.org/wiki/Grahams_Zahl) $g_{64} = 3 \\uparrow \\underbrace{\\uparrow \\ldots \\uparrow}_{g_{63}} \\uparrow 3 = 3(G63\\uparrow)3$ = the biggest number used constructively. If you count that number in your head, the total amount of information would turn your head into a black hole. Graham's number is **not** transfinite. But it is an astronomically large number that is defined using a recursive formula. The formula is so large that it cannot be written out in standard mathematical notation.\n",
        "\n",
        "> $3 \\uparrow \\uparrow 3=3 \\uparrow 3 \\uparrow 3 = 3^{3^3}=7,625,597,484,987$\n",
        "\n",
        "\n",
        "> $3 \\uparrow \\uparrow \\uparrow 3=3 \\uparrow \\uparrow 3 \\uparrow \\uparrow 3$ = $3^{3^{3^{(..)^3}}}$ - This means the number 3 is 7,625,597,484,987 (7.6 trillion) times exponentiated!\n",
        "\n",
        "> $g_1 = 3 \\uparrow \\uparrow \\uparrow \\uparrow 3 = 3 \\uparrow \\uparrow \\uparrow 3 \\uparrow \\uparrow \\uparrow 3$\n",
        "\n",
        "> $g_2 = 3 \\uparrow \\underbrace{\\uparrow \\ldots \\uparrow}_{g_1} \\uparrow 3  = 3(G1\\uparrow)3$\n",
        "\n",
        "> $g_3 = 3 \\uparrow \\underbrace{\\uparrow \\ldots \\uparrow}_{g_2} \\uparrow 3 $\n",
        "\n",
        "> ....\n",
        "\n",
        "> $g_{64} = 3 \\uparrow \\underbrace{\\uparrow \\ldots \\uparrow}_{g_{63}} \\uparrow 3 = 3(G63\\uparrow)3$ = [Grahams Zahl](https://de.m.wikipedia.org/wiki/Grahams_Zahl) the biggest number used constructively\n",
        "\n",
        "> Siehe: [Hyperoperation](https://en.m.wikipedia.org/wiki/Hyperoperation) und [Knuth‘s Up Arrow Notation](https://en.m.wikipedia.org/wiki/Knuth%27s_up-arrow_notation)\n",
        "\n",
        "* you can't say how many digits it has. If you imagine Graham's number in your head, then your head would collaps into a black hole. It is estimated that the observable universe is not large enough to contain an ordinary digital representation of Graham's number.\n",
        "\n",
        "* Upper bound: used in combinatorics, graph theory, as an upper bound for coloring graphs that are linked to higher dimensional cubes: for [\"Ramsey number for hypergraphs\"](https://en.m.wikipedia.org/wiki/Ramsey%27s_theorem) (This problem is concerned with the number of edges that need to be added to a hypergraph in order to make it so that any two distinct subsets of the hypergraph have either the same number of edges between them, or the opposite number of edges between them.). Graham's number is the max number for this to be true (and 6 or 11 is the lowest)\n",
        "\n",
        "* https://waitbutwhy.com/2014/11/1000000-grahams-number.html\n",
        "\n",
        "\n",
        "**tree(3)** [Kruskal's tree theorem](https://en.m.wikipedia.org/wiki/Kruskal%27s_tree_theorem)\n",
        "\n",
        "* tree theorems are larger numbers for mathematical proofs than graham's number\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Kruskal%27s_tree_theorem\n",
        "\n",
        "https://towardsdatascience.com/how-big-is-the-number-tree-3-61b901a29a2c\n",
        "\n",
        "- Inf-embedabble\n",
        "- Ackermann numbers as lower bound\n",
        "- Proof theory: kruskals tree theory\n",
        "    - Well quasi ordering\n",
        "    - Poincare recurrence, universe will reset itself due to entropy (limited number of steps) or proof doesn‘t fit in our universe\n",
        "    - Ordinals, trans-finite arithmetic\n",
        "- Video 1: https://www.youtube.com/watch?v=3P6DWAwwViU\n",
        "- Video 2: https://www.youtube.com/watch?v=IihcNa9YAPk\n",
        "\n",
        "\n",
        "**Loaders number** $D^{(5)}(99)$\n",
        "\n",
        "* It's the fifth iteration of a certain function  D  on the value 99. TREE(3) is indistinguishable from zero compared to Loader's number. Code was limited to 512 characters, otherwise it would get bigger\n",
        "\n",
        "* https://googology.fandom.com/wiki/Loader%27s_number\n",
        "\n",
        "* The interesting point is that  D , the function, is a very fast-growing function with a particularly compact representation, and it’s valuable to compare its growth rate with that of other computable functions.\n",
        "\n",
        "* I’m not sure much is known about the place of  D  in the fast-growing hierarchy. The Googology entry seems to indicate that, for example, finite promise games produce a faster-growing computable function.\n",
        "\n",
        "* **TREE(3) is indistinguishable from zero compared to Loader's number[1]**, which basically takes every bit pattern up to some n and expresses this as a program in the Calculus of Constructions. This system is a bit weaker than being Turing complete, but the programs do always terminate (this makes the number computable compared with, say, the Busy Beaver number which does a similar thing with Turing complete programs).\n",
        "It also has the geek cred of being represented by an obfuscated C program (the unobfuscated verson is also available[2]).\n",
        "[1] http://googology.wikia.com/wiki/Loader%27s_number\n",
        "[2] https://github.com/rcls/busy\n",
        "\n",
        "\n",
        "**SCG(13) and SSCG(3)** [Friedman's SSCG function](https://en.m.wikipedia.org/wiki/Friedman's_SSCG_function)\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Friedman%27s_SSCG_function\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Friedman's_SSCG_function\n",
        "\n",
        "* SCG(13) and SSCG(3) - [Friedman's SSCG function](https://en.m.wikipedia.org/wiki/Friedman's_SSCG_function). SCG(13) is computable, whereas Rayo's number is uncomputable. Rayo's number >> SCG(13).\n",
        "\n",
        "* The SSCG sequence begins slower than SCG, SSCG(0) = 2, SSCG(1) = 5, but then grows rapidly.\n",
        "\n",
        "* This number is known for being able to surpass TREE(3) and is defined with SSCG. It is praised for being much larger than TREE(TREE(TREE(TREE… (over TREE(3) times …TREE(TREE(TREE(TREE(3)…).\n",
        "\n",
        "* SSCG(3) is much larger than both TREE(3)\n",
        "\n",
        "* SCG(13) is computable, whereas Rayo's number is uncomputable. From here we can already say Rayo's number >> SCG(13). For large numbers beyond g(64), we can only use boundaries to define them, hence the uncertainty.\n",
        "\n",
        "* Adam P. Goucher claims there is no qualitative difference between the asymptotic growth rates of SSCG and SCG. He writes \"It's clear that SCG(n) ≥ SSCG(n), but I can also prove SSCG(4n + 3) ≥ SCG(n).\"\n",
        "\n",
        "\n",
        "* SCG(13) and SSCG(3) - [Friedman's SSCG function](https://en.m.wikipedia.org/wiki/Friedman's_SSCG_function). SCG(13) is computable, whereas Rayo's number is uncomputable. Rayo's number >> SCG(13).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bek6CfuxWq1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\">**$\\uparrow \\uparrow$ Here separates the computable from the uncomputable $\\downarrow \\downarrow$**\n",
        "\n",
        "**Busy Beaver - Separating the computable from the uncomputable**\n",
        "\n",
        "* [Busy Beaver](https://en.m.wikipedia.org/wiki/Busy_beaver): endliche, aber im Allgemeinen nicht berechenbare Funktion. The Busy Beaver function Σ(n) grows faster than any computable function. Hence, it is not computable; only a few values are known. some mathematical system loose the ability to prove its values beyond a point. ps: Rayo's number is much bigger than the Beaver - but the Busy Beaver isn't relevant to Rayo. Rayo is fundamentally about truth rather than provability, and so the relevant \"logical obstacle\" is Tarski's undefinability theorem rather than the incomputability of the halting problem\n",
        "\n",
        "* Difference between (in)finite value and (in)finite instruction: ZFC can't pin down the precise value of even BB(7918). However, ZFC can define the Busy Beaver function itself, in less than, say, a billion symbols.\n",
        "\n",
        "* Die [Fleißiger-Biber-Funktion bzw. Radó-Funktion Σ](https://de.m.wikipedia.org/wiki/Flei%C3%9Figer_Biber) ist in der theoretischen Informatik ein Standardbeispiel für eine **endliche, aber im Allgemeinen nicht berechenbare Funktion**\n",
        "\n",
        "* **Open Questions**: Open Questions BB($10^{100}$) > Tree($10^{100}$) ??.\n",
        "\n",
        "* Die Rado-Funktion Σ ist nicht Turingmaschinen-berechenbar. Obwohl es sehr viele nicht-berechenbare Funktionen gibt - sogar mehr als berechenbare -, muss man sich doch Außergewöhnliches einfallen lassen, um eine nicht-berechenbare Funktionen möglichst konkret zu beschreiben. [Source](https://www.inf-schule.de/algorithmen/berechenbarkeit/grenzenderberechenbarkeit/station_fleissigebiber)\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Busy_beaver\n",
        "\n",
        "* $\\sum(n)$ : The Busy Beaver function\n",
        "  * Consider all n-state Turing machines.\n",
        "  * Run each on a tape of all 0's.\n",
        "  * Of all machines that halted,\n",
        "    * $\\sum(n)$ = max count of 1's\n",
        "\n",
        "* **$\\Sigma(n)$ is not a computable function!** (for all n, but for a specific n it's computable). **The Busy Beaver function Σ(n) grows faster than any computable function. Hence, it is not computable; only a few values are known**\n",
        "\n",
        "* Some mathematical system loose the ability to prove its values beyond a point. A computable function requires a finite number of steps to produce the output. Siehe [Berechenbarkeit](https://de.m.wikipedia.org/wiki/Berechenbarkeit)\n",
        "\n",
        "* this function grows faster than any computable function! For: If f(n) : $\\mathbb{N}$ => $\\mathbb{N}$ for any computable function, then there exists $n_f$ such that: $f(n) < \\Sigma(n)$ for all $n$ ≥ $n_f$\n",
        "\n",
        "* **Means: The busy beaver function beyond some value of $\\mathbb{N}$ will grow faster than $\\mathbb{N}$**\n",
        "\n",
        "* There are true statements like: \"$\\Sigma$(1000) = k\" that cannot be proved in our normal axiomatic systems. Mathematics looses the ability to make claims about these numbers.\n",
        "\n",
        "* the nineteenth busy beaver number is greater than grahams number\n",
        "\n",
        "* [Aaronson: Busy Beaver Updates: Now Even Busier](https://scottaaronson.blog/?p=6673)\n",
        "\n",
        "* Source Video: [The Boundary of Computation](\n",
        "https://www.youtube.com/watch?v=kmAc1nDizu0):\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1627.png)\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1628.png)\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1629.png)\n",
        "\n",
        "\n",
        "**Rayo($10^{100}$)** [Rayo's number](https://en.m.wikipedia.org/wiki/Rayo).\n",
        "\n",
        "* Rayo's number is the smallest number that cannot be expressed anymore. even grahams number would look like a 0 next to rayos number. [Video](https://www.youtube.com/watch?v=X3l0fPHZja8).\n",
        "\n",
        "* Rayo's number is defined as the smallest number that is larger than any number that can be named by an expression in the language of first-order set theory with a googol symbols or less. This means that Rayo's number is much larger than a Gogol.\n",
        "\n",
        "* Compared to Busy beaver: Rayo is way way way way WAY bigger than the Beaver - but the Busy Beaver just isn't relevant to Rayo.) Rayo is fundamentally about truth rather than provability, and so the relevant \"logical obstacle\" is Tarski's undefinability theorem rather than the incomputability of the halting problem [Source](https://math.stackexchange.com/questions/3910468/a-confusion-regarding-rayos-number-and-busy-beaver-function)\n",
        "\n",
        "**Chaitin's constant**\n",
        "\n",
        "* [Chaitin's constant](https://en.m.wikipedia.org/wiki/Chaitin%27s_constant) or halting probability is a real number that, informally speaking, represents the probability that a randomly constructed program will halt.\n",
        "\n",
        "* ***Chaitin's number is transfinite. It is an uncomputable number that measures the randomness of a computer program***. The higher the Chaitin's number, the more random the program is. Chaitin's number is uncomputable (because it is impossible to determine the halting probability of a Turing machine.)\n",
        "\n",
        "* Each halting probability is a normal and transcendental real number that **is not computable**, which means that there is no algorithm to compute its digits. Each halting probability is [Martin-Löf random](https://en.m.wikipedia.org/wiki/Algorithmically_random_sequence), meaning there is not even any algorithm which can reliably guess its digits.\n",
        "\n",
        "**Fish number 7**\n",
        "\n",
        "* Fish number 7 belongs to the family of the fish numbers, which were defined by a Japanese googologist. **Fish numbers were often classified as “above Rayo's number”**, and they're pretty incomprehensible. [More info](https://googology.fandom.com/wiki/Fish_number_7).\n",
        "\n",
        "**Merten‘s Conjecture** $10^{10^{40}}$\n",
        "\n",
        "* [Merten‘s Conjecture](https://en.m.wikipedia.org/wiki/Mertens_conjecture) is disproven: at some point the sum will surpass the square root of the number. [Video](https://youtu.be/uvMGZb0Suyc).\n",
        "* If it had been true, that it would proof the Riemann hypothesis\n",
        "* But if we knew it, we cannot write it down, because **we would need more atoms than exist in the universe to write it down**\n",
        "    * PRIZE FOR SOLVING RIEMANN HYPOTHESIS $ 10€\n",
        "    * STARS IN THE UNIVERSE 10^22\n",
        "    * ATOMS IN THE UNIVERSE 10^80\n",
        "    * MERTENS CONJECTURE FAILS $10^{10^{40}}$\n",
        "* We have no way to describe the first that it happens, but we know it exists\n",
        "\n"
      ],
      "metadata": {
        "id": "DRzsUXULYvpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Infinity $\\infty$ and Transfinite numbers**\n",
        "\n",
        "*überabzählbare und abzählbare Unendlichkeit*\n",
        "\n",
        "* Tatsächlich gibt es nicht nur eine Unendlichkeit, sondern gleich unendlich viele. So unterscheidet man beispielsweise zwischen der Unendlichkeit der natürlichen Zahlen und der reellen Zahlen: Während man natürliche Zahlen wie 1, 2, 3, … lückenlos auflisten kann, ist das mit reellen Zahlen unmöglich. Eine Aufzählung existiert nicht, selbst wenn die Liste unendlich lang ist. Denn zwischen zwei reellen Zahlen findet man immer eine weitere, die dazwischensteckt. Auch wenn man vermuten würde, dass das bei Bruchzahlen ebenso ist, lassen diese sich dennoch wie die natürlichen Zahlen aufzählen, zum Beispiel, indem man sie nach der Größe ihres Nenners ordnet: 1⁄1, 1⁄2, 1⁄3, 2⁄3, 1⁄4, 3⁄4, 1⁄5, 2⁄5, 3⁄5, 4⁄5, … Damit haben wir zwei Kategorien von Unendlichkeiten ausgemacht: abzählbare Unendlichkeit, wie die der natürlichen oder rationalen Zahlen, und überabzählbare Unendlichkeit, wie die der reellen Zahlen. Und auch wenn beides unvorstellbare Größen sind, ist ihr Unterschied erheblich.\n",
        "\n",
        "https://www.spektrum.de/kolumne/masstheorie-eine-wahrscheinlichkeit-von-null-heisst-nicht-unmoeglich/2092452\n",
        "\n",
        "*In mathematics, transfinite numbers are numbers that are greater than all finite numbers. They are often used in set theory and topology.*\n",
        "\n",
        "There are two main types of transfinite numbers: ordinal numbers and cardinal numbers. Ordinal numbers are used to order sets, while cardinal numbers are used to count the number of elements in a set.\n",
        "\n",
        "Some examples of transfinite numbers are:\n",
        "\n",
        "* **$\\omega$** (omega): The smallest transfinite ordinal number. It is the order type of the natural numbers.\n",
        "* **$\\omega^2$** (omega squared): The number of all possible orderings of the natural numbers.\n",
        "* **$\\aleph_0$** (aleph null): The smallest transfinite cardinal number. It is the cardinality of the set of natural numbers.\n",
        "* **$\\aleph_1$** (aleph one): The cardinality of the set of all countable ordinal numbers.\n",
        "* **$\\aleph_2$** (aleph two): The cardinality of the set of all uncountable ordinal numbers.\n",
        "\n",
        "Transfinite numbers can be used to solve problems that are impossible to solve with finite numbers. For example, the problem of determining whether a given set is countable or uncountable can only be solved using transfinite numbers.\n",
        "\n",
        "The study of transfinite numbers is a complex and fascinating area of mathematics. It has applications in many different areas of mathematics, including set theory, topology, and logic.\n",
        "\n",
        "**what is the relationship between transfinite numbers and infinity?**\n",
        "\n",
        "Transfinite numbers are numbers that are greater than all finite numbers. Infinity is a concept that refers to something that is boundless or endless.\n",
        "\n",
        "The relationship between transfinite numbers and infinity is that transfinite numbers are a way of quantifying infinity. In other words, transfinite numbers allow us to talk about different sizes of infinity.\n",
        "\n",
        "For example, the natural numbers (1, 2, 3, ...) are finite numbers. The set of all natural numbers is countable, which means that it can be put into a one-to-one correspondence with the set of all positive integers.\n",
        "\n",
        "The set of all real numbers is uncountable, which means that it cannot be put into a one-to-one correspondence with the set of all positive integers. This means that the set of all real numbers is larger than the set of all natural numbers.\n",
        "\n",
        "Transfinite numbers can be used to quantify the size of the set of all real numbers. The smallest transfinite cardinal number is $\\aleph_0$, which is the cardinality of the set of all natural numbers. The cardinality of the set of all real numbers is $\\aleph_1$, which is larger than $\\aleph_0$.\n",
        "\n",
        "There are many different transfinite numbers, and they can be used to quantify the size of different sets. The study of transfinite numbers is a complex and fascinating area of mathematics.\n",
        "\n",
        "Here are some other ways to think about the relationship between transfinite numbers and infinity:\n",
        "\n",
        "* Transfinite numbers are a way of making infinity more precise.\n",
        "* Transfinite numbers allow us to compare different infinities.\n",
        "* Transfinite numbers can be used to solve problems that are impossible to solve with finite numbers.\n",
        "\n",
        "The study of transfinite numbers is a complex and fascinating area of mathematics. It has applications in many different areas of mathematics, including set theory, topology, and logic.\n",
        "\n",
        "http://peter-ripota.de/mathe/ordinalzahlen-einfach-weiterzaehlen/von-%CF%89-zu-%CE%B50-von-klein-omega-zu-epsilon-null/\n",
        "\n",
        "\n",
        "Infinity is not a number, it's an idea, a concept. Hence you cannot equal something to infinity.\n",
        "\n",
        "Aleph Null\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Aleph-Funktion\n",
        "\n",
        "https://www.spektrum.de/lexikon/mathematik/amp-aleph-0-aleph-null/443\n",
        "\n",
        "[Counting beyond infinity](https://youtu.be/SrU9YDoXE88)\n",
        "\n",
        "https://www.quantamagazine.org/how-many-numbers-exist-infinity-proof-moves-math-closer-to-an-answer-20210715/\n",
        "\n",
        "* Kontinuumshypothese (Cantor) kann man nicht beweisen oder widerlegen (Gödel). Die Mathematik kann funktionieren, wenn man sowohl davon ausgeht, dass die Kontiuumshypothese gilt, als auch, dass sie nicht gilt.\n",
        "\n",
        "* term of size (how many?) is: **Cardinality**\n",
        "\n",
        "* Rules for comparing cardinalities: injection, subjection, bijection\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_319.png)\n",
        "\n",
        "* How does the cardinality of a set A compares to that of its power set (=set of all subsets of A including itself)\n",
        "\n",
        "* The cardinality of the power set of A is strictly greater than the cardinality of its original set A, even when it's infinite\n",
        "\n",
        "* [How Big are All Infinities Combined? (Cantor's Paradox) | Infinite Series](https://www.youtube.com/watch?v=TbeA1rhV0D0&list=WL&index=12&t=86s)\n",
        "\n",
        "**Smallest Sizes of Infinity**\n",
        "\n",
        "* intuition is often misleading in mathematics!\n",
        "\n",
        "* There are infinitely many sizes of infinity\n",
        "\n",
        "* Smallest infinity: natural numbers (counting numbers). Here: even numbers and natural numbers are the same size!\n",
        "\n",
        "  * Natural numbers: $\\aleph$ \"Aleph-naught\" (the least infinity cardinality)\n",
        "\n",
        "* We need to find a way to tell which infinity is bigger without counting them.\n",
        "\n",
        "* You use something called Bijection: if you can pair up two sets, they are the same size\n",
        "\n",
        "\t* even numbers and natural numbers are the same size, because there is a bijection between the two sets! Each natural number is [aired with 2 times itself: 1 with 2, 2 with 4, 4 with 6 etc. Damit sind alles odd numbers out, but the set didn't get smaller\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_318.png)\n",
        "\n",
        "\t* the natural numbers are also the same size as the integers: Integers include all natural numbers + all the negative whole numbers. We can pair them up exactly, so they must be the same size.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_317.png)\n",
        "\n",
        "* Above the natural numbers are the real numbers in terms of infinity size. After that the real numbers.\n",
        "\n",
        "\t* an interval on the real number line is also an infinity. And an interval on the real line between 0 and 5 has the same size as an interval between 0 and 10. They are ll as big as the real numbers!!\n",
        "\n",
        "\t* You can show that any interval is the same size as the entire real number line !\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_316.png)\n",
        "\n",
        "* Cantor wondered if there is an infinity between the natural and the real numbers?\n",
        "\n",
        "\t* CONTINUUM HYPOTHESIS: there is no size of infinity between the natural numbers and the real numbers\n",
        "\n",
        "\t* Decades later, mathematicians found out that the Continuum hypothesis is independent of the Zermela-Fraenkel set theory with choice (ZFC) - the Continuum hypothesis can not be proved or disproved using the standard rules of mathematics\n",
        "\n",
        "* So in one model of the tower of infinities the real numbers sit directly above the natural numbers\n",
        "\n",
        "* But in other models there are many infinities in between\n",
        "\n",
        "* The rules of maths don't say that one tower is correct and the other wrong.\n",
        "\n",
        "> So it seems that mathematics seems to be surprisingly agnostics with regards to which hierarchy of infinities is correct\n",
        "\n",
        "* How does the cardinality of a set A compares to that of its power set (=set of all subsets of A including itself)\n",
        "\n",
        "* The cardinality of the power set of A is strictly greater than the cardinality of its original set A, even when it's infinite"
      ],
      "metadata": {
        "id": "6AKEytfrRpL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eine Wahrscheinlichkeit von null heißt nicht unmöglich**\n",
        "\n",
        "*$\\hookrightarrow$ 'Improbable but not impossible'*\n",
        "\n",
        "Wenn man also die Wahrscheinlichkeit berechnet, welche Art von reeller Zahl man antrifft, wenn man zufällig eine zieht, erhält man ein eindeutiges Ergebnis: In 100 Prozent der Fälle ist diese Zahl nicht berechenbar. Das heißt aber nicht, dass man keine andere Zahl ziehen kann – bei unendlichen Ereignismengen bedeutet eine Wahrscheinlichkeit von null nicht unmöglich. Das ist umso erstaunlicher, als dass nicht allzu viele nicht berechenbare Zahlen bekannt sind. [Source](https://www.spektrum.de/kolumne/die-meisten-reellen-zahlen-sind-nicht-berechenbar/2133762)\n",
        "\n",
        "https://www.spektrum.de/kolumne/masstheorie-eine-wahrscheinlichkeit-von-null-heisst-nicht-unmoeglich/2092452\n",
        "\n",
        "Dieses Problem wird auch **Dartscheiben-Paradoxon** genannt. Gelöst wird es durch die Erkenntnis, dass eine Wahrscheinlichkeit von null nicht zwangsläufig bedeutet, dass ein Ereignis niemals eintritt – sondern nur, dass es »fast sicher« nicht eintritt.\n",
        "\n",
        "Woher weiß man nun, ob man es mit einem tatsächlich unmöglichen Ereignis (etwa, eine Acht mit einem W6-Würfel zu würfeln) oder einem fast unmöglichen Ereignis (einen bestimmten Punkt auf der Dartscheibe treffen) zu tun hat? Das hängt von der Anzahl der möglichen Ereignisse ab, dem so genannten Ereignisraum: Ist der Ereignisraum endlich (bei einem Würfel besteht er aus sechs Elementen: den sechs Seiten, auf denen er liegen bleiben kann), dann bedeutet eine Wahrscheinlichkeit von null, dass das betrachtete Ereignis niemals eintreten wird. Betrachtet man hingegen einen unendlich großen Ereignisraum (wie die möglichen Treffpunkte auf einer Dartscheibe), dann bedeutet eine Wahrscheinlichkeit von null nicht zwangsläufig, dass das Ereignis nicht eintritt – sondern nur, dass es sehr unwahrscheinlich ist."
      ],
      "metadata": {
        "id": "_YFS2_Vt1_JB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"Blue\">*Beyond Quantum Computing (Hypercomputation)*"
      ],
      "metadata": {
        "id": "2rAAm4JiTDN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fundamental Limitations to Quantum Computation**\n",
        "\n",
        "* https://www.birs.ca/events/2024/5-day-workshops/24w5259\n",
        "* https://www.birs.ca/events/2024/5-day-workshops/24w5259/schedule\n",
        "\n",
        "* Yifan Jia: Hay from the haystack: explicit examples of exponential quantum circuit complexity: The vast majority of quantum states and unitaries have circuit complexity exponential in the number of qubits. In a similar vein, most of them also have exponential minimum description length, which makes it difficult to pinpoint examples of exponential complexity. In this work, we construct examples of constant description length but exponential circuit complexity. We provide infinite families such that each element requires an exponential number of two-qubit gates to be generated exactly from a product and where the same is true for the approximate generation of the vast majority of elements in the family. The results are based on sets of large transcendence degree and discussed for tensor networks, diagonal unitaries, and maximally coherent states.\n",
        "\n",
        "\n",
        "* Jens Eisert: Fundamental limits to quantum computation: Quantum computers promise superior computational power over classical computers for some structured problems. While this insight is not new, only in recent years, steps have been taken to actually build intermediate-sized quantum devices, creating an exciting state of affairs. For some paradigmatic problems, there is some evidence that quantum computers may outperform classical devices [1]. For practically motivated problems in machine learning [2, 3] and in optimization [4], fault tolerant quantum computers indeed perform better than classical ones. While this may be promising, actual systems to date are relatively small and noisy. The main part of the talk is concerned with identifying *limitations* to quantum computing in this realm. We discuss notions of learnability of output distributions of short quantum circuits - as they can be seen as parts of variational quantum algorithms - and find that a single T-gate renders learning them hard [5]. We identify exponentially tighter bounds on limitations of quantum error mitigation [6]. We finally discuss the impact of non-unital noise on quantum computing, with quite unexpected results [7]. We end on the note that while fault tolerant quantum computers offer substantial computational benefits, the race is still open for near-term quantum devices. [1] Computational advantage of quantum random sampling, D. Hangleiter, J. Eisert, Rev. Mod. Phys. 95, 035001 (2023). [2] A super-polynomial quantum-classical separation for density modelling, N. Pirnay, R. Sweke, J. Eisert, J.-P. Seifert, Phys. Rev. A 107, 042416 (2023). [3] Towards provably efficient quantum algorithms for large-scale machine-learning models, J. Liu, M. Liu, J.-P. Liu, Z. Ye, Y. Wang, Y. Alexeev, J. Eisert, L. Jiang, Nature Comm. 15, 434 (2024). [4] An in-principle super-polynomial quantum advantage for approximating combinatorial optimization problems via computational learning theory, N. Pirnay, V. Ulitzsch, F. Wilde, J. Eisert, J.-P. Seifert, arXiv:2212.08678, Science Advances (2024). [5] A single T-gate makes distribution learning hard, M. Hinsche, M. Ioannou, A. Nietner, J. Haferkamp, Y. Quek, D. Hangleiter, J.-P. Seifert, J. Eisert, R. Sweke, Phys. Rev. Lett. 130, 240602 (2023). [6] Exponentially tighter bounds on limitations of quantum error mitigation, Y. Quek, D. Stilck França, S. Khatri, J. Jakob Meyer, J. Eisert, arXiv:2210.11505, Nature Physics (2024). [7] Non-unital noise, friend of foe, A. A. Mele, A. Angrisani, A Ghosh, A. Khatri, J. Eisert, Y. Quek, D. Stilck Franca, in preparation (2024).\n"
      ],
      "metadata": {
        "id": "szGHIoNv-vxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is Hypercomputation?**\n",
        "* Beyond Turing Machines: Hypercomputation refers to theoretical models of computation that can solve problems that are uncomputable by a standard Turing machine. Examples include machines that can decide the halting problem or compute functions with infinite information content.\n",
        "* Mostly Theoretical: No universally accepted, physically realizable model of hypercomputation exists. They remain predominantly concepts within theoretical computer science.\n",
        "* <font color=\"blue\">**Solving the Halting problem would be an example of hypercomputation, but it would not be covered by the qECTT!**</font>\n",
        "  * **The Halting Problem:**  The Halting problem asks whether it's possible to create a universal algorithm that can definitively determine if any given computer program will eventually stop running or continue indefinitely.  Alan Turing famously proved this problem is undecidable by a standard Turing machine.\n",
        "  * **Why it's Hypercomputation:** <font color=\"blue\">If you could solve the Halting problem, you'd possess a machine (often envisioned as an \"oracle\") capable of doing something no Turing machine (classical or quantum) can achieve</font>. This computational superpower fits most definitions of hypercomputation.\n",
        "  * **qECTT Violation:** Since the qECTT asserts that a quantum computer is no more powerful than a theoretical quantum Turing machine, and a quantum Turing machine still can't solve the Halting problem, this type of  hypercomputation directly clashes with the qECTT.\n",
        "  * **Important Note:** While conceptually clear, hypercomputation is tricky because it's largely defined by what it isn't.  Building a hypercomputer in the real world might be fundamentally impossible.\n",
        "\n",
        "\n",
        "**Forms of [Hypercomputation](https://en.m.wikipedia.org/wiki/Hypercomputation)**\n",
        "\n",
        "* **Hypercomputers and Quantum Gravity Computers**:\n",
        "  * see description in seth lloyds: black hole computers\n",
        "  * [Black holes as tools for quantum computing by advanced extraterrestrial civilizations](https://arxiv.org/abs/2301.09575)\n",
        "  * [Quantum Gravity Computers](https://arxiv.org/abs/quant-ph/0701019)\n",
        "  * [A simple quantum system that describes a black hole](https://arxiv.org/abs/2303.11534)\n",
        "  * [Quantum computers could simulate a black hole in the next decade](https://www.newscientist.com/article/2370695-quantum-computers-could-simulate-a-black-hole-in-the-next-decade/)\n",
        "  * [Black Hole as a model of computation](https://www.sciencedirect.com/science/article/pii/S2211379719304036)\n",
        "\n",
        "* **Infinity Machines**\n",
        "  * **Infinity Machines**: with geometrically squeezed time cycles, such as the ones envisioned by Weyl [7] and others [8-18], are they physically feasible? Motivated by recent proposals to utilize quantum computation for trespassing the Turing barrier [19-22], these accelerating Turing machines have been intensively discussed [23] among other forms of hypercomputation [24-26].\n",
        "\n",
        "* **Quantum Gravity Computers / Black Holes as Computers**\n",
        "  * **Quantum Gravity Computer with CTCs**: no one knows how to combine quantum mechanics with general theory of relativity. Quantum gravity: breakdowns of causality itself, if closed timelike curves CTCs (i.e., [time machines to the past](https://www.pbs.org/wgbh/nova/article/do-time-travelers-tweet/) ) are possible. David Deutsch, John Watrous and Aaronson: “A time machine is definitely the sort of thing that might let us tackle problems too hard even for a quantum computer.”\n",
        "  * With closed timelike curves, then under fairly mild assumptions, one could “force” Nature to solve hard combinatorial problems, just to keep the universe’s history consistent (i.e., to prevent things like the grandfather paradox from arising). Notably, the problems you could solve that way include the NP-complete problems : a class that includes hundreds of problems of practical importance (airline scheduling, chip design, etc.), and that’s believed to scale exponentially in time even for quantum computers.\n",
        "  * According to a 1992 paper (Hogarth, Mark L. (1992). [\"Does general relativity allow an observer to view an eternity in a finite time?\"](https://link.springer.com/article/10.1007/BF00682813)), a computer operating in a [Malament–Hogarth spacetime](https://en.m.wikipedia.org/wiki/Malament%E2%80%93Hogarth_spacetime) or in **orbit around a rotating black hole could theoretically perform non-Turing computations for an observer inside the black hole**.\n",
        "  * Access to a CTC may allow the rapid solution to PSPACE-complete problems, a complexity class which, while Turing-decidable, is generally considered computationally intractable. - [Computability Theory of Closed Timelike Curves](https://www.scottaaronson.com/papers/ctchalt.pdf). There are spacetimes in which the [CTC (closed timelike curves)](https://en.m.wikipedia.org/wiki/Closed_timelike_curve) region can be used for relativistic hypercomputation. [Closed Timelike Curves Make Quantum and Classical Computing Equivalent](https://arxiv.org/abs/0808.2669). While quantum formulations of CTCs have been proposed,[5][6] a strong challenge to them is their ability to freely create entanglement,[7] which quantum theory predicts is impossible. If Deutsch's prescription holds, the existence of these CTCs implies also equivalence of quantum and classical computation (both in PSPACE).[8] If Lloyd's prescription holds, quantum computations would be PP-complete. https://en.m.wikipedia.org/wiki/Closed_timelike_curve.\n",
        "  * **Achtung:** CTCs brauchen exotische Teilchen, um rückwärts in der zeit zu reisen (laut Hawking), und diesr exotischen Teilchen wurden noch nicht gefunden [Source](https://www.quora.com/If-two-black-holes-collide-does-the-matter-around-them-travel-back-in-time) - <font color=\"red\">So CTCs don't seem to exist, and with that no np-hard computation!</font>\n",
        "  * Videos: [Limits of computation](https://youtu.be/ZDfaXJRtOoM) - [Limits of computation](https://youtu.be/gV12PS19YL8) - [Physical limits of computation](https://youtu.be/ZVj93b0pa2o) - [What is the computational power of the universe](https://youtu.be/ROdv1v_YsAw) - [Is the universe a Turing machine?](https://youtu.be/VY6TzB_xH-k) (Lex Fridman: Lee Cronin vs Joscha Bach) - [The universe is not hypercomputational](https://youtu.be/VV_kArap5TM) (min 2). [Computing Limit](https://youtu.be/jv2H9fp9dT8). [Is There Anything Beyond Quantum Computing? ](https://www.pbs.org/wgbh/nova/article/is-there-anything-beyond-quantum-computing/) (Aaronson).\n",
        "\n",
        "* **Omega Machines**\n",
        "  * These are machines that can solve the halting problem, which is a problem that is known to be unsolvable by a Turing machine. (from chaitin's (omega) number):\n",
        "  * omega appears to have two features which are normally consid- ered contradictory: it is one of the most informative mathematical numbers imaginable, yet at the same time this information is so com- pressed that it cannot be deciphered. Thus omega appears to be totally structureless and random.\n",
        "  * In this sense, for omega, total information and total randomness seem to be “two sides of the same coin”. On a more pragmatic level, it seems impossible here to differen- tiate between order and chaos, or between knowledge and chance. **This gives a taste of what can be expected from any “hyper-computation” beyond universal computability** as defined by Turing. Source: [How to Acknowledge Hypercomputation?](https://content.wolfram.com/uploads/sites/13/2019/03/18-1-6.pdf)\n",
        "  * [Non-Turing Computers and Non-Turing Computability](https://www.jstor.org/stable/193018)\n",
        "  * Adamyan, Calude, Pavlov: Transcending the Limits of Turing Computability. Kieu: Computing the Noncomputable. Ord: The Many Forms of Hypercomputation. Davis: The Myth of Hypercomputation. Doria and Costa: Introduction to the Special Issue on Hypercomputation. Davis: Why There Is No Such Discipline as Hypercomputation\n",
        "  * Church–Kalmár–Kreisel–Turing theses theoretical concerning (necessary) limitations of future computers and of deductive sciences, in view of recent results of classical general relativity theory.  https://arxiv.org/abs/gr-qc/0104023\n",
        "\n"
      ],
      "metadata": {
        "id": "hojYWzd_AAMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Motivation: Beyond Limits of Quantum Computers - Scientific Questions**\n",
        "\n",
        "1. **Computational Complexity and Black Holes**: The ultimate computers? AdS/CFT and information paradox? Are Black Holes (Non-)Turing machines (describable and computable)? Are there Unknown laws of quantum gravity?\n",
        "2. **Computational Complexity and Universe**: Is it describable and computable (simulatable), or a non-Turing machine? Can we not simulate all problems (including quantum gravity) on standard QC's? And are there problems that really require computers that are more complex than QC?\n",
        "  * Where is actually the computational limit of (standard) quantum computers?  Do we really need more powerful computers?  What actually means more powerful than quantum computers? - Are there systems that are hard to simulate on standard, qubit-based quantum computers, then those systems themselves could be thought of as more powerful kinds of quantum computers, which solve at least one problem—the problem of simulating themselves —faster than is otherwise possible.\n",
        "  * Benefits of thining about Limits of quantum computing: Minimum eigenvalue gap of my hamiltonian (spectral gap decrease polynomial or exponentially as a function of the number of particles?). Eigenvalue gap can become exponentially small. **Limits of quantum computing have explanatory power: why spectral gaps behave the way they do?** Why they help to protect geometry of spacetime. Scott Aaronson: [Black Holes, Firewalls, and the Limits of Quantum Computers](https://www.youtube.com/watch?v=cstKRACrMQY&t=2446)\n",
        "  * Lloyd also postulates that the Universe can be fully simulated using a quantum computer; however, in the absence of a theory of quantum gravity, such a simulation is not yet possible. \"Particles not only collide, they compute.\" https://en.m.wikipedia.org/wiki/Programming_the_Universe\n",
        "  * **It from Qubit - Everything is computation (The universe as a computer)**\n",
        "    * But to a physicist, all physical systems are computers. Rocks, atom bombs and galaxies may not run Linux, but they, too, register and process information. Every electron, photon and other elementary particle stores bits of data, and every time two such particles interact, those bits are transformed. Physical existence and information content are inextricably linked. As physicist John A. Wheeler of Princeton University says, It from bit.\n",
        "    * What is the universe computing? Instead the universe is computing itself. Powered by Standard Model software, the universe computes quantum fields, chemicals, bacteria, human beings, stars and galaxies. As it computes, it maps out its own spacetime geometry to the ultimate precision allowed by the laws of physics. **Computation is existence.**\n",
        "    * **It from Qubit** from [Simons Collaboration on Quantum Fields, Gravity, and Information](https://web.stanford.edu/~phayden/simons/overview.pdf):\n",
        "      * Does spacetime emerge from entanglement?\n",
        "      * Can quantum computers simulate all physical phenomena?\n",
        "      * Do black holes have interiors? Does the universe exist outside our horizon?\n",
        "3. **Computational Complexity and Consciousness**: Is consciousness reducable to computation?\n",
        "\n"
      ],
      "metadata": {
        "id": "FQOMlaEP1y6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Case why Turing Machines are powerful enough**\n",
        "\n",
        "*No need for hypercomputers*\n",
        "\n",
        "**Type 1: Power of Standard Quantum Computers**\n",
        "\n",
        "* Refers to non-relativistic quantum mechanics quantum computers. Fun Fact: there is a line of research how to efficiently simulate quantum circuits on classical computers.\n",
        "\n",
        "* **Standard QCs can simulate all of quantum chemistry and atomic physics efficiently**: Could Nature allow more powerful kinds of quantum computers than the “usual” qubit-based kind? - Strong evidence that answer is “no” comes from work by Richard Feynman in the 1980s, and by Seth Lloyd and many others starting in the 1990s. They showed how to take a wide range of realistic quantum systems and simulate them using nothing but qubits. (..) it looks likely that a single device, a quantum computer, would in the future be able to simulate all of quantum chemistry and atomic physics efficiently.\n",
        "\n",
        "* **Standard QCs can simulate Quantum Field Theory efficiently**: Stephen Jordan, Keith Lee, and John Preskill gave the first detailed, efficient simulation of a “realistic” quantum field theory using a standard quantum computer (“adiabatic state preparation”).\n",
        "\n",
        "* **Standard QCs can simulate Quantum Gravity efficiently**: hint that a standard quantum computer could efficiently simulate even quantum-gravitational processes, like the formation and evaporation of black holes. Most notably, the AdS/CFT correspondence (assuming the translation is also computationally efficient, see more below under Black Hole Computing)\n",
        "  * [A simple quantum system that describes a black hole](https://arxiv.org/abs/2303.11534)\n",
        "  * [Quantum computers could simulate a black hole in the next decade](https://www.newscientist.com/article/2370695-quantum-computers-could-simulate-a-black-hole-in-the-next-decade/)\n",
        "\n",
        "**Type 2: Quantum Field Theory Computers**\n",
        "\n",
        "* Includes special relativity (quantum field theory).\n",
        "\n",
        "* Challenge: It’s not clear what we should program our quantum computer to simulate. Also, in most quantum field theories, even a vacuum is a complicated object.\n",
        "\n",
        "* A \"Quantum field theory computer” like from Michael Freedman, Alexei Kitaev, and Zhenghan Wang showed how to simulate a “toy” class of quantum field theories, called **topological quantum field theories** (TQFTs). What kinds of QFT can be simulated on standard QC:\n",
        "\n",
        "  * Simulations of QFT on QC to study chiral symmetry breaking, confinement, and deconfinement phase transition. Bigger QCs: simulate more complex QFTs to understand dark matter and dark energy. Potential to revolutionize our understanding of the fundamental forces of nature, but still in early stage\n",
        "  * **Lattice field theory**: simulate dynamics of field that is discretized onto lattice\n",
        "  * **Schwinger model** (simple QFT to study behavior of electrons in strong electric field, Google used 53-qubit QC in 2022, simulation reproduced known results from analytical calculations and provided new insights into behavior of Schwinger model)\n",
        "  * More QFTs simulatable: **Ising model, XY model, Heisenberg model, U(1) gauge theory, QCD (quantum chromo dynamics)**\n",
        "\n",
        "* But Stephen Jordan, Keith Lee, and John Preskill gave the first detailed, efficient simulation of a “realistic” quantum field theory using a standard quantum computer (“adiabatic state preparation”)\n",
        "\n",
        "**Is Nature actually np-hard? Are there really physical problems we cannot solve on standard QC's efficiently?**\n",
        "  * Penrose: speculated that quantum gravity is literally impossible to simulate using either an ordinary computer or a quantum computer, even with unlimited time and memory at your disposal. Penrose: is the brain a quantum gravitational computer? He wants the brain to be exploiting as yet unknown laws of quantum gravity. Which would be uncomputable.\n",
        "  * No, nature is not np-hard, makes mistakes also in protein folding: Nature can <u>not</u> solve all np problems (like soap bubbles is a myth). Scott aaronson: doing the soap experiment: you need to repeat the trial several times, it does not always find the best solution. it seems to find a local optimum mostly. Prions in protein: local optima! Scott Aaronson: [Black Holes, Firewalls, and the Limits of Quantum Computers](https://www.youtube.com/watch?v=cstKRACrMQY&t=2446). And it cannot scale to large number of nails. **In the case of soap bubbles, nature just seems to apply a really fast approximation which is accurate for small cases but breaks down at larger instances** (due to actual physical properties... i.e. it is physically impossible to build arbitrarily thin rods to dip into soapy water.) Many other NP-problems can be modeled as physical systems in which a lowest-energy-state would correspond to a solution to the combinatorial problem. You can find that \"DNA computing\" solves the clique problem, for instance. [Source](https://groups.google.com/g/comp.theory/c/11lY926-P7M?pli=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "KI9Gpnnj20st"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Computational Complexity and Consciousness**\n",
        "\n",
        "* Penrose further speculates that human brain is sensitive to quantum gravity effects, and that this gives humans ability to solve problems that are fundamentally unsolvable by computers. However, no other expert in relevant fields agrees with arguments that lead Penrose to this provocative position. [Source from Aaronson](https://www.pbs.org/wgbh/nova/article/is-there-anything-beyond-quantum-computing/)\n",
        "* [Hard problem of consciousness](https://en.m.wikipedia.org/wiki/Hard_problem_of_consciousness) and [Pretty hard problem](https://forum.effectivealtruism.org/posts/Qiiiv9uJWLDptH2w6/the-pretty-hard-problem-of-consciousness)\n",
        "* [p Zombie (Stanford)](https://plato.stanford.edu/entries/zombies/) and [Philosophical_zombie](https://en.m.wikipedia.org/wiki/Philosophical_zombie)\n",
        "* [Integrated information theory](https://en.m.wikipedia.org/wiki/Integrated_information_theory) - Is consciousness reducable to computation?\n",
        "  * Aaaronson: [Why I Am Not An Integrated Information Theorist (or, The Unconscious Expander)](https://scottaaronson.blog/?p=1799)\n",
        "  * Tegmark has also tried to address the problem of the computational complexity behind the calculations. According to Max Tegmark “the integration measure proposed by IIT is computationally infeasible to evaluate for large systems, growing super-exponentially with the system’s information content.”\n",
        "  * As a result, Φ can only be approximated in general. However, different ways of approximating Φ provide radically different results.\n",
        "  * “Which physical states are associated with consciousness, and which are not?” This question is what Scott Aaronson (2014) has dubbed the term “Pretty Hard Problem” [Source](https://forum.effectivealtruism.org/posts/Qiiiv9uJWLDptH2w6/the-pretty-hard-problem-of-consciousness)\n",
        "  * thought experiments such as Mary the super-scientist, color spectrum inversion, or p-zombies, which are meant to draw our attention to the alleged gap between physical explanations and consciousness.\n",
        "  * Source: [Neuroscience Readies for a Showdown Over Consciousness Ideas](https://www.quantamagazine.org/neuroscience-readies-for-a-showdown-over-consciousness-ideas-20190306/)\n",
        "* Consciousness is compression: [Will GPT-5 achieve consciousness? | Joscha Bach and Lex Fridman](https://www.youtube.com/watch?v=YDkvE9cW8rw&t=139s)\n",
        "\n",
        "https://www.heise.de/hintergrund/Anzeichen-von-Bewusstsein-bei-ChatGPT-und-Co-9295425.html\n",
        "\n",
        "https://www.spektrum.de/news/hat-kuenstliche-intelligenz-wie-chatgpt-ein-bewusstsein/2193018\n",
        "\n",
        "Was Bewusstseinstheorien zu künstlicher Intelligenz sagen\n",
        "Das wurde in einer noch nicht begutachteten Arbeit, die Ende August 2023 erschienen ist, getan. 19 führende KI-Forscher und Forscherinnen haben darin anhand von fünf bekannten Bewusstseinstheorien geprüft, ob heutige KI-Systeme (oder Systeme, die man in naher Zukunft herstellen könnte) demnach ein Bewusstsein haben. Dazu haben die Fachleute jeweils »notwendige Bedingungen« aus den Theorien extrahiert, die ein System besitzen müsste, um ein Bewusstsein zu besitzen. Je mehr dieser notwendigen Anforderungen ein System erfülle, so die Argumentation, desto wahrscheinlicher sei es bewusst.\n",
        "\n",
        "* arxiv: [Consciousness in Artificial Intelligence: Insights from the Science of Consciousness](https://arxiv.org/abs/2308.08708)\n",
        "\n",
        "| Theorie des <br> Bewusstseins | Künstliches Bewusstsein, falls: |\n",
        "| :---: | :---: |\n",
        "| Recurrent <br> Processing <br> Theory | Eingabemodule besitzen elnen Rekursionsalgorithmus, der <br> es ermöglicht, strukturierte und integrierte Repräsentationen <br> von sensorischen Signalen erzeugen. |\n",
        "| Global <br> Workspace <br> Theory. | Spezialisierte Module Können parallel arbeiten, und ein <br> globaler Arbeitsraum repräsentiert nur den Input eines der <br> Module, wobei die Informationen im Workspace fưr alle <br> Module verfügbar sind. |\n",
        "| (Computational) <br> Higher Order <br> Theory | Top-down-Module überwachen und unterscheiden <br> zuverlässige Repräsentationen von sensorischen Signalen. |\n",
        "| Attention <br> Schema Theory | enthält ein prädiktives Modell, das die Kontrolle über den <br> aktuellen Zustand der Aufmerksamkeit ermöglicht und <br> diesen repräsentiert |\n",
        "| Predictive <br> Processing <br> Theory | Bewusste Rechenvorgänge tragen zur Sicherung der <br> fortwährenden Existenz des Systems bei. Der kausale Fluss <br> der bewussten Berechnungen entspricht dem kausalen <br> Fluss der physischen Dynamik des Systems. |\n",
        "| Integrated <br> Information <br> Theory | Das System integriert mehr Information als seine <br> Teilsysteme. |\n",
        "\n",
        "*Hyperdimensional computing*\n",
        "\n",
        "https://www.quantamagazine.org/a-new-approach-to-computation-reimagines-artificial-intelligence-20230413/?mc_cid=ad9a93c472&mc_eid=506130a407\n",
        "\n",
        "* Instead, Olshausen and others argue that information in the brain is represented by the activity of numerous neurons. So the perception of a purple Volkswagen is not encoded as a single neuron’s actions, but as those of thousands of neurons. The same set of neurons, firing differently, could represent an entirely different concept (a pink Cadillac, perhaps).\n",
        "\n",
        "* This is the starting point for a radically different approach to computation known as hyperdimensional computing. The key is that each piece of information, such as the notion of a car, or its make, model or color, or all of it together, is represented as a single entity: a hyperdimensional vector.\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Hyperdimensional_computing\n",
        "\n"
      ],
      "metadata": {
        "id": "NQjv96Zo5uag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color=\"Blue\">**Black Hole Complexity**"
      ],
      "metadata": {
        "id": "2Xmk4oUjXRHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Physics of Black Holes (Schwarzschild Solution)*"
      ],
      "metadata": {
        "id": "D9VH8cY6Ia40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Supermassive Black Holes*"
      ],
      "metadata": {
        "id": "KR_qJb-WbsTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abell 2744**\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Abell_2744\n",
        "\n",
        "https://t3n.de/news/gigantisches-schwarzes-loch-verstaendnis-kosmos-1610772/\n",
        "\n",
        "A high black hole to host mass ratio in a lensed AGN in the early Universe, Nature: https://www.nature.com/articles/s41586-024-07184-8"
      ],
      "metadata": {
        "id": "NyCWq-wUbuqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Back Holes*"
      ],
      "metadata": {
        "id": "Zd3SbuXPo-mz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Video: [The Map of Black Holes](https://youtu.be/Wf0uxjWGwPk)\n",
        "\n",
        "\n",
        "*Kann ein schwarzes Loch seine ganze umgebende Galaxie verschlucken?* Nein!\n",
        "\n",
        "1. [Schwarzschildradius (Ereignishorizont)](https://de.m.wikipedia.org/wiki/Ereignishorizont)\n",
        "\n",
        "2. [Eddington-Leuchtkraft](https://de.m.wikipedia.org/wiki/Eddington-Grenze)\n",
        "\n",
        "3. Long run: [*Hawking Radiation (Black Hole Radiation)*](https://de.m.wikipedia.org/wiki/Hawking-Strahlung)"
      ],
      "metadata": {
        "id": "F8bg3biAyAkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.quantamagazine.org/jwst-spots-giant-black-holes-all-over-the-early-universe-20230814/\n",
        "\n"
      ],
      "metadata": {
        "id": "sj6ZzMxCSft_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.quantamagazine.org/math-proof-draws-new-boundaries-around-black-hole-formation-20230816/"
      ],
      "metadata": {
        "id": "_zyvus7cf5vH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supermassive Black Hole in Cygnus A, M87\n",
        "\n",
        "Ultramassive Black Hole: OJ 287, TON 618 (11 solar systems would fit)"
      ],
      "metadata": {
        "id": "MUARabl5Yynl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[TON 618](https://de.m.wikipedia.org/wiki/TON_618) - ist ein ferner, lichtstarker Quasar im Sternbild der Jagdhunde. Er enthält das mit vermutlich 66 bis 70 Milliarden Sonnenmassen massereichste derzeit bekannte Schwarze Loch.\n",
        "\n",
        "- Stellar blackholes: up to 3-99 solar masses (maybe millions in Milky Way)\n",
        "- Intermediate blackholes 100-99.999 solar masses, via binary star systems\n",
        "- Supermassive blackholes: 100.000 solar masses up to millions, like Sagittarius A*\n",
        "- Ultramassive blackholes / SLABs: 10 billion solar masses and more, like IC 1101* (Abell 2029 BCG) with 40 billion suns (event horizon thousands of times large than Neptune), 50-60 billion solar masses maybe a physical limit\n",
        "- TON-618 (The 618th entry in the Tonantzintla Catalogue refers a radio-loud Quasar-galaxy, z=2.29): 66 billion solar masses, event horizon (Schwarzschild radius): 400 billion kilometers (40x the distance between Neptune and sun, 40x 30AU = 1300 AU radius). Probably it’s only 40 billion masses\n",
        "- Phoenix A* (seyfert type 2 galaxy), 5,6 min light years away, most x-rays , most star formation, highest luminous gas. Brightest cluster galaxies (BCG): maybe 100 billion solar masses (24,000 time larger than sagittarius a*, and 7% of entire Milky Way, and 3x larger than Messier 33. Triangulum Galaxy). Vent horizon of half a trillion kilometers = 100x more than median distance between Pluto and sun (40AU). Same size also for IC1101, and Holnberg 15A. But seems all three are ore around 40 billion solar masses.\n",
        "- Another big one: Abell 1201 BCG, cD galaxy with around 32 billion solar masses"
      ],
      "metadata": {
        "id": "qJYWRAnO7uUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Ton 618 vs phoenix A Black Hole Size Comparison](https://youtu.be/vtqWnq4RZUE?si=phRqddq9Vjp5v4-d)"
      ],
      "metadata": {
        "id": "gelqAIuAGg3O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The largest black hole http://youtu.be/dx53GHSHrSA"
      ],
      "metadata": {
        "id": "uvJpGb4vSIWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1550.png)"
      ],
      "metadata": {
        "id": "gJF8H851pCEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Penrose-Diagram*"
      ],
      "metadata": {
        "id": "DA5HMxDY9iHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Penrose-Diagramm**](https://de.m.wikipedia.org/wiki/Penrose-Diagramm)\n",
        "\n",
        "Video [Was passiert am Ereignishorizont? | Space Time | PBS Digital Studios](https://www.youtube.com/watch?v=mht-1c4wc0Q)\n",
        "\n",
        "> Mit diesem Diagramm kann die globale Struktur der Lösungen der allgemeinen Relativitätstheorie (wie schwarze Löcher und andere Singularitäten, Ereignishorizonte, asymptotische Flachheit) graphisch dargestellt werden.\n",
        "\n",
        "* In der theoretischen Physik ist ein Penrose-Diagramm ein zweidimensionales Diagramm, das den kausalen Zusammenhang von verschiedenen Punkten in einer Raumzeit darstellt.\n",
        "\n",
        "* Es ist eine **Erweiterung des Minkowski-Diagramms**, bei dem horizontal der Raum und vertikal die Zeit eingetragen sind und ein Lichtkegel den kausalen Zusammenhang zwischen unterschiedlichen Ereignissen der Raumzeit zeigt.\n",
        "\n",
        "* Die im Penrose-Diagramm darzustellende Metrik wird mittels konformer Transformation kompaktifiziert, sodass eine unendliche Zeit- und eine unendliche Raumkoordinate als zweidimensionaler endlicher Unterraum dargestellt werden.\n",
        "\n",
        "> Mit diesem Diagramm kann die globale Struktur der Lösungen der allgemeinen Relativitätstheorie (wie schwarze Löcher und andere Singularitäten, Ereignishorizonte, asymptotische Flachheit) graphisch dargestellt werden.\n",
        "\n",
        "*Penrose-Diagramm als konforme Abbildung der (asymptotisch) flachen Minkowski-Raumzeit (siehe Abb. 2). Beide Diagramme repräsentieren die identischen kausalen Zusammenhänge zwischen Ereignissen, wobei in beiden Diagrammen die Weltlinien der Lichtstrahlen mit $\\textstyle \\pm 45^{\\circ }$ geneigte Geraden sind. Die bernsteinfarbene Kurve zeigt eine zeitartige Weltlinie, die im Penrose-Diagramm, wie im Minkowski-Diagramm, immer innerhalb der lilafarbenen Vorwärtslichtkegel verläuft.*\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1220.png)"
      ],
      "metadata": {
        "id": "_k6uxeYQ7-va"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Schwarzschild Metric (Schwarzschild Coordinates)*"
      ],
      "metadata": {
        "id": "8APTJDua9uNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ausgangspunkt: Spherically symmetric spacetime**\n",
        "\n",
        "* [Spherically symmetric spacetime](https://en.m.wikipedia.org/wiki/Spherically_symmetric_spacetime) are commonly used to obtain analytic and numerical solutions to Einstein's field equations in the presence of radially moving matter or energy.\n",
        "\n",
        "* Because spherically symmetric spacetimes are by definition irrotational, they are not realistic models of black holes in nature.\n",
        "\n",
        "* However, their metrics are considerably simpler than those of rotating spacetimes, making them much easier to analyze.\n",
        "\n",
        "* Spherical symmetry is a characteristic feature of many solutions of Einstein's field equations of general relativity, especially the Schwarzschild solution and the Reissner–Nordström solution."
      ],
      "metadata": {
        "id": "VFvJh1U23J9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Schwarzschild Metric allows us to compare two points or events in spacetime around a massive object from the perspective of different observers.\n",
        "\n",
        "> $\\Delta s^2=-\\left(1-\\frac{r_s}{r}\\right) \\Delta t^2+\\frac{1}{\\left(1-\\frac{r_s}{r}\\right)} \\Delta r^2$\n",
        "\n",
        "Video: [The Phantom Singularity | Space Time](https://www.youtube.com/watch?v=-q7EvLhOK08)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1255.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1256.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1257.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1258.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1259.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1260.png)\n",
        "\n",
        "For objects not traveling at speed of light and being at event horizon, time and space switch. The objects falls towards the central singularity:\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1261.png)\n",
        "\n",
        "Light from event horizon never reaches us - has infinite wavelength:\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1262.png)\n",
        "\n",
        "Remove coordinate singularity with other coordinates at event horizon:\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1263.png)"
      ],
      "metadata": {
        "id": "FqIBuvFaepsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Schwarzschild Solution (Schwarzschild Coordinates)*\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1235.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1237.png)"
      ],
      "metadata": {
        "id": "rNxDekLPOL4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schwarzschild-Koordinaten (Linienelement):**\n",
        "\n",
        "> ${\\displaystyle \\mathrm {d} s^{2}=g_{\\mu \\nu }\\mathrm {d} x^{\\mu }\\mathrm {d} x^{\\nu }=-c^{2}\\left(1-{\\frac {r_{\\mathrm {s} }}{r}}\\right)\\mathrm {d} t^{2}+{\\frac {1}{1-{\\frac {r_{\\mathrm {s} }}{r}}}}\\mathrm {d} r^{2}+r^{2}\\mathrm {d} \\theta ^{2}+r^{2}\\sin ^{2}(\\theta )\\mathrm {d} \\phi ^{2}}$\n",
        "\n",
        "In einem natürlichen Einheitensystem mit ${\\displaystyle G=c=1,r_{\\mathrm {s} }=2M}$ wird das Linienelement zu\n",
        "\n",
        "> ${\\displaystyle \\mathrm {d} s^{2}=-\\left(1-{\\frac {2M}{r}}\\right)\\mathrm {d} t^{2}+{\\frac {1}{1-{\\frac {2M}{r}}}}\\mathrm {d} r^{2}+r^{2}\\mathrm {d} \\theta ^{2}+r^{2}\\sin ^{2}(\\theta )\\;\\mathrm {d} \\phi ^{2}}$\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1228.png)"
      ],
      "metadata": {
        "id": "W8GkCu3xdqDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Schwarzschild Metric as a solution to the Einstein Field Equations (Birkhoff'sche Theorem)**\n",
        "\n",
        "* Schwarzschild black hole, which is often termed as the most basic type, namely non-rotating and non-charged\n",
        "\n",
        "* One of the few analytic solution to the Einstein Field equations (Gravitationsfeld einer kugelsymmetrischen Masseverteilung - Herleitung der entsprechenden Metrik dafur gelang Schwarzschild 1916).\n",
        "\n",
        "  * Schwarzschild Metrik ist die eindeutige Lösung der Vakkum-Feldgleichungen (mit sphärischer Symmetrie und verschwindender kosmologischer Konstante). [Exact solutions in general relativity > Types of exact solution](https://en.m.wikipedia.org/wiki/Exact_solutions_in_general_relativity#Types_of_exact_solution)\n",
        "\n",
        "  * Siehe auch [Birkhoff'sche Theorem](https://de.m.wikipedia.org/wiki/Birkhoff-Theorem): „*Eine sphärisch symmetrische [Vakuumlösung](https://de.m.wikipedia.org/wiki/Vakuumlösung) der einsteinschen Feldgleichungen außerhalb einer sphärisch symmetrischen Massenverteilung muss statisch sein und diese Lösung muss die Schwarzschild-Lösung sein*.“\n",
        "\n",
        "* [Schwarzschild-Metrik](https://de.m.wikipedia.org/wiki/Schwarzschild-Metrik) ist für ein statisches und ungelades Schwarzes Loch\n",
        "\n",
        "* **Die Schwarzschild-Metrik gilt für alle sphärisch-symmetrischen Massen-verteilungen mit verschwindender kosmologischer Konstante**. Befindet sich diese Massenverteilung vollständig unterhalb des Schwarzschild-Radius, so beschreibt sie auch eines der außergewöhnlichsten Objekte in der ART - ein statisches Schwarzes Loch.\n",
        "\n",
        "* Schwarzschild-Metrik **drescribes the most simplified Black hole which can exist: a single unit of a compressed mass within a completely empty plane of spacetime, and hence unaffected by surroundings** (It's an eternal black hole)\n",
        "\n",
        "* **The [Schwarzschild metric](https://de.m.wikipedia.org/wiki/Schwarzschild-Metrik) describes the gravitational field outside a spherical mass**.\n",
        "\n",
        "* Nur Aussenrand betrachtet erstmal. Innenraum: interessant bei Behandlung Neutronensterne\n",
        "\n",
        "\n",
        "* Video: [Schwarzschild metric - part 1](https://www.youtube.com/watch?v=UJmAl10srHs)\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1160.png)\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1159.png)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MZfJ-Rft5yrI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Singularities**\n",
        "\n",
        "* Some singularities come from choice of reference frame or coordinate system.\n",
        "\n",
        "  * Like event horizon is a frame-dependent singularity.\n",
        "\n",
        "  * Or on earth, North and south pole are ‘coordinate singularities’, because you can pass time zones infinitely quickly, but only because of choice of spherical coordinates.\n",
        "\n",
        "* But gravitational singularity at the center of a black hole is a real singularity, because curvature and density are infinite from any reference frame. You can change to any coordinate system and you get the same result.\n",
        "\n",
        "* However, the reality of the black hole singularity may give reason to **doubt the theory** that predicts such a thing.\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1254.png)"
      ],
      "metadata": {
        "id": "NgRkZKXTdW2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Event Horizon and Schwarzschild Radius**\n",
        "\n",
        "* A Schwarzschild black hole is characterized by a surrounding spherical boundary called the [event horizon](https://en.m.wikipedia.org/wiki/Event_horizon) / [Ereignishorizont](https://de.m.wikipedia.org/wiki/Ereignishorizont) which occurs at the Schwarzschild radius.\n",
        "\n",
        "\n",
        "* Bei statischen Schwarzen Löchern ist der Ereignishorizont eine Kugeloberfläche, deren Radius [Schwarzschild-Radius](https://en.m.wikipedia.org/wiki/Schwarzschild_radius) genannt wird. [Source](https://de.wikipedia.org/wiki/Allgemeine_Relativitätstheorie#Metriken_Schwarzer_Löcher)\n",
        "\n",
        "  * The sun, for example, has a radius of 700,000km\n",
        "but has a Schwarzschild radius of just 3km.\n",
        "\n",
        "  * The earth's radius is 6371 km but its Schwarzschild radius is just 9mm, about the size of a peanut.\n",
        "\n",
        "* <font color=\"blue\">Either of these would have to collapse to their respective Schwarzschild radius before the force of gravity would overcome the nuclear forces and they would continue to become a black hole</font>, something that will never happen to either of them because they don't have the mass required.\n",
        "\n",
        "\n",
        "Video: [Do Events Inside Black Holes Happen?](https://www.youtube.com/watch?v=vNaEBbFbvcY)\n",
        "\n",
        "* Events at and in the black hole don't happen to an observer form outside. Events = Where and <strike>When</strike>? A \"when\" cannot not consistently be assigned!\n",
        "\n",
        "> **And a black hole is exactly that set of events (that don't happen to an outside observer)**\n",
        "\n",
        "* black hole is not just a set of locations. Black hole = all events that take place at these locations.\n",
        "\n",
        "* it's not a visibility issue (thaty things happen but we simply cant see them). a black hole is the collection of happenings that we say dont happen at all. **And the black blob is just how it looks like in ordinary temporal and spatial terms when you delete these occurrences from all observers from the history of the universe**.\n",
        "\n",
        "* the last thing we can see is the called 'event horizon'. but it's not just a spherical surface in space. **An event horizon is a surface in spacetime. It represents the last event to which you can even assign a \"when\"**\n",
        "\n",
        "* Fun fact: a black hole is not because all light is sucked in it\n",
        "\n",
        "  * the photons are simply falling radially inwards and the geometry inside a black hole is so distored, that going out is not a valid option anymore\n",
        "\n",
        "  * Moreover, from our external point the photon never entered the black hole. everyhting freezes on its surface to us. The wavelength of the last photon is stretch until infinity (redshifted to undetectable low frequencies).\n",
        "\n",
        "  > **So to us a black hole looks black because light that gets emitted just outside the horizon is redshifted into invisibility.**\n",
        "\n",
        "  * the infinite redshift keeps you from seeing it at all.\n",
        "\n",
        "If the sun is a perfect sphere\n",
        "\n",
        "* It determines the spacetime geometry in its neighbourhood, the resulting geodesics of which correspond to radial freefall, obrits etc\n",
        "\n",
        "* If I replace the sun with a 6 km (3) black hole, the geodesics beyond where the sun's edge used to be, remain change. Earth's orbit won't be any different = that black hole generates the same spacetime geometry out here than the sun does\n",
        "\n",
        "* the black hole is not a vaccum cleaner that suck stuff in. The idea comes from the region that used to be inside the sun but outside the black hole (event horizon edge)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1245.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1246.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "V8VF1RCIsK41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Penrose–Hawking singularity theorems & Gravitational singularity**\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Gravitational_singularity\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Penrose–Hawking_singularity_theorems\n",
        "\n",
        "*Gravitational singularity*\n",
        "\n",
        "* A [gravitational singularity](https://en.m.wikipedia.org/wiki/Gravitational_singularity), spacetime singularity or simply singularity is a condition in which gravity is so intense that spacetime itself breaks down catastrophically.\n",
        "\n",
        "* As such, a singularity is by definition no longer part of the regular spacetime and cannot be determined by \"where\" or \"when\"."
      ],
      "metadata": {
        "id": "LDb92b8nynXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why space and time switch in a black hole?**"
      ],
      "metadata": {
        "id": "_mBEZRzjJbIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Switch means what flows unidirectional forward: time outside, and space (all paths) inside)**\n",
        "\n",
        "> Once crossing the event horizon, all paths lead to singularity - **space flows unidirectional downwards** and leading only to the central singularity (faster than speed of light), just like **time flows unidirectional forward** outside the black hole. [Source](https://www.youtube.com/watch?v=mht-1c4wc0Q)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1270.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "lFqJcKjaQVKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Event Horizon and Kretschmann-Skalar / Singularität**\n",
        "\n",
        "* Der [Kretschmann-Skalar](https://de.m.wikipedia.org/wiki/Kretschmann-Skalar) $K$ (auch Kretschmann-Invariante oder Riemannsche Invariante) bezeichnet eine skalare Invariante im Bereich der Lorentzschen Mannigfaltigkeiten.\n",
        "\n",
        "* Er kann als Maß für die Krümmung der Raumzeit in der allgemeinen Relativitätstheorie gedeutet werden.\n",
        "\n",
        "* Für die Schwarzschild-Metrik ist der Kretschmann-Skalar mit dem Schwarzschild-Radius $r_{s}$ gegeben durch:\n",
        "\n",
        "> ${\\displaystyle K={\\frac {12{r_{s}}^{2}}{r^{6}}}={\\frac {48G^{2}M^{2}}{c^{4}r^{6}}}}$\n",
        "\n",
        "* Dieser Krümmungsskalar verhält sich im Gegensatz zum Ricci-Skalar bei $r$ = $r_s$ regulär und hat keine Singularität - es ist nur eine [Coordinate_singularities](https://en.m.wikipedia.org/wiki/Singularity_(mathematics)#Coordinate_singularity)\n",
        "\n",
        "* **Bei $r = r_s$ (am Ereignishorizont) erreicht die [Fluchtgeschwindigkeit](https://de.m.wikipedia.org/wiki/Fluchtgeschwindigkeit_(Raumfahrt)) des schwarzen Loches die Lichtgeschwindigkeit**\n",
        "\n",
        "\n",
        "* Es hat dennoch eine physikalische Bedeutung, denn die Metrikkomponenten $g_{tt}$ und $g_{rr}$ in der Schwarzschild-Metrik wechseln die Vorzeichen.\n",
        "\n",
        "* Das bedeutet die Koordinaten Zeit t und Raum r tauschen hier ihren raum- bzw. zeitartigen Charakter. Im Fall der Schwarzschild-Metrik wird diese Kugeloberfläche auch Ereignishorizont genannt. Nichts dahinter kann von aussen beobachtet werden.\n",
        "\n",
        "\n",
        "> Die Lichtkegel verengen sich bei Annäherung an den Schwarzschild-Radius. Für r > r_s sind sie entlang der Zeitachse geöffnet, **für r < r_s öffnen sich die Lichtkegel entlang der Raumachse, d. h. r wird eine zeitartige und t eine raumartige Koordinate**. Unterhalb des Horizonts bewegt sich alles unausweichlich auf die Singularität bei r = 0 zu.\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1213.png)\n"
      ],
      "metadata": {
        "id": "Af7lNN5vtAV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[Why space and time switch in a black hole? - Spacetime Singularity & Curvature Singularity (Gravitational singularity)](https://en.m.wikipedia.org/wiki/Gravitational_singularity)**\n",
        "\n",
        "Video:[**Why space and time switch in a black hole?**](https://www.youtube.com/watch?v=GQZ3R81iyE0)\n",
        "\n",
        "Video: [Wie Zeit in einem schwarzen Loch zu Raum wird | Space Time](https://www.youtube.com/watch?v=KePNhUJ2reI)\n",
        "\n",
        "\n",
        "* At a  center of every black hole lies a **spacetime singularity**; a point so deformed by mass compression that it punches through the fabric of spacetime to become a physical boundary of the universe, a place where all light and matter meet their eternal end.\n",
        "\n",
        "* In addition, a black hole has a **curvature singularity**, which is the part where the curvature of deformed spacetime begins to take on infinite values. It is here where science begins to depart from General relativity.\n",
        "\n",
        "* If we were somehow able to survive up until this point, then we would experience something very strange: **time and space, as connected entities, would switch roles, as the black hole's interior becomes infinite**.\n",
        "\n",
        "> **The singularity is suddenly no longer a physical point, but rather an inevitable event in the future.**\n",
        "\n",
        "* Space is so warped that all paths will inevitably lead us to this singularity, but time is so that we would require an ever-increasing amount of it to get there, as time on the outside slows down and eventually stops, forever.\n",
        "\n",
        "* And so, at this point, our cosmic fate would be sealed. We would be frozen in that moment of time forever more. The singularity now represents the infinite future of a featureless, timeless dimension, from which nothing will ever be able to escape. You would never reach the bottom of this sinkhole.. you would just continue cruising deeper into your eternal cosmic chamber, unless you were to hit another part of spacetime."
      ],
      "metadata": {
        "id": "F0XISHhtq4Sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the mathematical explanation:\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1235.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1237.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1238.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1239.png)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ge36WXVaQIkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And here the graphical explanation based on Penrose diagrams:\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1240.png)\n",
        "\n",
        "We need to switch to Penrose diagram:\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1241.png)\n",
        "\n",
        "> <font color=\"blue\">See above: in left picture time is Y axis (going only forward) and space is X axis. In right picture (in black hole) the time is now X axis and space is Y axis (going only forward) </font>\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1242.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1243.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1244.png)"
      ],
      "metadata": {
        "id": "3YOkZqCrVjAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[Why time stops in the Black Hole and we can't see inside a Black Hole? - Tidal Forces](https://en.m.wikipedia.org/wiki/Tidal_force), Speed of Light and Event Horizon**\n",
        "\n",
        "* Tidal forces: The strength of gravity is inversely proportional to the square of the distance away between two objects.\n",
        "\n",
        "* In the black hole, space is increasing faster then the speed of light, due to the gravitational pull, hence light cannot escape. <font color=\"blue\">**Reaching the centre of the black hole would take forever, and the photon would never reach the centre, because the gravitation is increasing faster than the speed of light (otherwise light would be able to escape the black hole)**</font>\n",
        "\n",
        "* To a photon, a journey from one side of the\n",
        "universe to the other is instant because at the speed of light time stops even though\n",
        "to us as the outside observers it takes a hundred billion years or more allowing for\n",
        "the expanding universe.\n",
        "\n",
        "* <font color=\"blue\">Because the force of gravity goes from very little away from the black hole to infinity at its centre, the tidal forces generated could be huge over distances at short as a couple of meters.</font>\n",
        "\n",
        "* Once beyond the horizon, everything including space itself is travelling faster than the speed of light if you could measure it against a fixed point outside. This is allowed, although nothing can travel faster than the speed of light in a vacuum, there is nothing to say that space itself can't travel faster.\n",
        "\n",
        "> <font color=\"blue\">That's what's happening with a black hole: **the extreme pull of gravity is distorting space-time so much that its moving faster towards the singularity than the light inside and that's why we can never see inside a black hole and once over the horizon, we would never see our astronaut again**.</font>\n",
        "\n",
        "Crossing the event horizon:\n",
        "\n",
        "* there is\n",
        "no absolute time, time is relative to each person and their circumstances depending on\n",
        "how warped the piece of spacetime where they are.\n",
        "* This leads us to a rather strange duality\n",
        "of possibilities:\n",
        "* Whilst our astronaut was moving closer to the event horizon in maybe a few just minutes or seconds of their time, to us on the outside\n",
        "they were already travelling close to the speed of light, so seconds to them would become\n",
        "months and ears to us. By the time they cross the horizon, it could be in the far future for us as time for them essentially grinds to a halt from our perspective.\n",
        "* To our astronaut looking out at the universe,\n",
        "it would seem as though the rest of it was speeding up exponentially and even though\n",
        "the amount of time they have left to live could be measured in minutes or seconds, they\n",
        "will have outlived all the life on earth and whatever humans became either by design or\n",
        "evolution.\n",
        "* The astronaut would be somehow dead and alive at the same time: Whilst the rest of the crew would return to live their lives, our astronaut would be frozen in time, alive in their version of reality, yet dead to us\n",
        "\n",
        "Temperature and density in a black hole\n",
        "* Before they reach the centre of the black hole they will enter the most extreme place in the universe this side of the big bang. The density of matter at the centre of the singularity is thought to reach the plank density or higher.\n",
        "* Planck density: if you take all matter of the observable universe and compress it into a space of the size of an atom\n",
        "* As you compress matter the it gets hotter\n",
        "as the particles collide together ever more energetically and as it approaches the centre\n",
        "of the black hole the temperature would rise to trillions of times greater than the centre\n",
        "of the sun but then at the actual singularity, the point of infinity, it would be about just\n",
        "a millionth of a degree above absolute zero because heat is energy is light and it can't\n",
        "escape, so there is nothing to measure, therefore there is essentially no temperature, except\n",
        "the tiny amount from the hawking radiation that leaks out.\n",
        "* end of a black hole maybe: information in form of Hawking radiation in 10^100 years during the heat death of the universe as the black holes eventually evaporates away\n",
        "\n",
        "Source: https://www.youtube.com/watch?v=JqyX26y6g2A&list=WL&index=8"
      ],
      "metadata": {
        "id": "3KRczKRz67yG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Maximally-Extended Schwarzschild Solution (Kruskal-Szekeres Coordinates)*"
      ],
      "metadata": {
        "id": "OQhOPkypmczT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [PBS: How new coordinates help solve the coordinate singularity](https://youtu.be/T4oYvSH6jJ8) (eddington finkelstein and kruskal szekeres)"
      ],
      "metadata": {
        "id": "pzWO-UNuPXJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Kruskal-Szekeres-Koordinaten](https://de.m.wikipedia.org/wiki/Kruskal-Szekeres-Koordinaten)\n",
        "\n",
        "* Penrose-Diagramm eines statischen Schwarzen Loches. **Grundlage ist die Schwarzschild-Metrik mit [Kruskal-Szekeres-Koordinaten](https://de.m.wikipedia.org/wiki/Kruskal-Szekeres-Koordinaten)** als maximale analytische Erweiterung der Schwarzschildlösung [Source](https://de.m.wikipedia.org/wiki/Penrose-Diagramm)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0711.png)\n",
        "\n",
        "* Kruskal-Szekeres-Koordinaten sind Koordinaten für die Schwarzschild-Metrik, die Metrik, die den Außenraum einer kugelsymmetrischen, nicht rotierenden und elektrisch neutralen Massenverteilung beschreibt.\n",
        "\n",
        "* Die [Kruskal-Lösung](https://de.m.wikipedia.org/wiki/Kruskal-Lösung) ist eine maximale Erweiterung der Schwarzschild-Lösung. Sie weist intrinsische Singularitäten auf, weshalb sie nicht vollständig ist.\n",
        "\n",
        "* Die Lösung kann als eine Beschreibung von Einstein-Rosen-Brücken bzw. Wurmlöchern angesehen werden.\n",
        "\n",
        "* Kruskal-Szekeres-Koordinaten werden am Ereignishorizont $r=2M$ nicht singulär und werden deswegen gerne für die Beschreibung Schwarzer Löcher eingesetzt (präziser: für die Beschreibung durch mitbewegte, interne Beobachter im Gegensatz zu externen Beobachtern, die zum Beispiel im Außenbereich an einen Stern „fixiert“ sind.)\n",
        "\n",
        "* In general relativity [Kruskal–Szekeres coordinates](https://en.m.wikipedia.org/wiki/Kruskal–Szekeres_coordinates) are a coordinate system for the Schwarzschild geometry for a black hole. **These coordinates have the advantage that they cover the entire spacetime manifold** of the maximally extended Schwarzschild solution and are well-behaved everywhere outside the physical singularity. There is **no misleading coordinate singularity at the horizon**.\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1216.png)\n",
        "\n",
        "*The [Kruskal–Szekeres diagram](https://en.m.wikipedia.org/wiki/Kruskal–Szekeres_coordinates), illustrated for 2GM=1. The quadrants are the black hole interior (II), the white hole interior (IV) and the two exterior regions (I and III). The dotted 45° lines, which separate these four regions, are the event horizons. The darker hyperbolas which bound the top and bottom of the diagram are the physical singularities. The paler hyperbolas represent contours of the Schwarzschild r coordinate, and the straight lines through the origin represent contours of the Schwarzschild t coordinate:*\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1224.png)"
      ],
      "metadata": {
        "id": "7erd6uybQIce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Maximally-Extended Schwarzschild Metric with [White Holes](https://en.m.wikipedia.org/wiki/White_hole) and [Einstein-Rosen-bridges (Wormholes)](https://en.m.wikipedia.org/wiki/Wormhole)**\n",
        "\n",
        "*Schwarzschild Metric with Eternal Black Holes*\n",
        "\n",
        "* A few months after Einstein presented his Theory of General Relativity, in which he first predicted the black hole, a German scientist named Karl Schwarzschild solved the field equations for their first exact solution; giving us the Schwarzschild Metric.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0700.jpg)\n",
        "\n",
        "* The Schwarzschild Metric describes the most simplified black hole which can exist; a single unit of compressed mass within a completely empty plane of spacetime, which is therefore unaffected by its surroundings. One which was never born and one that will never die, never growing or shrinking- an Eternal Black Hole.\n",
        "\n",
        "* It was from this earliest of case studies for General Relativity that the white hole was extrapolated, almost half a century later. **In addition to admitting positive square root value solutions, the Schwarzschild Metric also admits negative square root solutions.**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0701.jpg)\n",
        "\n",
        "* In simple terms, we can extend the Eternal Black Hole model to account for a new dimension where we find the white hole.\n",
        "\n",
        "* To make this easier to understand, we can use a diagram. Here is our universe, with us at the centre- you have the infinite past and future running along the y-axis, and distance running along the x-axis, marked by the cosmic horizon.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0702.jpg)\n",
        "\n",
        "* Spacetime is represented by curling lines which flow across the diagram, and light travels diagonally.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0703.jpg)\n",
        "\n",
        "* Now, if we add in the eternal black hole- one of the cosmic horizons becomes the black hole's event horizon- the point of no return and a boundary of the universe. Anything within this event horizon will need to travel for an infinite amount of time to escape, i.e., it will never happen.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0704.jpg)\n",
        "\n",
        "* If we go beneath this horizon, we extend the diagram into the black hole's interior. This is the area we spoke about where space and time switch roles; the place where time stops and the singularity becomes the infinite future.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0705.jpg)\n",
        "\n",
        "* The thing is, however, that this black hole is eternal- and so as well as accounting for the infinite future, we must account for the infinite past. And so, we can extend our diagram on the past side. What we get is a time-reversed black hole- as in, a black hole viewed backwards in time, and thus, it ejects its matter and energy.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0706.jpg)\n",
        "\n",
        "* The singularity is now an event in the infinite past which can never be reached trying to get there would be like trying to travel backwards in time.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0707.jpg)\n",
        "\n",
        "* And so instead, light and matter can only flow outwards, away from the singularity and into the universe.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0708.jpg)\n",
        "\n",
        "* And thus, we have our white hole- which works inversely to the black hole, by ejecting matter into space.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0709.jpg)\n",
        "\n",
        "* And connecting the horizons is our Einstein-Rosen Bridge, which may lead us to another part of space, another point in time, or perhaps to a new dimension entirely..\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0710.jpg)\n",
        "\n",
        "**White Holes as New Universes**\n",
        "\n",
        "* Big bang = White hole? This idea gives us the perspective we need to complete our cosmic diagram. Once we've added in our past and future black hole extensions, the Einstein-Rosen Bridge does not lead us back into another place within our universe, like a wormhole would.\n",
        "\n",
        "* Instead, if we follow the negative square root solution of the Schwarzschild Metric beyond the black hole's interior, past it leads to its own universe- a parallel universe Where time runs backwards, thus giving us: our maximally-extended Schwarzschild Solution, the [Kruskal–Szekeres coordinates](https://en.m.wikipedia.org/wiki/Kruskal–Szekeres_coordinates).\n",
        "\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0711.png)\n",
        "\n",
        "> Video: [Black Hole Cosmology (Schwarzschild cosmology) - other side of a black hole](https://youtu.be/ZVPsNDonA84)"
      ],
      "metadata": {
        "id": "FhYVACl3pHGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Killing vector and a Killing horizon*"
      ],
      "metadata": {
        "id": "ypsYD62SW6N9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://de.m.wikipedia.org/wiki/Killing-Vektorfeld\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Killing_horizon\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Null_hypersurface"
      ],
      "metadata": {
        "id": "0H2cDGKOXUj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The concept of a \"killing vector\" and \"killing horizon\" is a theoretical concept in physics that describes the boundary between regions of spacetime where it is possible to escape to a distant observer and regions where it is not. The concept was introduced by the physicist Roger Penrose in the 1960s.\n",
        "\n",
        "A killing vector is a vector field that leaves the spacetime metric (which describes the curvature of spacetime) invariant. In other words, if you move along a killing vector, the spacetime metric around you does not change. This means that killing vectors are geodesics, which are the straightest possible paths in spacetime.\n",
        "\n",
        "A killing horizon is a surface that is orthogonal to all killing vectors. In other words, if you cross a killing horizon, you can no longer move along a killing vector. This means that killing horizons are the boundaries of regions of spacetime where it is not possible to escape to a distant observer.\n",
        "\n",
        "The concept of killing vectors and killing horizons is important in understanding the formation of black holes. Black holes are regions of spacetime where gravity is so strong that not even light can escape. The boundary of a black hole is called the event horizon. According to Penrose's theory, the event horizon of a black hole is a killing horizon.\n",
        "\n",
        "The concept of killing vectors and killing horizons is also important in understanding the Big Bang. The Big Bang was the event that marked the beginning of the universe. According to Penrose's theory, the Big Bang singularity is a killing horizon. This means that it is not possible to escape from the Big Bang singularity, even in principle.\n",
        "\n",
        "The concept of killing vectors and killing horizons is a complex one, and it is still not fully understood. However, it is a powerful tool for understanding some of the most fundamental phenomena in physics, such as black holes and the Big Bang."
      ],
      "metadata": {
        "id": "SrtoCEpMXORB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A \"Killing vector\" in the context of mathematics and physics, particularly in general relativity and differential geometry, is a concept that describes symmetries in spacetime or other geometric spaces. Here's a more detailed explanation:\n",
        "\n",
        "1. **Killing Vector**: A Killing vector field on a Riemannian manifold (which is a space where you can define distances and angles) is a vector field that represents a symmetry of the manifold. Essentially, if you move along a Killing vector, the geometry of the space does not change. In general relativity, Killing vectors are used to identify symmetries of spacetime. For example, in a spacetime that is symmetric in time, there will be a Killing vector corresponding to this time symmetry. Similarly, in a spherically symmetric space, there are Killing vectors corresponding to rotational symmetries.\n",
        "\n",
        "2. **Killing Horizon**: A Killing horizon is a hypersurface in spacetime on which a Killing vector field becomes null (or lightlike). This is a concept that is particularly important in the study of black holes. In simple terms, a Killing horizon is often associated with the event horizon of a black hole. It is the region where the Killing vector, which represents a certain symmetry (like time translation symmetry), becomes null. This means that at the horizon, the concepts of time and space as understood in normal circumstances become intertwined in a way that is characteristic of the relativistic effects near a black hole.\n",
        "\n",
        "Both concepts are crucial in the study of general relativity and play a significant role in understanding the geometry of spacetime and the behavior of objects like black holes."
      ],
      "metadata": {
        "id": "0QcVrW6XW-sg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Singularitäten-Theorem*"
      ],
      "metadata": {
        "id": "HX_Y0zpTYD8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [How The Penrose Singularity Theorem Predicts The End of Space Time](https://www.youtube.com/watch?v=z4odQd8q3xY)\n",
        "\n",
        "[Singularitäten-Theorem](https://de.m.wikipedia.org/wiki/Singularitäten-Theorem): Penrose–Hawking singularity theorems: a set of results in general relativity that attempt to answer the question of when gravitation produces singularities\n",
        "\n",
        "A singularity in solutions of the Einstein field equations is one of two things:\n",
        "1. a situation where matter is forced to be compressed to a point (a space-like singularity)\n",
        "2. a situation where certain light rays come from a region with infinite curvature (a time-like singularity)\n",
        "\n",
        "Space-like singularities are a feature of non-rotating uncharged black holes as described by the Schwarzschild metric, while time-like singularities are those that occur in charged or rotating black hole exact solutions. Both of them have the property of geodesic incompleteness, in which either some light-path or some particle-path cannot be extended beyond a certain proper time or affine parameter (affine parameter being the null analog of proper time).\n",
        "\n",
        "> **In a Schwarzschild black hole, time ceases at the point-like central singularity, while in Kerr black holes space ends at the ring singularity.**\n",
        "\n",
        "[Geodesic incompleteness](https://en.m.wikipedia.org/wiki/Geodesic_manifold): In the theory of general relativity, which describes gravity in terms of a pseudo-Riemannian geometry, many important examples of geodesically incomplete spaces arise, e.g. non-rotating uncharged black-holes or cosmologies with a Big Bang. The fact that such incompleteness is fairly generic in general relativity is shown in the Penrose–Hawking singularity theorems.\n",
        "\n"
      ],
      "metadata": {
        "id": "PdxyWChlYIs0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Spinning Black holes (Kerr Solution & Boyer–Lindquist & Kerr-Schild coordinates)*"
      ],
      "metadata": {
        "id": "T3lxJ4d7BriG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Blandford-Zjanek process or Black hole bomb with mirrors: [How Black holes spin space time](https://youtu.be/UjgGdGzDFiM?si=i3q0LFySMKns9CV9)"
      ],
      "metadata": {
        "id": "hT_t4X2USOr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1696.png)"
      ],
      "metadata": {
        "id": "KycDWFFzcOFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1697.png)"
      ],
      "metadata": {
        "id": "6bICQVNJcQGe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extremal Kerr black holes could amplify new physics**\n",
        "\n",
        "* [Theoretical study shows that Kerr black holes could amplify new physics](https://phys-org.cdn.ampproject.org/c/s/phys.org/news/2023-09-theoretical-kerr-black-holes-amplify.amp)\n",
        "\n",
        "* Researchers have shown that extremal Kerr black holes, a type of rapidly spinning black hole, could be sensitive probes of new physics. These black holes have a unique characteristic: their horizons are affected by infinite tidal forces in the presence of a cosmological constant. This means that if anything were to fall into the black hole, it would be crushed by gravity before it moved even remotely close to the black hole's center.\n",
        "\n",
        "* However, the researchers showed that if the cosmological constant is zero, as it is assumed to be in many astrophysical scenarios, this effect vanishes. They then considered Einstein gravity coupled to its leading quantum corrections, and found that these corrections make the singularity jump all the way from the center of the black hole to the horizon. This suggests that the spacetime geometry near the horizon of these black holes is sensitive to new physics at higher energies.\n",
        "\n",
        "  * Class of black holes known as **extremal Kerr black holes**, which are **uncharged stationary black holes with a coinciding inner and outer horizon**. These black holes' unique characteristics could make them ideal \"amplifiers\" of new, unknown physics.\n",
        "\n",
        "  * in the presence of a cosmological constant extremal black holes are affected by infinite tidal forces. This means that if living beings were to fall into the black hole, they would be crushed by gravity before they moved even remotely close to the black hole's center. Yet the team showed that if the cosmological constant is zero, as it is assumed to be in many astrophysical scenarios, this effect vanishes.\n",
        "\n",
        "  * work on black hole horizon singularities, I asked whether other effects could give rise to such phenomena. My previous work on effective field theories (EFTs), particularly development of physics models with quantum corrections, gave me an idea. Talking with Horowitz, I wondered whether the higher-derivative terms in a gravitational EFT (i.e., quantum corrections to the Einstein equations) could themselves lead to singularities on the horizons of extreme black holes.\"\n",
        "\n",
        "  * the researchers considered Einstein gravity coupled to its leading quantum corrections: \"The Einstein equations are linear in the Riemann tensor, a mathematical object describing the curvature of spacetime,\" Remmen explained. \"In three space dimensions, the leading corrections to Einstein are terms that are cubic (third power) and quartic (fourth power) in the curvature. Because curvature is a measure of derivatives of the spacetime geometry, such terms are called 'higher-derivative terms.' We calculated the effect of these higher-derivative terms on rapidly spinning black holes.\"\n",
        "\n",
        "  * \"Surprisingly, EFT corrections make the singularity jump all the way from the center of the black hole out to the horizon, where you wouldn't expect it to be,\" Remmen said. \"The value of the coefficient in front of a given EFT term—the 'dial settings' in the laws of physics—are dictated by the couplings and types of particle that are present at high energies and short distances. In this sense, EFT coefficients are sensitive to new physics.\"\n",
        "\n",
        "  * Kolanowski, Horowitz, Remmen and Santos also found that the strength of the divergence in tides at the horizon of extremal black holes, and the possible occurrence of tidal singularity, heavily depends on the EFT coefficients. The results of their calculations thus suggest that the spacetime geometry near the horizon of these black holes is sensitive to new physics at higher energies.\n",
        "\n",
        "  * \"Interestingly, this unexpected singularity is present for the values of these EFT coefficients generated by the Standard Model of particle physics,\" Remmen said.\n",
        "\n",
        "  * \"Our results are surprising, since they imply that the low-energy description of physics can break down in a situation where you wouldn't expect that to happen. In physics, there's usually a sense of 'decoupling' between different distance scales. For example, you don't need to know the details of water molecules to describe waves using hydrodynamics. Yet for rapidly spinning black holes, that's precisely what happens: the low-energy EFT breaks down at the horizon.\"\n",
        "\n",
        "  * Overall, the calculations carried out by this team of researchers hint at the promise of extremal Kerr black holes for probing new physical phenomena. While the horizon of these black holes can be very large, it was not expected to have an infinitely large curvature (i.e., infinite tidal forces) in the EFT. Their results show that it does.\n",
        "\n",
        "  * \"In future work, we are interested in exploring whether the singularities can be resolved by ultraviolet physics,\" Remmen added. \"A pressing question is whether the sensitivity of the horizon to new physics persists all the way to the Planck scale, or whether the horizon 'smooths out' at the short-distance scale associated with the EFT. We are also looking for other situations in which short distance effects might show up unexpected at large distances.\"\n",
        "\n",
        "* Gary T. Horowitz et al, [Extremal Kerr Black Holes as Amplifiers of New Physics](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.131.091402), Physical Review Letters (2023). DOI: 10.1103/PhysRevLett.131.091402"
      ],
      "metadata": {
        "id": "_Ij60GralS7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://en.m.wikipedia.org/wiki/Kerr_metric"
      ],
      "metadata": {
        "id": "7z7w6ETYB15u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kerr solution\n",
        "\n",
        "Mass and rotstion, but no charge: kerr black hole\n",
        "\n",
        "https://youtu.be/UjgGdGzDFiM"
      ],
      "metadata": {
        "id": "wlPIlr6hJdOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rotating / Spinning Black holes\n",
        "\n",
        "* [Ergosphere](https://de.m.wikipedia.org/wiki/Ergosphäre)\n",
        "* [Ringularity](https://en.m.wikipedia.org/wiki/Ring_singularity)\n",
        "* [Penrose process](https://de.m.wikipedia.org/wiki/Penrose-Prozess)\n",
        "* [Super radiant scattering](https://en.m.wikipedia.org/wiki/Superradiance)\n",
        "* Video: [Black hole bombs (kurzgesagt)](https://youtu.be/ulCdoCfw-bY?si=NJptNw0Pm9wHRKQd)"
      ],
      "metadata": {
        "id": "t7lJPdkcZLmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Black Hole Cosmology (Einstein–Cartan Theory)*"
      ],
      "metadata": {
        "id": "jBlZmRcPPd8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Alan Guth: big bang and black hole\n",
        "* Lee Smolin: black hole here is big bang in another universe\n",
        "* Andrei Linde: eternal inflation"
      ],
      "metadata": {
        "id": "QX_vqN5b6gVy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Any such model requires that the **Hubble radius of the observable universe be equal to its Schwarzschild radius**, that is, the product of its mass and the Schwarzschild proportionality constant. This is indeed known to be nearly the case; at least one cosmologist, however, considers this close match to be a coincidence."
      ],
      "metadata": {
        "id": "HEU41Z5U77Wz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0711.png)\n",
        "\n",
        "> Video: [Black Hole Cosmology (Schwarzschild cosmology) - other side of a black hole](https://youtu.be/ZVPsNDonA84)"
      ],
      "metadata": {
        "id": "lVco1sIYPojc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Cosmological Natural Selection (Lee Smolin)"
      ],
      "metadata": {
        "id": "WcMMue0zbajh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosmological event horizon: no events that happen NOW beyond that horizon can never be seen\n",
        "\n",
        "The obvious difference is that the black hole singularity seems to us to be a point of infinite density in space, while the big bang singularity is a time of infinite density that included all of space.\n",
        "\n",
        "Both the big bang and black hole singularities do occupy all of space - the difference is that the big bang singularity exists in the past for all of space, while the black hole singularity exists in the future for all of the black hole space.\n",
        "\n",
        "Oppenheimer-Snyder solution: until singularity, a black hole is flat, also homogenous andzero pressure (like FLRW metric and what Friedman discivered for our universe)\n",
        "\n",
        "Raj Pathria: turn time around to get white hole and it looks like our universe from inside (black hole cosmology 1972)\n",
        "\n",
        "Lee Smolin - black hole natural selection\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1320.jpg)\n",
        "\n",
        "Video: PBS: https://youtu.be/jeRgFqbBM5E"
      ],
      "metadata": {
        "id": "OO1DZ5_QkuJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://sites.imsa.edu/hadron/2021/11/07/schwarzschild-cosmology-and-black-hole-ception/"
      ],
      "metadata": {
        "id": "y0n8dfhk71bn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Einstein–Cartan theory and Black Hole Cosmology**\n",
        "\n",
        "Die [Einstein-Cartan-Theorie](https://de.m.wikipedia.org/wiki/Einstein-Cartan-Theorie) (ECT, auch Einstein-Cartan-Sciama-Kibble-Theorie, ECSK-Theorie) ist eine Verallgemeinerung der Allgemeinen Relativitätstheorie auf die Riemann-Cartan-Geometrie.\n",
        "\n",
        "* In der Cartan-Geometrie taucht die Torsion als zusätzlicher Freiheitsgrad auf, was in der ECT eine zusätzliche Feldgleichung ergibt. Diese zweite Feldgleichung koppelt die Torsion mit dem Spindichtetensor.\n",
        "\n",
        "A [black hole cosmology](https://en.m.wikipedia.org/wiki/Black_hole_cosmology) (also called Schwarzschild cosmology or black hole cosmological model) (also called Schwarzschild cosmology or black hole cosmological model) **is a cosmological model in which the observable universe is the interior of a black hole**. Such models were originally proposed by theoretical physicist Raj Pathria, and concurrently by mathematician I. J. Good.\n",
        "\n",
        "Brian Cox: Do we live inside of a Black Hole? https://youtu.be/4013hHZHf0I\n",
        "\n",
        "* According to general relativity, the gravitational collapse of a sufficiently compact mass forms a singular Schwarzschild black hole. In the Einstein–Cartan–Sciama–Kibble theory of gravity, however, it forms a regular Einstein–Rosen bridge, or wormhole. Schwarzschild wormholes and Schwarzschild black holes are different mathematical solutions of general relativity and the Einstein–Cartan theory. Yet for observers, the exteriors of both solutions with the same mass are indistinguishable.\n",
        "\n",
        "* The Einstein–Cartan theory extends general relativity by removing a constraint of the symmetry of the affine connection and regarding its antisymmetric part, the torsion tensor, as a dynamical variable. Torsion naturally accounts for the quantum-mechanical, intrinsic angular momentum (spin) of matter. The minimal coupling between torsion and Dirac spinors generates a repulsive spin-spin interaction which is significant in fermionic matter at extremely high densities.\n",
        "\n",
        "* Such an interaction prevents the formation of a gravitational singularity. Instead, the collapsing matter reaches an enormous but finite density and rebounds, forming the other side of an Einstein-Rosen bridge, which grows as a new universe. Accordingly, the Big Bang was a nonsingular Big Bounce at which the universe had a finite, minimum scale factor. Or, the Big Bang was a supermassive white hole that was the result of a supermassive black hole at the heart of a galaxy in our parent universe.\n",
        "\n",
        "*[Black Hole Cosmology](https://en.m.wikipedia.org/wiki/Black_hole_cosmology): Drehimpuls (Spin) mit Verkruemmung (Torsion) with Antigravitation*\n",
        "\n",
        "* *Black Hole Cosmology: Spin & Torsion (Nikodem Poplawski)*\n",
        "\n",
        "* [Arte: Leben wir in einem Schwarzen Loch?](https://youtu.be/mgXv3aE5eQc) - **Nikodem Poplawski**\n",
        "\n",
        "> Accordingly, our Universe may be closed and may have born in the interior of a black hole existing in a parent universe. [arxiv:0911.0334](https://arxiv.org/abs/0911.0334)\n",
        "\n",
        "* Drehimpuls (Spin) mit Verkruemmung (Torsion) with Antigravitation. Matter never reaches singularity, because torsion prevents that, matter spins faster and faster. Durch Torsion entsteht Abstossung, was ein neues expandierendes Universum erzeugt. - Big Bounce in Black Hole - Singularity-free universe\n",
        "\n",
        "* http://www.nikodempoplawski.com/ULA2020.pdf\n",
        "\n",
        "* https://www.pbs.org/wgbh/nova/article/big-bounce/\n",
        "\n",
        "* https://www.insidescience.org/news/every-black-hole-contains-new-universe\n"
      ],
      "metadata": {
        "id": "MbD8C5B1zk1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Planck Relic*"
      ],
      "metadata": {
        "id": "c1GtjXg4e2yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Planck relics: **tiny black holes at the end of the hawking radiation process in the size of the Planck length**.\n",
        "\n",
        "Smallest black hols would need 10^66 years, but primordial black holes could be candidate now. Important for dark matter explanation. Planck relics would also solve black hole information paradox.\n",
        "\n",
        "Black hole information paradox: if black holes radiate a perfect thermal spectrum then,  by definition, that radiation has maximum entropy and contains no information about whatever fell into the black hole. The black holes evaporates and all information that went into is deleted. This breaks rule of conservation of quantum information.\n",
        "\n",
        "What if all the information they eat is trapped forever in the tiny Planck relic? However that would break another rule: the Bekenstein bound (max of information that a region of space can contain).\n",
        "\n",
        "A way around this has been proposed - what if space inside black holes actually expands to a region larger than the event horizon? What if at the singularity of a black hole a new inflation is triggered. Then there is enough space.\n",
        "\n",
        "To explain dark matter there is one Planck Eric every 30 km^3 in space. (This is how empty space is)\n",
        "\n",
        "Video: [What If (Tiny) Black Holes Are Everywhere?](https://www.youtube.com/watch?v=srVKjWn26AQ&list=WL&index=4)"
      ],
      "metadata": {
        "id": "zePptyFTe7Yt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Eddington-Leuchtkraft (Eddington luminosity)*"
      ],
      "metadata": {
        "id": "Oz7oDSQ5Bm6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Eddington-Leuchtkraft](https://de.m.wikipedia.org/wiki/Eddington-Grenze)"
      ],
      "metadata": {
        "id": "_F-zucqUBto0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Gibbons-Hawking-Effekt*"
      ],
      "metadata": {
        "id": "La_aZKRrBaXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gibbons-Hawking-Effekt**\n",
        "\n",
        "* Der [Gibbons-Hawking-Effekt](https://de.m.wikipedia.org/wiki/Gibbons-Hawking-Effekt) besagt, dass jeder Lösung der Einsteinschen Feldgleichungen, die über einen kausalen Horizont verfügt, eine Temperatur zugeordnet werden kann;\n",
        "\n",
        "* der kausale Horizont erweitert den Begriff des Ereignishorizonts von Schwarzen Löchern auf kosmologische Dimensionen, er ist diejenige Fläche in der Raum-Zeit, jenseits der Ereignisse den Beobachter nicht mehr beeinflussen können."
      ],
      "metadata": {
        "id": "bv5MxZ86y_8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Extremal Surfaces*"
      ],
      "metadata": {
        "id": "-wgjwv48EPNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUANTUM EXTREMAL SURFACES IN ISOLATED BLACK HOLES\n",
        "* Netta Engelhardt\n",
        "* https://www.youtube.com/watch?v=LWfbZp5vJts&list=WL&index=3&t=761s\n",
        "* https://www.quantamagazine.org/the-most-famous-paradox-in-physics-nears-its-end-20201029/"
      ],
      "metadata": {
        "id": "fufuZarjCgyb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Naked singularity*"
      ],
      "metadata": {
        "id": "pgvi8Yztfy7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naked singularity: https://de.m.wikipedia.org/wiki/Nackte_Singularität\n",
        "\n",
        "Cosmic censorship hpyothesis: https://en.m.wikipedia.org/wiki/Cosmic_censorship_hypothesis"
      ],
      "metadata": {
        "id": "b3oIovTcf1bg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Holography of the Photon Ring (Sphere)*"
      ],
      "metadata": {
        "id": "XyPztHZDog1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Article: [A Black Hole’s Orbiting Ring of Light Could Encrypt Its Inner Secrets](https://www.quantamagazine.org/black-holes-ring-of-light-could-encrypt-its-inner-secrets-20220908/)\n",
        "\n",
        "* A [photon sphere or photon circle](https://en.m.wikipedia.org/wiki/Photon_sphere) is an area or region of space where gravity is so strong that photons are forced to travel in orbits, which is also sometimes called the last photon orbit\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1680.png)\n",
        "\n",
        "\n",
        "* In [a paper posted online](https://arxiv.org/abs/2205.05064) in May and recently accepted for publication in Classical Quantum Gravity, Strominger and his collaborators revealed that the photon ring around a spinning black hole has an unexpected kind of symmetry — a way that it can be transformed and still stay the same. **The symmetry suggests that the ring may encode information about the hole’s quantum structure.**\n",
        "\n",
        "* “This symmetry smells like something to do with the central problem of understanding the quantum dynamics of black holes,” he said. The discovery has led researchers to debate whether the photon ring might even be part of a black hole’s “holographic dual” — a quantum system that’s exactly equivalent to the black hole itself, and which the black hole can be thought of as emerging out of like a hologram.\n",
        "\n",
        "* Much more theoretical study is needed before researchers can say for sure whether, or in what way, the photon ring encodes a black hole’s inner contents. But: “It’s a target for a holographic description,” (Juan Maldacena)\n",
        "\n",
        "* Light from the inner subrings has made more orbits and was therefore captured before the light from outer subrings, resulting in a series of time-delayed snapshots of the surrounding universe. **“Together, the set of subrings are akin (ähnlich) to the frames of a movie, capturing the history of the visible universe as seen from the black hole,”**. - ‘Hey, there’s an infinite number of copies of the universe right there at that screen? Couldn’t that be where the holographic dual lives?’”\n",
        "\n",
        "* The researchers realized that **the ring’s concentric structure is suggestive of a group of symmetries called conformal symmetry. A system that has conformal symmetry exhibits “scale invariance,” meaning it looks the same when you zoom in or out**. In this case, each photon subring is an exact, demagnified copy of the previous subring. Moreover, a conformally symmetric system stays the same when translated forward or backward in time and when all spatial coordinates are inverted, shifted and then inverted again.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DJOF5vuwondV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Computational Complexity of Black Holes*"
      ],
      "metadata": {
        "id": "mUfHuBR4Nhcn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://de.m.wikipedia.org/wiki/Quantengravitation"
      ],
      "metadata": {
        "id": "8JQND4dvHkja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "quantum chaos"
      ],
      "metadata": {
        "id": "1MOoIWpurMu4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Does quantum theory imply the entire Universe is preordained?\n",
        "https://www.nature.com/articles/d41586-023-04024-z"
      ],
      "metadata": {
        "id": "sV0gYoKcCQKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strominger Vafa black hole\n",
        "\n",
        "* Bekenstein-Hawking area-entropy\n",
        "* https://arxiv.org/abs/hep-th/9601029: Microscopic Origin of the Bekenstein-Hawking Entropy\n",
        "* https://arxiv.org/abs/1904.03232: Conceptual Analysis of Black Hole Entropy in String Theory"
      ],
      "metadata": {
        "id": "INcfc_vURqEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Forscher:innen ist es erstmals gelungen, die Schwerkraft in der Quantenwelt zu messen**\n",
        "\n",
        "* Jetzt ist es uns gelungen, Gravitationssignale bei der kleinsten jemals aufgezeichneten Masse zu messen\n",
        "* Durch das Verständnis der Quantengravitation könnten wir einige der Rätsel unseres Universums lösen, beispielsweise, wie alles begann oder was in schwarzen Löchern passiert\n",
        "* Gelungen ist das den Wissenschaftler:innen mit einer neuen Technik, bei der schwebende Magnete zum Einsatz kommen, die klein genug sind, um in den Quantenbereich einzudringen. Damit waren sie in der Lage, die schwache Anziehungskraft eines winzigen Teilchens nachzuweisen.\n",
        "* Bislang konnte entsprechend nur angenommen werden, dass Teilchen und Kräfte auf mikroskopischer Ebene anders interagieren als Objekte normaler Größe.\n",
        "\n",
        "\n",
        "* https://t3n.de/news/schwerkraft-quantenwelt-quantengravitation-1610416/\n",
        "* https://www.science.org/doi/10.1126/sciadv.adk2949"
      ],
      "metadata": {
        "id": "lAW0fbMJb7sA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Complexity of Black Holes*"
      ],
      "metadata": {
        "id": "ql8hl9HHzAOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [Peter Shor - Scrambling Time and black holes - Green Family Lecture at IPAM at UCLA](https://www.youtube.com/watch?v=GPz8iCzlMTY)\n",
        "\n",
        "Video: [Virtual Seminar: Shira Chapman \"On the Complexity of Black Holes\"](https://www.youtube.com/watch?v=G_YdsmH6SBE)\n",
        "\n",
        "Video: [Causality and closed time like curves - 1](https://www.youtube.com/watch?v=MzAvr8Zau8Q)\n",
        "\n",
        "Video: [Erik Verlinde \"Emergence of Gravity from Quantum Information: a Progress Report\"](https://youtu.be/rj6-bq55ccQ?si=6BYQNujmWt4nCe9V)"
      ],
      "metadata": {
        "id": "aY1n53q90eXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum Circuit Complexity of Black Holes**\n",
        "\n",
        "* **Why is that interesting?**\n",
        "  * By understanding the quantum circuit complexity of black holes, we can gain insights into the physics of black holes and the nature of quantum gravity.\n",
        "  * Machine learning of circuits: is the ultimate physical limit of computation and data science, and we want to know how far you can push that (good framework of gravitational computer error-correction)\n",
        "  * But: What is the circuit complexity of a black hole? And  What is the computational capacity (complexity) of a black hole?\n",
        "  * Can you solve (quantum or classical) exponential or even undecidable problems in a black hole (efficiently)? Is the black hole a more powerful computer than a quantum computer or not?\n",
        "\n",
        "* Approaches: **One way**: holographic principle. Information in spacetime volume is encoded on boundary -> quantum circuit complexity of black hole can be studied by studying quantum circuit complexity of its boundary. **Another way**: AdS/CFT correspondence -> quantum circuit complexity of black hole in AdS spacetime can be studied by studying the quantum circuit complexity of CFT on boundary of AdS spacetime. **Another way**: Kerr/CFT.\n",
        "\n",
        "* **Background**: Connection between Quantum information and quantum gravity: Hawking 1970s: What happens to quantum information dropped into a black hole? Black holes radiate, photons slowly come out (takes long 10^76 years for black holes of size of the sun, but does it), output is thermal / uncorrelated what came in, so information is gone. That contradicts quantum mechanics.\n",
        "  * **Dilemma:** Stays in black hole forever =› Violates quantum mechanics. Comes out in Hawking radiation =› if there's also a copy inside the black hole, seems to violate the \"No-Cloning Theorem\".\n",
        "  * **Black Hole Complementarity (modern view):** Inside is not a different state than outside, inside is just a \"re-encoding\" of exterior, so no cloning is needed to have (y) in both places. - Jumping into a black hole is just a weird way of measuring the same quantum information that you could have measured if you had stayed outside the black hole.\n",
        "  * **2012: firewall paradox**. (Almheiri et al. 2012): Qubit coming out of black hole cannot be entangled with a qubit inside the blackhole. But Hawking said if you want to see a smooth geometry of spacetime at the event horizon, the qubits need to be entangled. (In QFT spacetime is built up of a huge amount of local entanglement. No entanglement = no smooth spacetime, which means space and time end at the event horizon = the firewall). But this end of spacetime is at the singularity, not at the event horizon already).\n",
        "\n",
        "  * You can simulate gravity possibly on a standard QCs: “Even if a quantum gravity theory seems ‘wild’—even if it involves nonlocality, wormholes, and other exotica—there might be a dual description of the theory that’s more ‘tame,’ and that’s more amenable to simulation by a quantum computer.” If we wanted to simulate quantum gravity phenomena in AdS space, we might be able to do so by first translating to the CFT side, then simulating the CFT on our quantum computer, and finally translating the results back to AdS. The key point here is that, since the CFT doesn’t involve gravity, the difficulties of simulating it on a quantum computer are “merely” the relatively prosaic difficulties of simulating quantum field theory on a quantum computer. - For this to work, **the translation between the AdS and CFT descriptions also needs to be computationally efficient**—and it’s possible that there are situations where it isn’t.\n",
        "  * This means: **nature seems computable** (Penrose disagrees seems): you can build the universe out of NAND gates, see 1:00:00 [Video](https://www.youtube.com/watch?v=nAMjv0NAESM&t=2240s) and **Black holes seems describable** - <font color=\"red\">but to answer the final answer - if universe and black holes describable and computable - we need a theory of quantum gravity, what we don't have!</font>\n",
        "\n",
        "* Paper 1: [Computational Complexity and Black Hole Horizons](https://arxiv.org/abs/1402.5674) and [The Second Law of Quantum Complexity](https://arxiv.org/abs/1701.01107) (Susskind)\n",
        "  * Quantamagazine article: [In New Paradox, Black Holes Appear to Evade Heat Death](https://www.quantamagazine.org/in-new-paradox-black-holes-appear-to-evade-heat-death-20230606) with Video: [Can a New Law of Physics Explain a Black Hole Paradox?](https://www.youtube.com/watch?v=yLOHdW7dLug&list=PLBn8lN0DcvpkjulnKfyCmgO5SWzRxrRFq&index=14)\n",
        "  * Video: [Black Holes and the Quantum-Extended Church-Turing Thesis | Quantum Colloquium (Leonard Susskind)](https://www.youtube.com/live/1CpzigpEJnU?si=C5mB8zppTHXU8XO7)\n",
        "  * Susskind proposed that holographic principle can be used to relate black hole entropy to quantum circuit complexity. Holographic principle states that information contained in volume of spacetime can be encoded on lower-dimensional boundary of that volume. Susskind and his colleagues propose that the black hole entropy is proportional to the quantum circuit complexity of the state that is encoded on the black hole's event horizon.\n",
        "  * Proposal has led to a number of interesting insights into the relationship between black holes and quantum circuit complexity: growth of black hole entropy is consistent with  growth of quantum circuit complexity over time. And relationship between black hole entropy and quantum circuit complexity can be used to derive the laws of thermodynamics for black holes.\n",
        "  * One of the most important aspects of black holes is their entropy. Black hole entropy is a measure of the number of possible microstates that a black hole can be in. Susskind. proposed that black hole entropy is related to complexity of information that is encoded on the black hole's event horizon:\n",
        "    * Black hole entropy is proportional to the area of the black hole's event horizon.\n",
        "    * The area of the black hole's event horizon is proportional to the number of bits of information that can be encoded on the event horizon.\n",
        "    * Therefore, black hole entropy is proportional to the complexity of the information that is encoded on the black hole's event horizon.\n",
        "  * **Susskind's argument suggests that black holes may be able to store and process information in a very efficient way. This could lead to new insights into the nature of information and the laws of physics.**\n",
        "  * **Complexity grows linearly and then stops growing**\n",
        "  - Black hole: from outside in thermal equilibrium, but inside it still grows linearly with time towards the singularity (see penrose diagram) - quantum (circuit) complexity growing? - number of gates, grows until it‘s constant.\n",
        "  - Computational complexity of black holes?\n",
        "  - Two quantum states: how complex to distinguish them? (Metacomplexity / complexiy of complexity)\n",
        "  - Quantum extended chruch turing thesis\n",
        "  - Quantum gravity extneded church turing thesis QGECTT applies to observers outside the black hole. Information inside black hole can be read for someone inside, but cannot be sent outside, which protects the QGECTT (reading from outside would / gaining information which would violate thesis)\n",
        "  - New complexity class: JI/poly (jumping in)\n",
        "  * Different versions of Circuit complexity: with and without ancilla qubits\n",
        "  * Geofffrey Penington: 3SAT solvable by jumping in a black hole?\n",
        "  * Edward Witten: Gravity doesn‘t let us do something, that we can‘t do without gravity.\n",
        "  * Scott Aaronson: Is there some analog for fault tolerance for gravitational or black hole computing?\n",
        "  * **It shouldn‘ let us answer any classical decision problems more efficiently, because:**\n",
        "    * Assuming we can do these things no errors,\n",
        "    * So we make an obviscated circuit that is exponentially long to prepraring some state that has some simply observable thing, but you cannot tell because it ios obviscated\n",
        "    * Then from lenny‘ point of view we ignore the cost of carrying out the instructions of doing that circuit (would take us an exponentially long time, but we assume we get that for free)\n",
        "    * Then we ask how much time does it take us to figure out the problem? by jumping into the black hole we can find the answer immediately. If we are not allowed to jump in, we are still sort of at sqaure one, or it will still take us a long time to do from the outside.\n",
        "    * That is a very different problem from if you could have some efficient obviscated circuit, something that could efficiently be done by jumping in. A classical problem, phrased in classical terms and has an answer in classical terms, a classical decision problem you could solve by jumping in.\n",
        "    * Is that not about asking aboiut the boundaries of this complexity class? Asking whether it actually includes any interesting computations that actually can be done inside the black hole. But we don‘t know.\n",
        "    * Vazirani: Creating this obviscated circuit for this state, and then create it homomorphically so the state can be acted on homorphically by the shockwaves that are coming in. You fall in with this classicla description and then you act on this hidden quantum state and you eventuelly end up answering this question.\n",
        "    * Penington‘s objection: in QFT they think the quantum extended church turing thesis is true (lenny made possible conditions for it). Assuming everything we do in the quantum gravity theory is well described by quantum field theory in a semi-classical background, then it also shouldn‘t be able to break the quantum church turing thesis.\n",
        "    * So we either need to be given as part of the problem - a quantum state that has a non-trivial holographic dual geometry that didn‘t make from scratch (that‘s the case in lenny‘s setup). Or we need to somehow make that semi-classical evolution break down.\n",
        "    * I would say from what we know about quantum gravity to make the latter happen, we either need planck-length curvature or we need exponential complexity (time or number of things involved). It would be very problematic for semi-classical spacetime if we could make it breakdown without either of these conditions being true.\n",
        "    * That‘s why I‘m inclided to say: It shouldn‘ let us answer any classical decision problems more efficiently.\n",
        "    * …\n",
        "    * Sciott: You need some actual phyiscal resource to resolve some porblme beyond what a quantum computer can solve. And the question is simpky: are black holes such a resource ot not?\n",
        "    * Peningoit: my claim (without evidence) is i don’t think that you can make semi-classical gravity break down  without either by planck-lenght curvature oir by exponential times. There shoulndt be anything you do\n",
        "  * **Established: circuit complexity and physics**\n",
        "    * How do you decode information from hawikin radiation about infalling matter\n",
        "    * how does ads/cft dictionary work? (Circuit complexity is the fundamental quantity)\n",
        "    * But depends on input: is iot maximally random (exponential time to solve), or only pseudorandom (solvable in ploynomal time\n",
        "    * Geoffrey Penington: Black hole information: [YouTube · Galileo Galilei Institute (GGI)620+ Aufrufe  ·  vor 1 JahrGeoff Penington: \"Black holes and holographic entanglement entropy - II\" - YouTube](https://m.youtube.com/watch?v=kl6GE10jD9s)\n",
        "  * Computation = spacetime volume, when following Susskind‘s logic as he sees the space to the singularity growing in penrose‘s diagram. But volume cannot be measured, that‘s why he didn‘t use it\n",
        "  * Seth Lloyd: Black Hole Quantum computer (2004): howe many operations can you perform with stuff falling into the black hole?\n",
        "  * Black holes are not different to ordinary rindler space\n",
        "\n",
        "* Paper 2: [Computational pseudorandomness, the wormhole growth paradox, and constraints on the AdS/CFT duality](https://arxiv.org/abs/1910.14646) (Adam Bouland, Bill Fefferman, Umesh Vazirani)\n",
        "  * A fundamental issue in the AdS/CFT correspondence is the wormhole growth paradox. Susskind's conjectured resolution of the paradox was to equate the volume of the wormhole with the circuit complexity of its dual quantum state in the CFT. We study the ramifications of this conjecture from a complexity-theoretic perspective.\n",
        "  \n",
        "* Paper 3: [The Complexity of Quantum States and Transformations: From Quantum Money to Black Holes](https://arxiv.org/abs/1607.05256) (Scott Aaronson)\n",
        "  * [The event horizon’s involved, but the singularity is committed](https://scottaaronson.blog/?p=213) Aaronson on Lenny Susskind's “Black Holes and Holography.”\n",
        "  * **'The favorite measure, at the moment, is known as circuit complexity'** - role of complexity in the black-hole information paradox and the AdS/CFT correspondence (through connections made by Harlow-Hayden, Susskind, and others).\n",
        "\n",
        "* Paper 4: [Black Holes Produce Complexity Fastest](https://physics.aps.org/articles/v9/49)\n",
        "\n",
        "* Paper 5: [Quantum Computational Complexity -- From Quantum Information to Black Holes and Back](https://arxiv.org/abs/2110.14672)\n",
        "  * Quantum computational complexity estimates the difficulty of constructing quantum states from elementary operations, a problem of prime importance for quantum computation.\n",
        "  * Surprisingly, this quantity can also serve to study a completely different physical problem - that of information processing inside black holes.\n",
        "\n",
        "* Paper 6: [Quantum Computation as Gravity](https://arxiv.org/abs/1807.04422) - Optimal quantum computation linked from Gravity.\n",
        "    * Over the years, using holography and Anti-de Sitter/conformal field theories, we have been learning that gravity is intimately related to quantum information.\n",
        "    * The lesson from our findings is that gravity may also teach us how to perform quantum computation in physical systems in the most efficient way.\" [Article](https://phys.org/news/2019-06-optimal-quantum-linked-gravity.html)\n",
        "\n",
        "* Articles:\n",
        "  * [What is complexity in particle physics?](https://www.aei.mpg.de/120719/what-is-complexity-in-particle-physics)\n",
        "  * [nlab: computational complexity and physics](https://ncatlab.org/nlab/show/computational+complexity+and+physics)\n",
        "\n",
        "* Videos:\n",
        "  * [Black Holes and the Quantum-Extended Church-Turing Thesis](https://www.youtube.com/watch?v=1CpzigpEJnU&list=WL&index=4&t=2205s)\n",
        "  * [Black holes and computational complexity](https://www.youtube.com/live/1CpzigpEJnU)\n",
        "  * [Quantum information tools between quantum theory and gravity - Lecture 1 | Flaminia Giacomini](https://www.youtube.com/watch?v=KP09NR3qP8g&list=WL&index=6&t=653s)\n",
        "  * [Quantum Tasks in Holography - Alex May](https://www.youtube.com/watch?v=twa08og43DI)\n",
        "  * [Quantum Black Holes: a Status Report | Steve Giddings](https://www.youtube.com/watch?v=eVjbL1wOMOU)\n",
        "  * [The AdS/CFT Correspondence: a Status Report | Rajesh Gopakumar](https://www.youtube.com/watch?v=UVVfpNR8ISg)\n",
        "  * [Pseudorandomness and the AdS/CFT Correspondence - Adam Bouland](https://www.youtube.com/watch?v=WQ25Srp1zJI)\n",
        "  * [An Introduction to Celestial Holography and the flat space limit of AdS/CFT](https://youtu.be/Wbkj_2KqMoQ)\n"
      ],
      "metadata": {
        "id": "WpyK1qGu3A_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computational Complexity and High Energy Physics\n",
        "* Complexity of AdS,CTF, Firewalls and CTCs\n",
        "* Suppose CTCs exist, how would they change the theory of computation? - Problem: where is the fix point?\n",
        "\n",
        "Video: [Chaos, Black Holes, and Quantum Mechanics - Stephen Shenker, Stanford University](https://www.youtube.com/watch?v=vC0x-QXM8Qg&list=WL&index=5&t=1333s)\n",
        "\n",
        "Video: [Scott Aaronson: Computability Theory of Closed Timelike Curves](https://www.youtube.com/watch?v=fUGjv44_X4Q&list=PLUz_4vZOI0H1XnMEj9uk4Ezp9AUJBVAPE&index=4)\n",
        "\n",
        "Kurt Gödel ist bekannt für seinen bedeutenden Beitrag zur theoretischen Physik in Form der sogenannten „Gödel-Metrik“, welche die Möglichkeit von geschlossenen zeitartigen Kurven (englisch: Closed Timelike Curves, CTCs) in der Allgemeinen Relativitätstheorie aufzeigt. Diese Arbeit leistete er im Rahmen der Feierlichkeiten zu Einsteins 70. Geburtstag im Jahr 1949.\n",
        "\n",
        "Die Gödel-Metrik beschreibt eine Lösung der Feldgleichungen der Allgemeinen Relativitätstheorie, die ein rotierendes Universum darstellt. In einem solchen Universum können geschlossene zeitartige Kurven existieren, was bedeutet, dass ein Pfad durch die Raumzeit theoretisch in seine eigene Vergangenheit zurückkehren könnte. Dies impliziert die Möglichkeit von Zeitreisen innerhalb des theoretischen Rahmens der Allgemeinen Relativitätstheorie.\n",
        "\n",
        "Abstract: In a seminal 1991 paper, David Deutsch proposed a formal model of closed timelike curves (CTCs), or time travel into the past, which used linear algebra to \"resolve the grandfather paradox.\"  In 2008, John Watrous and I showed that, under Deutsch's model, both a classical computer and a quantum computer with access to a polynomial-size CTC could solve exactly the problems in PSPACE.  In this talk, I'll review this result and then give a new extension to the setting of computability theory.  Namely, I'll show that a classical or quantum computer with access to a Deutschian CTC (with no bound on its size) could solve exactly the problems that are Turing-reducible to the halting problem.  Just like in the complexity setting, the most technically interesting part is the upper bound on the power of quantum computers with access to a Deutschian CTC.\n"
      ],
      "metadata": {
        "id": "ZbLeuiw4zEp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Black Holes Surface and Quantum Error Correction: AdS/CFT*\n",
        "\n",
        "* \"Black holes surface behaving like a quantum computer\"\n",
        "* [From black holes to quantum computing - with Marika Taylor](https://www.youtube.com/watch?v=861coSFLOvk&t=193)\n",
        "* [Black Holes and Quantum Error Correction - part 1](https://www.youtube.com/watch?v=uNYVQo9RH4Q)\n",
        "\n",
        "\n",
        "**Emergent Space-Time and Quantum Error Correction**: Recent theoretical work suggests that the space-time geometry itself, especially in the context of black holes, might emerge from a kind of quantum error-correcting code. The idea is that the way information is encoded on a black hole's surface (its event horizon) might be analogous to how information is protected in a quantum error-correcting code. This means that the fabric of space-time itself could be understood as a quantum error-correcting code, which is a radical and exciting concept blending quantum mechanics, general relativity, and quantum computing."
      ],
      "metadata": {
        "id": "VeuipFGXvjfN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is meant by \"Black holes are the fastest scramblers in Nature\"?**\n",
        "\n",
        "The phrase \"Black holes are the fastest scramblers in Nature\" refers to a concept in theoretical physics that describes how black holes process information. In this context, \"scrambling\" refers to the way in which information that enters a black hole gets mixed up or dispersed throughout the black hole's horizon.\n",
        "\n",
        "Here are the key points to understand this concept:\n",
        "\n",
        "1. **Information Theory and Black Holes**: In the realm of physics, especially quantum mechanics and general relativity, information is a fundamental concept. It's often considered in terms of quantum information, which deals with the quantum states of particles.\n",
        "\n",
        "2. **Scrambling in Black Holes**: When information falls into a black hole, it doesn't get destroyed (as per the principle of quantum information conservation). Instead, it gets scrambled. This means the information is spread out across the event horizon of the black hole in a highly mixed state. It's like shuffling a deck of cards so thoroughly that the original order is completely lost.\n",
        "\n",
        "3. **Fastest Scramblers**: The assertion that black holes are the fastest scramblers suggests that they are extremely efficient at this process. This idea comes from the holographic principle in string theory, where the time it takes for information to scramble in a black hole is related to its size. The larger the black hole, the faster it scrambles information.\n",
        "\n",
        "4. **Implications for Quantum Physics and Gravity**: This concept is important in the study of quantum gravity and the information paradox. It suggests a deep connection between gravity (black holes) and quantum mechanics (information theory).\n",
        "\n",
        "5. **Chaos Theory and Black Holes**: The scrambling effect is also associated with chaos theory in physics, where small changes in initial conditions can lead to vastly different outcomes. In a black hole, the scrambling of information is an ultimate form of chaotic behavior.\n",
        "\n",
        "This idea is a topic of ongoing research and debate in theoretical physics, particularly in the context of understanding the fundamental nature of black holes, quantum mechanics, and the fabric of spacetime."
      ],
      "metadata": {
        "id": "cuu9KesIzKj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**is it possible to recover the information, that is spread out across the event horizon of the black hole in a highly mixed state?**\n",
        "\n",
        "The question of whether information that has been spread out across the event horizon of a black hole can be recovered is a major topic in theoretical physics, particularly in the context of the black hole information paradox. This paradox arises from the clash between quantum mechanics, which says information cannot be destroyed, and general relativity, which suggests that information falling into a black hole is lost forever.\n",
        "\n",
        "Here are some key points in this discussion:\n",
        "\n",
        "1. **Hawking Radiation and Information Loss**: Stephen Hawking initially proposed that black holes emit radiation (now known as Hawking radiation) and can eventually evaporate completely. This led to the paradox: if the black hole disappears, what happens to the information that fell into it? Hawking initially argued that this information is lost forever, which contradicts the principles of quantum mechanics.\n",
        "\n",
        "2. **Information Scrambling vs. Destruction**: While black holes are believed to scramble information almost beyond recognition, scrambling is not the same as destruction. Theoretical work, particularly in the context of the holographic principle and string theory, suggests that while information is highly scrambled, it is not necessarily destroyed.\n",
        "\n",
        "3. **AdS/CFT Correspondence**: A concept from string theory called the Anti-de Sitter/Conformal Field Theory (AdS/CFT) correspondence provides a framework where the physics inside a black hole (including the fate of information) might be understood in terms of a lower-dimensional boundary, like the event horizon. This has led some physicists to propose that information is somehow encoded on the horizon and could, in principle, be recovered.\n",
        "\n",
        "4. **Black Hole Complementarity**: Another proposed solution is the concept of black hole complementarity, which suggests that information is both reflected at the event horizon and passes through, but no observer can confirm both realities simultaneously. This tries to reconcile the information loss with quantum mechanics without requiring information to actually be duplicated.\n",
        "\n",
        "5. **Firewall Hypothesis**: Some researchers have suggested the existence of a \"firewall\" at the event horizon, which would destroy any information. This hypothesis aims to resolve the paradox but is controversial and contradicts the idea that crossing a black hole's event horizon is uneventful (as predicted by general relativity).\n",
        "\n",
        "6. **Recent Developments**: Recent theoretical developments, including the use of quantum error correction in the context of the holographic principle, suggest that information may indeed be recoverable in principle, although the exact mechanism remains unclear.\n",
        "\n",
        "In summary, while it's theoretically possible that information spread out across a black hole's event horizon might be recoverable, this remains a topic of active research and debate in the fields of quantum mechanics, quantum gravity, and cosmology. The true nature of information processing by black holes continues to be one of the most intriguing puzzles in modern theoretical physics."
      ],
      "metadata": {
        "id": "CJ2pyl5mzOXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Articles, Papers and Videos*"
      ],
      "metadata": {
        "id": "-OrLJOuEP4GO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://twitter.com/Andercot/status/1741837072632332649"
      ],
      "metadata": {
        "id": "kZLYtY05aMJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Articles**\n",
        "\n",
        "* Causality doesn't exist? https://www.quantamagazine.org/quantum-mischief-rewrites-the-laws-of-cause-and-effect-20210311/\n",
        "\n",
        "* https://news.berkeley.edu/2019/03/06/can-entangled-qubits-be-used-to-probe-black-holes\n",
        "\n",
        "  * recovering quantum information falling into a black hole is possible if the information is scrambled rapidly inside the black hole.\n",
        "  * The more thoroughly it is mixed throughout the black hole, the more reliably the information can be retrieved via teleportation.\n",
        "  * His group implemented the protocol proposed by Yoshida and Yao and effectively measured an out-of-time-ordered correlation function. Called OTOCs, these peculiar correlation functions are created by comparing two quantum states that differ in the timing of when certain kicks or perturbations are applied.\n",
        "  * can be used in quantum computers to detect more complicated noise. “One possible application for our protocol is related to the benchmarking of quantum computers, where one might be able to use this technique to diagnose more complicated forms of noise and decoherence in quantum processors,” Yao said. “The ability to diagnose how noise affects quantum simulations is key to building better fault-tolerant algorithms and getting accurate answers from current noisy quantum computers.”\n",
        "  * **the fact that we can relate it to cosmology is because we believe the dynamics of quantum information is the same - nderstanding the dynamics of quantum information connects many areas of research within this initiative: quantum circuits and computing, high energy physics, black hole dynamics, condensed matter physics and atomic, molecular and optical physics. The language of quantum information has become pervasive for our understanding of all these different systems.**\n",
        "  * but: OTOCs do not generally discriminate between quantum scrambling and ordinary decoherence. https://www.nature.com/articles/s41586-019-0952-6\n",
        "\n",
        "* https://www.wired.com/story/black-holes-will-destroy-all-quantum-states/\n",
        "\n",
        "* https://www.quantamagazine.org/new-calculations-show-how-to-escape-hawkings-black-hole-paradox-20230802/\n",
        "\n",
        "* https://www.quantamagazine.org/the-most-famous-paradox-in-physics-nears-its-end-20201029/\n",
        "\n",
        "* https://www.quantamagazine.org/black-holes-ring-of-light-could-encrypt-its-inner-secrets-20220908/\n",
        "\n",
        "* https://www.quantamagazine.org/mathematicians-find-an-infinity-of-possible-black-hole-shapes-20230124/\n",
        "\n",
        "* https://www.quantamagazine.org/how-space-and-time-could-be-a-quantum-error-correcting-code-20190103/\n",
        "\n",
        "* https://www.quantamagazine.org/new-codes-could-make-quantum-computing-10-times-more-efficient-20230825/\n",
        "\n",
        "* https://www.quantamagazine.org/a-century-later-new-math-smooths-out-general-relativity-20231130/\n",
        "\n",
        "* https://phys-org.cdn.ampproject.org/c/s/phys.org/news/2023-12-theory-einstein-gravity-quantum-mechanics.amp\n",
        "\n",
        "* https://www.quantamagazine.org/alan-turing-and-the-power-of-negative-thinking-20230905/\n",
        "\n",
        "* https://t3n.de/news/radikale-neue-theorie-quanentmechanik-schwerkraft-1594368/\n",
        "\n",
        "* https://www.quantamagazine.org/mathematicians-prove-symmetry-of-phase-transitions-20210708/\n",
        "\n",
        "* https://www.quantamagazine.org/computer-scientists-inch-closer-to-major-algorithmic-goal-20230623/\n",
        "\n",
        "* https://scottaaronson.blog/?p=7651\n",
        "\n",
        "* https://www.quantamagazine.org/the-quest-to-quantify-quantumness-20231019/\n",
        "\n",
        "* https://www.quantamagazine.org/quantum-computers-struggle-against-classical-algorithms-20180201/\n",
        "\n",
        "* https://www.quantamagazine.org/a-new-map-of-the-universe-painted-with-cosmic-neutrinos-20230629/\n",
        "\n",
        "* https://www.derstandard.de/story/3000000198164/astronom-falcke-schwarze-loecher-sind-wie-ein-wundersamer-raum-voller-suessigkeiten\n"
      ],
      "metadata": {
        "id": "s72DQTORSAEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Youtube Videos**\n",
        "\n",
        "[Geoffrey Penington (UC Berkeley): Black Holes and Quantum Computers](https://www.youtube.com/watch?v=FtpWt4MexMU&list=WL&index=4&t=1560s)\n",
        "\n",
        "[Virtual Seminar: Shira Chapman \"On the Complexity of Black Holes\"](https://www.youtube.com/watch?v=G_YdsmH6SBE&t=1329s)\n",
        "\n",
        "[Peter Shor - Scrambling Time and black holes - Green Family Lecture at IPAM at UCLA](https://www.youtube.com/watch?v=GPz8iCzlMTY&t=5s)\n",
        "\n",
        "[Quantum Complexity Inside Black Holes | Leonard Susskind](https://www.youtube.com/watch?v=FpSriHE1r4E&list=WL&index=6)\n",
        "\n",
        "[The Physics of Black Holes - with Chris Impey](https://www.youtube.com/watch?v=roM1QPr8lNo&list=WL&index=1&t=1542s)\n",
        "\n",
        "[Information scrambling: a path-integral perspective](https://www.youtube.com/watch?v=oA9fMN8aWBQ&list=WL&index=2&t=415s)\n",
        "\n",
        "[Chaos, Black Holes, and Quantum Mechanics - Stephen Shenker, Stanford University](https://www.youtube.com/watch?v=vC0x-QXM8Qg&list=WL&index=3&t=3162s)\n",
        "\n",
        "[Quantum learning for quantum chaos](https://www.youtube.com/watch?v=d1iZ-ov5QOI&list=WL&index=5)\n",
        "\n",
        "[Entanglement and Complexity: Gravity and Quantum Mechanics](https://www.youtube.com/watch?v=9crggox5rbc&list=WL&index=8&t=3073s)\n",
        "\n",
        "[Conservation and scrambling of quantum information](https://www.youtube.com/watch?v=BJ1Teu-ZK8M&list=WL&index=10)\n",
        "\n"
      ],
      "metadata": {
        "id": "5HgnJHpsWbAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Research with QML and QKD for Black Holes*"
      ],
      "metadata": {
        "id": "qOXTdQWbu6wm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum Key Distribution + Quantum Machine Learning + Black Holes**\n",
        "\n",
        "1. **Simulate dynamics of black holes**\n",
        "  \n",
        "  * **Hawking radiation**: Use QML to develop better simulations of black hole evaporation (Hawking radiation)\n",
        "\n",
        "  * **Black hole states**: Use QML to develop new representations and evolution of black hole states, typically done using a quantum circuit, that are more efficient to simulate than traditional representations (the entanglement of the Hawking radiation particles is thought to be encoded in the complexity of the black hole state. This means that the quantum circuit that represents a black hole state would need to be very complex in order to capture the information that is encoded in the Hawking radiation)\n",
        "\n",
        "2. **Extract information from black holes**\n",
        "\n",
        "  * **Scan Hawking radiation (black hole evaporation)**\n",
        "  \n",
        "    * Use QML to develop new methods for detecting quantum correlations in Hawking radiation (that may contain information about objects that have fallen into)\n",
        "\n",
        "    * Use QML to develop new algorithms for learning symmetries and dynamics of black holes (better understand known ones, and learn new ones) to reduce complexity (Black holes are believed to have many symmetries, but these symmetries are not fully understood).\n",
        "    \n",
        "      * Study the entanglement structure of black hole states: Hawking radiation or electromagnetic radiation\n",
        "      \n",
        "      * Study the dynamics of black holes: gravitational waves or neutrinos\n",
        "\n",
        "  * **Send messages across black hole event horizons (black hole complementarity)**: Develop new methods (protocols) to extract information from entangled states in Hawking radiation that are more robust to interferences with QKD signals (QKD could be used to create and distribute entangled states. Interferences come from high energy particles or gravitational effects on polarization states of entangled photons)\n",
        "\n",
        "> <font color=\"blue\">**Use QML to develop new algorithms for learning symmetries and dynamics of black holes with more robust QKD protocols**\n",
        "\n",
        "Use QML to develop automatic symmetry-learning techniques (find best methods to learn symmetries) that assist in designing more robust QKD protocols against various noise and attack scenarios\n"
      ],
      "metadata": {
        "id": "6pfK42egHjTN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use QML to unscramble information from Black Holes which are quantum encryption devices**\n",
        "\n",
        "https://www.quantamagazine.org/new-calculations-show-how-to-escape-hawkings-black-hole-paradox-20230802/\n",
        "\n",
        "**They treated the black hole as a quantum encryption device — something that takes in legible information (normal matter) and spits out what appears to be scrambled information (the radiation).** In this context, one could imagine carrying out the AMPS experiment by using a **machine to unscramble the information — a machine like a quantum computer**. And with a key result from Aaronson’s doctoral thesis on the limits of quantum computation, they discovered something curious.\n",
        "\n",
        "A black hole pulverizes infalling matter so thoroughly that if an astronaut actually tasked a quantum computer with unscrambling the radiation, the task would take eons. It would take so long that the black hole would be long gone before the progress bar reached even a fraction of 1%. And by then, the astronaut wouldn’t be able to jump in to catch outside information moonlighting on the inside, because the inside wouldn’t exist.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QD3z_denetrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Symmetries in Black Holes**\n",
        "\n",
        "*Symmetries can also be used to relate the complexity of black hole states to other quantities of interest, such as the entropy or the information content of the black hole*.\n",
        "\n",
        "* For example, it has been shown that the complexity of a black hole state is equal to the entropy of the black hole up to a logarithmic correction. This suggests that complexity may be a more fundamental measure of a black hole's information content than entropy.\n",
        "\n",
        "* **Conformal symmetry:** By using conformal transformations of the coordinates, it is possible to map a black hole to a state with a simpler circuit description. This can be used to simplify the complexity calculations. This symmetry arises from the fact that black holes are solutions to the Einstein equation, which is conformally invariant. Conformal symmetry implies that the complexity of black hole states should be independent of certain transformations of the coordinates. This can be used to simplify the complexity calculations by fixing the coordinates in a particular way.\n",
        "\n",
        "* **Entanglement structure:** By understanding the entanglement structure of black hole states, it is possible to identify certain operations that can be performed efficiently. This can be used to reduce the computational complexity of certain tasks. Black hole states are highly entangled, and this **entanglement can be exploited to reduce the computational complexity of certain tasks**. For example, it has been shown that the complexity of the state of a black hole that is created by collapsing a massive particle is proportional to the entanglement entropy of the particle.\n",
        "\n",
        "* **Symmetry between black hole formation and evaporation:** There is a symmetry between the complexity of a black hole state that is created by collapsing a massive particle and the complexity of the state that is emitted from the black hole's horizon. This symmetry can be used to relate the complexity of black holes to their entropy and information content."
      ],
      "metadata": {
        "id": "5p98JYDcRzpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Can quantum machine learning be used to quantum computational complexity of black holes?**\n",
        "\n",
        "Quantum machine learning, an emerging field combining quantum computing with machine learning techniques, could potentially be applied to explore complex phenomena such as black holes, particularly in understanding their quantum computational complexity. Here's how this could work:\n",
        "\n",
        "1. **Quantum Computational Complexity of Black Holes:** This concept relates to understanding how complex the quantum states of black holes can be, especially in the context of the information paradox and the nature of the event horizon (as in the firewall hypothesis). Quantum computational complexity in this context refers to the number of quantum operations needed to create a particular state from a simple reference state.\n",
        "\n",
        "2. **Quantum Machine Learning Algorithms:** Quantum machine learning algorithms could potentially model and analyze the quantum states associated with black holes. These algorithms can process and analyze information in ways that are fundamentally different from classical algorithms, possibly offering new insights into the highly complex quantum states of black holes.\n",
        "\n",
        "3. **Simulation and Modeling:** Quantum computers could simulate aspects of black hole physics that are otherwise extremely challenging for classical computers, such as the entanglement structure of Hawking radiation or the dynamics of spacetime near the event horizon.\n",
        "\n",
        "4. **Pattern Recognition and Data Analysis:** Quantum machine learning can excel in identifying patterns in large datasets. If applicable to data obtained from astronomical observations or theoretical simulations related to black holes, it could uncover new insights into their properties and behavior.\n",
        "\n",
        "5. **Exploring Quantum Gravity Theories:** Insights gained from quantum machine learning could potentially contribute to theories of quantum gravity, a field that seeks to reconcile general relativity (which describes black holes) with quantum mechanics.\n",
        "\n",
        "6. **Challenges and Limitations:** It's important to note that practical quantum computing, especially at a scale necessary to tackle such complex problems, is still in its infancy. Furthermore, the theoretical understanding required to directly apply quantum machine learning to black hole computational complexity is highly advanced and speculative.\n",
        "\n",
        "7. **Interdisciplinary Collaboration:** This kind of research would likely require close collaboration between quantum physicists, computer scientists, and astrophysicists, given the highly interdisciplinary nature of the problem.\n",
        "\n",
        "In summary, while theoretically possible, the application of quantum machine learning to understand the quantum computational complexity of black holes is still largely in the realm of speculative and cutting-edge research. As both fields of quantum computing and black hole physics evolve, more practical applications might emerge in the future.\n",
        "\n",
        "****\n",
        "\n",
        "Yes, quantum machine learning (QML) has the potential to be used to calculate the quantum computational complexity of black holes. QML is a new field that combines the principles of quantum mechanics with machine learning. It has the potential to solve problems that are intractable for classical computers.\n",
        "\n",
        "One way that QML could be used to calculate the quantum computational complexity of black holes is to develop algorithms that can learn the structure of black hole states from data. For example, an algorithm could be trained on a dataset of black hole states, and then it could be used to calculate the complexity of new black hole states.\n",
        "\n",
        "Another way that QML could be used to calculate the quantum computational complexity of black holes is to develop algorithms that can efficiently simulate the evolution of black hole states. This could be done by using QML to develop new representations of black hole states that are more efficient to simulate than traditional representations.\n",
        "\n",
        "Researchers are currently exploring a number of different ways to use QML to calculate the quantum computational complexity of black holes. These efforts are still in their early stages, but they have the potential to lead to new insights into the nature of black holes and quantum gravity.\n",
        "\n",
        "Here are some specific examples of how QML could be used to calculate the quantum computational complexity of black holes:\n",
        "\n",
        "* **Train a machine learning model on a dataset of black hole states, and then use the model to calculate the complexity of new black hole states.**\n",
        "\n",
        "* **Develop a new quantum circuit representation for black hole states that can be efficiently simulated by a quantum computer, and then use QML to develop algorithms for simulating these circuits.**\n",
        "\n",
        "* **Use QML to develop new algorithms for estimating the probability of a particular outcome of a quantum computation, and then use these algorithms to estimate the complexity of black hole states.**\n",
        "\n",
        "Research in this area is still in its early stages, but it has the potential to revolutionize our understanding of black holes and quantum gravity. As quantum computers become more powerful, QML is likely to play an increasingly important role in our quest to understand the universe at its most fundamental level."
      ],
      "metadata": {
        "id": "RbqvlS1PvGeM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Black Holes as (Quantum) Computers*"
      ],
      "metadata": {
        "id": "GwAZXBb_beZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Powerful X-rays emitted near these black holes have properties that make them ideal information carriers for quantum computing\n",
        "\n",
        "* If the star that forms it rotates, as most stars do, the black hole will also spin.\n",
        "* Material that gets close to a rotating black hole but does not fall into it will aggregate into a circular structure known as an accretion disk. Powerful forces acting on accretion disks raise their temperature so they emit X-rays, which can act as carriers of quantum information.\n",
        "* The photons that make up the X-rays have two properties: polarisation and orbital angular momentum. Each of these can encode a qubit (quantum bit) of information, the standard information unit in quantum computing. \"Lab-based researchers already use beam splitters and prisms to entangle these properties in X-ray photons and process quantum information,\" says Racorean. \"It now seems that the curvature of spacetime around a black hole will play the same role as this apparatus.\"\n",
        "* Thus far, however, this process is only a prediction. The final proof will come when the properties of X-rays near spinning black holes are observed, which could happen in the next decade.\n",
        "* Two space probes with the same mission will be launched around 2022: the Imaging X-ray Polarimetry Explorer (IXPE) by NASA, and the X-ray Imaging Polarimetry Explorer (XIPE) by the European Space Agency. These will investigate the polarisation of all X-rays found in space, including those emitted close to black holes. \"If we find that the X-ray polarisation changes with distance from the black hole, with those in the central region being least polarised, we will have observed entangled states that can carry quantum information,\" says Racorean.\n",
        "* This topic may seem esoteric, but it could have practical applications. **\"One day, we may even be able to use rotating black holes as quantum computers by sending [X-ray] photons on the right trajectory around these ghostly astronomical bodies,\"** Racorean concludes.\n",
        "* Additionally, scientists believe that simulation of unusual states of matter will be an important early application of quantum computing, and there are few more unusual states of matter than those found in the vicinity of black holes.\n",
        "\n",
        "https://phys.org/news/2017-11-black-holes-spacetime-quantum.amp"
      ],
      "metadata": {
        "id": "7fPBrXRFasEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Symmetries (equivariances or invariances) in quantum computational complexity of black holes*"
      ],
      "metadata": {
        "id": "8fYo65BMPmqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In quantum computational complexity of black holes, are there any symmetries (equivariances or invariances) that can be exploited?**\n",
        "\n",
        "Yes, there are several symmetries (equivariances or invariances) that can be exploited in the quantum computational complexity of black holes. These symmetries can be used to simplify the problem of calculating the complexity of black hole states and to gain new insights into the relationship between black holes and quantum information theory.\n",
        "\n",
        "One of the most important symmetries of black holes is their conformal symmetry. This symmetry arises from the fact that black holes are solutions to the Einstein equation, which is conformally invariant. Conformal symmetry implies that the complexity of black hole states should be independent of certain transformations of the coordinates. This can be used to simplify the complexity calculations by fixing the coordinates in a particular way.\n",
        "\n",
        "Another important symmetry of black holes is their entanglement structure. Black hole states are highly entangled, and this entanglement can be exploited to reduce the computational complexity of certain tasks. For example, it has been shown that the complexity of the state of a black hole that is created by collapsing a massive particle is proportional to the entanglement entropy of the particle.\n",
        "\n",
        "Symmetries can also be used to relate the complexity of black hole states to other quantities of interest, such as the entropy or the information content of the black hole. For example, it has been shown that the complexity of a black hole state is equal to the entropy of the black hole up to a logarithmic correction. This suggests that complexity may be a more fundamental measure of a black hole's information content than entropy.\n",
        "\n",
        "The study of symmetries in the quantum computational complexity of black holes is an active area of research. As we learn more about these symmetries, we will be able to gain a better understanding of the relationship between black holes and quantum information theory. This could ultimately lead to new insights into the nature of black holes and quantum gravity.\n",
        "\n",
        "Here are some specific examples of how symmetries can be exploited in the quantum computational complexity of black holes:\n",
        "\n",
        "* **Conformal symmetry:** By using conformal transformations of the coordinates, it is possible to map a black hole to a state with a simpler circuit description. This can be used to simplify the complexity calculations.\n",
        "\n",
        "* **Entanglement structure:** By understanding the entanglement structure of black hole states, it is possible to identify certain operations that can be performed efficiently. This can be used to reduce the computational complexity of certain tasks.\n",
        "\n",
        "* **Symmetry between black hole formation and evaporation:** There is a symmetry between the complexity of a black hole state that is created by collapsing a massive particle and the complexity of the state that is emitted from the black hole's horizon. This symmetry can be used to relate the complexity of black holes to their entropy and information content.\n",
        "\n",
        "Symmetries play a crucial role in understanding the quantum computational complexity of black holes. By exploiting these symmetries, we can gain new insights into the nature of black holes and quantum information theory."
      ],
      "metadata": {
        "id": "cSAnOF4gPxVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Can you represent conformal symmetry in a quantum circuit?**\n",
        "\n",
        "Yes, conformal symmetry can be represented in a quantum circuit using a specific type of gate called a conformal gate. Conformal gates are unitary operators that preserve the conformal group, which is the group of transformations that leave the conformal structure of a spacetime invariant.\n",
        "\n",
        "**Conformal Gates**\n",
        "\n",
        "Conformal gates are typically represented as a combination of two-qubit gates, such as the controlled-Z gate (CZ) and the controlled-Hadamard gate (CH). These gates can be used to implement the conformal group, which consists of dilations, translations, and special conformal transformations.\n",
        "\n",
        "**Dilation**\n",
        "\n",
        "A dilation is a transformation that increases or decreases the size of a system. In quantum mechanics, this corresponds to a scaling of the Hamiltonian. A dilation can be implemented using a CZ gate followed by a Hadamard gate (H), as shown below:\n",
        "\n",
        "```\n",
        "CZ |q0, q1⟩ ⇒ |q0, q0⟩\n",
        "H |q0⟩ ⇒ |+⟩\n",
        "```\n",
        "\n",
        "This circuit transforms the state |q0, q1⟩ into |+, +⟩, which is the maximally mixed state on two qubits. This represents a dilation of the system, as the entropy of the state has increased.\n",
        "\n",
        "**Translation**\n",
        "\n",
        "A translation is a transformation that moves a system to a different location. In quantum mechanics, this corresponds to adding a constant offset to the Hamiltonian. A translation can be implemented using a CZ gate followed by a Pauli X gate (X), as shown below:\n",
        "\n",
        "```\n",
        "CZ |q0, q1⟩ ⇒ |q1, q0⟩\n",
        "X |q1⟩ ⇒ |-⟩\n",
        "```\n",
        "\n",
        "This circuit transforms the state |q0, q1⟩ into |-, -⟩, which is the orthogonal complement of the maximally mixed state. This represents a translation of the system, as the state has moved to a different point on the Bloch sphere.\n",
        "\n",
        "**Special Conformal Transformation**\n",
        "\n",
        "A special conformal transformation is a combination of a translation and a dilation. In quantum mechanics, this corresponds to a squeezing of the system. A special conformal transformation can be implemented using a CZ gate followed by a combination of H and X gates, as shown below:\n",
        "\n",
        "```\n",
        "CZ |q0, q1⟩ ⇒ |q0, q1⟩\n",
        "H |q1⟩ ⇒ |-⟩\n",
        "X |-⟩ ⇒ |+⟩\n",
        "```\n",
        "\n",
        "This circuit effectively transforms the state |q0, q1⟩ back to itself, but it has introduced some non-classical correlations between the qubits. This represents a squeezing of the system, as the state has become more entangled.\n",
        "\n",
        "**Combining Conformal Gates**\n",
        "\n",
        "Conformal gates can be combined to implement more complex conformal transformations. For example, the following circuit implements a combination of a dilation and a special conformal transformation:\n",
        "\n",
        "```\n",
        "CZ |q0, q1⟩ ⇒ |q0, q0⟩\n",
        "H |q0⟩ ⇒ |+⟩\n",
        "X |+⟩ ⇒ |-⟩\n",
        "X |-⟩ ⇒ |+⟩\n",
        "```\n",
        "\n",
        "This circuit transforms the state |q0, q1⟩ into |+, -⟩, which is a partially entangled state. This represents a combination of a dilation and a squeezing of the system.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "Conformal gates can be used to represent conformal symmetry in a quantum circuit. These gates can be used to implement the conformal group, which consists of dilations, translations, and special conformal transformations. Conformal gates have applications in various fields, including quantum field theory, quantum gravity, and condensed matter physics."
      ],
      "metadata": {
        "id": "gQT79SohR-JG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Black Hole Information Paradox*"
      ],
      "metadata": {
        "id": "P4NJL0kOLbfi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution: Quantengravitationskorrekturen\n",
        "\n",
        "https://www.derstandard.de/story/2000145317520/schwarze-loecher-zeigen-ihr-weiches-haar-jetzt-oeffentlich\n",
        "\n",
        "* Noch ist unklar, wie sich die Theorie überprüfen lassen könnte. Angesichts vieler neuer Informationen über Schwarze Löcher, vor allem durch die neuen Gravitationswellenexperimente, scheint eine künftige Überprüfung zumindest nicht ganz aussichtslos.\n",
        "\n",
        "* Calmet selbst regt an, Modelle Schwarzer Löcher im Labor nachzubauen. Der Bereich der \"Quantensimulation\" ist tatsächlich eine der spannendsten Anwendungen moderner Quantentechnologie.\n",
        "\n",
        "* Auch die Simulation von Effekten der Teilchenphysik, wie sie hier nötig wären, [gelang bereits](https://www.derstandard.at/story/2000039596758/innsbrucker-quantencomputer-simuliert-phaenomen-der-teilchenphysik). Es besteht also Hoffnung, dass die Aussage der Forscher, im Gegensatz zu vielen anderen, die den Grenzbereich von Quantenphysik und Relativitätstheorie betreffen, doch experimentell überprüfbar ist. (Reinhard Kleindl, 8.4.2023)\n",
        "\n",
        "> Science: [Quantum gravitational corrections to particle creation by black holes](https://www.sciencedirect.com/science/article/pii/S0370269323001545)"
      ],
      "metadata": {
        "id": "layD8eDpdwkr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Black hole information paradox: **if black holes radiate a perfect thermal spectrum then, by definition, that radiation has maximum entropy and contains no information about whatever fell into the black hole**. The black holes evaporates and all information that went into is deleted. This breaks rule of conservation of quantum information.\n",
        "\n",
        "What if all the information they eat is trapped forever in the tiny Planck relic? However that would break another rule: the Bekenstein bound (max of information that a region of space can contain)."
      ],
      "metadata": {
        "id": "clcxWo4_eQbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1481.jpg)"
      ],
      "metadata": {
        "id": "6kL2b_sbTvYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The [black hole information paradox](https://en.m.wikipedia.org/wiki/Black_hole_information_paradox) is a puzzle that appears when the predictions of quantum mechanics and general relativity are combined. The theory of general relativity predicts the existence of black holes that are regions of spacetime from which nothing — not even light — can escape.\n",
        "\n",
        "* In the 1970s, Stephen Hawking applied the rules of quantum mechanics to such systems and found that an isolated black hole would emit a form of radiation called Hawking radiation. Hawking also argued that the detailed form of the radiation would be **independent of the initial state of the black hole and would depend only on its mass, electric charge and angular momentum (=No hair conjecture)**.\n",
        "\n",
        "* The information paradox appears when one considers a process in which a black hole is formed through a physical process and then evaporates away entirely through **= Hawking radiation**.\n",
        "\n",
        "* Hawking's calculation suggests that the final state of radiation would retain information only about the total mass, electric charge and angular momentum of the initial state. Since many different states can have the same mass, charge and angular momentum this suggests that many initial physical states could evolve into the same final state. Therefore, information about the details of the initial state would be permanently lost.\n",
        "\n",
        "* However, this violates a core precept of both classical and quantum physics—that, in principle, the state of a system at one point in time should determine its value at any other time. Specifically, in quantum mechanics the state of the system is encoded by its wave function. The evolution of the wave function is determined by a unitary operator, and unitarity implies that the wave function at any instant of time can be used to determine the wave function either in the past or the future.\n",
        "\n",
        "* It is now generally believed that information is preserved in black-hole evaporation."
      ],
      "metadata": {
        "id": "SjA9CngZDwbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Black hole information paradox**\n",
        "\n",
        "[What Survives Inside A Black Hole?](https://www.youtube.com/watch?v=GscfuQWZFAo)\n",
        "\n",
        "Conservation of quantum information, Gateway to blackhole thermodynamics and holographic principle\n",
        "\n",
        "- Mass, electric charge and angular momentum: only three properties to describe a black hole: no hair conjecture (Jakob bekenstein)\n",
        "- the inside of the black hole is disconnected from the outside, cannot influence. We know only the three above information\n",
        "- These properties are remembered in the curvature of spacetime, in the gravitational field, according to Gauss’s law for gravity (like in electric fields), that’s why we at least have these information about the black hole\n",
        "- Gauss’s law for gravity: THE GrAVITATIONAL FLUX ThROUGh ANY CLOSED SURFACE IS PROPORTIONAL т O tHE ENciOSED MASS. the distribution of the matter is irrelevant (as a point, or along a region)\n",
        "- Since graviational force and electric force are infinite, the mass and charge of any region in space are remembered in the field (see inverse inverse square law)\n",
        "- Same for angular momentum: you get a magnetic field when an electric field changes. Frame dragging changes the shape of the event horizon and the orbit of anything nearby. If material with angular momentum (spinning star, rotating gas) falls in a black hole it will add or subtract from the flow of space above the event horizon. Its angular momentum is remembered in the frame dragging!! (Gravity probe B)\n",
        "- But something seems too get lost: number of particles of different types, like balance between quarks and antiquarks, represented by Baryon number (which is a conserved quantity)"
      ],
      "metadata": {
        "id": "uIBWis-eN7yC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Closed Timeline Curves (CTC), Ergosphere, Retrocausality and Superdeterminism*"
      ],
      "metadata": {
        "id": "Dgy31jigwHId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How time and space switch in the ergosphere [How Black holes spin space time](https://youtu.be/UjgGdGzDFiM?si=i3q0LFySMKns9CV9)"
      ],
      "metadata": {
        "id": "q-23-lCWRXKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://de.m.wikipedia.org/wiki/Ergosphäre\n",
        "\n",
        "https://www.astro.umd.edu/~richard/ASTRO350/Astro350_2020_class09.pdf\n",
        "\n",
        "https://www.sciencedirect.com/science/article/pii/S0550321320301747"
      ],
      "metadata": {
        "id": "skb7hbj3a-L2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Physiker simulieren Zeitreisen mit Quantenpartikeln\n",
        "\n",
        "* https://t3n.de/news/physiker-simulieren-zeitreisen-quantenpartikeln-1585445/\n",
        "\n",
        "* [APS - Nonclassical Advantage in Metrology Established via Quantum Simulations of Hypothetical Closed Timelike Curves](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.131.150202)"
      ],
      "metadata": {
        "id": "4-NUqdJCZu9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://en.m.wikipedia.org/wiki/Closed_timelike_curve\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Retrocausality\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Superdeterminism"
      ],
      "metadata": {
        "id": "kn3NToI5wNFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Holographic Principle, Ads/CFT and Kerr/CFT correspondence*"
      ],
      "metadata": {
        "id": "DOOx_crf83HT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SYK model: https://en.m.wikipedia.org/wiki/Sachdev–Ye–Kitaev_model"
      ],
      "metadata": {
        "id": "r1ZxrtXNQBHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Background: Holographic Principle, Ads/CFT and Kerr/CFT correspondence**\n",
        "\n",
        "1. **Holographic Principle**: This is a fundamental idea that suggests that all of the information contained within a given volume of space can be represented by information on the boundary of that space. Think of it as a kind of \"hologram\" where a 2D surface can contain all the information about a 3D volume. This principle was inspired by the behavior of black holes, where the entropy (a measure of information) of a black hole is proportional to its surface area and not its volume.\n",
        "\n",
        "2. **AdS/CFT correspondence**: This is a specific realization of the holographic principle. It's a conjectured relationship between two types of physical theories:\n",
        "    - AdS: Anti-de Sitter space, which is a type of space in gravity theories.\n",
        "    - CFT: Conformal Field Theories, which are quantum field theories defined on the boundary of the AdS space.\n",
        "\n",
        "  * The AdS/CFT correspondence posits that a quantum field theory on the boundary (CFT) is equivalent to a gravity theory in the bulk (AdS). This provides a powerful duality that allows for the study of difficult problems in one theory using the tools of the other. In essence, while the holographic principle is a general idea about the nature of information and space, AdS/CFT is a specific, concrete example that ties together quantum mechanics and gravity.\n",
        "\n",
        "3. **Kerr/CFT Correspondence**\n",
        "  * [Kerr/CFT Correspondence (wiki)](https://en.m.wikipedia.org/wiki/Kerr/CFT_correspondence)\n",
        "  * [The Kerr/CFT Correspondence](https://arxiv.org/abs/0809.4266)"
      ],
      "metadata": {
        "id": "HRuHg-4_81ei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Überraschende Entdeckung: Gleichartiges Leuchten von schwarzen Löchern stellt Theorien infrage\n",
        "\n",
        "https://t3n.de/news/ueberraschende-entdeckung-schwarze-loecher-geichartiges-leuchten-bisherige-theorie-1594532/\n",
        "\n",
        "https://arxiv.org/abs/2307.13872"
      ],
      "metadata": {
        "id": "2HXUAGyzPAq5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Landauer-Prinzip vs Nernst-Theorem*"
      ],
      "metadata": {
        "id": "I2xPw5u9vGWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wie man Daten am Quantencomputer zuverlässig löscht\n",
        "\n",
        "Die Frage beim Löschen eines Qubits sei nun, zu welchen Kosten das erfolgt: \"Sind diese endlich, wie es das [Landauer-Prinzip](https://de.m.wikipedia.org/wiki/Landauer-Prinzip) sagt, oder dem [Nernst-Theorem](https://de.m.wikipedia.org/wiki/Dritter_Hauptsatz_der_Thermodynamik) folgend unendlich?\", so Huber. Wie der Quantenphysiker mit seinem Team nun herausfand, ist im Prinzip der unendliche Energieeinsatz nur notwendig, wenn man in endlicher Zeit kühlen bzw. löschen will. Würde man unendlich lang Zeit haben, könnte man auf diesen erforderlichen unendlichen Energieeinsatz verzichten.\n",
        "\n",
        "https://futurezone.at/amp/science/daten-quantencomputer-loeschen-qubit-wien-tu-technische-universitaet-nullpunkt/402414446\n",
        "\n",
        "https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.4.010332"
      ],
      "metadata": {
        "id": "Kp2FOzw0vOQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Unruh-Effect (Unruh Radiation and Rindler horizon)*"
      ],
      "metadata": {
        "id": "y4YO0LQ4A4IX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unruh-Effect (Unruh Radiation)**\n",
        "\n",
        "* Je schneller man sich bewegt, desto mehr Teilchen mit erhöhter Temperatur entstehen vor einem bewegenden Beobachter (befindet sich im Wärmebad). Diese Teilchen kann ein ruhender Beobachter nicht sehen.\n",
        "\n",
        "* **Ist ein relativistisches Phänomen: nicht nur Zeit und Distanz hängen vom Beobachter ab, sondern auch die Existenz von Teilchen**\n",
        "\n",
        "* ist rein theoretisch, hat noch nieman beobachtet.\n",
        "\n",
        "* Schwarze Löcher strahlen Teilchen aus. Unruh-Effekt interessant fur komplizierte Phänomene wie Hawking-Strahlung oder expandierendes Universum\n",
        "\n",
        "* **sowohl bei Hawking-Strahlung als auch bei Unruh-Effekt scheinen Teilchen aus dem Nichts zu entstehen, wodurch das Vakuum eine endliche Temperatur erhält**."
      ],
      "metadata": {
        "id": "iC7r8vzaiiO5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Der [Unruh-Effekt](https://de.m.wikipedia.org/wiki/Unruh-Effekt) ist eine Vorhersage der Quantenfeldtheorie: Ein im Vakuum gleichmäßig beschleunigter Beobachter oder Detektor sieht anstelle des Vakuums ein Gas von Teilchen (Photonen, Elektronen, Positronen, …) mit einer Temperatur T, die proportional zur Beschleunigung ist.\n",
        "\n",
        "* nature of quantum fields seems to change as the observer is accelerating\n",
        "* accelerating cuts of causal access to a region in the universe and **creates a type of event horizon ([Rindler horizon](https://en.m.wikipedia.org/wiki/Rindler_coordinates))**\n",
        "* the presence of horizons distorts the quantum vacuum in a way that can create particles (Hawking radiation) -> Unruh effect\n",
        "* created even horizon behind you can't catch you, but its Unruh radiation can!\n",
        "* accelerating observers find themselves in a warm bath of particles\n",
        "* Unruh-deWitt-detector to detect particles - **the existence of partices is observer-dependent!**\n",
        "* [The Unruh Effect](https://www.youtube.com/watch?v=7cj6oiFDEXc&list=WL&index=11)\n",
        "\n",
        "\n",
        "https://physicsworld.com/a/black-holes-could-reveal-their-quantum-superposition-states-new-calculations-reveal/"
      ],
      "metadata": {
        "id": "k3Jd1qq8fX7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *No hair conjecture (Jakob Bekenstein)*"
      ],
      "metadata": {
        "id": "aZ3xS4t7CWRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The [no-hair theorem](https://en.m.wikipedia.org/wiki/No-hair_theorem) states that **all stationary black hole solutions** of the Einstein–Maxwell equations of gravitation and electromagnetism in general relativity can be **completely characterized by only three independent externally observable classical parameters: mass, electric charge, and angular momentum**.\n",
        "\n",
        "* Other characteristics (such as geometry and magnetic moment) are uniquely determined by these three parameters, and all other information (for which \"hair\" is a metaphor) about the matter that formed a black hole or is falling into it \"disappears\" behind the black-hole event horizon and **is therefore permanently inaccessible to external observers after the black hole \"settles down\" (by emitting gravitational and electromagnetic waves)**.\n",
        "\n",
        "* Physicist John Archibald Wheeler expressed this idea with the phrase \"black holes have no hair\", which was the origin of the name.\n",
        "\n",
        "\n",
        "Mass, electric charge and angular momentum: only three properties to describe a black hole: no hair conjecture (Jakob bekenstein)\n",
        "the inside of the black hole is disconnected from the outside, cannot influence. We know only the three above information"
      ],
      "metadata": {
        "id": "hf4RmooSCYnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Hawking Radiation*"
      ],
      "metadata": {
        "id": "gj5tJ7BnBLC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[*Hawking Radiation (Black Hole Radiation)*](https://de.m.wikipedia.org/wiki/Hawking-Strahlung)\n",
        "\n",
        "* Schwarze Löcher verlieren Energie\n",
        "\n",
        "* Schwarze Löcher geringer Masse sind von geringer Ausdehnung, d. h., sie haben einen kleineren Schwarzschildradius.\n",
        "\n",
        "* Die den Ereignishorizont umgebende Raumzeit ist entsprechend stärker gekrümmt. Je größer und damit massereicher ein Schwarzes Loch ist, desto weniger strahlt es also.\n",
        "\n",
        "* Je kleiner ein Schwarzes Loch ist, umso höher ist seine Temperatur und aufgrund stärkerer Hawking-Strahlung verdampft es umso schneller.\n",
        "\n",
        "* [Nature: Quantum simulation of black-hole radiation](https://www.nature.com/articles/d41586-019-01592-x)"
      ],
      "metadata": {
        "id": "sNuPQnPNB0jr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hawking Radiation & Destruction of Information (No hair theorem)**\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/No-hair_theorem\n",
        "\n",
        "Destruction of Information by Hawking radiation\n",
        "\n",
        "https://www.youtube.com/watch?v=9XkHBmE-N34\n",
        "\n",
        "[Warum Quanteninformationen niemals zerstört wird](https://www.youtube.com/watch?v=HF-9Dy6iB_4)\n",
        "\n",
        "**No hair theorem**: black hole shields every information away except mass, electrci charge and angular momentu -> informatoon is still there, just not accessible. but Hawking radiation seems to evaporate all information..\n",
        "\n",
        "\n",
        "Video: [Hawking Radiation](https://www.youtube.com/watch?v=qPKj0YnKANw)\n",
        "\n",
        "[Hawking-Strahlung](https://de.m.wikipedia.org/wiki/Hawking-Strahlung): postulierte Strahlung Schwarzer Löcher\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1264.png)\n",
        "\n",
        "Hawking radiation has wavelengths of the size of the event horizon (the size of the entire black hole). These are the de Broglie wavelenghts of created particles:\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1265.png)\n",
        "\n",
        "**Important**:\n",
        "\n",
        "* large black holes (event horizon several kilometers long) have very long wavelenght of Hawking radiation, just photons - kilometer-long electromagnetic, low energy radio-waves  - they are cold and leak energy very slowly.\n",
        "\n",
        "* the smaller the black hole gets, the shorter the wavelengths and the higher the energy, and the thermal enegry heats up. Evaporation rate increases. It's a runnaway process\n",
        "\n",
        "* the end of probably a Planck relic (tiny black holes in size of planck length) that either create an own inflation with a new universe, or evaporate\n",
        "\n",
        "* Video: [What If (Tiny) Black Holes Are Everywhere?](https://www.youtube.com/watch?v=srVKjWn26AQ&list=WL&index=4)\n",
        "\n",
        "They tell us that there is an enormous uncertainty in the location of these particles. Hawking radiation must appear to come from the global black hole, not from specific points at the event horizon\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1266.png)\n",
        "\n",
        "This radiation is visible only to distant observers, but not if you fall into the black hole (then you see flat vaccum space). Only if you hover fixed distanced above the horizon, then you see partices. This is due to the [Unruh radiation](https://de.m.wikipedia.org/wiki/Unruh-Effekt).\n",
        "\n"
      ],
      "metadata": {
        "id": "jTf6z42jo76R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1342.jpg)"
      ],
      "metadata": {
        "id": "2dj913yMCipe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Bekenstein-Bound, Bekenstein-Hawking-Entropie, and Holografische Prinzip*"
      ],
      "metadata": {
        "id": "XW6H46KpBVW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bekenstein bound**\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Bekenstein_bound\n",
        "\n",
        "Black hole information paradox: if black holes radiate a perfect thermal spectrum then,  by definition, that radiation has maximum entropy and contains no information about whatever fell into the black hole. The black holes evaporates and all information that went into is deleted. This breaks rule of conservation of quantum information.\n",
        "\n",
        "What if all the information they eat is trapped forever in the tiny Planck relic? However that would break another rule: the Bekenstein bound (max of information that a region of space can contain).\n",
        "\n",
        "\n",
        "*According to the Bekenstein bound, the entropy of a black hole is proportional to the number of Planck areas that it would take to cover the black hole's event horizon.*\n",
        "\n",
        "![ggg](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Bekenstein-Hawking_entropy_of_a_black_hole.jpg/640px-Bekenstein-Hawking_entropy_of_a_black_hole.jpg)\n",
        "\n",
        "A way around this has been proposed - what if space inside black holes actually expands to a region larger than the event horizon? What if at the singularity of a black hole a new inflation is triggered. Then there is enough space."
      ],
      "metadata": {
        "id": "fq2o4mluelgv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bekenstein-Hawking-Entropie & Holografische Prinzip**\n",
        "\n",
        "[*Bekenstein-Hawking-Entropie*](https://de.m.wikipedia.org/wiki/Bekenstein-Hawking-Entropie)\n",
        "\n",
        "* Heuristische Überlegungen führten J. D. Bekenstein bereits 1973 zu der Hypothese, dass die Oberfläche des Ereignishorizontes ein Maß für die Entropie eines Schwarzen Loches sein könnte, siehe Bekenstein-Hawking-Entropie.\n",
        "\n",
        "* Die Bekenstein-Hawking-Entropie war eine Motivation für das [Holografische Prinzip](https://de.m.wikipedia.org/wiki/Holografisches_Prinzip).\n"
      ],
      "metadata": {
        "id": "BAJVWziCxtWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The inverse square law**\n",
        "\n",
        "* Gauss's law is a more general form of this. It applies to any shaped surface surrounding any shaped mass charge.\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1269.png)"
      ],
      "metadata": {
        "id": "A2R7_zGXLYl2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Killing Horizons Decohere Quantum Superpositions: Do Black Holes and the Cosmic Event Horizon create physical reality?*"
      ],
      "metadata": {
        "id": "nMRTXb5a56Aq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rindler horizin, kiling horizon\n",
        "\n",
        "Event horizon produce decoherence of quantum states, producing reality?\n",
        "Video: [Strange New Explanation for Why Quantum World Collapses Into Reality](https://www.youtube.com/watch?v=3_hi48l-cj8&list=WL&index=8)\n",
        "\n",
        "https://arxiv.org/abs/2301.00026 Killing Horizons Decohere Quantum Superpositions\n",
        "\n"
      ],
      "metadata": {
        "id": "Top6h_dkRvNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suggestion that horizons from black holes and the expansion of the universe cause the quantum collapse into reality\n",
        "\n",
        "* Ausgangspunkt: two entangled particles, one falls in back hole - according to general relativity they cannot decohere, because no information gets out, but that‘s not what happens according to quantum theory. maybe the edge of a black hole (event horizon) acts like an observer and decoheres the entangled state\n",
        "* Bringing this idea to the next level: The edge of the universe acts like an observer of everything that happens inside of it\n",
        "* Observation means here decoherence and brings things from quantum state into real physical state\n",
        "* Edge of universe is an event horizon (just opposite side to black holes): Rindler horizon (particularly the Killing horizon in this case)\n",
        "\n",
        "Video: https://youtu.be/3_hi48l-cj8\n",
        "\n",
        "Paper: Killing Horizons Decohere Quantum Superpositions  https://arxiv.org/abs/2301.00026"
      ],
      "metadata": {
        "id": "u8oJFM3N53sW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Gravity - Quantum Cosmology & Quantum Complexity (Dump)*"
      ],
      "metadata": {
        "id": "AbTRWe0r27UX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entanglement: Gravity’s long-distance connection Wormhole links between black holes could broker quantum-general relativity merger\n",
        "\n",
        "https://www.sciencenews.org/article/entanglement-gravitys-long-distance-connection"
      ],
      "metadata": {
        "id": "NGwdlAhRQhog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.quantamagazine.org/renate-loll-blends-universes-to-unlock-quantum-gravity-20230525/"
      ],
      "metadata": {
        "id": "Cdf_URbpqfmw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noncommutative geometry and cosmology\n",
        "\n",
        "there is also a book!\n",
        "\n",
        "http://www.its.caltech.edu/~matilde/CosmoBeijing2013.pdf\n",
        "\n",
        "https://arxiv.org/abs/gr-qc/0305077\n"
      ],
      "metadata": {
        "id": "WczJMFxaGXf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why Physicists Think Gravity Creates Light**\n",
        "\n",
        "* Gravity into light: oscillations of inflaton field can produce this resonance in any field, including the gravitational fields of the primordial universe. Oscillating graviational fields are better known as gravitational waves.\n",
        "\n",
        "* If the inflation resonance coupled to the creation of gravitational waves in the early universe, this could create gravitational standing waves of incredibly high energy\n",
        "\n",
        "* in places where the refractive index of light is greater than 1 (= meaning that gravitational waves move faster than light waves), this can result in gravitational waves driving oscillations in the electromagnetic field, essentially creating a shock wave that generates spontaneous particles of light - light out of the fabric of spacetime. (Somehow analogous to Cherenkov radiation)\n",
        "\n",
        "* For a particle physics description, rather than a quantum field description: * think of a standing gravitational wave as a collective behavior of two groups of massless gravitons - particles of gravity - traveling in opposite directions. At high enough energies and densities, these can collide and decay into other particles, in this case photons. Just like a pair of high energy photons can collide and decay into an electron positron pair.\n",
        "\n",
        "* the process is very inefficient and probably only occured in early universe. Or (gravitational waves) exist today only in binary black hole systems, but the refractive index isn't usually greater than 1 in these systems, so it's difficult to create these shockwave-like environments.\n",
        "\n",
        "Video: [Why Physicists Think Gravity Creates Light](https://www.youtube.com/watch?v=LtTIE7C7me0)\n",
        "\n",
        "Paper: [Graviton to photon conversion via parametric resonance](https://www.sciencedirect.com/science/article/pii/S2212686423000365)"
      ],
      "metadata": {
        "id": "VPk6KpkSsPwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Group Field Theories for Quantum Gravity](https://youtu.be/aO3sNENdV1k)\n",
        "\n",
        "[Effective Spin Foam for quantum gravity](https://youtu.be/6n1iaT1bw1Y)"
      ],
      "metadata": {
        "id": "s35ijjuCHacG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sensing between particle’s intrinsic quantum spin and Earth’s gravitational field**\n",
        "\n",
        "how does a quantum spin interact with a gravitational field\n",
        "\n",
        "https://physics.aps.org/articles/v16/80\n",
        "\n",
        "A hunt for a spin-gravity interaction has implications for the existence of hypothetical forces of nature and for the origin of the Universe’s matter-antimatter asymmetry.\n",
        "\n",
        "https://mriquestions.com/why-at-larmor-frequency.html\n"
      ],
      "metadata": {
        "id": "ju1r0FkIziC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Concepts**\n",
        "\n",
        "* A theory of the cosmological quantum state is an objective of quantum cosmology (but we've only got one system). A theory of a quantum state is a necessary part of any final theory [Source](https://www.youtube.com/watch?v=xcJ7diTtURc).\n",
        "\n",
        "* Hawking's [no-boundary wave function (NBWF)](https://web.physics.ucsb.edu/~quniverse/nbwf-form.html) is a theory of the quantum state of the universe. Such a state is a necessary part of any final theory along with a theory of quantum dynamics. In principle all predictions depend on both, and predictions of the large scale universe are observationally sensitive to its details. NBWF fluctuations start in their ground state. Essentially the [Bunch-Davies vacuum](https://en.m.wikipedia.org/wiki/Bunch–Davies_vacuum)\n",
        "\n",
        "* [Bunch–Davies vacuum](https://en.m.wikipedia.org/wiki/Bunch–Davies_vacuum): In quantum field theory in curved spacetime, there is a whole class of quantum states over a background de Sitter space which are invariant under all the isometries: the alpha-vacua. Among them there is a particular one whose associated Green functions verify a condition (Hadamard condition) consisting to behave on the light-cone as in flat space. This state is usually called the Bunch–Davies vacuum or Euclidean vacuum\n",
        "\n",
        "* [quantum field theory in curved spacetime (QFTCS)](https://en.m.wikipedia.org/wiki/Quantum_field_theory_in_curved_spacetime)"
      ],
      "metadata": {
        "id": "FolSJUgxM3q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.einstein-online.info/en/spotlight/quantum_cosmo_path_integrals/"
      ],
      "metadata": {
        "id": "Nn__-qpARqWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [APS Physics 2015 - Quantum Gravity and Quantum Cosmology](https://www.youtube.com/watch?v=xcJ7diTtURc)\n",
        "\n",
        "* Quantum theory of gravity means a quantum theory of spacetime geometry\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1482.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1483.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1484.png)\n"
      ],
      "metadata": {
        "id": "mhyFfc16LGoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [PBS - Quantum Gravity and the Hardest Problem in Physics](https://www.youtube.com/watch?v=YNEBhwimJWs)\n",
        "\n",
        "* Non-renormalizability of general relativity: precise localized particles produce black holes (you need so much energy to localize below one planck length or one planck time, that it produces black holes. the more precise, the larger the black hole gets"
      ],
      "metadata": {
        "id": "NWEVty9lUJCr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Event: Quantum Gravity and Quantum Cosmology\n",
        "\n",
        "https://meetings.aps.org/Meeting/APR15/Session/W1.2"
      ],
      "metadata": {
        "id": "g43DMitiCBp9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://de.m.wikipedia.org/wiki/Quantengravitation"
      ],
      "metadata": {
        "id": "Yq_BfEMg-na6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://en.m.wikipedia.org/wiki/Quantum_cosmology"
      ],
      "metadata": {
        "id": "U_d9X5mHN3po"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://link.springer.com/book/10.1007/978-3-642-33036-0"
      ],
      "metadata": {
        "id": "GQCbRUEx-2uc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://hyperspace.uni-frankfurt.de/2020/01/29/phd-position-in-quantum-cosmology-and-quantum-gravity-sheffield-uk/"
      ],
      "metadata": {
        "id": "rfbwN8e0A7am"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosmological consequences of Quantum Gravity proposals\n",
        "\n",
        "https://arxiv.org/abs/1804.02262"
      ],
      "metadata": {
        "id": "69rhcTNQA-mq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The central object of interest in quantum cosmology is the wave function of a closed universe\n",
        "\n",
        "> $\n",
        "\\Psi\\left[h_{i j}(\\mathbf{x}), \\Phi(\\mathbf{x}), B\\right]\n",
        "$\n",
        "\n",
        "https://arxiv.org/pdf/0909.2566v1.pdf"
      ],
      "metadata": {
        "id": "0kb6n6uzO3dH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.quantamagazine.org/why-gravity-is-not-like-the-other-forces-20200615/"
      ],
      "metadata": {
        "id": "u07V5uko_KhW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <font color=\"blue\">***Quantum Cosmology and Quantum Gravitation*** *(AdS/CFT Correspondence)*\n",
        "\n",
        "> <font color=\"blue\">***Theory of Everything*** *(Electroweak + Strong Nuclear Force + Gravitation)*"
      ],
      "metadata": {
        "id": "L2nptK1EqBuK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.quora.com/What-is-Quantum-Cosmology-Is-it-a-real-area-of-study-What-is-its-current-status"
      ],
      "metadata": {
        "id": "7MTjftEoOvgr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://de.m.wikipedia.org/wiki/Weltformel"
      ],
      "metadata": {
        "id": "_T3m-BQeqfRU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "STRONG = 1\n",
        "\n",
        "ELECTROMAGNETIC = 1/137\n",
        "\n",
        "WEAK = 10^-6\n",
        "\n",
        "GRAVITY = 10^-38"
      ],
      "metadata": {
        "id": "rDpZ1cFET_s8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://en.wikipedia.org/wiki/AdS/CFT_correspondence\n",
        "\n",
        "\n",
        "\"According to the AdS/CFT correspondence, the geometries of certain spacetimes are fully determined by quantum states that live on their boundaries-indeed, by the von Neumann entropies of portions of those boundary states. This work investigates to what extent the geometries can be reconstructed from the entropies in polynomial time. Bouland, Fefferman, and Vazirani (2019) argued that the AdS/CFT map can be exponentially complex if one wants to reconstruct regions such as the interiors of black holes. Our main result provides a sort of converse: we show that, in the special case of a single 1D boundary, if the input data consists of a list of entropies of contiguous boundary regions, and if the entropies satisfy a single inequality called Strong Subadditivity, then we can construct a graph model for the bulk in linear time. Moreover, the bulk graph is planar, it has O(N?) vertices (the information-theoretic minimum), and it's \"universal,\" with only the edge weights depending on the specific entropies in question. From a combinatorial perspective, our problem boils down to an \"inverse\" of the famous min-cut problem: rather than being given a graph and asked to find a min-cut, here we're given the values of min-cuts separating various sets of vertices, and need to find a weighted undirected graph consistent with those values. Our solution to this problem relies on the notion of a \"bulkless\" graph, which might be of independent interest for AdS/CFT. We also make initial progress on the case of multiple 1D boundaries-where the boundaries could be connected via wormholes- including an upper bound of O (N4) vertices whenever an embeddable bulk graph exists (thus putting the problem into the complexity class\n",
        "NP).\"\n",
        "-Scott Aaronson and Jason Pollack\n",
        "\n",
        "Discrete Bulk Reconstruction, arxiv: 2210.15601v2 [quant-ph] (2022). https://arxiv.org/pdf/2210.15601.pdf"
      ],
      "metadata": {
        "id": "DHHvq0bsJh2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Neil Turok - Some progress towards the Path Integral for Gravity](https://youtu.be/L17Cx-iD8uU)"
      ],
      "metadata": {
        "id": "4VPAPdz4YVeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://de.m.wikipedia.org/wiki/Quantengravitation\n",
        "\n",
        "https://www.spektrum.de/news/quantengravitation-woraus-besteht-die-raumzeit/2007706\n",
        "\n",
        "Quantengravitationstheoretikerin Alejandra Castro von der Universität Amsterdam.\n",
        "\n",
        "*Supersymmetry (String Theory & AdS/CFT correspondence): Electroweak + Strong Nuclear Force + Gravitation ('Theory of Everything')*\n",
        "\n",
        "> **Quantum Field Theory and General Relativity are extremely well tested, but cannot be combined. This is a problem at things like Black Holes and Big Bang.**\n",
        "\n",
        "* Two electrons a centimeter apart would feel a repulsion from their electric charges, but attract each other due to their mutual gravity.\n",
        "\n",
        "* But the **force from the electric charge is $10^{24}$ higher than the attraction they feel from gravity**. That's 24 orders of magnitude bigger.\n",
        "\n",
        "* So any effect of gravity is lost down in the tenth forth decimal place of the electrostatic force. An incredible small effect.\n",
        "\n",
        "* So to test quantum gravity you need places with a huge amount of matter squeezed into very small volumes, which are always very high energy situations, like back holes or the Big Bang.\n",
        "\n",
        "* These are things we cannot create experimentally with our current technology.  To get to these energies we would need a particle accelerator like CERN, but the size of the solar system and with detectors the size of Jupiter. And to create enough energy to test quantum gravity, the experiment would actually end up turning into a black hole.\n",
        "\n",
        "* Currently we study this by using Gravitational Wave Astronomy (for Black Holes) and study the Cosmic Microwave Background (for Big Bang).\n",
        "\n",
        "**Quantum field theory in curved space time**\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Physical_cosmology\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Quantum_cosmology\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Causal_sets\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Quantum_gravity\n",
        "\n",
        "* It is conceivable that, in the correct theory of quantum gravity, the infinitely many unknown parameters will reduce to a finite number that can then be measured. One possibility is that normal perturbation theory is not a reliable guide to the renormalizability of the theory, and that there really is a UV fixed point for gravity.\n",
        "\n",
        "* Since this is a question of non-perturbative quantum field theory, finding a reliable answer is difficult, pursued in the asymptotic safety program.\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Background_independence\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Composite_gravity\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Effective_field_theory\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Quantum_field_theory_in_curved_spacetime\n",
        "\n",
        "* Video: [Quantum Gravity | The Search For a Theory of Everything](https://www.youtube.com/watch?v=d-86tNCSJsg&t=241s)\n",
        "\n",
        "* Video: [Quantum Gravity: How quantum mechanics ruins Einstein's general relativity](https://www.youtube.com/watch?v=S3Wtat5QNUA)\n",
        "\n",
        "* Video: [Quantum Gravity and the Hardest Problem in Physics | Space Time](https://www.youtube.com/watch?v=YNEBhwimJWs)\n",
        "\n",
        "* Video: [Quantum Gravity / Fermilab](https://www.youtube.com/watch?v=CbPWYjnQIO8)\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Supersymmetric_theory_of_stochastic_dynamics\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Higher-dimensional_supergravity\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Supergravity\n",
        "\n",
        "* https://de.m.wikipedia.org/wiki/Weltformel\n",
        "\n",
        "**Graviton**\n",
        "\n",
        "* [Gravitons](https://de.m.wikipedia.org/wiki/Graviton) are tiny compared to a gravitational wave. Currently too small to be seen by Ligo and Virgo gravitational wave detectors\n",
        "\n",
        "* perhaps it will be impossible because we need to detect changes smaller than a Planck length 1.616255(18)x$10^{-35}$ meters, which is impossible according to quantum mechanics\n",
        "\n",
        "**Supersymmetry**\n",
        "\n",
        "* [Supersymmetry](https://en.m.wikipedia.org/wiki/Supersymmetry) is an integral part of string theory, a possible theory of everything.\n",
        "\n",
        "> Supersymmetrie: Vereinigung der Bosonen mit den Fermionen\n",
        "\n",
        "* Die [Supersymmetrie](https://de.m.wikipedia.org/wiki/Supersymmetrie) ist eine hypothetische Symmetrie der Teilchenphysik, die Bosonen (Teilchen mit ganzzahligem Spin) und Fermionen (diese haben halbzahligen Spin) ineinander umwan. delt und die dadurch das gleiche Energiespektrum haben.\n",
        "\n",
        "* Die Supersymmetrie verbindet ein Teilchen mit seinem Superpart. ner. Die einfachste Realisierung einer Supersymmetrie findet man in eindimensionalen quantenmechanischen Systemen mit Hamilton-Operatoren:\n",
        "\n",
        "> $\n",
        "\\hat{H}_{+}=\\hat{A}^{\\dagger} \\hat{A}, \\quad \\hat{H}_{-}=\\hat{A} \\hat{A}^{\\dagger}\n",
        "$ (Theoretical Physics book, Page 876)\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Minimal_Supersymmetric_Standard_Model\n",
        "\n",
        "* The Minimal Supersymmetric Standard Model (MSSM) **is an extension to the Standard Model** that realizes supersymmetry.\n",
        "\n",
        "*  [Supersymmetry](https://en.m.wikipedia.org/wiki/Supersymmetry) is a [spacetime symmetry](https://en.m.wikipedia.org/wiki/Spacetime_symmetries) between two basic classes of particles:\n",
        "* bosons, which have an integer-valued spin and follow Bose–Einstein statistics, and\n",
        "* fermions, which have a half-integer-valued spin and follow Fermi–Dirac statistics.\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Supersymmetry_algebra\n",
        "\n",
        "**ADS-CFT Correspondance & Holografisches Prinzip**\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/AdS/CFT_correspondence\n",
        "\n",
        "**String Theory / M Theory** (incl. Supersymmetry and AdS/CFT correspondence)\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/String_theory\n",
        "\n",
        "* Im Gegensatz zum Standardmodell der Teilchenphysik sind bei der Stringtheorie die bei fundamentalen Bausteine der Welt keine punktförmigen Teilchen, sondern vibrierende eindimensionale Objekte. Diese werden als „Strings\" bezeichnet. Die Elementarteilchen sin Schwingungsanregungen der Strings.\n",
        "\n",
        "**Loop Quantum Gravity**\n",
        "\n",
        "* https://de.m.wikipedia.org/wiki/Schleifenquantengravitation\n",
        "\n",
        "**Topological quantum field theory**\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Topological_quantum_field_theory\n",
        "\n",
        "* Quantum gravity is believed to be background-independent (in some suitable sense), and TQFTs provide examples of background independent quantum field theories. This has prompted ongoing theoretical investigations into this class of models.\n"
      ],
      "metadata": {
        "id": "YgboF2J3nKOl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Are gravity and spacetime emergent phanomena?*"
      ],
      "metadata": {
        "id": "fP_EL_HY_Xew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Are gravity and spacetime emergent phanomena?*\n",
        "\n",
        "* **It from Qubit**: Does spacetime emerge from entanglement? Can quantum computers simulate all physical phenomena? [Simons Collaboration on Quantum Fields, Gravity, and Information](https://web.stanford.edu/~phayden/simons/overview.pdf)\n",
        "* **Does gravity come from quantum information?** Paper: [Gravity from Quantum Information](https://arxiv.org/abs/1001.5445). The Einstein equation describes an information-energy relation during this process, which implies that entropic gravity is related to the quantum entanglement of the vacuum and has a quantum information theoretic origin.\n",
        "* **Can Gravity be emergent?** Video: [Ads/CFT correspondence and holographic Principle](https://www.youtube.com/watch?v=uj6wrT0nSZg): is entanglement on the boundary (since it determines  geometry within) causing gravity in 3d holographic universe? Idea comes from holographic Principle and Ads/CFT correspondence. It suggests that gravity in anti de sitter space might emerge from entanglement structure on its boundary.\n",
        "* **Spacetime is maybe emergent phenomena** (Unitarity 2.0: Isometry): [Physicists Rewrite a Quantum Rule That Clashes With Our Universe](https://www.quantamagazine.org/physicists-rewrite-a-quantum-rule-that-clashes-with-our-universe-20220926/): Isometrie, Amplituhedron und quantenphysik: [amplituhedron](https://de.m.wikipedia.org/wiki/Amplituhedron ) does not explicitly contain any notion of spacetime. Instead, it is a purely mathematical object. This suggests that spacetime may be an emergent phenomenon, arising from the geometry of the amplituhedron.\n",
        "  * There are many different amplituhedra that can be used to describe the scattering of the same particles. This suggests that spacetime may not be a fundamental property of the universe, but rather a way of organizing our observations of the amplituhedron.\n",
        "* Nota bene: AdS/CFT correspondence, which emerged from string theory, posits a “duality” between two extremely different-looking kinds of theories. On one side of the duality is AdS (Anti de Sitter): a theory of quantum gravity for a hypothetical universe that has a negative cosmological constant, effectively causing the whole universe to be surrounded by a reflecting boundary. On the other side is a CFT (Conformal Field Theory): an “ordinary” quantum field theory, without gravity, that lives only on the boundar y of the AdS space. The [AdS/CFT correspondence](https://www.pbs.org/wgbh/nova/article/holograms-black-holes-and-the-nature-of-the-universe/) , for which there’s now overwhelming evidence (though not yet a proof), says that any question about what happens in the AdS space can be translated into an “equivalent” question about the CFT, and vice versa. “Even if a quantum gravity theory seems ‘wild’—even if it involves nonlocality, wormholes, and other exotica—there might be a dual description of the theory that’s more ‘tame,’ and that’s more amenable to simulation by a quantum computer.”\n",
        "\n",
        "*Non-locality in Bell-theorem is proven. Does at least superdeterminism exist?*\n",
        "\n",
        "* Violation Bell ineuqlity experiment in 2015. it closed Locatility loophole and detection loophole - physicao reality of entsnglemenr proven. open: [superdeterminism](https://en.m.wikipedia.org/wiki/Superdeterminism)."
      ],
      "metadata": {
        "id": "hrzdeyoD_Z8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color=\"blue\">**Quantum Applications**"
      ],
      "metadata": {
        "id": "RcixBlEjhSch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Astrophysics*"
      ],
      "metadata": {
        "id": "wagDIGtWD_f9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantum computing could improve the accuracy and speed of these simulations, allowing astrophysicists to better understand the origins of the universe. Developing quantum sensors for astronomy: Quantum sensors, such as atom interferometers, can be used to measure gravity and acceleration with high precision.\n",
        "\n",
        "https://www.linkedin.com/pulse/quantum-computing-astrophysics-ajay-gokhale#:~:text=Quantum%20computing%20could%20improve%20the,and%20acceleration%20with%20high%20precision."
      ],
      "metadata": {
        "id": "AGZafQvaEFp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/2101.05821"
      ],
      "metadata": {
        "id": "PsZSMfcZFI9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://bootcamp.uxdesign.cc/quantum-computing-in-space-science-88d88f505bbb"
      ],
      "metadata": {
        "id": "bChWoIMqE37A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Quantum Black Holes*"
      ],
      "metadata": {
        "id": "lzzwwpi2DUGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://news.umich.edu/whats-inside-a-black-hole-u-m-physicist-uses-quantum-computing-machine-learning-to-find-out/"
      ],
      "metadata": {
        "id": "wOwwsajZDeya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://journals.aps.org/pra/abstract/10.1103/PhysRevA.106.062434"
      ],
      "metadata": {
        "id": "61nFnqzMDmaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/pdf/2306.14817.pdf"
      ],
      "metadata": {
        "id": "rF_-dj_fDXoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Quantum High-Energy Physics*"
      ],
      "metadata": {
        "id": "XI4x12wxCMwE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/2307.03236"
      ],
      "metadata": {
        "id": "-Fh0dk8VCRhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Finance*"
      ],
      "metadata": {
        "id": "uxq8EP-8YIIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://scholar.google.com/citations?user=aZTAV7sAAAAJ&hl=es"
      ],
      "metadata": {
        "id": "UZ5_dRnzPCTR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/2210.03210 (Marika): Universal Quantum Speedup for Branch-and-Bound, Branch-and-Cut, and Tree-Search Algorithms"
      ],
      "metadata": {
        "id": "z-XDiS4BPG_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strong presence of JPMorgan Chase & Co.'s Global Technology Applied Research at the American Physical Society March Meeting, premiere annual Physics conference, taking place in Minneapolis, Minnesota this week.  The #quantumcomputing team has eight talks, a poster and an invited keynote presentation:\n",
        "\n",
        "D51.9 \"Parameter Setting in Quantum Approximate Optimization of Weighted Problems.\" Presenter: Shree Hari Sureshbabu\n",
        "F52.4 \"Local Counterdiabatic Driving for Ground State Preparation: Mechanism, Improvement and Implementations.\" Presenter: Changhao Li\n",
        "J00.286 \"Communication-Efficient Blind Quantum Machine Learning with Quantum Bipartite Correlator\" (poster) Presenter: Changhao Li\n",
        "M44.2 \"Revolutionizing the Financial Industry with Quantum Technology\" (invited keynote presentation). Presenter: Marco Pistoia\n",
        "M51.11 \"Evidence of Scaling Advantage for the Quantum Approximate Optimization Algorithm on a Classically Intractable Problem.\" Presenter: Ruslan Shaydulin\n",
        "N49.13 \"The Adjoint is All You Need: Characterizing Barren Plateaus in Quantum Ansätze.\" Presenter: Dylan Herman\n",
        "T49.2 \"Design QAOA by Alignment between Initial State and Mixer for Constrained Optimization.\" Presenter: Zichang He\n",
        "W51.4 \"Expressive Quantum Circuits Provide Inherent Privacy in Federated Learning.\" Presenter: Niraj Kumar\n",
        "Z49.9 Des-q: A Quantum Algorithm to Construct and Efficiently Retrain Decision Trees for Regression and Binary Classification. Presenter: Romina Yalovetzky\n",
        "Z50.4 Fast Simulation of High-Depth QAOA Circuits. Presenter: Danylo Lykov"
      ],
      "metadata": {
        "id": "hQ6qJ6jxTXFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Black Scholar equation - Verasitum: [The trillion dollar equation](https://youtu.be/A5w-dEgIU1M?si=ogNUOUu32tMc1yqr)"
      ],
      "metadata": {
        "id": "QQWiZVRcPUW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantum option pricing via the Karhunen-Loève expansion\n",
        "\n",
        "https://arxiv.org/abs/2402.10132"
      ],
      "metadata": {
        "id": "GcB55l_GH0pD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantum Amplitude Loading for Rainbow Options Pricing\n",
        "\n",
        "https://arxiv.org/abs/2402.05574  In this article, I analyzed T-depth for an optimized quantum amplitude estimation algorithm for fault tolerance purposes."
      ],
      "metadata": {
        "id": "dY3qoEW1-1Va"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantum computing for finance: Overview and prospects: https://www.sciencedirect.com/science/article/pii/S2405428318300571\n",
        "\n",
        "Quantum computing for finance: https://arxiv.org/abs/2307.11230"
      ],
      "metadata": {
        "id": "1J77NPkGfErd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Chemistry*"
      ],
      "metadata": {
        "id": "U2lhywuKYNRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding local ground state minima - Physicists Finally Find a Problem That Only Quantum Computers Can Do**\n",
        "\n",
        "* https://www.quantamagazine.org/physicists-finally-find-a-problem-only-quantum-computers-can-do-20240312/\n",
        "\n",
        "* A team of physicists including John Preskill (left) and Robert Huang recently found a problem that seems to demonstrate the utility of quantum computers: finding the local minimum energy level of a quantum system."
      ],
      "metadata": {
        "id": "uaT64X0W_9jE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 20 molecules for quantum computing: https://pennylane.ai/blog/2024/01/top-20-molecules-for-quantum-computing/\n",
        "\n",
        "Video: [Jennifer Cano: topological quantum chemistry](https://youtu.be/-aSTTyes5jI?si=st1Hq6T-9NNoKRUg)\n",
        "\n",
        "Video: [Aurora Clarke: topology in quantum chemistry applications](https://youtu.be/qSJeynJbmqU?si=EDc99iTdVxG9CY0w)\n",
        "\n",
        "Video: [Hunting for real-world applications of quantum algorithms for chemistry](https://www.youtube.com/watch?v=XOLHX6GfRpQ&list=WL&index=6&t=153s)"
      ],
      "metadata": {
        "id": "y3LZgO4OYNSA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a nice article published by Smik Patel and Artur F. Izmaylov. They basically represent the Hamiltonian as a direct sum of Lie algebras that are solvable by Lie group rotations. Hence, by expressing a given Hamiltonian in this particular sum, one would obtain part of the solution for each term and then sum over all terms.\n",
        "\n",
        "In this work, we applied algebraic methods to develop new decompositions of the electronic Hamiltonian for VQE. The exact solvability of the fragments is based on combining commutativity and anti-commutativity conditions for Pauli products in a way consistent with Lie algebraic structures.\n",
        "These algebraic structures are re-\n",
        "vealed once the Pauli symmetries are measured.\n",
        "The re-\n",
        "sulting effective Hamiltonian is an element of a compact Lie algebra, and can therefore be measured by applying a unitary in the corresponding Lie group.\n",
        "\n",
        "https://arxiv.org/abs/2402.09376"
      ],
      "metadata": {
        "id": "7Uz_YYYhJG-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Drug design on quantum computers**\n",
        "\n",
        "https://www.nature.com/articles/s41567-024-02411-5.epdf?sharing_token=zHOR5chUIybWONl53qDrhtRgN0jAjWel9jnR3ZoTv0OcpAHY5j7t7mFbUik_g16XA-z1Px38QCn1G3MLL9JsVYqVrWPgselGHp1Ic6d4T9pSUKmgAA7nNqILpqVddGlbTM5IwNppWELdl-SOUHOHMtxyqClLPJmo3iym2ACuwyg="
      ],
      "metadata": {
        "id": "F2SYPkFcEAto"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is an ongoing debate about whether quantum computers are ready to help with drug discovery applications or whether useful usage is still a few years away. A group of researchers presents a quantum computing pipeline designed for real-world drug discovery challenges, focusing on two main tasks: determining Gibbs free energy profiles for prodrug activation and simulating covalent bond interactions. They demonstrate the practical application of quantum computing in drug design, specifically targeting the covalent bonding issue, with results showcasing the potential for integrating quantum computing into drug design workflows.\n",
        "\n",
        "https://www.biorxiv.org/content/10.1101/2024.01.08.574600v2"
      ],
      "metadata": {
        "id": "x1-RpnevJW78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Power of Classical Machine Learning*"
      ],
      "metadata": {
        "id": "GZOmqj0cJlVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[A paper](https://www.nature.com/articles/s41467-021-22539-9) by Huang and collaborators at Google Quantum AI underscored that intuition: Classical machine learning algorithms trained with enough quantum data can be computationally powerful enough to model quantum systems.\n",
        "\n",
        "But there was still a problem. These machine learning models were still fundamentally classical, meaning that it’s impossible for them to process truly quantum data and output quantum states. To get around this, Huang and colleagues showed in a [Science paper](https://www.science.org/doi/10.1126/science.abk3333) last year how to use classical shadows to convert quantum information into classical data. They could then train a machine learning model to predict properties of new quantum systems.\n",
        "\n",
        "“The advantage they create is a quantum map between [quantum] inputs and [quantum] outputs, both of which are classical shadows — since you are never going to succeed if it blows up to the full quantum state,” said Jarrod McClean, a computer scientist at Google Quantum AI.\n",
        "\n",
        "https://www.quantamagazine.org/machine-learning-aids-classical-modeling-of-quantum-systems-20230914/"
      ],
      "metadata": {
        "id": "Bpla9sLbFpMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Random Circuit Sampling*"
      ],
      "metadata": {
        "id": "-91jSrDIX7jC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[New Algorithm Closes Quantum Supremacy Window](https://www.quantamagazine.org/new-algorithm-closes-quantum-supremacy-window-20230109/)\n",
        "\n",
        "*Random circuit sampling, a popular technique for showing the power of quantum computers, doesn’t scale up if errors go unchecked.*\n",
        "\n",
        "If you imagine continually increasing the number of qubits as complexity theorists do, and you also want to account for errors, you need to decide whether you’re also going to keep adding more layers of gates — increasing the circuit depth, as researchers say. Suppose you keep the circuit depth constant at, say, a relatively shallow three layers, as you increase the number of qubits. You won’t get much entanglement, and the output will still be amenable to classical simulation. On the other hand, if you increase the circuit depth to keep up with the growing number of qubits, the cumulative effects of gate errors will wash out the entanglement, and the output will again become easy to simulate classically."
      ],
      "metadata": {
        "id": "N_8INTIQe7Dj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "80 qubits: fidelyt decreases"
      ],
      "metadata": {
        "id": "JD-K1jPIy-6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.nature.com/articles/s41586%20019%201666%205\n",
        "\n",
        "* Original experiment from Aaronson: boson sampling. Google: random circuit sampling (RCS). In both it is exponentially hard to compute the output distribution (also for quantum -> limits of quantum computing). But a quantum computer can sample efficiently from this distribution\n",
        "* Challenge: you can‘t go to 80 qubits or so, because then it is impossible for a classical computer to verify. Google used 53 qubits, because then you can at least verify (with 10,000 years on classical computer, doing extrapolation). But this opens the door to spoof the results classically (-> what did aaronson mean by that?)\n",
        "* Google did two things badly:\n",
        "    * They didn‘t properly estimate the 10.000 years on a supercomputer (breaking down and then extrapolate)\n",
        "    * google didn‘t use the best classical algorithm to compare with: later people used tensor networks to speed up the classical calculation and now it‘s down to 1 few seconds.\n",
        "* But this raises a question of what means supremacy: in terms of electrticity usage, quantum is still exponentially better than classical in this example: kilowatt vs megawatt or so\n",
        "* In terms of clockspeed though, classical is equally fast for this expoeriement, because classical computing is highly parallelizable (many operations in parallel)\n"
      ],
      "metadata": {
        "id": "Sie8LRdbgjj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "spoofing: technical term, do something fraudently, how do i know that they ran the computation and got a result?\n",
        "easy to sample random bits from porter thomas distribution.\n",
        "\n",
        "page 3: https://www.cs.cmu.edu/~odonnell/quantum18/lecture25.pdf\n",
        "\n",
        "for RCS we dont have an euqivalent way of verfying this? KL divergence between what it should look like\n",
        "\n",
        "spoofing: clasical ciruti doesnt smiluate, but does anything up to simulaotyon. it can fool a verifyer."
      ],
      "metadata": {
        "id": "U_wyYl8ExRxj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Hidden Subgroup Problem*"
      ],
      "metadata": {
        "id": "g9-cNnkyYxVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hidden subgroup problem**\n",
        "\n",
        "The dihedral hidden subgroup problem https://arxiv.org/abs/2106.09907\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Hidden_subgroup_problem"
      ],
      "metadata": {
        "id": "K5mtRvKj1f07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Examples of HSP over non-Abelian groups](https://www.youtube.com/watch?v=D-pfWjGqENg)\n",
        "\n",
        "* We describe the HSP over symmetric and dihedral groups and their interesting applications.\n",
        "\n",
        "* example 2 graphs A and B: it's not sufficient if they have same number of edges and vertices\n",
        "\n",
        "* it's also important to know if they have the same connectivity (ismorphic): edge 5 and 10 in graph A are connected as well as edge 5 and 10 in graph B\n",
        "\n",
        "* compelixity of graph ismorphism is NP: if you have the solution, it's easy to check if it's true.\n",
        "\n",
        "* Graph automorpphism: you relabel the graph and it looks the same (non trivial besides identity map)\n"
      ],
      "metadata": {
        "id": "idQjSalFVKtn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Hidden Subgroup Problem](https://en.m.wikipedia.org/wiki/Hidden_subgroup_problem) (HSP) generalizes many problems on which quantum computers offer a potential exponential speed-up over classical computers and derives its significance from two important and related questions. First, the study of the problem sheds some light on what it is that quantum computers are really good at. Second, the ability to solve HSP for non-Abelian groups in polynomial time would enable us to extend the set of problems on which quantum computers offer substantial performance advantage. In this introductory talk, I will recap essential concepts from group theory before defining the Hidden Subgroup Problem and describing the quantum algorithm that solves it quickly. I will end by showing how to express a number of well-known problems, such as Simon's problem, discrete logarithm and graph isomorphism, as instances of HSP.\n"
      ],
      "metadata": {
        "id": "X1R28Zo3W95J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Hidden Subgroup Problem (HSP) is a computational problem in the field of quantum computing and cryptography. It is a generalization of the well-known problem called the Discrete Logarithm Problem (DLP) and the Integer Factorization Problem (IFP), which are both important in modern cryptography.\n",
        "\n",
        "In the Hidden Subgroup Problem, the input is a group G and a function f: G -> X, where G is a finite group and X is a finite set. The goal is to find a subgroup H of G such that f(x) is constant for all elements x in the same coset of H. In simpler terms, the problem involves finding a hidden structure within a group based on the information provided by the function.\n",
        "\n",
        "The Hidden Subgroup Problem has important implications in cryptography because certain mathematical problems, such as factoring large numbers, can be reduced to it. If an efficient quantum algorithm were developed to solve the Hidden Subgroup Problem, it would have significant consequences for public-key cryptosystems like RSA and elliptic curve cryptography, which rely on the difficulty of factoring large numbers or solving the DLP.\n",
        "\n",
        "Efforts have been made to find efficient quantum algorithms for solving the Hidden Subgroup Problem, particularly using quantum Fourier transform-based algorithms like Shor's algorithm. However, no general efficient quantum algorithm has been discovered yet for arbitrary groups, although there are some specific cases where efficient algorithms have been developed.\n",
        "\n",
        "The study of the Hidden Subgroup Problem and its related algorithms is an active area of research in quantum computing and cryptography, with the aim of better understanding the limits and possibilities of quantum computing's impact on cryptographic systems."
      ],
      "metadata": {
        "id": "Se1miG3Q2qH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the challenge in the hidden subgroup problem?\n",
        "\n",
        "The main challenge in the Hidden Subgroup Problem (HSP) is to efficiently find the hidden subgroup within a given group based on the information provided by a function. The difficulty lies in identifying the underlying structure or pattern that the function reveals about the subgroup.\n",
        "\n",
        "One of the key aspects that makes the HSP challenging is that the function only provides partial information about the subgroup. The function maps elements of the group to a set of values, but it does not directly reveal the subgroup itself. Instead, the function is designed in such a way that it distinguishes elements of different cosets of the hidden subgroup while keeping elements within the same coset indistinguishable. This limited information makes it difficult to directly extract the subgroup.\n",
        "\n",
        "Another challenge is that the HSP encompasses a wide range of group structures. While some specific cases of the problem have been efficiently solved using quantum algorithms, finding a general solution that works for arbitrary groups remains an open question. The difficulty varies depending on the properties and structure of the group involved.\n",
        "\n",
        "Additionally, the HSP is of particular interest in the field of quantum computing because it has the potential to break certain cryptographic protocols. Efficiently solving the HSP for specific groups could lead to the development of quantum algorithms that can break widely used encryption schemes based on problems like factoring large numbers or solving the Discrete Logarithm Problem.\n",
        "\n",
        "Despite efforts to develop quantum algorithms for the HSP, no general solution has been found yet. The challenge lies in understanding the underlying mathematical structures, devising efficient algorithms, and leveraging the power of quantum computation to solve the problem in a scalable and practical manner."
      ],
      "metadata": {
        "id": "r6qrUX10Wh-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you have a concrete example for a hidden subgroup?\n",
        "\n",
        "\n",
        "Certainly! One of the well-known examples of the Hidden Subgroup Problem involves the symmetric group, denoted as S<sub>n</sub>. The symmetric group consists of all possible permutations of n elements. In this case, the hidden subgroup problem involves finding the hidden subgroup based on the information provided by a function.\n",
        "\n",
        "Let's consider an example with n = 3, where the elements of the symmetric group S<sub>3</sub> are permutations of three objects, let's say {1, 2, 3}. The hidden subgroup problem would involve finding a hidden subgroup within S<sub>3</sub> based on the function f: S<sub>3</sub> -> X, where X is some set.\n",
        "\n",
        "In this scenario, the function f could be defined as follows:\n",
        "f(1, 2, 3) = 'A'\n",
        "f(1, 3, 2) = 'A'\n",
        "f(2, 1, 3) = 'B'\n",
        "f(2, 3, 1) = 'B'\n",
        "f(3, 1, 2) = 'C'\n",
        "f(3, 2, 1) = 'C'\n",
        "\n",
        "Here, the function assigns labels 'A', 'B', and 'C' to certain permutations in S<sub>3</sub>. The goal of the Hidden Subgroup Problem would be to determine the hidden subgroup, which, in this case, corresponds to the permutations that are labeled with the same letter.\n",
        "\n",
        "In this particular example, the hidden subgroup consists of the identity permutation (1, 2, 3), the permutation (2, 1, 3), and the permutation (3, 2, 1). The function f labels these permutations with the letter 'A'. So, the hidden subgroup in this case is { (1, 2, 3), (2, 1, 3), (3, 2, 1) }.\n",
        "\n",
        "The challenge is to find the hidden subgroup based on the given function, which may involve clever algorithms and techniques to deduce the structure of the subgroup from the function's output."
      ],
      "metadata": {
        "id": "8XCw9wUqWk3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What would be a potential algorithm in this case?\n",
        "\n",
        "In the specific case of the Hidden Subgroup Problem (HSP) for the symmetric group S<sub>3</sub> with the given function f: S<sub>3</sub> -> X, there is a known efficient algorithm called the Coset Sampling Algorithm. This algorithm allows us to find the hidden subgroup by exploiting the structure of the symmetric group.\n",
        "\n",
        "The Coset Sampling Algorithm for S<sub>3</sub> proceeds as follows:\n",
        "\n",
        "1. Start with an initial candidate subgroup H = {identity permutation}.\n",
        "2. For each element g in S<sub>3</sub> - H:\n",
        "   a. Compute the coset gH.\n",
        "   b. Apply the function f to each element in the coset gH and record the results.\n",
        "3. Analyze the recorded results to determine if there is a consistent pattern.\n",
        "   a. If the results show that all elements in a coset map to the same value, update H to include the elements of that coset.\n",
        "   b. If the results do not exhibit a consistent pattern, return to step 2 with the next element in S<sub>3</sub> - H.\n",
        "4. Repeat steps 2 and 3 until no new cosets are added to H.\n",
        "5. The final H obtained is the hidden subgroup.\n",
        "\n",
        "In the case of S<sub>3</sub>, the Coset Sampling Algorithm will correctly identify the hidden subgroup { (1, 2, 3), (2, 1, 3), (3, 2, 1) } based on the given function f.\n",
        "\n",
        "It's important to note that the Coset Sampling Algorithm is specific to the symmetric group S<sub>3</sub> and may not generalize to other groups. The Hidden Subgroup Problem for other groups often requires different algorithms and techniques tailored to the specific group's structure."
      ],
      "metadata": {
        "id": "Y38g40y_WosB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you write this as a python function?\n",
        "\n",
        "Certainly! Here's an example of a Python function that implements the Coset Sampling Algorithm for the Hidden Subgroup Problem in the case of the symmetric group S<sub>3</sub>:\n",
        "\n",
        "In this example, the hidden_subgroup_algorithm_S3 function implements the Coset Sampling Algorithm for S<sub>3</sub>. The f parameter represents the given function that maps permutations to certain values. The algorithm iterates through the elements of S<sub>3</sub> and updates the candidate subgroup H based on the function's output until no new cosets are added to H. Finally, the function returns the discovered hidden subgroup.\n",
        "\n",
        "You can run this code to find the hidden subgroup in the provided example function example_function. Feel free to modify the function example_function or provide your own function f to experiment with different scenarios."
      ],
      "metadata": {
        "id": "nixfuFWvWrEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum Speedup in Combinatorial Optimization: the status**\n",
        "\n",
        "A pivotal challenge in quantum information science's ever-evolving realm is designing quantum algorithms that outpace their classical counterparts. A recent experimental observation showcased a superlinear quantum speedup in solving the Maximum Independent Set problem on specific graph instances. This has spurred the development of a comprehensive theoretical framework to compare the performance of quantum adiabatic algorithms and classical Markov chain Monte Carlo algorithms.\n",
        "\n",
        "The Quantum-Classic Conundrum\n",
        "\n",
        "Combinatorial optimization problems, foundational to modern computer science, encompass NP-hard problems that remain elusive to efficient solutions through known algorithms. While classical combinatorial optimization algorithms focus on minimizing a cost function over bit strings, Quantum adiabatic algorithms (QAAs) serve as their quantum analogs, preparing low-energy states of a classical cost Hamiltonian through adiabatic evolution. However, the relative efficacy of QAA and classical counterparts like simulated annealing (SA) remains a topic of debate and exploration.\n",
        "\n",
        "From Theory to Application\n",
        "\n",
        "The recent experimental results, particularly the superlinear speedup observed using a programmable Rydberg atom array, have ignited a renewed interest in this domain. This study presents a theoretical framework that zeroes in on problem instances characterized by flat energy landscapes. Here, the quantum algorithm's performance hinges on the (de)localization of the low-energy eigenstates of the adiabatic Hamiltonian. When these eigenstates are delocalized and the quantum evolution is optimized, the QAA can achieve a significant speedup over classical algorithms like SA.\n",
        "\n",
        "Toward a Quantum Future\n",
        "\n",
        "Building on this foundation, the researchers introduce a modified QAA that showcases a quadratic speedup over SA on specific problem instances. This algorithm employs local Hamiltonians without a sign problem, making them more amenable to quantum Monte Carlo simulations. The study concludes by applying these insights to interpret experimental observations, identifying instances where quantum algorithms either outperform or underperform classical ones due to the localization properties of the low-energy eigenstates.\n",
        "\n",
        "In Summary\n",
        "\n",
        "This work offers a deep dive into the intricate dance between quantum and classical algorithms in the context of combinatorial optimization. Shedding light on the conditions under which quantum algorithms can achieve a speedup paves the way for further advancements in the quantum computing landscape.\n",
        "\n",
        "Link to the publication:\n",
        "\n",
        "https://arxiv.org/pdf/2306.13123.pdf\n"
      ],
      "metadata": {
        "id": "NzA9GTLcVnpW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Categorization of Optimization Problem with different orders of their objective function**\n",
        "* Einführung: [Optimization_problem](https://en.m.wikipedia.org/wiki/Optimization_problem)\n",
        "* **First order**: [Linear optimization](https://en.m.wikipedia.org/wiki/Linear_programming): Many practical problems in [operations research](https://en.m.wikipedia.org/wiki/Operations_research) can be expressed as linear programming problems. See [Simplex_algorithm](https://en.m.wikipedia.org/wiki/Simplex_algorithm)\n",
        "* **Second Order**: [Quadratic optimization (Quadratic programming)](https://en.m.wikipedia.org/wiki/Quadratic_programming): finance (for portfolio optimization), machine learning (for support vector machines), and operations research. Example: In the Markowitz model, the objective function to be minimized is the portfolio variance, which is a quadratic function of the decision variables (asset weights in the portfolio), given the covariance matrix of the returns of the assets.\n",
        "* **Higher Order**: Polynomial optimization problems or non-linear optimization problems (optimize design of a machine part, where the objective function includes terms related to the volume of material used which might be cubic if we're considering three-dimensional parts. Often require more advanced techniques, such as [interior-point methods](https://de.m.wikipedia.org/wiki/Innere-Punkte-Verfahren), branch-and-bound techniques, or heuristic methods."
      ],
      "metadata": {
        "id": "caPGPXRMFtqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Quantum annealing is a quantum computing algorithm that can be used to solve a variety of problems, including NP-hard problems.\n",
        "* However, the efficiency of quantum annealing is limited by the **exponential closing of the spectral gap with increasing system size.**\n",
        "* The spectral gap is a measure of the connectivity of a quantum system. **A large spectral gap means that the system is well-connected, while a small spectral gap means that the system is poorly connected**. The exponential closing of the spectral gap means that the spectral gap decreases exponentially with increasing system size.\n",
        "* This means that quantum annealing becomes exponentially slow for solving NP-hard problems as the system size increases. This is because **the quantum system becomes more and more poorly connected as the system size increases, and it takes longer and longer for the system to reach its ground state**.\n",
        "* There are a number of ways to address the problem of exponential closing of the spectral gap. One approach is to use a technique called adiabatic quantum computation. Adiabatic quantum computation is a variation of quantum annealing that uses a slower annealing schedule. This can help to prevent the spectral gap from closing too quickly.\n",
        "* Another approach to addressing the problem of exponential closing of the spectral gap is to use a technique called quantum error correction. Quantum error correction is a technique that can be used to protect quantum systems from noise. This can help to prevent the quantum system from becoming too poorly connected as the system size increases.\n",
        "* The problem of exponential closing of the spectral gap is a major challenge for quantum annealing. However, there are a number of promising approaches to addressing this problem. As quantum annealing technology continues to develop, it is possible that quantum annealing will become a viable solution for solving NP-hard problems.\n"
      ],
      "metadata": {
        "id": "OzaliSbDGPm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connectivity and Solution Finding in Quantum Annealing**\n",
        "\n",
        "Quantum annealing is a quantum computing technique used to find the minimum value of a given objective function over a defined set of possible solutions. It draws inspiration from classical annealing, a process in which a system is gradually cooled to find its lowest energy state. The hope in quantum annealing is to leverage quantum properties, such as superposition and tunneling, to more efficiently explore the solution space and find the ground state, which represents the minimum of the objective function.\n",
        "\n",
        "Connectivity plays an essential role in this process. Let's understand this with a few key points:\n",
        "\n",
        "1. **Local Minima and Global Minima**: In complex optimization problems, there are often many local minima. Finding the global minimum (or a sufficiently good approximation of it) is the main challenge. High connectivity means that the system can more easily explore the solution space, jumping from one potential solution to another and avoiding getting trapped in local minima.\n",
        "\n",
        "2. **Quantum Tunneling**: One of the primary advantages of quantum annealing over classical annealing is quantum tunneling. Tunneling allows the system to \"pass through\" barriers between states, meaning that the system can more easily escape local minima and move towards the global minimum. If the quantum system's connectivity is low, the benefit from quantum tunneling can be diminished.\n",
        "\n",
        "3. **Effective Exploration of Solution Space**: In a highly connected system, any given qubit (quantum bit) is more likely to interact with many other qubits. <font color=\"blue\">This allows for a richer exploration of the solution space. With fewer connections, the qubits are limited in their interactions, making the exploration less effective.</font>\n",
        "\n",
        "4. **Scaling Issues**: <font color=\"blue\">as the system size increases, maintaining high connectivity becomes more challenging. The difficulty in keeping high connectivity in larger systems is one reason why quantum annealing's efficiency decreases for more complex NP-hard problems</font>. The sparser the connectivity, the less able the system is to effectively leverage quantum effects.\n",
        "\n",
        "5. **Error Correction and Noise**: Highly connected quantum systems can be more susceptible to certain types of errors or noise. So, while high connectivity can aid in the exploration of solution space, it can also introduce challenges in terms of maintaining the coherence and reliability of the quantum information.\n",
        "\n",
        "In summary, high connectivity in quantum annealing is crucial for effectively exploring the solution space, leveraging quantum effects like tunneling, and ensuring the system doesn't get trapped in local minima. As system sizes increase, maintaining this connectivity becomes more challenging, which contributes to the reduced efficiency of quantum annealing for large NP-hard problems."
      ],
      "metadata": {
        "id": "B3FyVDMsHbsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> *Does spectral gap stand in quantum annealing for difference between global and local optimum, or graph connectivity?* For graph connectivity it would be bad to have a small spectral gap, meanhwile for optimum it would be potentially good.\n",
        "\n",
        "*Spectral gap stands for graph connectivity. if that is low, then there are fewer connections in the graph, and that results that it's harder to find the global optimum*"
      ],
      "metadata": {
        "id": "bFO9RXzswtM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Around the same time, it was argued that QA is exponentially slow for solving NP-hard problems due to exponential closing of the spectral gap with increasing system size*\n",
        "https://arxiv.org/pdf/2212.13649.pdf\n",
        "\n",
        "[20]  Jorg, T., Krzakala, F., Kurchan, J. & Maggs, A. Simple glass models and their quantum annealing. Physical review letters 101, 147204 (2008).\n",
        "[21]  Altshuler, B., Krovi, H. & Roland, J. Adiabatic quantum optimization fails for random in- stances of np-complete problems. arXiv preprint arXiv:0908.2782 (2009).\n",
        "\n",
        "*exponential closing of the quantum gap with increasing problem size* https://www.nature.com/articles/s41467-018-05239-9\n",
        "\n",
        "*The efficiency of Adiabatic Quantum Annealing is limited by the scaling with system size of the minimum gap that appears between the ground and first excited state in the annealing energy spectrum. In general the algorithm is unable to find the solution to an optimisation problem in polynomial time due to the presence of avoided level crossings at which the gap size closes exponentially with system size.* https://arxiv.org/pdf/2203.06779.pdf\n",
        "  * A particular problem which has been highlighted is the potential for so called perturbative crossings to form between the low energy eigenstates of the problem Hamiltonian towards the end of the anneal [11, 12]. The corresponding energy gap has been found to be exponentially small with the Hamming distance between the eigenstates, which can generally be expected to grow with the system size [11]."
      ],
      "metadata": {
        "id": "ZpMmh8PMFC_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In quantum annealing, an exponential spectral gap generally presents a challenge** = energy difference between ground state and first excited state is very small. This small gap can make it harder for the quantum annealer to distinguish between the two states, especially when there's noise in the system. \"However, efficiency of quantum annealing is limited by the exponential closing of the spectral gap with increasing system size.\" Problems:\n",
        "  * In order to stay close to ground state throughout annealing process, evolution parameter \\( s \\) or \\( t \\) needs to change very slowly. This can lead to very long quenching times, making annealing process computationally inefficient.\n",
        "  * Thermal Excitations: thermal fluctuations can easily push system out of ground state because energy difference is small. This makes finding the correct solution (the ground state) less likely.\n",
        "  * Small spectral gap implies sensitivity to external noise. Small gap can cause system to be easily perturbed away from desired evolution.\n",
        "  * Techniques and strategies, like optimized annealing schedules or error-correction methods, may be needed to cope with these challenges.\n",
        "* An exponential spectral gap might mean that the first excited state is close to ground state in terms of energy, the implications for solution quality can vary. Depending on the problem, this could mean you have a nearly optimal solution, or it could mean you're still far from the best possible configuration.\n",
        "  1. **Nature of the Problem**: The importance of the energy difference can vary depending on the nature of the problem you're trying to solve. In some optimization problems, even a small energy difference might correspond to a significant difference in solution quality. In others, the difference might be negligible in practical terms.\n",
        "  2. **Many-body Systems**: Quantum annealing is often applied to complex many-body systems. In these systems, the difference in energy between the ground state and the first excited state might correspond to a complex reconfiguration of many particles or spins. So, the \"distance\" between these states in terms of system configuration might be significant even if their energy difference is small.\n",
        "  3. **Landscapes with Many Local Minima**: In complex optimization problems, there can be many local minima (sub-optimal solutions that are better than their immediate neighbors). The presence of an exponential spectral gap might indicate that the system is easily getting trapped in one of these local minima. While the first excited state might be close in energy to the ground state, there might be other states with much higher energies that are also close in terms of the system's configuration.\n",
        "  4. **Goal of Quantum Annealing**: The primary goal of quantum annealing is to find the global minimum (or a very close approximation to it). So, while the first excited state might offer a \"good\" solution, the aim is typically to find the \"best\" solution, especially in problems where small differences can have amplified outcomes.\n",
        "\n"
      ],
      "metadata": {
        "id": "9NOM1t6kumrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Scott Aaronson - Dismantling quantum hype](https://youtu.be/qs0D9sdbKPU)"
      ],
      "metadata": {
        "id": "OuTUAgMok4ts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/@quantum_wa/quantum-annealing-cdb129e96601\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Annealing_(materials_science)"
      ],
      "metadata": {
        "id": "W_qghovmjQpW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kerr and ising gate: non linear gates\n",
        "\n",
        "* The Kerr gate is a gate that introduces nonlinearity into a quantum system. The Kerr gate can be used to implement a variety of quantum operations, such as quantum logic gates and quantum simulations.\n",
        "\n",
        "* The quartic gate is a gate that introduces even higher-order nonlinearity into a quantum system. The quartic gate can be used to implement a variety of quantum operations, such as quantum error correction and quantum machine learning.\n",
        "\n",
        "* The cubic gate is a gate that introduces cubic nonlinearity into a quantum system. The cubic gate can be used to implement a variety of quantum operations, such as quantum cryptography and quantum teleportation."
      ],
      "metadata": {
        "id": "k0Tcx25SAxn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is the Kerr ising model?**\n",
        "\n",
        "\n",
        "The Kerr Ising model (KIM) is a quantum many-body model that combines the features of the Ising model and the Kerr nonlinearity. The Ising model is a classical model of interacting spins, while the Kerr nonlinearity is a quantum effect that describes the interaction of light with matter.\n",
        "\n",
        "The KIM is described by the following Hamiltonian:\n",
        "\n",
        "> $H = -\\sum_{i,j} J_{ij} \\sigma^z_i \\sigma^z_j - \\sum_i \\frac{\\alpha}{2} \\sigma^x_i^2$\n",
        "\n",
        "where $\\sigma^z_i$ and $\\sigma^x_i$ are Pauli matrices that represent the spin of the $i$th qubit, $J_{ij}$ is the Ising coupling strength between the $i$th and $j$th qubits, and $\\alpha$ is the Kerr nonlinearity coefficient.\n",
        "\n",
        "The KIM has been studied in a variety of contexts, including quantum annealing, quantum simulation, and quantum information processing. It has been shown that the KIM can be used to solve certain NP-complete problems, and it can also be used to simulate the dynamics of other quantum many-body systems.\n",
        "\n",
        "Here are some of the key features of the Kerr Ising model:\n",
        "\n",
        "* It is a quantum many-body model that combines the features of the Ising model and the Kerr nonlinearity.\n",
        "* It has been shown to be useful for quantum annealing, quantum simulation, and quantum information processing.\n",
        "* It has been studied in a variety of contexts, including theoretical studies and experimental implementations.\n",
        "\n",
        "The Kerr Ising model is a promising platform for a variety of quantum applications. As our understanding of the model continues to grow, we can expect to see even more exciting applications in the future.\n",
        "\n",
        "https://iopscience.iop.org/article/10.1088/1367-2630/ab7255"
      ],
      "metadata": {
        "id": "SfRYAYFrizmF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is the difference between adiabatic quantum computing and quantum annealing?**\n",
        "\n",
        "Adiabatic quantum computing (AQC) and quantum annealing (QA) are both approaches to quantum computing that use a time-dependent Hamiltonian to solve problems. However, there are some key differences between the two approaches.\n",
        "\n",
        "In AQC, the Hamiltonian is slowly varied from an initial Hamiltonian that is easy to prepare to a final Hamiltonian that encodes the solution to the problem. The system is then allowed to evolve adiabatically, meaning that it remains in its ground state throughout the evolution. This ensures that the system will end up in the ground state of the final Hamiltonian, which is the solution to the problem.\n",
        "\n",
        "In QA, the Hamiltonian is also slowly varied from an initial Hamiltonian to a final Hamiltonian. However, the final Hamiltonian does not necessarily encode the solution to the problem. Instead, the goal of QA is to find the ground state of the final Hamiltonian, which is a global minimum of the energy landscape. This can be useful for solving optimization problems, where the goal is to find the minimum value of a function.\n",
        "\n",
        "Another difference between AQC and QA is that AQC is a universal model of quantum computation, while QA is not. This means that AQC can be used to solve any problem that can be solved by a classical computer, while QA is only able to solve optimization problems.\n",
        "\n",
        "In practice, QA is often used to solve problems that are difficult for classical computers to solve. This is because the adiabatic evolution can help the system to tunnel through energy barriers that would be insurmountable for a classical computer. However, there is still some debate about whether QA is truly a quantum-mechanical phenomenon, or whether it can be explained by classical physics.\n",
        "\n",
        "Here is a table that summarizes the key differences between AQC and QA:\n",
        "\n",
        "| Feature | Adiabatic Quantum Computing | Quantum Annealing |\n",
        "|---|---|---|\n",
        "| Hamiltonian | Varied slowly from an easy-to-prepare initial Hamiltonian to a final Hamiltonian that encodes the solution to the problem. | Varied slowly from an easy-to-prepare initial Hamiltonian to a final Hamiltonian that is a global minimum of the energy landscape. |\n",
        "| Universality | Yes | No |\n",
        "| Applications | Any problem that can be solved by a classical computer | Optimization problems |\n",
        "| Quantum-mechanical phenomenon | Yes | Possibly |\n"
      ],
      "metadata": {
        "id": "AX_5iM-LivWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imaginary time evolution**\n",
        "\n",
        "\n",
        "https://physics.stackexchange.com/questions/557225/why-do-we-use-the-imaginary-time-evolution-in-simulations-of-some-quantum-system\n",
        "\n",
        "Imaginary time is a concept derived from quantum mechanics and statistical mechanics. It introduces the idea of replacing \"real time\" with \"imaginary time\" by a Wick rotation in the complex plane. That is, the time variable 't' is replaced with an imaginary number 'it', where 'i' is the imaginary unit.\n",
        "\n",
        "Imaginary time evolution plays a significant role in several areas of physics, including quantum field theory, statistical mechanics, and quantum computing.\n",
        "\n",
        "1. **Quantum Field Theory and Statistical Mechanics**: In these fields, the use of imaginary time is often a mathematical trick that simplifies calculations. By transforming to imaginary time, the calculations of quantum mechanics often become calculations in statistical mechanics. This is utilized in the technique called \"path integral formulation,\" where the evolution of a system in imaginary time makes the system go to its lowest energy state or the ground state.\n",
        "\n",
        "2. **Quantum Computing**: In quantum computing, the idea of imaginary time evolution can be used to design quantum algorithms for tasks such as finding the ground state of a system. This is used in the Quantum Approximate Optimization Algorithm (QAOA) and the Quantum Imaginary Time Evolution (QITE) algorithm.\n",
        "\n",
        "Remember that \"imaginary time\" is not about time in the sense that we experience it. Instead, it's a mathematical construct that physicists use to solve certain types of problems.\n",
        "\n",
        "Imaginary time is an unphysical, yet powerful, mathematical concept. It has been utilised in numerous physical domains, including quantum mechanics, statistical mechanics and cosmology. Often referred to as performing a ‘Wick rotation’\n",
        "\n",
        "https://www.nature.com/articles/s41534-019-0187-2"
      ],
      "metadata": {
        "id": "yO5fzJsOye7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Quantum Adiabatic Evolution Algorithm Applied to Random Instances of an NP-Complete Problem\n",
        "\n",
        "https://arxiv.org/abs/quant-ph/0104129"
      ],
      "metadata": {
        "id": "dbVdUXkbE4f-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Miscellaneous*"
      ],
      "metadata": {
        "id": "hNQBtp95w2Di"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [Ewin Tang - On quantum linear algebra for machine learning - IPAM at UCLA](https://youtu.be/TFphS0a3JCs?si=w9fj1cRSyGMdrkgV)\n",
        "\n",
        "Video: [Hsin Yuan Huang, Recent Advances in Predicting Properties of Quantum Systems](https://youtu.be/tnxelo56F80?si=gU2FwOMBbxr9kPgy)\n",
        "\n",
        "Video: [Beyond quantum kernel methods with limited circuit architectures (Vedran Dunjko)](https://youtu.be/E1KKLEwQOf4?si=YUoml3H2fI8Xf26r)\n",
        "\n",
        "Video: [Hamiltonian simulation: motivation and problem statement](https://youtu.be/42EedQybld0?si=KyZUQLVZMjllPvVZ)"
      ],
      "metadata": {
        "id": "pr-64awFOdrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hamiltonian Learning\n",
        "\n",
        "\\subsubsection{Hamiltonian Learning}\n",
        "\\label{sec:learning_hamiltonian}\n",
        "\n",
        "\\textit{Hamiltonian learning}: The Goal: Hamiltonian learning is the task of figuring out the Hamiltonian of an unknown quantum system. The Hamiltonian is the operator that dictates the energy of the system, and therefore, governs its dynamics. The Process: You usually perform Hamiltonian learning by: Preparing the system in known states. Letting these states evolve for various time durations. Performing measurements. Using these observations to infer the Hamiltonian. Unitary Dynamics/ Evolution:  The Tool: Unitary evolution is a fundamental tool used within the process of Hamiltonian learning.  Recall that unitary evolution is governed by the equation: $|\\psi(t)\\rangle = e^{(-iHt)} |\\psi(0)$. Here, $H$ is the Hamiltonian, and knowing it allows you to determine how any state $|\\psi (0)|rangle$ evolves over time. The Connection: When performing Hamiltonian learning, you're essentially using the observed unitary evolutions (changes in the state over time) to work backward and learn the Hamiltonian ($H$) that produced those changes. Unitary evolution is the mechanism by which a physical system changes over time. The Hamiltonian is the 'engine' driving that unitary evolution. Hamiltonian learning is the process of figuring out the specifications of that 'engine' by observing the evolution it causes.\n",
        "\n",
        "\n",
        "\\textit{Observables} represent quantities that can be measured in a quantum system (e.g., position, momentum, energy, spin). Expectation values: QML algorithms often aim to estimate expectation values of observables. This could help predict the results of experiments or characterize a quantum system. Measurements: In many algorithms, the final step of a quantum computation is measuring an observable, linked to the problem's solution.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Hamiltonian learning is a process or technique in quantum mechanics and quantum information science. Its purpose is to determine the Hamiltonian of a quantum system. The Hamiltonian is the operator that represents the total energy of the system and dictates how the quantum state evolves over time according to the Schrödinger equation. In Hamiltonian learning, you use various quantum measurements (which can include projective measurements, POVMs, or other types of measurements) and advanced computational techniques to infer the underlying Hamiltonian of a system. This process often involves: Performing Measurements: Collecting data from the quantum system by measuring different observables at different times.\n",
        "Data Analysis: Using algorithms, often based on machine learning or statistical inference, to analyze the measurement results.\n",
        "Model Construction: Building a model of the Hamiltonian that best explains the observed data.\n",
        "\n",
        "The key difference is that Hamiltonian learning is a broader process involving both the act of measurement and the subsequent analysis and modeling to understand the system's dynamics. It's not just a measurement technique but an entire methodology for gaining insight into the fundamental nature of a quantum system. This is crucial in quantum simulation, quantum computing, and quantum control, where accurate knowledge of the Hamiltonian is essential for predicting and manipulating quantum behavior. The Hamiltonian learning problem aims to estimate the unknown underlying Hamiltonian operator of a quantum system. Consider an $n$-qubit Hermitian Hamiltonian $H$ with dimension $d \\times d$ and $d=2^n$, which can be decomposed on the Pauli operator basis as \\eq{hamiltonian} with real coefficients $s_\\alpha$. Here the $\\mathrm{P}^n=$ $\\{I, X, Y, Z\\}^{\\otimes n}$ is the refined Pauli group consisting of $4^n$ Pauli matrices. We label each element therein by a $2 n$-bit string as $\\alpha$ for $P_\\alpha$.\n",
        "\n",
        "\\begin{equation}\\label{eq:hamiltonian}\n",
        "H=\\sum_{P_\\alpha \\in \\mathrm{P}^n} s_\\alpha P_\\alpha\n",
        "\\end{equation}\n",
        "\n",
        "'Hamiltonian learning is an important procedure in quantum system identification, calibration, and successful operation of quantum computers. Through queries to the quantum system, this procedure seeks to obtain the parameters of a given Hamiltonian model and description of noise sources' \\cite{PhysRevResearch.5.033060}. Hamiltonian learning is a part of a broader set of techniques known as quantum characterization, verification, and validation (QCVV). These techniques are essential for the development of reliable and efficient quantum computers and other quantum technologies. By accurately learning the Hamiltonian, researchers can better understand the dynamics of quantum systems, identify sources of noise and decoherence, and improve the design of quantum algorithms and error correction schemes.\n",
        "\n",
        "Hamiltonian learning in quantum computing refers to the process of inferring the parameters of a Hamiltonian (the energy function of a quantum system) through observations and measurements. This is an important task in quantum information science, as the Hamiltonian dictates the evolution of quantum systems and is crucial for understanding, controlling, and manipulating these systems effectively.\n",
        "\n",
        "The process typically involves the following steps: Data Collection: Experimental measurements are taken from a quantum system. These measurements could be, for example, the outcomes of quantum state tomography, where the state of the quantum system is reconstructed at different time points. Model Selection: A theoretical model of the Hamiltonian is proposed. This model includes parameters that need to be estimated. For instance, the model could assume certain types of interactions between qubits or particles in the system. Parameter Estimation: Using the collected data, the parameters of the Hamiltonian model are estimated. This is often done through statistical methods or optimization algorithms. The goal is to adjust the parameters so that the Hamiltonian model best explains the observed data. Validation: The accuracy of the learned Hamiltonian is tested, often by using it to predict the outcome of other experiments and comparing these predictions to actual results.\n",
        "\n"
      ],
      "metadata": {
        "id": "t3FWxbYKhjK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantum Sensing: Atomic Clock from atomkernen https://www.scinexx.de/dossierartikel/atomkern-statt-huelle/\n",
        "\n",
        "https://www.scinexx.de/dossierartikel/licht-statt-mikrowellen/"
      ],
      "metadata": {
        "id": "CmmJSwyw5MUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Locally flat distributions*"
      ],
      "metadata": {
        "id": "DyGjb0ZUwy_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.nature.com/articles/s41598-023-43404-3\n",
        "\n",
        "we use a robust local minima problem to compare state-of-the-art local optimizers (SLSQP, COBYLA, L-BFGS-B and SPSA) against DE using the Variational Quantum Eigensolver algorithm."
      ],
      "metadata": {
        "id": "Wl6tjloxxBNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.quantum.ibm.com/api/qiskit/qiskit.algorithms.optimizers.SLSQP"
      ],
      "metadata": {
        "id": "Mv_PoowCww0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is so interesting aboiut Locally flat distributions and Paulis on quantum computers?**\n",
        "\n",
        "Here's what's interesting about locally flat distributions and Paulis (Pauli operators) in the context of quantum computers, and why they matter:\n",
        "\n",
        "**Locally Flat Distributions**\n",
        "\n",
        "* **Noise Representation:** Locally flat distributions are used to model a particular type of noise in quantum circuits. This noise has the property that small errors become much more likely than large errors. Locally flat distributions capture this behavior.\n",
        "* **Error Correction and Threshold Theorems:** Understanding the properties of locally flat distributions plays a role in the development of quantum error correction codes.  Importantly, they are connected to the idea of fault-tolerance thresholds – limits on error rates below which quantum computation can be made reliable.\n",
        "* **Simulation and Analysis:** Studying locally flat distributions helps researchers design and analyze quantum algorithms that are robust to this specific type of noise.\n",
        "\n",
        "**Paulis (Pauli Operators)**\n",
        "\n",
        "* **Fundamental Building Blocks:** The Pauli operators (X, Y, Z) together with the identity operator (I) form a basis for the space of operators on a single qubit.  This means any operation on a single qubit can be expressed as a combination of Paulis.\n",
        "* **Error Representation:** Many common quantum errors can be represented as combinations of Pauli operators acting on qubits. This makes them convenient for describing noise processes\n",
        "* **Qubit Control:**  Pauli operators are used as quantum gates to manipulate the state of qubits, forming the essential toolkit for quantum computation.\n",
        "\n",
        "**Where They Intersect**\n",
        "\n",
        "* **Describing Noise with Paulis:** Locally flat noise distributions can often be well-described in terms of probabilistic combinations of Pauli errors.  This connection helps analyze how such noise affects quantum circuits.\n",
        "* **Error Correction Tailored to Paulis:** Quantum error-correcting codes can be specifically designed to combat Pauli errors, which are a common type of noise. Understanding the relationship between Paulis and noise distributions helps in creating more effective codes.\n",
        "* **Efficient Simulation:** Certain simulation techniques, such as stabilizer circuit simulations, heavily exploit the structure of Pauli operators to efficiently simulate specific classes of quantum circuits.\n",
        "\n",
        "**In Summary**\n",
        "\n",
        "Locally flat distributions and Paulis provide a framework to model, analyze, and mitigate the effects of noise in quantum computers. Understanding their connection enables the design of more resilient quantum algorithms and the development of robust error-correction schemes that are crucial for the advancement of practical quantum computing.\n",
        "\n",
        "**Let me know if you'd like to dive deeper into any of these aspects, such as quantum error correction codes, noise modeling, or stabilizer circuits!**\n"
      ],
      "metadata": {
        "id": "yB16-W-bwYg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is low degree truncation in quantum computing?**\n",
        "\n",
        "Here's an explanation of low-degree truncation in quantum computing, its uses, and its significance:\n",
        "\n",
        "**What is Low-Degree Truncation?**\n",
        "\n",
        "Low-degree truncation is a technique used in quantum computing to simplify calculations involving complex quantum systems. It involves approximating a system's Hamiltonian (the operator that describes its energy) by keeping only the terms with low-degree polynomials.\n",
        "\n",
        "**How It Works**\n",
        "\n",
        "1. **Hamiltonian Representation:**  The Hamiltonian of a quantum system can often be expressed as a sum of terms involving products of Pauli operators (X, Y, Z).  Each term has a degree determined by the number of Pauli operators in the product (e.g., the term XY has degree 2).\n",
        "\n",
        "2. **Truncation:** In low-degree truncation, you keep only the terms in the Hamiltonian up to a certain degree and discard the higher-degree terms. This simplifies the representation and makes calculations more manageable.\n",
        "\n",
        "**Why Use Low-Degree Truncation**\n",
        "\n",
        "* **Computational Complexity:** Simulating complex quantum systems on classical computers can be extremely computationally expensive. The number of terms in the Hamiltonian grows exponentially with the size of the system. Low-degree truncation reduces this complexity.\n",
        "* **Focus on Essential Interactions:** In many systems, the essential physics is often captured by the low-order interactions. Truncating higher-order terms may introduce some error but often provides a good approximation while significantly simplifying the calculations.\n",
        "* **Resource Limitations:** Quantum computers themselves have a limited number of qubits and limited gate depth they can apply. Low-degree truncation can make problems more amenable to simulation on near-term quantum devices.\n",
        "\n",
        "**Applications**\n",
        "\n",
        "* **Quantum Chemistry Simulations:** Low-degree truncation is used in simulating the electronic structure of molecules. This helps understand chemical reactions and design new materials.\n",
        "* **Material Science:**  It's used in simulations of materials to predict their properties, aiding in the discovery of new materials with tailored characteristics.\n",
        "* **Quantum Optimization:**  Some quantum optimization algorithms are amenable to low-degree truncation, making it possible to approximate solutions to complex optimization problems.\n",
        "\n",
        "**Significance**\n",
        "\n",
        "Low-degree truncation is a powerful tool for making quantum simulations more tractable, especially when dealing with large or complex systems. However, there's a trade-off:\n",
        "\n",
        "* **Accuracy vs. Efficiency:**  Truncation introduces errors, so it's important to balance accuracy requirements with computational efficiency when choosing the degree of truncation.\n",
        "\n",
        "**Example**\n",
        "\n",
        "Consider a Hamiltonian with terms like X, Y, Z, XY, XZ, YZ, XYZ.  A low-degree truncation at degree 2 would only keep the terms X, Y, Z, XY, XZ, and YZ, and discard the XYZ term.\n",
        "\n",
        "**Let me know if you would like to explore any specific application of low-degree truncation in more detail!**\n"
      ],
      "metadata": {
        "id": "FrqzVdYqwaWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is the Depolarizing channel in each qubit?**\n",
        "\n",
        "Here's a breakdown of the depolarizing channel in quantum computing, including how it works and its significance:\n",
        "\n",
        "**What is the Depolarizing Channel?**\n",
        "\n",
        "* **Definition:** The depolarizing channel is a type of quantum channel (a mathematical model of how quantum states evolve) that introduces noise into a qubit (the basic unit of quantum information).  It does this by effectively shrinking the Bloch sphere representation of the qubit's state.\n",
        "* **Behavior:** With a probability `p`, the depolarizing channel replaces the input qubit with the completely mixed state (a state of maximum uncertainty). With the remaining probability `(1-p)`, the qubit is left unchanged.\n",
        "* **Effect:** The depolarizing channel introduces randomness, making it harder to reliably store and process quantum information.\n",
        "\n",
        "**Mathematical Representation**\n",
        "\n",
        "The depolarizing channel can be represented mathematically using the Kraus operator-sum representation:\n",
        "\n",
        "```\n",
        "ℰ(ρ) = (1-p) ρ + p/3 (XρX + YρY + ZρZ)\n",
        "```\n",
        "\n",
        "Where:\n",
        "\n",
        "* `ρ` is the input density matrix (representing the qubit's state).\n",
        "* `p` is the depolarization probability.\n",
        "* `X`, `Y`, and `Z` are the Pauli matrices (basic quantum gates).\n",
        "\n",
        "**Geometric Interpretation**\n",
        "\n",
        "The depolarizing channel can be visualized as shrinking the Bloch sphere (a geometric representation of a qubit's state):\n",
        "\n",
        "* The completely mixed state is represented by the center of the Bloch sphere.\n",
        "* The depolarizing channel moves the qubit's state closer to the center, shrinking its representation on the Bloch sphere.\n",
        "* The stronger the depolarization (higher `p`), the more the Bloch sphere shrinks.\n",
        "\n",
        "**Significance**\n",
        "\n",
        "* **Modeling Noise:** The depolarizing channel is a useful model for representing realistic noise in quantum systems.  Real-world qubits interact with their environment, leading to decoherence that is often well-approximated by a depolarizing channel.\n",
        "* **Error Correction:** Understanding the depolarizing channel is crucial for designing quantum error correction codes. These codes help protect quantum information from the effects of noise.\n",
        "* **Capacity Limits:** The depolarizing channel affects the capacity of a quantum communication channel, which limits the amount of information that can be reliably transmitted.\n",
        "\n",
        "**Example**\n",
        "\n",
        "Suppose you have a qubit in the pure state |0⟩. If it passes through a depolarizing channel with probability `p = 0.25`, the output state would be:\n",
        "\n",
        "```\n",
        "(1 - 0.25) |0⟩⟨0| + 0.25/3 (I/2) = 0.75 |0⟩⟨0| + 0.083 I\n",
        "```\n",
        "\n",
        "This is a mixed state, indicating a loss of quantum information.\n",
        "\n",
        "**Let me know if you would like a deeper dive into any of these aspects or have a specific application in mind!**\n"
      ],
      "metadata": {
        "id": "3J6s2aTawcbX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Quantum hadamrd test](https://youtu.be/F98jpHBQPys?si=_pH2ozWfJjwL7Ap5)\n",
        "\n",
        "[Algebra of pauli matrices](https://youtu.be/Gj9iezP89Dk?si=w_6P8vH3ONLq1a8L)\n",
        "\n"
      ],
      "metadata": {
        "id": "4zPmw5k95FR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://phys-org.cdn.ampproject.org/c/s/phys.org/news/2024-02-magnesium-tantalum-material-qubits.amp"
      ],
      "metadata": {
        "id": "CeWSjnS5DjD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www-insidequantumtechnology-com.cdn.ampproject.org/c/s/www.insidequantumtechnology.com/news-archive/news-from-infleqtion-inertial-sensors-atomic-clocks-rf-receivers-oh-and-1600-qubits-by-brian-siegelwax/amp/"
      ],
      "metadata": {
        "id": "ObzMgs60-XB4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://thequantuminsider.com/2024/02/07/quantum-matters-quantum-ai-early-days-for-a-killer-combination/\n",
        "\n",
        "https://arxiv.org/abs/2402.03871: Geometric quantum machine learning of BQP^A protocols and latent graph classifiers\n",
        "\n",
        "https://www.spektrum.de/news/revolutioniert-die-fusion-von-ki-und-quantenphysik-die-wissenschaft/2203074"
      ],
      "metadata": {
        "id": "UN-M-61Vhj1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Daniel Sank: The superconducting transmon qubit as a microwave resonator](https://www.youtube.com/watch?v=dKTNBN99xLw&list=WL&index=7&t=2329s)\n",
        "\n",
        "[Quantum Industry Talks: Quantum computing hardware](https://www.youtube.com/watch?v=eyICn3KCUPI&list=WL&index=6&t=2000s)"
      ],
      "metadata": {
        "id": "nKydZaFIbSqo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Course 3: How to build a quantum network/ Hardware perspective](https://youtu.be/iGdbROJfmiw?si=v7Bi6FIfY01Dobrd)\n",
        "\n",
        "[Course 4: How to build a quantum network/ Theory perspective](https://youtu.be/pZJVU_60Gd8?si=LLIgpDalf4eLx_ps)"
      ],
      "metadata": {
        "id": "TYad4CPW-EfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hamiltonian simulation and Trotterization: https://vtomole.com/blog/2019/04/07/trotter"
      ],
      "metadata": {
        "id": "1RO_b38EmEgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.golem.de/news/militaer-erfolgreiche-demonstration-von-quanten-funkkommunikation-2401-181120.amp.html"
      ],
      "metadata": {
        "id": "q8fwKeBZlQ8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pending:**\n",
        "\n",
        "* [Robert Huang: Fundamental aspects of solving quantum problems with machine learning\n",
        "](https://www.youtube.com/watch?v=VazUK13iwpQ&list=WL&index=5&t=936s)\n",
        "\n",
        "* [Vedran Dunjko - Building the case for Quantum Machine Learning](https://www.youtube.com/watch?v=td3jfKxT5TI&list=WL&index=7&t=2795s)\n",
        "\n",
        "* [Vedran Dunjko - Exponential separations between classical and quantum learners - IPAM at UCLA](https://www.youtube.com/watch?v=IlEixl4mq0o&list=WL&index=5&t=163s)\n",
        "\n",
        "* [Markus Müller - Topological Quantum Error Correction: From Theoretical Concepts to Experiments](https://www.youtube.com/watch?v=tbrTOemjxow&t=11s)\n",
        "\n",
        "* [Xanadu PennyLane Quantum Computing Training - 2023 NUG Annual Meeting](https://www.youtube.com/watch?v=gJUBBZIq8zo&list=WL&index=4&t=4450s)\n",
        "\n",
        "*Applied Reviews*\n",
        "\n",
        "* [A Look Back at 2023 and Quantum Predictions for 2024](https://www.youtube.com/watch?v=ORhwzlDHdy8&list=PLBn8lN0DcvpmcGQ1H_9YMFPew1ZsP_8Sj&index=3&t=2742s)"
      ],
      "metadata": {
        "id": "UvrswVv2QT7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NISQ and LISQ**\n",
        "\n",
        "https://dabacon.org/pontiff/2024/01/03/acronyms-beyond-nisq/\n",
        "\n",
        "https://www.linkedin.com/pulse/bye-nisq-hello-lisq-simone-severini-ybkmc"
      ],
      "metadata": {
        "id": "OzwFAIepZQMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Encoding and QSVT**\n",
        "\n",
        "* [Pennylane: Intro to QSVT](https://pennylane.ai/qml/demos/tutorial_intro_qsvt/#transforming-matrices-encoded-in-matrices)\n",
        "\n"
      ],
      "metadata": {
        "id": "f-mVvct2q9g5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experimental advantage in learning with noisy Quantum memory - Quantum Summer Symposium 2021**\n",
        "\n",
        "* Video: [Experimental advantage in learning with noisy Quantum memory - Quantum Summer Symposium 2021](https://www.youtube.com/watch?v=GEgJkqQNwvQ&list=WL&index=1)\n",
        "\n",
        "*details used for QML book"
      ],
      "metadata": {
        "id": "OgCGvQeGkFtM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> $f(x)=\\left\\langle 0\\left|U_0^{\\dagger}(x)   U_0(x)\\right| 0\\right\\rangle=\\left\\langle x| x\\right\\rangle$\n",
        "\n",
        "The given expression $f(x)=\\left\\langle 0\\left|U_0^{\\dagger}(x)   U_0(x)\\right| 0\\right\\rangle=\\left\\langle x|x\\right\\rangle$ represents the **squared norm of the quantum state |x⟩**. The squared norm of a quantum state is a measure of its overall size or amplitude. It is calculated by taking the inner product of the state with itself.\n",
        "\n",
        "Let's break down the expression:\n",
        "\n",
        "* **⟨0|:** This denotes the inner product of the vacuum state |0⟩ with itself. The vacuum state is the state with no particles, and it has unit norm.\n",
        "\n",
        "* **U_0^{\\dagger}(x):** This is the conjugate transpose of the identity operator I0, which is a unitary operator that acts as the identity on the vacuum state. The conjugate transpose is a common operation in quantum mechanics, and it relates the action of an operator on a quantum state to its action on the dual state.\n",
        "\n",
        "* **U_0(x):** This is the identity operator I0. The identity operator is a unitary operator that does not change the state of a quantum system. It is the simplest and most fundamental unitary operator.\n",
        "\n",
        "* **|0⟩:** This is the vacuum state |0⟩. The vacuum state is the state with no particles, and it has unit norm.\n",
        "\n",
        "* **⟨x|x⟩:** This denotes the inner product of the state |x⟩ with itself. The inner product of two quantum states is a measure of their overlap. It is calculated by taking the dot product of their corresponding complex vectors.\n",
        "\n",
        "Putting everything together, the expression $f(x)=\\left\\langle 0\\left|U_0^{\\dagger}(x)   U_0(x)\\right| 0\\right\\rangle=\\left\\langle x|x\\right\\rangle$ represents the squared norm of the quantum state |x⟩. It is a scalar quantity that indicates the overall size or amplitude of the state.\n"
      ],
      "metadata": {
        "id": "Fkcx5erfdR5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variational Circuits and Parameter-Shift Rule - Part 1**\n",
        "\n",
        "* Video: [Parameter--Shift Rule Derivation — Part 1 | PennyLane Tutorial](https://www.youtube.com/watch?v=crgmwXBogx4&list=PLzgi0kRtN5sO8dkomgshjSGDabnjtjBiA&index=5)\n",
        "* https://pennylane.ai/qml/glossary/parameter_shift/#gaussian-gate-example-\n",
        "* Also see: [Automatic Differentiation of Quantum Circuits](https://www.youtube.com/watch?v=McgBeSVIGus&t=1s)\n",
        "* Also see: [Parameter Shift Rule for calculation of Gradients in Quantum Variational Circuits](https://www.youtube.com/watch?v=yJriVOy5l_8&list=WL&index=1&t=6s)\n",
        "* Represent certain expectation values with Fourier series, important to derive some parameter shift rules in order to compute quantum gradients\n",
        "* Fourier representation is also useful to expressivity of certain quantum models\n",
        "* **We are computing the expectation value <font color=\"green\">$E(x)$</font> of operator <font color=\"red\">$B$</font> such that we have a quantum state $\\psi$ which is evolved by some unitary <font color=\"blue\">$U(x)$</font>**\n",
        "\n",
        "> <font color=\"green\">$E(x)$</font> $=\\langle\\psi|$ <font color=\"blue\">$U^{\\dagger}(x)$</font> <font color=\"red\">$B$</font> <font color=\"blue\">$U(x)$</font> $| \\psi\\rangle$\n",
        "\n",
        "This kind of expression is common in quantum computing and quantum mechanics, **where it's used to calculate the expected outcomes of various quantum operations**, which are critical for understanding how quantum algorithms will behave.\n",
        "\n",
        "**How to solve this? $E(x) =\\langle\\psi| U^{\\dagger}(x) B U(x) | \\psi\\rangle$**\n",
        "\n",
        "* Two main approaches to calculating the eigenvalues of a Hermitian operator B:\n",
        "  1. **Diagonalization:** This method involves finding an orthonormal basis of eigenvectors of B. The eigenvalues of B are then the corresponding eigenvalues of the Hermitian matrix representing B in this basis.\n",
        "  2. **Eigenvalue Solvers:** There are various numerical methods for calculating eigenvalues of Hermitian operators, such as the Rayleigh-Ritz quotient, the Lanczos algorithm, and the Arnoldi algorithm. These methods can be used to calculate eigenvalues for large Hermitian matrices that cannot be diagonalized directly.\n",
        "* In the case of $E(x) =\\langle\\psi| U^{\\dagger}(x) B U(x) | \\psi\\rangle$, the observable B is sandwiched between the unitary operator $U(x)$ and its conjugate transpose $U^{\\dagger}(x)$.\n",
        "* This means that $B$ can be expressed as a combination of powers of $U(x)$ and $U^{\\dagger}(x)$. **If we can find the eigenvalues of this combination of operators $U(x)$ and $U^{\\dagger}(x)$, then we can calculate the eigenvalues of $E(x)$**.\n",
        "  * One way to achieve this is to use a diagonalization method - accurate and but computational expensive. This involves finding a suitable basis for the Hilbert space of quantum states, and representing U(x) and U^{\\dagger}(x) in this basis. The eigenvalues of B can then be calculated by diagonalizing the matrix representing B in this basis.\n",
        "  * Another approach is to use an eigenvalue solver - efficient, but not super accurate. This involves choosing an appropriate numerical method, and applying it to the matrix representing B in the basis defined by U(x) and U^{\\dagger}(x). The eigenvalues of B can then be calculated by using the numerical method.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_89dYYPMwz0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variational Circuits and Parameter-Shift Rule - Part 2**\n",
        "\n",
        "(same video, continuation, [Parameter--Shift Rule Derivation — Part 1 | PennyLane Tutorial](https://www.youtube.com/watch?v=crgmwXBogx4&list=PLzgi0kRtN5sO8dkomgshjSGDabnjtjBiA&index=5)\n",
        ")\n",
        "\n",
        "* <font color=\"blue\">$U(x) = e^{ixG}$</font>\n",
        "* <font color=\"orange\">$G$</font> = hermitian operator <font color=\"orange\">$G^{\\dagger}$ = $G$</font> is called the **generator** of the operator $U$ (e.g. the generator of a Y rotation gate is the Pauli Y gate with a factor of $-\\frac{1}{2}$\n",
        "\n",
        "Eigenvalues and Eigenstates of <font color=\"orange\">$G$</font>, denoted by some $\\omega_j$. We create set out of these eigenvalues, ordered in non-descending order. j is from e, which is defined as set of positive integers from 1 to d\n",
        "\n",
        "> Eigenvalue: <font color=\"orange\">$\\left\\{\\omega_j\\right\\}_{j \\in[d]}$ $\\quad$ with $[d]:=\\{1, \\cdots, d\\}$\n",
        "\n",
        "> Eigenequation: <font color=\"orange\">$G\\left|\\varphi_j\\right\\rangle=\\omega_j\\left|\\varphi_j\\right\\rangle$\n",
        "\n",
        "Eigenvalues and Eigenstates of <font color=\"blue\">$U(x)$</font>:\n",
        "\n",
        "> Eigenvalue: <font color=\"blue\">$\\left\\{e^{i x \\omega_j}\\right\\}_{j \\in[d]}$ $\\quad$ with $[d]:=\\{1, \\cdots, d\\}$\n",
        "\n",
        "> Eigenstate: <font color=\"blue\">$|\\varphi_j\\rangle_{j \\in[d]}$\n",
        "\n",
        "> Eigenequation: <font color=\"blue\">$U(x)\\left|\\varphi_j\\right\\rangle=e^{i x \\omega_j}\\left|\\varphi_j\\right\\rangle$\n",
        "\n",
        "Two more definitions:\n",
        "\n",
        "> $\\psi_j := \\left\\langle\\varphi_j \\mid \\psi\\right\\rangle$\n",
        "\n",
        "> $b_{j k} := \\left\\langle\\varphi_j|B| \\varphi_k\\right\\rangle$ with $j, k \\in[d]$\n",
        "\n",
        "Now we can re-express the expectation value <font color=\"green\">$E(x)$</font> by expanding each of these terms in the multiplication in the Eigenbasis of the unitary <font color=\"blue\">$U(x)$</font>:\n",
        "\n",
        "> $\\begin{gathered}E(x)=\\sum_{j, k=1}^d \\psi_j^*\\left[e^{i x \\omega_j}\\right]^* b_{j k} e^{i x \\omega_k} \\psi_k \\\\ \\psi_j=\\left\\langle\\varphi_j \\mid \\psi\\right\\rangle \\\\ b_{j k}=\\left\\langle\\varphi_j|B| \\varphi_k\\right\\rangle\\end{gathered}$"
      ],
      "metadata": {
        "id": "156UXYtVzz68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variational Circuits and Parameter-Shift Rule - Part 3**\n",
        "\n",
        "Video: [QHack 2021: Maria Schuld—Quantum Differentiable Programming](https://www.youtube.com/watch?v=cwiINWkMOvA)\n",
        "\n",
        "Are there QML problems that are proven to be superior to CML? - Yes, there are certain problems superior on QML, but none are useful. Useful QML problems with exponential separation to CML are still an open question.\n",
        "\n",
        "What model class is QML? How can it generalize? Let's describe what it is, before we look into concrete cases with only exponential speedups.\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1685.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1686.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1687.png)\n"
      ],
      "metadata": {
        "id": "STeAmaKnzi8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum Chemistry**\n",
        "* Video: [Introduction to Quantum Chemistry | PennyLane Tutorial](https://www.youtube.com/watch?v=khC0CCjxB7k&list=WL&index=11)\n",
        "* See also: [Aurora Clark (3/10/20): Topology in chemistry applications](https://www.youtube.com/watch?v=qSJeynJbmqU&list=WL&index=12&t=1252s)\n",
        "* Predict properties of materials\n",
        "* What chemical reactions can happen under certain circumstances\n",
        "* Molecular orbitals of electrons: how to represent them with qubits? With Jordan Wigner representation\n",
        "* Hamiltonian operator (all interactions and movements) important to know the energy levels occupied by the electrons in order to predict accurately the chemical properties of the molecules\n",
        "* Hamiltonian operator = all interactions and movements -> too complicated, so we approximate: Hartree Fock approximation\n",
        "    * Calculates molecular geometry (positions where the atomic nuclei are)\n",
        "    * Then calculate hamiltonian\n",
        "* **Jordan Wigner representation**\n",
        "  * https://learn.microsoft.com/en-us/azure/quantum/user-guide/libraries/chemistry/concepts/jordan-wigner\n",
        "  * https://en.m.wikipedia.org/wiki/Jordan–Wigner_transformation\n",
        "  * https://www.cond-mat.de/events/correl21/manuscripts/koch.pdf"
      ],
      "metadata": {
        "id": "Z6d3CddIw4Ph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variational Quantum Algorithms**\n",
        "* Video: [Variational Quantum Algorithms](https://www.youtube.com/watch?v=YtepXvx5zdI&t=21s)\n",
        "* Contains **Great images of model types etc)**\n",
        "* https://pennylane.ai/qml/glossary/variational_circuit/\n",
        "* Also known as: parametrized quantum circuits, quantum neural networks\n",
        "* example: VQE (variational quantum eigensolver) for chemistry problems or QAOA for optimization and many more\n",
        "* Variational quantum circuits are already hybrid models"
      ],
      "metadata": {
        "id": "Ezjnw5L2w_ro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hybrid Quantum-Classical Machine Learning**\n",
        "* Video: [Hybrid Quantum-Classical Machine Learning](https://www.youtube.com/watch?v=t9ytqPTij7k)\n",
        "* * Variational quantum circuits are already hybrid models\n",
        "* Backprop:\n",
        "  * treat the quantum circuit as a basic atomic individual step in the computation graph.  \n",
        "  * the expectation value of a quantum circuit is a differentiable function.\n",
        "  * So if we treat that single expectation value as a single step, we can use the parameter shift rule to determine the gradient of that same function.\n",
        "  * Means: we can feed that to the backprop algorithm."
      ],
      "metadata": {
        "id": "gD0Zvm95xCNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizing a quantum circuit with PennyLane | PennyLane Tutorial**\n",
        "* Quantum circuit is a function. Think of quantum circuit as cost function and measurement will be the cost -> useful for finding minimum in optimization or ground state in chemistry.\n",
        "* Video: [Optimizing a quantum circuit with PennyLane | PennyLane Tutorial](https://www.youtube.com/watch?v=42aa-Ve5WmI)\n",
        "* https://docs.pennylane.ai/en/stable/introduction/interfaces.html\n"
      ],
      "metadata": {
        "id": "xzAcWeX8xT3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Beyond-classical computing, Sergio Boixo**\n",
        "* Video: [Beyond-classical computing, Sergio Boixo](https://www.youtube.com/watch?v=cGaULUQuu1A&list=WL&index=1&t=1147s)\n",
        "* Sample problem, approximate from a sample distribution\n",
        "* Experimental Random Circuit Sampling (RCS)"
      ],
      "metadata": {
        "id": "iBn3SNx_w9qT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to solve the QUBO problem | PennyLane Tutorial**\n",
        "\n",
        "* Video: [How to solve the QUBO problem | PennyLane Tutorial](https://www.youtube.com/watch?v=LhbDMv3iA9s&t=212s)"
      ],
      "metadata": {
        "id": "M72_rlVX5fsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Haar Measure | PennyLane Tutorial**\n",
        "\n",
        "* Video: [The Haar Measure | PennyLane Tutorial](https://www.youtube.com/watch?v=d4tdGeqcEZs)\n"
      ],
      "metadata": {
        "id": "QkYxR2W-5p8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Physical simulation through a quantum computational lens, Jarrod McClean**\n",
        "\n",
        "* Video: [Physical simulation through a quantum computational lens, Jarrod McClean](https://www.youtube.com/watch?v=-8fYbDwLAug&list=WL&index=2&t=383s)\n",
        "\n",
        "* What we mean with quantum chemistry simulation: we want some amount of understanding if the system. Like learn interesting things, like will a system absorb light and why? How often will it show up?\n",
        "\n",
        "* The predictive power of (free) energies: Can all physically interesting questions be answered by some reduced model? Recent, but there are undecidable, there can't be an algorithm that determines the answer:\n",
        "  * Does a system thermalize?\n",
        "  * Does a system have an electronic gap?\n",
        "  * Will molecule X ever form from constituents Y?\n",
        "\n",
        "* qualitative changes that can't be predicted ahead of time: proteins, RNA/DNA\n",
        "\n",
        "* Physical undecidability - as the system evolves in time, there are sudden, qualitative changes that cannot be predicted in any way except evolving forward in time and seeing if it happened, and no answer in finite time can indicate if it will never happen (for all systems).\n",
        "\n",
        "> Undecidability formally broken by advice in some cases - and data is a restricted form of advice!\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1688.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1689.png)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A5K4X-OB5RiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Jarrod McClean - The role of data, precomputation, and communication in a quantum learning landscape**\n",
        "\n",
        "* Video: [Jarrod McClean - The role of data, precomputation, and communication in a quantum learning landscape](https://www.youtube.com/watch?v=dOUppTONVDM&list=WL&index=8&t=819s)\n",
        "\n",
        "* Quantum data is interesting for future discovery of the universe (recall the impact of CCD cameras on telescopes - see\n",
        "\"The Perfect Theory\"), but most data we work with today, even from quantum systems, seems classical.\n",
        "\n",
        "* There are a few pieces of evidence that QC might help for classical data (sampling hard distributions, learning problems based on discrete log, linear algebra routines, ...) but a lot of pieces of evidence that it will be hard to achieve in practice\n",
        "\n",
        "* Question - What is the full class of uniquely quantum pre-computations we can do to accelerate time to solution?\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1690.png)\n"
      ],
      "metadata": {
        "id": "pDVzhkBUBGja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color=\"blue\">**Quantum Algorithms**"
      ],
      "metadata": {
        "id": "LRIi-9lWbiAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Algorithms*"
      ],
      "metadata": {
        "id": "fSOCv2LsgeIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Fourier Transform*"
      ],
      "metadata": {
        "id": "AXGHc7oUfx_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Momentum Space and Position Space with Quantum Fourier Transform\n",
        "\n",
        "https://youtu.be/W8QZ-yxebFA"
      ],
      "metadata": {
        "id": "9wrzQ3norW5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Quantum Fourier Transform is the change from one basis (computational) to another (Fourier basis)**\n",
        "\n",
        "* Quantum Fourier Transform is the inverse Discrete Fourier Transform)\n",
        "\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_047.png)\n",
        "\n",
        "**General formula**\n",
        "\n",
        "* Remember: <font color=\"blue\">$e^{2\\pi i}$ = 1</font> (identity operation), and see why $e^{\\pi i}$ = -1 in [this video](https://youtu.be/-AyE1Wpgo3Q)\n",
        "\n",
        "\n",
        "* In QFT we change the <font color=\"blue\">$\\theta$ = phase in $e^{2\\pi i \\theta}$</font> = Eigenvalue of Oracle function $U$ associated with an eigenvector |u⟩\n",
        "\n",
        "* The phase $\\theta$ is expressed as: <font color=\"blue\">$\\theta$ = $\\frac{x_n}{2^{k_n}}$</font> with:\n",
        "\n",
        "  * <font color=\"blue\">$x_n$ = 0 or 1</font> state\n",
        "\n",
        "  * <font color=\"blue\">$k_n$</font> number of Qubits\n",
        "\n",
        "* This is expressed in a so-called \"controlled-R quantum gate\" that **applies a relative phase change to |1>**\n",
        "\n",
        "* The matrix form of this operator is: <font color=\"blue\">$\\hat{R}_{k}=\\left(\\begin{array}{cc}1 & 0 \\\\ 0 & e^{2 \\pi i \\frac{x_n}{ 2^{k_n}}}\\end{array}\\right)$</font>"
      ],
      "metadata": {
        "id": "I_dkpT8Cdvyt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Quantum Fourier Transform with 3 Qubits: Introduction*\n",
        "\n",
        "**Computational Basis States:** <font color=\"blue\">$\\tilde{x_1}$ = 0 or 1</font>, <font color=\"blue\">$\\tilde{x_2}$ = 0 or 1</font>, <font color=\"blue\">$\\tilde{x_3}$ = 0 or 1</font>. Number of Qubits: <font color=\"blue\">$k_1$ = 1, $k_2$ = 2, $k_3$ = 3</font>\n",
        "\n",
        "> <font color=\"blue\">$\\tilde{x_1}$ = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{\\mathrm{x}_{1}}{2^{k_1}}+\\frac{x_{2}}{2^{k_2}}+\\frac{x_{3}}{2^{k_3}}\\right)}|1\\rangle\\right)$</font> = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{\\mathrm{x}_{1}}{2^1}+\\frac{x_{2}}{2^2}+\\frac{x_{3}}{2^3}\\right)}|1\\rangle\\right)$  = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{\\mathrm{x}_{1}}{2}+\\frac{x_{2}}{4}+\\frac{x_{3}}{8}\\right)}|1\\rangle\\right)$\n",
        "\n",
        "* If only $\\tilde{x_1}$ is activated, then it is a 180° Z-rotation of $\\pi$ radians = -1\n",
        "\n",
        "* If only $\\tilde{x_2}$ is activated, then it is a 90° S-rotation of $\\frac{\\pi}{2}$ radians = i\n",
        "\n",
        "* If only $\\tilde{x_3}$ is activated, then it is a 45° T-rotation of $\\frac{\\pi}{4}$ radians = between 1 and i\n",
        "\n",
        "> <font color=\"blue\">$\\tilde{x_2}$ = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{x_2}{2^{k_1}}+\\frac{x_3}{2^{k_2}}\\right)}|1\\rangle\\right)$</font> = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{x_2}{2^1}+\\frac{x_3}{2^2}\\right)}|1\\rangle\\right)$ = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{x_2}{2}+\\frac{x_3}{4}\\right)}|1\\rangle\\right)$\n",
        "\n",
        "* If only $\\tilde{x_2}$ is activated, then it is a 180° Z-rotation of $\\pi$ radians = -1\n",
        "\n",
        "* If only $\\tilde{x_3}$ is activated, then it is a 90° S-rotation of $\\frac{\\pi}{2}$ radians = i\n",
        "\n",
        "* If both $\\tilde{x_2}$ and $\\tilde{x_3}$ are activated, then it is a 180° + 90° = 170° rotation of $\\pi + \\frac{\\pi}{2}$ radians = -i\n",
        "\n",
        "> <font color=\"blue\">$\\tilde{x_3}$ = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{x_3}{2^{k_1}}\\right)}|1\\rangle\\right)$</font> = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{x_3}{2^1}\\right)}|1\\rangle\\right)$ = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{\\pi \\mathrm{i}x_3}|1\\rangle\\right)$\n",
        "\n",
        "* If $\\tilde{x_3}$ is activated, then it is a 180° Z-rotation of $\\pi$ radians = -1\n"
      ],
      "metadata": {
        "id": "xOBGPt6Pdvyz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Circuit Construction**\n",
        "\n",
        "*Compare the equations above with the circuit activations below (how a circuits computes the results). For example for the first qubit the operator / gate $S$ = 90° rotation is only activated if the second qubit $x_2$ is in state 1. Here it is activated because $x_2$ = 1:*\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0812.png)\n",
        "\n",
        "*Here including the 8x8 matrix form for the complete operator:*\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0801.png)"
      ],
      "metadata": {
        "id": "J8n3fjsedvyz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Quantum Fourier Transform with 1 Qubit*\n",
        "\n",
        "**Computational Basis States:** <font color=\"blue\">$\\tilde{x_1}$ = 0 or 1</font>. Number of Qubits: <font color=\"blue\">$k_1$ = 1</font>\n",
        "\n",
        "\n",
        "*Linear transformation of a qubit in the computational basis 0 and 1 each separately to the Fourier basis:*\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0813.png)\n",
        "\n",
        "**Computational Basis in $|0\\rangle$**\n",
        "\n",
        "> <font color=\"blue\">For $x_1$ = 0 $\\Rightarrow$</font> <font color=\"blue\">$\\tilde{x_1}$ = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{x_1}{2^{k_1}}\\right)}|1\\rangle\\right)$</font> = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{x_1}{2^1}\\right)}|1\\rangle\\right)$  $\\Rightarrow$ $\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{0}{2}\\right)}$ = $\\mathrm{e}^{2 \\pi \\mathrm{i} 0}$  = $\\mathrm{e}^{0}$ = 1 (no rotation)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0810.png)\n",
        "\n",
        "**Computational Basis in $|1\\rangle$**\n",
        "\n",
        "> <font color=\"blue\">For $x_1$ = 1 $\\Rightarrow$</font> <font color=\"blue\">$\\tilde{x_1}$ = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{x_1}{2^{k_1}}\\right)}|1\\rangle\\right)$</font> = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{x_1}{2^1}\\right)}|1\\rangle\\right)$ $\\Rightarrow$ $\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{1}{2}\\right)}$ = $e^{\\pi i 1} =$ <font color=\"blue\">$-1$</font> (180° Z-rotation)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0811.png)"
      ],
      "metadata": {
        "id": "hBqueHp-dvyu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D4Vdy6sdvyv"
      },
      "source": [
        "*Quantum Fourier Transform with 1 Qubit is a Hadamard transform!*\n",
        "\n",
        "**One qubit QFT matrix**: $\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{ll}1 & 1 \\\\ 1 & \\mathrm{e}^{\\pi i}\\end{array}\\right)$, where $\\mathrm{e}^{\\pi \\mathrm{i}}$ = -1. So it is: <font color=\"blue\"> QFT für x=1 = $\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{ll}1 & 1 \\\\ 1 & -1\\end{array}\\right)$\n",
        "\n",
        "**Compare with Hadamard transform matrix:**\n",
        "\n",
        "In quantum computing, the Hadamard gate is a one-qubit rotation, mapping the qubitbasis states $|0\\rangle$ and $|1\\rangle$ to two **superposition** states with **equal weight of the computational basis** states $|0\\rangle$ and $|1\\rangle$. Usually the phases are chosen so that\n",
        "\n",
        ">$\n",
        "H=\\frac{|0\\rangle+|1\\rangle}{\\sqrt{2}}\\langle 0|+\\frac{|0\\rangle-|1\\rangle}{\\sqrt{2}}\\langle 1|\n",
        "$\n",
        "\n",
        "in Dirac notation. This corresponds to the transformation matrix\n",
        "\n",
        "> <font color=\"blue\">$\n",
        "H_{1}=\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}\n",
        "1 & 1 \\\\\n",
        "1 & -1\n",
        "\\end{array}\\right)\n",
        "$\n",
        "\n",
        "in the $|0\\rangle,|1\\rangle$ basis, also known as the computational basis. The states $\\frac{|0\\rangle+|1\\rangle}{\\sqrt{2}}$ and $\\frac{|0\\rangle-|1\\rangle}{\\sqrt{2}}$ are known as $|+\\rangle$ and $|-\\rangle$ respectively, and together constitute the polar basis in quantum computing.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_073.jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zJhiyX4dvyw"
      },
      "source": [
        "**Why Hadamard transform is exactly a 1 qubit Quantum Fourier Transform:** (see result of + for 0 state and - for 1 state) - Matrix-Vector-Multiplication (Single Qubit)\n",
        "\n",
        "> <font color=\"blue\">$H |0\\rangle$</font> $ = \\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right)\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right] =\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{c}1 \\\\ 1\\end{array}\\right]$ <font color=\"blue\">$ \\,\\,= |+\\rangle$ = $\\frac{1}{\\sqrt{2}}(|0\\rangle+|1\\rangle)$\n",
        "\n",
        "> <font color=\"blue\">$H |1\\rangle$</font>$ = \\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right)\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right]=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{c}1 \\\\ -1\\end{array}\\right]$ <font color=\"blue\">$ = |-\\rangle$ = $\\frac{1}{\\sqrt{2}}(|0\\rangle-|1\\rangle)$\n",
        "\n",
        "$|+\\rangle=\\frac{1}{\\sqrt{2}}(|0\\rangle+|1\\rangle)$ weil <font color=\"gray\">wegen $|0\\rangle=\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]$ und $|1\\rangle=\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right]$ daher:</font> $\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{ll}1 + 0 \\\\ 0 + 1\\end{array}\\right]=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{c}1 \\\\ 1\\end{array}\\right]$\n",
        "\n",
        "$|-\\rangle=\\frac{1}{\\sqrt{2}}(|0\\rangle-|1\\rangle)$ weil: $\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{ll}1 - 0 \\\\ 0 - 1\\end{array}\\right]=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{c}1 \\\\ -1\\end{array}\\right]$\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_045.png)\n",
        "\n",
        "2 im denominator verschwindet hier. 2^n für n=1 qubit. mit 2 oben und unten verschwinden beide."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Quantum Fourier Transform with 3 Qubits for $|001\\rangle$*\n",
        "\n",
        "**Computational Basis in $|001\\rangle$**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0804.png)\n",
        "\n",
        "**Fourier Basis for $|001\\rangle$**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0805.png)\n",
        "\n",
        "**Computational States:** <font color=\"blue\">$\\tilde{x_1}$ = 0</font>, <font color=\"blue\">$\\tilde{x_2}$ = 0</font>, <font color=\"blue\">$\\tilde{x_3}$ = 1</font>. Number of Qubits: <font color=\"blue\">$k_1$ = 1 qubit, $k_2$ = 2 qubits, $k_3$ = 3 qubits</font>\n",
        "\n",
        "> <font color=\"blue\">Qubit 1 = $\\tilde{x_1}$</font> = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{\\mathrm{x}_{1}}{2^{k_1}}+\\frac{x_{2}}{2^{k_2}}+\\frac{x_{3}}{2^{k_3}}\\right)}|1\\rangle\\right)$ = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{0}{2}+\\frac{0}{4}+\\frac{1}{8}\\right)}|1\\rangle\\right)$  = <font color=\"blue\">$\\frac{\\pi i}{4}$</font> (45° T-rotation)\n",
        "\n",
        "> <font color=\"blue\">Qubit 2 = $\\tilde{x_2}$</font> = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{\\mathrm{x}_{2}}{2^{k_1}}+\\frac{x_{3}}{2^{k_2}}\\right)}|1\\rangle\\right)$ = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{0}{2}+\\frac{1}{4}\\right)}|1\\rangle\\right)$ = <font color=\"blue\">$\\frac{\\pi i}{2}$</font> (90° S-rotation)\n",
        "\n",
        "> <font color=\"blue\">Qubit 3 = $\\tilde{x_3}$</font> = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{\\mathrm{x}_{3}}{2^{k_1}}\\right)}|1\\rangle\\right)$ = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i} \\frac{1}{2}}|1\\rangle\\right)$ = $e^{\\pi i 1} =$ <font color=\"blue\">$-1$</font> (180° Z-rotation)"
      ],
      "metadata": {
        "id": "XH-LUgBzdvy2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Circuit Construction**\n",
        "\n",
        "*Compare the equations above with the circuit activations below (how a circuits computes the results). For example for the first qubit the operator / gate $S$ = 90° rotation is only activated if the second qubit $x_2$ is in state 1. Here it is not activated because $x_2$ = 0:*\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0812.png)"
      ],
      "metadata": {
        "id": "tAr5mMp3dvy2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Quantum Fourier Transform with 3 Qubits for $|111\\rangle$*\n",
        "\n",
        "**Computational Basis in $|111\\rangle$**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0802.png)\n",
        "\n",
        "**Fourier Basis for $|111\\rangle$**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0803.png)\n",
        "\n",
        "**Computational States:** <font color=\"blue\">$\\tilde{x_1}$ = 1</font>, <font color=\"blue\">$\\tilde{x_2}$ = 1</font>, <font color=\"blue\">$\\tilde{x_3}$ = 1</font>. Number of Qubits: <font color=\"blue\">$k_1$ = 1 qubit, $k_2$ = 2 qubits, $k_3$ = 3 qubits</font>\n",
        "\n",
        "> <font color=\"blue\">Qubit 1 = $\\tilde{x_1}$</font> = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{\\mathrm{x}_{1}}{2^{k_1}}+\\frac{x_{2}}{2^{k_2}}+\\frac{x_{3}}{2^{k_3}}\\right)}|1\\rangle\\right)$ = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{1}{2}+\\frac{1}{4}+\\frac{1}{8}\\right)}|1\\rangle\\right)$ = $\\mathrm{e}^{2 \\pi i 0.875} = \\mathrm{e}^{\\pi i 1.75}$ (180° Z-rotation + 90° S-rotation + 45° T-rotation)\n",
        "\n",
        "> <font color=\"blue\">Qubit 2 = $\\tilde{x_2}$</font> = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{\\mathrm{x}_{2}}{2^{k_1}}+\\frac{x_{3}}{2^{k_2}}\\right)}|1\\rangle\\right)$ = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{1}{2}+\\frac{1}{4}\\right)}|1\\rangle\\right)$ = $e^{\\pi i 1.5} =$ <font color=\"blue\">$-i$</font> (180° Z-rotation + 90° S-rotation)\n",
        "\n",
        "> <font color=\"blue\">Qubit 3 = $\\tilde{x_3}$</font> = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{\\mathrm{x}_{3}}{2^{k_1}}\\right)}|1\\rangle\\right)$ = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i} \\frac{1}{2}}|1\\rangle\\right)$ = $e^{\\pi i 1} =$ <font color=\"blue\">$-1$</font> (180° Z-rotation)"
      ],
      "metadata": {
        "id": "qXRBmM0advy1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Circuit Construction**\n",
        "\n",
        "*Compare the equations above with the circuit activations below (how a circuits computes the results). For example for the first qubit the operator / gate $S$ = 90° rotation is only activated if the second qubit $x_2$ is in state 1. Here it is activated because $x_2$ = 1:*\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0812.png)"
      ],
      "metadata": {
        "id": "HYY1eloedvy2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Cirq Code for Quantum Fourier Transform*\n",
        "\n",
        "*Compare the code above with the circuit activations below (how a circuits computes the results):*\n",
        "\n",
        "* $H$ gate = bring qubit in superposition.\n",
        "\n",
        "  * *For $x=0$, no further rotation*\n",
        "\n",
        "  * *For $x=1$, then appy additional *$Z$ gate = 180° rotation = $\\pi$**\n",
        "\n",
        "* *$S$ gate = 90° rotation = $\\frac{\\pi}{2}$*\n",
        "\n",
        "* *$T$ gate = 45° rotation = $\\frac{\\pi}{4}$*\n",
        "\n",
        "$C R_{j}=C Z^{1 / 2^{j-1}}$\n",
        "\n",
        "* $Z$ entspricht $\\pi$ (ein halber Kreis, zB von +1 zu -1 auf X-Achse)\n",
        "\n",
        "* $S$ entspricht $\\frac{\\pi}{2}$, also wenn qubit 1 = 1, dann bei qubit 0 das $S$ transform anwenden (0,5)\n",
        "\n",
        "  * S: The square root of Z gate, equivalent to cirq.Z ** 0.5\n",
        "\n",
        "  * See: [Cirq Gates](https://quantumai.google/cirq/gates)\n",
        "\n",
        "* $T$ entspricht $\\frac{\\pi}{4}$"
      ],
      "metadata": {
        "id": "lWJ2Oz2Ydvy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cirq -q\n",
        "import cirq\n",
        "\n",
        "def make_qft(qubits):\n",
        "\n",
        "    # Generate list of qubits\n",
        "    qreg = list(qubits)\n",
        "\n",
        "    # Make sure list is longer than 0 qubits:\n",
        "    while len(qreg) > 0:\n",
        "\n",
        "    # Remove first qubit from list and return its value (set as head-qubit):\n",
        "        q_head = qreg.pop(0)\n",
        "\n",
        "    # Apply Hadamard superposition to this head-qubit\n",
        "        yield cirq.H(q_head)\n",
        "\n",
        "    # Enumerate through list with i (index position) and corresponding qubit value (0 or 1)\n",
        "        for i, qubit in enumerate(qreg):\n",
        "\n",
        "    # Apply Controlled-Z * Theta-Phase-Shift on target ('q-head') if control-qubit ('qubit') is in state 1\n",
        "            yield (cirq.CZ ** (1 / 2 ** (i + 1)))(qubit, q_head)\n",
        "\n",
        "    # Do the inverse QFT as subroutine in quantum phase estimation\n",
        "    #        yield (cirq.CZ ** (-1 / 2 ** (i + 1)))(qubit, q_head)\n",
        "\n",
        "# Use inverse QFT as subroutine in quantum phase estimation\n",
        "# phase_estimator.append(make_qft_inverse(qubits[::-1]))\n",
        "\n",
        "    # Iterating through until \"while len(qreg) = 0\", then processes stops\n",
        "\n",
        "\"\"\"Visually check the QFT circuit.\"\"\"\n",
        "qubits = cirq.LineQubit.range(17)\n",
        "qft = cirq.Circuit(make_qft(qubits))\n",
        "print(qft)"
      ],
      "metadata": {
        "id": "myOgAQXddvy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0815.png)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0812.png)"
      ],
      "metadata": {
        "id": "mzHIk-hJdvy5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oTg0Uyudvy6"
      },
      "source": [
        "*Inverse Quantum Fourier Transform ('QFT Dagger' - Dagger is a complex conjugate operation!)*\n",
        "\n",
        "Reminder of QFT:\n",
        "\n",
        "* $QFT\\,\\,|x\\rangle=|\\tilde{x}\\rangle=$ $\\frac{1}{\\sqrt{N}} \\sum_{y=0}^{N-1} e^{\\frac{2 \\pi i}{N} x y} |y\\rangle$\n",
        "\n",
        "**Remember: Dagger is a complex conjugate operation!**\n",
        "\n",
        "QFT inverse (see -2 turning i in -i which is a complex conjugate operation):\n",
        "\n",
        "* $QFT^{\\dagger}|\\tilde{x}\\rangle=|x\\rangle=$ $\\frac{1}{\\sqrt{N}} \\sum_{y=0}^{N-1} e^{\\frac{-2 \\pi i}{N} x y} |y\\rangle$\n",
        "\n",
        "\n",
        "The operator is then (\n",
        "We have already seen that the Hadamard gate is self-inverse, and the same is clearly true for the SWAP gate; the inverse of the rotations gate $R_k$ is given by):\n",
        "\n",
        "> The matrix form of inverse QFT operator is: <font color=\"blue\">${R^{\\dagger}}_{k}=\\left(\\begin{array}{cc}1 & 0 \\\\ 0 & e^{-2 \\pi i / 2^{k}}\\end{array}\\right)$</font> and compare with QFT operator:  <font color=\"blue\">$\\hat{R}_{k}=\\left(\\begin{array}{cc}1 & 0 \\\\ 0 & e^{2 \\pi i / 2^{k}}\\end{array}\\right)$\n",
        "\n",
        "https://www.cl.cam.ac.uk/teaching/1920/QuantComp/Quantum_Computing_Lecture_9.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Shor's Algorithm*"
      ],
      "metadata": {
        "id": "A90mbGhcftHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/deltorobarba/sciences/blob/master/shor.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ],
      "metadata": {
        "id": "5sOhM-vlXeD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shor’s algorithm for factoring, which is not NP-complete, has been run on real quantum computers. The largest number it has been used to factor (that I could find a reference to) is 56153: New largest number factored on a quantum device is 56,153. And that was on 4 qubits (https://phys.org/news/2014-11-largest-factored-quantum-device.html).\n",
        "\n",
        "*(RSA) Encryption*\n",
        "\n",
        "Video [Breaking RSA](https://youtu.be/-ShwJqAalOk)\n",
        "\n",
        "Public key cryptography\n",
        "* https is developed on top of this\n",
        "* RSA: revest shavor edelmann, based on prime numbers, older more established algoithm\n",
        "* Elliptic curve cryptography\n",
        "* Modular arithmetic\n",
        "* Feistel Cypher (block cypher): https://de.m.wikipedia.org/wiki/Feistelchiffre\n",
        "* Diffie Hellmann key exchange\n",
        "* It's an exponential problem on classical computers that quantum computers can solve in polynomial time\n",
        "\n",
        "Extended Euclidean algorithm\n",
        "\n",
        "$\\begin{aligned} & (e, n)(d) \\\\ & n=p \\cdot q \\\\ & \\Phi(n)=(p-1) \\cdot(q-1) \\\\ & e \\cdot d \\equiv 1 \\bmod (\\Phi(n))\\end{aligned}$\n",
        "\n",
        "Fermat‘s factorization algorithm: if p and q are close to each other, this gives you a solution extremely quickly\n",
        "\n",
        "$\\begin{aligned} & N=a^2-b^2=(a+b) \\cdot(a-b) \\\\ & b^2=a^2-N \\\\ & a=[\\sqrt{N}]\\end{aligned}$\n",
        "\n",
        "[Prime Numbers and RS Encryption Algorithm](https://youtu.be/JD72Ry60eP4)\n",
        "\n"
      ],
      "metadata": {
        "id": "m6cJFp1SUIMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2019) How to factor 2048 bit RSA integers in 8 hours using 20 million noisy qubits\n",
        "\n",
        "https://arxiv.org/abs/1905.09749\n",
        "\n",
        "Yes, Craig Gidney has made significant contributions to the study of the discrete logarithm problem. In particular, he has developed quantum algorithms for solving the DLP that are significantly faster than classical algorithms.\n",
        "\n",
        "In 2010, Gidney published a paper in which he showed that the DLP could be solved using a quantum algorithm that is exponentially faster than the best classical algorithm. This algorithm is based on the use of modular forms, which are a type of mathematical function that has certain properties that make them well-suited for quantum computation.\n",
        "\n",
        "Gidney's work on the DLP has had a major impact on the field of cryptography. It has shown that the DLP is not as secure as previously thought, and it has led to the development of new cryptographic systems that are more resistant to quantum attacks.\n",
        "\n",
        "In addition to his work on the DLP, Gidney has also made significant contributions to other areas of quantum computing, such as quantum error correction and quantum simulation. He is a leading expert in the field of quantum computing, and his work is helping to pave the way for the development of practical quantum computers.\n",
        "\n",
        "Here are some of the specific contributions that Craig Gidney has made to the study of the discrete logarithm problem:\n",
        "\n",
        "* In 2010, he showed that the DLP could be solved using a quantum algorithm that is exponentially faster than the best classical algorithm.\n",
        "* In 2012, he developed a quantum algorithm for solving the DLP in the presence of noise.\n",
        "* In 2019, he co-authored a paper that showed how to use the DLP to factor RSA integers.\n",
        "\n",
        "Gidney's work on the DLP has had a major impact on the field of cryptography. It has shown that the DLP is not as secure as previously thought, and it has led to the development of new cryptographic systems that are more resistant to quantum attacks.\n",
        "\n",
        "I hope this helps! Let me know if you have other questions."
      ],
      "metadata": {
        "id": "HM92BvMZCJST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://quantumai.google/cirq/experiments/shor"
      ],
      "metadata": {
        "id": "1S_wdVn7P6_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Der Shor-Algorithmus lässt sich am besten für die Primfaktorzerlegung erklären. Damit Quantencomputer diese Aufgabe meistern können, muss man das Problem allerdings etwas umformulieren. Denn der Quantenalgorithmus stützt sich auf eine Anleitung zum Faktorisieren von Zahlen, die aus den 1970er Jahren stammt. Damals fand man heraus, dass nur vier Schritte nötig sind, um die Primfaktoren p und q einer Zahl N = p·q zu berechnen.\n",
        "\n",
        "1. Wähle eine zufällige Zahl a < N.\n",
        "\n",
        "2. Finde die Periodenlänge r von a Modulo N.\n",
        "\n",
        "3. Stelle sicher, dass r eine gerade Zahl ist und dass (a^(r/2) + 1) nicht durch N teilbar ist.\n",
        "\n",
        "4. Dann ist p der größte gemeinsame Teiler von (a^(r/2) − 1) und N. Der andere Primteiler q ist entsprechend der größte gemeinsame Teiler von (a^(r/2) + 1) und N.\n",
        "\n",
        "https://www.spektrum.de/kolumne/shor-algorithmus-wie-quantencomputer-verschluesselungen-knacken/2133048\n"
      ],
      "metadata": {
        "id": "cbvNcG-vOM6M"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6yeVZAuzrMk"
      },
      "source": [
        "**Classical Calculation**\n",
        "\n",
        "* <font color=\"blue\">Factoring is equivalent to finding a nontrivial squareroot of 1 mod N.\n",
        "\n",
        "* all we need to do is find this nontrivial squareroot of unity, and we can factor whatever number we need. As promised, we can do this with period finding, specifically by computing the order of a random integer\n",
        "\n",
        "* The order of some integer x modulo N is the smallest integer r such that $x^r$ = 1 mod N"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCxHYDSsb6-y"
      },
      "source": [
        "*Modular Arithmetic*\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_088.jpg)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_089.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axJsmDe1lF5Y"
      },
      "source": [
        "**<font color=\"blue\">Step 1: Pick coprime of N**\n",
        "\n",
        "*Drei mögliche Verfahren zur Berechnung des ggT :*\n",
        "\n",
        "Erstes Verfahren: Euklidischer Algorithmus\n",
        "* 15\t:\t13\t  = \t1\t  Rest  \t2.\t  Also ist ggT (15,13)= ggT (13,2)\n",
        "* 13\t:\t2\t  = \t6\t  Rest  \t1.\t  Also ist ggT (13,2)= ggT (2,1)\n",
        "* 2\t:\t1\t  = \t2\t  Rest  \t0.\t  Also ist ggT (2,1)= ggT (1,0)\n",
        "* Ergebnis: Der ggT von 15 und 13 ist 1.\n",
        "\n",
        "Zweites Verfahren: Vergleichen der Teilermengen .\n",
        "* Die Teilermenge von 15 lautet: {1,3,5,15}.\n",
        "* Die Teilermenge von 13 lautet: {1,13}.\n",
        "* Die größte in beiden Teilermengen vorkommende Zahl ist 1. Also ist 1 der ggT von 15 und 13.\n",
        "\n",
        "Dritte Möglichkeit: Vergleichen der Primfaktorzerlegung\n",
        "* Die Primfaktorzerlegung von 15 lautet: 15= 3·5.\n",
        "* Die Primfaktorzerlegung von 13 lautet: 13= 13.\n",
        "* Die gemeinsamen Primfaktoren sind: 1.\n",
        "* Also ist 1 der ggT.\n",
        "\n",
        "*Modulo (kurz: mod) berechnet den Rest einer Division zweier Zahlen. In Mathematischen Formeln wird modulo mit mod abgekürzt, beispielsweise: 23 mod 8 = 7. Bei dieser Rechnung kommt 7 heraus, weil die 8 zweimal in die 23 passt und dann 7 übrig bleiben.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48daYc8to4oz"
      },
      "source": [
        "# Product of two prime numbers (to check later if result is correct)\n",
        "N=5 * 3\n",
        "\n",
        "# Pick coprime (!) number to N to factorize N into primes\n",
        "a=13\n",
        "\n",
        "# Code Example to understand periodicity in the context of factoring prime numbers:\n",
        "\n",
        "import math\n",
        "# Compute greated common divisor between a and N\n",
        "math.gcd(a, N)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzqnmPhvoTQw"
      },
      "source": [
        "**<font color=\"blue\">Step 2: Find the period of $a^r$ $\\equiv$ 1 $(modN)$:**\n",
        "\n",
        "* <font color=\"blue\">the order of x is just the period of the function f(i) = $x^i$ mod N.\n",
        "\n",
        "* <font color=\"blue\">In quantum computing you use QFT in order to determine the period !!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SoazOyVpdiU"
      },
      "source": [
        "import matplotlib. pyplot as plotter\n",
        "sns.set(rc={'figure.figsize':(12, 5), \"lines.linewidth\": 1.5})\n",
        "\n",
        "r = list(range(N))\n",
        "y= [a**r0 % N for r0 in r]\n",
        "\n",
        "plotter.plot (r, y)\n",
        "plotter.xlabel('r')\n",
        "plotter.ylabel('Rest:' f'{a}^r (mod{N})')\n",
        "plotter.title('Periode der Restwerte (aus den Multiples von r)')\n",
        "plotter.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6qyWTdoZDtL"
      },
      "source": [
        "<font color=\"red\">**Beispiel: Choose any number $a$ and takes its multiple $r$ so many times, until the rest in modulo is 1, (except r=0)**</font>\n",
        "\n",
        "> $13^0$ (mod 15) = 1 (mod 15) = 1\n",
        "\n",
        "> $13^1$ (mod 15) = 13\n",
        "\n",
        "> $13^2$ (mod 15) = 169 (mod 15) = 4\n",
        "\n",
        "* <font color=\"blue\">*Erlauterung: Nimm 15 * 11 = 165, bis zur 169 verbleibt ein Rest 4*\n",
        "\n",
        "> $13^3$ (mod 15) = 2197 (mod 15) = 7\n",
        "\n",
        "* <font color=\"blue\">*Erlauterung: Nimm 15 * 146 = 2190, bis zur 2197 verbleibt ein Rest 7*\n",
        "\n",
        "> $13^4$ (mod 15) = 28561 (mod 15) = 1 (<font color=\"blue\"><u>hier started die Periode wieder, that's the r we are looking for!</u>)\n",
        "\n",
        "> usw.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dblciep4qxfM"
      },
      "source": [
        "r= r[y[1:].index(1)+1]\n",
        "print(f'r = {r}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26HLzUiXj6AR"
      },
      "source": [
        "**<font color=\"blue\">Step 3: Bestimme $x \\equiv a^{\\frac{r}{2}}(\\operatorname{mod} N)$**. Mindestens einer der beiden Primfaktoren von N={p,q} is beinhalted in gcd(x+1, N) bzw. gcd(x-1, N)\n",
        "\n",
        "*In this case with a=13, N=15 and r=4:*\n",
        "\n",
        "* $x \\equiv a^{\\frac{r}{2}}(\\operatorname{mod} N)$\n",
        "\n",
        "* $x \\equiv 13^{\\frac{4}{2}}(\\operatorname{mod} 15)$\n",
        "\n",
        "* x = 169 (mod 15) = 4\n",
        "\n",
        "  * gcd(x-1, N) = 3 = p\n",
        "\n",
        "  * gcd(x+1, N) = 5 = q\n",
        "\n",
        "Achtung: in einem anderen Beispiel: N=11*7 (Primzahlen), a=18, ergibt x=43.\n",
        "\n",
        "* Davon x-1=42 und x+1=44.\n",
        "* Das sind naturlich keine Primzahlen,\n",
        "* Aber deren Faktoren sind: 44 = 2 * 2 * 11 und 42 = 2 * 3 * 7\n",
        "* das heisst, x-1 und x+1 kann auch die Primzahlen indirekt enthalten!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8MwnRiUrqhR"
      },
      "source": [
        "if r % 2 == 0:\n",
        "  x = (a**(r/2.)) % N\n",
        "  print(f'x = {x}')\n",
        "  if ((x + 1) % N) != 0:\n",
        "    print(math.gcd((int(x)+1), N), math.gcd((int(x)-1), N))\n",
        "  else:\n",
        "      print (\"x + 1 is 0 (mod N)\")\n",
        "else:\n",
        "  print (f'r = {r} is odd')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rj2GI7_cC86"
      },
      "source": [
        "**Shor's Algorithm**\n",
        "\n",
        "* When finding order using the period finding algorithm, it is important to use enough qubits. A sensible rule is that you need to use m qubits so that $2^m$ >> $N^2$, where N is the number we are trying to factor, because the order of a random number might be as large as N\n",
        "\n",
        "* Example: Lets factor N=119. Suppose we pick the number 16 to start with. Wie viele Qubits m sollten wir mindestens nehmen? $N^2$ = $119^2$ =14.161 und $2^m$ muss deutlich grosser sein, also mindestens = $2^{14}$ = 16.384. Wir brauchen also mindestens 14 Qubits, um 119 zu faktorisieren.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_090.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrrdCnywczMT"
      },
      "source": [
        "* Because we know that the order of x will be even and $x^{s/2}$ will be a nontrivial square root with probability at least 1/2, we can be confident that we will be able to factor N in just a few runs of the algorithm. Because the time it takes to find the period grows as a polynomial in the number of bits, and the number of bits grows like 2logN(by the above requirement), we expect the time it takes to factor N to grow as a polynomial in logN.\n",
        "\n",
        "* Here is the circuit for Shor’s Algorithm. It relies heavily on period finding, and so the circuit looks a lot like the circuit for period finding. The key difference is that we are finding the period of f(i) = xi, and the number of bits we need to input is very large.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_091.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHQthOfm_JfT"
      },
      "source": [
        "**How does it work in the quantum circuit?**\n",
        "\n",
        "That's the function in $U$: given an $x$, the $U$ will compute:\n",
        "\n",
        "> $f_{a, N}(x) \\equiv a^{x}(\\bmod N)$\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_092.png)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_093.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mApRUwSPydz"
      },
      "source": [
        "**<font color=\"blue\">Shor's Algorithm: Step by Step**\n",
        "\n",
        "**Beispiel: a=13 und N=15, was macht Shor's Algorithm genau im Circuit an der Stelle $U_{f_{(a,N)}}$ und $QFT^{\\dagger}$?**\n",
        "\n",
        "ps: a muss ein Coprime von N sein. Wenn es kein Coprime ist, muessen wir nicht durch Shor's Algorithm gehen, weil a dann einen Faktor mit N teilt :) Aber es ist very unlikely to find a coprime of a large number N.\n",
        "\n",
        "**First let's divide it into steps. 1-5:**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_095.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrEvCMunLBeC"
      },
      "source": [
        "**Step 1**: Get Qubits in state 0 and apply Hadamard Superposition\n",
        "\n",
        "We start with 4 Qubits all in zeros, mit den Registers x und w, und jedes 4 Mal Tensorproduct multipliziert, weil wir 4 Qubits haben:\n",
        "\n",
        "> $|0\\rangle_{x}^{\\otimes 4}$ $|0\\rangle_{w}^{\\otimes 4}$\n",
        "\n",
        "All Hamadard Gates are applied to top 4 Qubits (x register), and right part (w register) gets nothing applied to it:\n",
        "\n",
        "> $[H^{\\otimes 4}|0\\rangle] \\,\\, |0\\rangle^{\\otimes^{4}}$\n",
        "\n",
        "> = $\\frac{1}{4}[|0\\rangle+|1\\rangle+|2\\rangle+\\cdots+|15\\rangle]$ $|0\\rangle$\n",
        "\n",
        "* Reminder 1: Multiplikation mit $\\frac{1}{4}$, weil 4 Qubits in Hadamard-Superposition\n",
        "\n",
        "* Reminder 2: this is the 4 bit representation of the decimal number, so for example 15 in binary = 1111. Daher kann man auch die 4 angeben als Erinnerung der Bit representation:\n",
        "\n",
        "> = $\\frac{1}{4}[|0\\rangle_4+|1\\rangle_4+|2\\rangle_4+\\cdots+|15\\rangle_4]$ $|0\\rangle_4$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKOyXX5bG_i1"
      },
      "source": [
        "**Step 2**: Compute $U$ with $f_{a, N}(x) \\equiv a^{x}(\\bmod N)$ - Was passiert genau in der Box mit $U_{f_{(a,N)}}$?\n",
        "\n",
        "**Given an $x$, the $U$ will compute: <font color=\"red\">$f_{a, N}(x) \\equiv a^{x}(\\bmod N)$</font>**\n",
        "\n",
        "Schauen wir nochmal im vorherigen Schritt und markieren eine Komponente:\n",
        "\n",
        "> = $\\frac{1}{4}[$ <font color=\"red\">$|0\\rangle_4$</font> $+|1\\rangle_4+|2\\rangle_4+\\cdots+|15\\rangle_4]$ $\\,$ $|0\\rangle_4$\n",
        "\n",
        "<font color=\"red\">$U_{f_{(a,N)}}$</font> macht dann folgendes:\n",
        "\n",
        "> = $\\frac{1}{4}$ <font color=\"red\">[$|0\\rangle_{4}\\, \\left|  0 \\bigoplus 13^{0}(\\bmod 15)\\right\\rangle_{4}$</font> + $|1\\rangle_{4}\\left|0 \\bigoplus 13^{1}(\\bmod 15)\\right\\rangle_{4}$ + $|2\\rangle_{4}\\left|0 \\bigoplus 13^{2}(\\bmod 15)\\right\\rangle_{4}$ + $|3\\rangle_{4}\\left|0 \\bigoplus 13^{3}(\\bmod 15)\\right\\rangle_{4}$ etc..]\n",
        "\n",
        "Remember: $\\bigoplus$ means \"addition modular 2\" bzw. \"XOR\". Anything XORs with 0, is thing itself: 0 $\\bigoplus$ Z = Z. damit ergibt sich folgende Rechnung:\n",
        "\n",
        "> = $\\frac{1}{4}$ <font color=\"red\">[$|0\\rangle_{4}\\, \\left|   13^{0}(\\bmod 15)\\right\\rangle_{4}$</font> + $|1\\rangle_{4}\\left| 13^{1}(\\bmod 15)\\right\\rangle_{4}$ + $|2\\rangle_{4}\\left| 13^{2}(\\bmod 15)\\right\\rangle_{4}$ + $|3\\rangle_{4}\\left| 13^{3}(\\bmod 15)\\right\\rangle_{4}$ etc..]\n",
        "\n",
        "\n",
        "Aus der Modulo-Rechnung ergeben sich die Restwerte:\n",
        "\n",
        "* <font color=\"red\">$13^{0}(\\bmod 15)$ = 1</font>\n",
        "\n",
        "* $13^{1}(\\bmod 15)$ = 13\n",
        "\n",
        "* $13^{2}(\\bmod 15)$ = 4\n",
        "\n",
        "* $13^{3}(\\bmod 15)$ = 7\n",
        "\n",
        "* $13^{4}(\\bmod 15)$ = 1\n",
        "\n",
        "* usw..\n",
        "\n",
        "Since it's periodic, it will repeat, with the x and w register:\n",
        "\n",
        "> = $\\frac{1}{4}$ <font color=\"red\">[$|0\\rangle_{4}\\,\\left|1\\right\\rangle_{4}$</font> + $|1\\rangle_{4}\\left|13\\right\\rangle_{4}$ + $|2\\rangle_{4}\\left|4\\right\\rangle_{4}$ + $|3\\rangle_{4}\\left|7\\right\\rangle_{4}$ etc..]\n",
        "\n",
        "Hier nochmal untereinander mit denselben Restwerten zur besseren Visualisierung:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_094.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_-QZylnP7nv"
      },
      "source": [
        "**Step 3: Measurement of the w register / bottom 4 Qubits**\n",
        "\n",
        "* the outputs of the w-register measurements are either 1, 13, 4 or 7 (die Restwerte) with equal probability\n",
        "\n",
        "* let's say we measure 7, what happens to x? X becomes either 3, 7, 11 or 15 (the value in front of the qubit with 7!) with equal probability:\n",
        "\n",
        "  * after $|\\omega\\rangle$ = $|7\\rangle_4$ , $|x\\rangle$ becomes:\n",
        "\n",
        "  * <font color=\"blue\">$|x\\rangle$ $|\\omega\\rangle$ = $\\frac{1}{2}\\left[|3\\rangle_{4}+|7\\rangle_{4}+|11\\rangle_{4}+ |15 \\rangle_{4}\\right]$ $\\otimes |7\\rangle_4$\n",
        "\n",
        "  * Normalization has changed: before we had 16 combinations mit 1/4, here we have only 4 combinations with 1/2 (=one over square root of 4)\n",
        "\n",
        "* **For the next step 4, the Restwert doesn't matter anymore, here: $\\otimes |7\\rangle_4$. We can ignore it. Because it step 4 we apply the measured $|x\\rangle$ in the $QFT^{\\dagger}$, and don't care about $|\\omega\\rangle$ anymore**. And $|x\\rangle$ is in this case: $\\frac{1}{2}\\left[|3\\rangle_{4}+|7\\rangle_{4}+|11\\rangle_{4}+ |15 \\rangle_{4}\\right]$\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_095.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Exkurs: Eine komplexe Zahl $z=a+b i$ und die zu ihr konjugiert komplexe Zahl $\\bar{z}=a-b i$*:\n",
        "\n",
        "![gg](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Komplexe_konjugation.svg/294px-Komplexe_konjugation.svg.png)\n",
        "\n",
        "Ändert man das Vorzeichen des Imaginärteils $b$ einer komplexen Zahl\n",
        "\n",
        "> $z=a+b \\mathrm{i}$\n",
        "\n",
        "so erhält man die zu $z$ konjugiert komplexe Zahl\n",
        "\n",
        "> $\\bar{z}=a-b \\mathrm{i}$\n",
        "\n",
        "(manchmal auch $z^{*}$ geschrieben).\n",
        "\n",
        "Die Konjugation $\\mathbb{C} \\rightarrow \\mathbb{C}, z \\mapsto \\bar{z}$ ist ein (involutorischer) Körperautomorphismus, da sie mit Addition und Multiplikation verträglich ist, d. h., für alle $y, z \\in \\mathbb{C}$ gilt\n",
        "\n",
        ">$\n",
        "\\overline{y+z}=\\bar{y}+\\bar{z}, \\quad \\overline{y \\cdot z}=\\bar{y} \\cdot \\bar{z}\n",
        "$\n",
        "\n",
        "In der Polardarstellung hat die konjugiert komplexe Zahl $\\bar{z}$ bei unverändertem Betrag gerade den negativen Winkel von $z$.\n",
        "\n",
        "* **Man kann die Konjugation in der komplexen Zahlenebene also als die Spiegelung an der reellen Achse interpretieren**.\n",
        "\n",
        "* <font color=\"blue\">**Insbesondere werden unter der Konjugation genau die reellen Zahlen auf sich selbst abgebildet**.\n",
        "\n",
        "Das Produkt aus einer komplexen Zahl $z=a+b$ i und ihrer komplex Konjugierten $\\bar{z}$ ergibt das Quadrat ihres Betrages:\n",
        "\n",
        "> $\n",
        "z \\cdot \\bar{z}=(a+b i)(a-b i)=a^{2}+b^{2}=|z|^{2}\n",
        "$\n",
        "\n",
        "Die komplexen Zahlen bilden damit ein triviales Beispiel einer [C*-Algebra](https://de.m.wikipedia.org/wiki/C*-Algebra)."
      ],
      "metadata": {
        "id": "imQLT4Zc7er9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_7uaW02Wyvg"
      },
      "source": [
        "**Step 4**: Apply inverse $QFT^{\\dagger}$ on the $|x\\rangle$ register\n",
        "\n",
        "* $QFT\\,\\,|x\\rangle=|\\tilde{x}\\rangle=$ $\\frac{1}{\\sqrt{N}} \\sum_{y=0}^{N-1} e^{\\frac{2 \\pi i}{N} x y} |y\\rangle$ (Reminder!)\n",
        "\n",
        "* $QFT^{\\dagger}|\\tilde{x}\\rangle=|x\\rangle=$ $\\frac{1}{\\sqrt{N}} \\sum_{y=0}^{N-1} e^{\\frac{-2 \\pi i}{N} x y} |y\\rangle$ (see -2 turning i in -i which is a **complex conjugate operation**)\n",
        "\n",
        "* We want to know what QFT dagger is doing to (it is $\\frac{1}{\\sqrt{16}}$ because we have 4 Qubits)\n",
        "\n",
        "  * $QFT^{\\dagger}|3\\rangle_4$ = $\\frac{1}{\\sqrt{16}} \\sum_{y=0}^{N-1} e^{\\frac{-2 \\pi i 3 y}{16}}|y\\rangle$\n",
        "\n",
        "  * $QFT^{\\dagger}|7\\rangle_4$ = $\\frac{1}{\\sqrt{16}} \\sum_{y=0}^{N-1} e^{\\frac{-2 \\pi i 7 y}{16}}|y\\rangle$\n",
        "\n",
        "  * $QFT^{\\dagger}|11\\rangle_4$ = $\\frac{1}{\\sqrt{16}} \\sum_{y=0}^{N-1} e^{\\frac{-2 \\pi i 11 y}{16}}|y\\rangle$\n",
        "\n",
        "  * $QFT^{\\dagger}|15\\rangle_4$ = $\\frac{1}{\\sqrt{16}} \\sum_{y=0}^{N-1} e^{\\frac{-2 \\pi i 15 y}{16}}|y\\rangle$\n",
        "\n",
        "Alltogether:\n",
        "\n",
        "  * $QFT^{\\dagger}|x\\rangle$ = $\\frac{1}{{8}} \\sum_{y=0}^{15}$ [ $e^{-i\\frac{ 3 \\pi}{8}y}$ + $e^{-i\\frac{ 7 \\pi}{8}y}$ + $e^{-i\\frac{ 11 \\pi}{8}y}$ + $e^{-i\\frac{ 15 \\pi}{8}y}$] $|y\\rangle$\n",
        "\n",
        "    * with: $e^{-i\\frac{ 3 \\pi}{8}y}$ = $\\cos \\left(\\frac{3 \\pi}{8} y\\right)-i \\sin \\left(\\frac{3 \\pi}{8} y\\right)$ (und aquivalent fur alle anderen drei)\n",
        "\n",
        "    * siehe coding rechnung unten was genau passiert hier!\n",
        "\n",
        "  * <font color=\"blue\">$QFT^{\\dagger}|x\\rangle$ = $\\frac{1}{{8}}$ [ $4|0\\rangle_4$ + $4i|4\\rangle_4$ $-4|8\\rangle_4$ $-4i|12\\rangle_4$ ]</font>\n",
        "\n",
        "  * Remember we had a sum before: $\\frac{1}{{8}} \\sum_{y=0}^{15}$. And notice how all the other terms now vanished to zero, because you had equal contributions of plus and minus.\n",
        "\n",
        "    * **This is exactly what it means when people tell you that quantum computers take advantage of interference!! = when a lot of the terms vanish, and the answer only converges to the terms that we care about.**\n",
        "\n",
        "    * here is the calculation what happened, you see many zeros:\n",
        "\n",
        "<font color=\"red\">Hier Beispielrechnung fur y=1, um vanishing components zu verstehen</font>. Unten im Code die Ergebnisse, zum Beispiel fur y=1 als Ergebnis = 0, $QFT^{\\dagger}|x\\rangle$ fur y = 1:\n",
        "\n",
        "  * $e^{-i\\frac{ 3 \\pi}{8}y}$ + $e^{-i\\frac{ 7 \\pi}{8}y}$ + $e^{-i\\frac{ 11 \\pi}{8}y}$ + $e^{-i\\frac{ 15 \\pi}{8}y}$ =\n",
        "\n",
        "  * $e^{-i\\frac{ 3 \\pi}{8}1}$ + $e^{-i\\frac{ 7 \\pi}{8}1}$ + $e^{-i\\frac{ 11 \\pi}{8}1}$ + $e^{-i\\frac{ 15 \\pi}{8}1}$ =\n",
        "\n",
        "    * $e^{-i\\frac{ 3 \\pi}{8}1}$ = <font color=\"green\">0,382683432 - 0,923879533 i</font>\n",
        "\n",
        "    * $e^{-i\\frac{ 7 \\pi}{8}1}$ = <font color=\"orange\">-0,923879533 - 0,382683432 i</font>\n",
        "\n",
        "    * $e^{-i\\frac{ 11 \\pi}{8}1}$ = <font color=\"green\">-0,382683432 + 0,923879533 i</font>\n",
        "\n",
        "    * $e^{-i\\frac{ 15 \\pi}{8}1}$ = <font color=\"orange\">0,923879533 + 0,382683432 i</font>\n",
        "\n",
        "  * Wie man sieht canceln sich die Terme aus (in gleicher Farbe), weshalb als Ergebnis fur y=1 Null entsteht."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWn_Jmu_OMSJ"
      },
      "source": [
        "# Hier Beispiel fur y=1 und den ersten e-Term:\n",
        "y = 1\n",
        "pi = np.pi\n",
        "coeff = np.exp(-1j*3*pi/8 * y)\n",
        "if abs(coeff) < 1e-10: coeff= 0\n",
        "print(y, coeff)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iERBMPR2y9hm"
      },
      "source": [
        "# Hier die komplette Rechnung fur alle y und alle 4 e-Terme:\n",
        "import numpy as np\n",
        "\n",
        "pi = np.pi\n",
        "for y in range (15) :\n",
        "  coeff = np.exp(-1j*3*pi/8 * y) + \\\n",
        "          np.exp(-1j*7*pi/8 * y) + \\\n",
        "          np.exp(-1j*11*pi/8* y) + \\\n",
        "          np.exp(-1j*15*pi/8* y)\n",
        "  if abs(coeff) < 1e-10: coeff= 0\n",
        "  print(y, coeff)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfXrcIqo14n0"
      },
      "source": [
        "**Step 5: Measure the |x> register**\n",
        "\n",
        "* You get either 0 or 4 or 8 or 12 with equal probability\n",
        "\n",
        "* Remaining steps are classical post-processing\n",
        "\n",
        "* You can already see the periodicity in the result: the difference is always 4\n",
        "\n",
        "* Analyse what happens for each outcome: **The measurement results peak near $j\\frac{N}{r}$ for same integer j $\\in Z$. And r is the period that we are looking for. N = $2^n$ Qubits!**\n",
        "\n",
        "  * if we measure |4>$_4$: $j\\frac{16}{r}$ = 4, true if j=1 and r=4\n",
        "\n",
        "  * there are multiple values that would work, but this is the lowest one\n",
        "\n",
        "* now check our protocoll for r=4:\n",
        "\n",
        "  * Is r even? yes!\n",
        "\n",
        "  * $x \\equiv a^{r / 2}(\\bmod N)$ = $13^{4 / 2}(\\bmod 15)$ = 4\n",
        "\n",
        "  * x+1 = 5 and x-1 = 3\n",
        "\n",
        "* This looks good, now check:\n",
        "\n",
        "  * $\\operatorname{gcd}(x+1, N)=\\operatorname{gcd}(5,15)=5$\n",
        "\n",
        "  * $\\operatorname{gcd}(x-1, N)=\\operatorname{gcd}(3,15)=3$\n",
        "\n",
        "What do you do if r = 8 ?\n",
        "\n",
        "* |8>$_4$: $j\\frac{16}{r}$ = 8, true if j=1 and r=2 AND j=2 and r=4\n",
        "\n",
        "* if r=4 we are back in the case before\n",
        "\n",
        "* if r=2 then $x \\equiv a^{r / 2}(\\bmod N)$ = $13^{2 / 2}(\\bmod 15)$ = 2, which brings x+1 = 3 and x-1 = 1\n",
        "\n",
        "  * $\\operatorname{gcd}(x+1, N)=\\operatorname{gcd}(3,15)=3$\n",
        "\n",
        "  * $\\operatorname{gcd}(x-1, N)=\\operatorname{gcd}(1,15)=1$\n",
        "\n",
        "* This leads you to a partial solution. Now you can back out the other solution, with checking 3 divides into 15\n",
        "\n",
        "* If we get r=0, then we need to do the experiment again\n",
        "\n",
        "Hier die Faktorisierungsergebnisse fur verschiedene QC-Ausgaben r. Mit r=0 geht es nicht, also kann man in 3 von 4 Faellen faktorisieren (und mit r=8 bekommt man eine partial solution, kann aber immer noch faktorisieren).\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_097.png)\n",
        "\n",
        "Aus dem 2001 Paper von IBM, Faktorisierung von 15 auf einem Quantum Computer:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_096.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8beuwX8zVd_"
      },
      "source": [
        "**Appendix: What is the Gate structure in $U$?**\n",
        "\n",
        "* $a^{x_1}$, $a^{x_2}$, $a^{x_n}$ tells you this is a controlled operation\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_098.png)\n",
        "\n",
        "* look now how the exponent doesn't contain $x_1$, $x_2$, .. $x_n$ anymore\n",
        "\n",
        "* this is done by implementing it by doing these controls\n",
        "\n",
        "* this is exactly like quantum phase estimation\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_099.png)\n",
        "\n",
        "**Der linke Term stammt aus QPE, der rechte Term ist der Teil $U$ aus Shor's Algorithms:**\n",
        "\n",
        "> <font color=\"blue\">$U^{2^{x}}=a^{2^{x}}(\\bmod N)$</font>\n",
        "\n",
        "continue: https://youtu.be/IFmkzWF-S2k?t=1181"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Phase Estimation*"
      ],
      "metadata": {
        "id": "GXXGNyygfl3B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Exkurs: Quantum Phase Kickback*"
      ],
      "metadata": {
        "id": "Op-cit2CFEiK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNOT Gate and Phase Kickback**\n",
        "\n",
        "<font color=\"blue\">*CNOT-Gate applied to the computational basis 0 and 1*\n",
        "\n",
        "* https://qiskit.org/textbook/ch-gates/phase-kickback.html\n",
        "\n",
        "* Main article about Phase Kickback: https://towardsdatascience.com/quantum-phase-kickback-bb83d976a448\n",
        "\n",
        "The CNOT-gate is a two-qubit gate. Thus, it transforms qubit states whose state we represent by a four-dimensional vector.\n",
        "\n",
        ">$\n",
        "|\\psi\\rangle=\\alpha|0\\rangle|0\\rangle+\\beta|0\\rangle|1\\rangle+\\gamma|1\\rangle|0\\rangle+\\delta|1\\rangle|1\\rangle=\\left[\\begin{array}{c}\n",
        "\\alpha \\\\\n",
        "\\beta \\\\\n",
        "\\gamma \\\\\n",
        "\\delta\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n",
        "Remember Vector-Vector-Multiplikation (Kronecker / tensor product):\n",
        "\n",
        "> $\\mathbf{uv}$ = $\\left[\\begin{array}{c}u_{1} \\\\ u_{2}\\end{array}\\right]$ $\\otimes$ $\\left[\\begin{array}{c}v_{1} \\\\ v_{2} \\end{array}\\right]$ = $\\left[\\begin{array}{l}u_{1}\\left[\\begin{array}{l}v_{1} \\\\ v_{2}\\end{array}\\right] \\\\ u_{2}\\left[\\begin{array}{l}v_{1} \\\\ v_{2}\\end{array}\\right]\\end{array}\\right]$=  $\\left[\\begin{array}{c}u_{1} v_{1} \\\\ u_{1} v_{2}\\\\ u_{2} v_{1} \\\\ u_{2} v_{2}\\end{array}\\right]$\n",
        "\n",
        "> $\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]=|0\\rangle, \\quad\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right]=|1\\rangle$.\n",
        "\n",
        "We choose two qubits in state $|0\\rangle$:\n",
        "\n",
        "> $|0\\rangle \\otimes|0\\rangle = \\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right] \\otimes\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]=$</font> $\\left[\\begin{array}{l}1\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right] \\\\ 0\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]\\end{array}\\right]=$ $\\left [\\begin{array}{l}11 \\\\ 10 \\\\ 01 \\\\ 00\\end{array}\\right]$ = <font color=\"gray\">$\\left [\\begin{array}{l}3 \\\\ 2 \\\\ 1 \\\\ 0\\end{array}\\right]$</font> = <font color=\"blue\">$\\left [\\begin{array}{l}1 \\\\ 0 \\\\ 0 \\\\ 0\\end{array}\\right]$\n",
        "\n",
        "Quits in two different states:\n",
        "\n",
        "> $|0\\rangle \\otimes|1\\rangle = \\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right] \\otimes\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right]=\\left[\\begin{array}{l}1\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right] \\\\ 0\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right]\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\ 1 \\\\ 0 \\\\ 0\\end{array}\\right]$\n",
        "\n",
        "Accordingly, the CNOT-gate has a $4 \\times 4$ transformation matrix.\n",
        "\n",
        ">$\n",
        "C N O T=\\left[\\begin{array}{llll}\n",
        "1 & 0 & 0 & 0 \\\\\n",
        "0 & 1 & 0 & 0 \\\\\n",
        "0 & 0 & 0 & 1 \\\\\n",
        "0 & 0 & 1 & 0\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n",
        "There is no effect if the control qubit (at the left-hand position in the Dirac notation) is in state |0⟩, as in states |00⟩ and |01⟩.\n",
        "\n",
        "> CNOT $\\cdot|00\\rangle=\\left[\\begin{array}{llll}1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0\\end{array}\\right] \\cdot\\left[\\begin{array}{l}1 \\\\ 0 \\\\ 0 \\\\ 0\\end{array}\\right]=\\left[\\begin{array}{l}1 \\\\ 0 \\\\ 0 \\\\ 0\\end{array}\\right]=|00\\rangle$\n",
        "\n",
        "> CNOT $\\cdot|01\\rangle=\\left[\\begin{array}{llll}1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0\\end{array}\\right] \\cdot\\left[\\begin{array}{l}0 \\\\ 1 \\\\ 0 \\\\ 0\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\ 1 \\\\ 0 \\\\ 0\\end{array}\\right]=|01\\rangle$\n",
        "\n",
        "<font color=\"blue\">But if the control qubit is in state |1⟩, then the controlled (target) qubit switches from |0⟩ to |1⟩ and vice versa.</font>\n",
        "\n",
        "> CNOT $\\cdot|10\\rangle=\\left[\\begin{array}{llll}1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0\\end{array}\\right] \\cdot\\left[\\begin{array}{l}0 \\\\ 0 \\\\ 1 \\\\ 0\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\ 0 \\\\ 0 \\\\ 1\\end{array}\\right]=|11\\rangle$\n",
        "\n",
        "> CNOT $\\cdot|11\\rangle=\\left[\\begin{array}{llll}1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0\\end{array}\\right] \\cdot\\left[\\begin{array}{l}0 \\\\ 0 \\\\ 0 \\\\ 1\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\ 0 \\\\ 1 \\\\ 0\\end{array}\\right]=|10\\rangle$\n",
        "\n",
        "When we describe the quantum states and operations in terms of mathematical formulae, we use the vectors |0⟩ and |1⟩ as a basis. |0⟩ and |1⟩ denote the standard or computational basis states. These states correspond to the possible measurements we might obtain when looking at the qubit. We measure a qubit in state |0⟩ as 0 with absolute certainty. And, we measure a qubit in state |1⟩ as 1, accordingly. While the basis {|0⟩,|1⟩} is convenient to work with mathematically, it is just a representation of the underlying physics.\n"
      ],
      "metadata": {
        "id": "-0AI_GVFZk0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\">*CNOT-Gate applied to the superposition basis + and -*\n",
        "\n",
        "The mathematical basis we chose leads to a specific representation of the CNOT-transformation. But this is not the only possible representation. In fact, there are infinitely many other possible choices. Our qubits are not limited to these two states. Qubits can be in a superposition of both states. For instance, there are the states that result from applying the Hadamard-gate on the basis states:\n",
        "\n",
        "> $|+\\rangle=\\left[\\begin{array}{c}\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}}\\end{array}\\right]$ and $|-\\rangle=\\left[\\begin{array}{c}\\frac{1}{\\sqrt{2}} \\\\ -\\frac{1}{\\sqrt{2}}\\end{array}\\right]$\n",
        "\n",
        "Remember: Apply Hadamard gate on a qubit that is in the |0> state:\n",
        "\n",
        "> $\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right)\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{l}1 \\\\ 1\\end{array}\\right]$\n",
        "\n",
        "Now apply Hadamard gate on a qubit that is in the |1> state:\n",
        "\n",
        "> $\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right)\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right]=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{l}1 \\\\ -1\\end{array}\\right]$\n",
        "\n",
        "Mathematically, the following matrix represents the application of Hadamard gates on each of the two qubits.\n",
        "\n",
        "> $H \\otimes H=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{cc}H & H \\\\ H & -H\\end{array}\\right]=\\frac{1}{2}\\left[\\begin{array}{cccc}1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1\\end{array}\\right]$\n",
        "\n",
        "So, if we apply this matrix on two qubits in state |00⟩, they end up in state |++⟩.\n",
        "\n",
        "> $\\begin{aligned} H \\otimes H(|00\\rangle) &=\\frac{1}{2}\\left[\\begin{array}{cccc}1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1\\end{array}\\right] \\cdot\\left[\\begin{array}{l}1 \\\\ 0 \\\\ 0 \\\\ 0\\end{array}\\right]=\\frac{1}{2}\\left[\\begin{array}{l}1 \\\\ 1 \\\\ 1 \\\\ 1\\end{array}\\right] \\\\ &=\\frac{1}{2}(|0\\rangle|0\\rangle+|0\\rangle|1\\rangle+|1\\rangle|0\\rangle+|1\\rangle|1\\rangle) \\\\ &=\\frac{1}{\\sqrt{2}}(|0\\rangle+|1\\rangle) \\otimes \\frac{1}{\\sqrt{2}}(|0\\rangle+|1\\rangle) \\\\ &=|++\\rangle \\end{aligned}$\n",
        "\n",
        "The input state |01⟩ results in state |+−⟩.\n",
        "\n",
        "> $\\begin{aligned} H \\otimes H(|01\\rangle) &=\\frac{1}{2}\\left[\\begin{array}{cccc}1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1\\end{array}\\right] \\cdot\\left[\\begin{array}{l}0 \\\\ 1 \\\\ 0 \\\\ 0\\end{array}\\right]=\\frac{1}{2}\\left[\\begin{array}{c}1 \\\\ -1 \\\\ 1 \\\\ -1\\end{array}\\right] \\\\ &=\\frac{1}{2}(|0\\rangle|0\\rangle-|0\\rangle|1\\rangle+|1\\rangle|0\\rangle-|1\\rangle|1\\rangle) \\\\ &=\\frac{1}{\\sqrt{2}}(|0\\rangle-|1\\rangle) \\otimes \\frac{1}{\\sqrt{2}}(|0\\rangle+|1\\rangle) \\\\ &=|+-\\rangle \\end{aligned}$\n",
        "\n",
        "The input state |10⟩ results in state |−+⟩.\n",
        "\n",
        "> $\\begin{aligned} H \\otimes H(|10\\rangle) &=\\frac{1}{2}\\left[\\begin{array}{cccc}1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1\\end{array}\\right] \\cdot\\left[\\begin{array}{l}0 \\\\ 0 \\\\ 1 \\\\ 0\\end{array}\\right]=\\frac{1}{2}\\left[\\begin{array}{c}1 \\\\ 1 \\\\ -1 \\\\ -1\\end{array}\\right] \\\\ &=\\frac{1}{2}(|0\\rangle|0\\rangle+|0\\rangle|1\\rangle-|1\\rangle|0\\rangle-|1\\rangle|1\\rangle) \\\\ &=\\frac{1}{\\sqrt{2}}(|0\\rangle+|1\\rangle) \\otimes \\frac{1}{\\sqrt{2}}(|0\\rangle-|1\\rangle) \\\\ &=|-+\\rangle \\end{aligned}$\n",
        "\n",
        "Finally, if we apply this transformation on two qubits in state |11⟩, we put them into state |−−⟩.\n",
        "\n",
        "> $\\begin{aligned} H \\otimes H(|11\\rangle) &=\\frac{1}{2}\\left[\\begin{array}{cccc}1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1\\end{array}\\right] \\cdot\\left[\\begin{array}{l}0 \\\\ 0 \\\\ 0 \\\\ 1\\end{array}\\right]=\\frac{1}{2}\\left[\\begin{array}{c}1 \\\\ -1 \\\\ -1 \\\\ 1\\end{array}\\right] \\\\ &=\\frac{1}{2}(|0\\rangle|0\\rangle-|0\\rangle|1\\rangle-|1\\rangle|0\\rangle+|1\\rangle|1\\rangle) \\\\ &=\\frac{1}{\\sqrt{2}}(|0\\rangle-|1\\rangle) \\otimes \\frac{1}{\\sqrt{2}}(|0\\rangle-|1\\rangle) \\\\ &=|--\\rangle \\end{aligned}$"
      ],
      "metadata": {
        "id": "7s9KUHDdV_5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let’s apply the CNOT-gate on qubits in superposition. We can calculate the overall transformation matrix by multiplying the matrices of the CNOT-gate and the H⊗H transformation. The CNOT-gate switches the second and fourth columns of the H⊗H-matrix.\n",
        "\n",
        "> $\\operatorname{CNOT}(H \\otimes H)=\\left[\\begin{array}{cccc}1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0\\end{array}\\right] \\cdot \\frac{1}{2}\\left[\\begin{array}{cccc}1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & 1 & -1 & -1 \\\\ 1 & -1 & -1 & 1\\end{array}\\right]=\\frac{1}{2}\\left[\\begin{array}{cccc}1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & -1 & -1 & 1 \\\\ 1 & 1 & -1 & -1\\end{array}\\right]$\n",
        "\n",
        "* And now, we apply this transformation to the four combinations of basis states.\n",
        "\n",
        "<font color=\"blue\">If the target qubit (at the right-hand side) is in state |1⟩, the state of the control qubit (at the left-hand side) flips from |+⟩ to |−⟩ and vice versa:\n",
        "\n",
        ">\n",
        "\n",
        "> $\\begin{aligned} \\operatorname{CNOT}(H \\otimes H(|00\\rangle)) &=\\frac{1}{2}\\left[\\begin{array}{cccc}1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & -1 & -1 & 1 \\\\ 1 & 1 & -1 & -1\\end{array}\\right] \\cdot\\left[\\begin{array}{l}1 \\\\ 0 \\\\ 0 \\\\ 0\\end{array}\\right]=\\frac{1}{2}\\left[\\begin{array}{l}1 \\\\ 1 \\\\ 1 \\\\ 1\\end{array}\\right] \\\\ &=\\frac{1}{2}(|0\\rangle|0\\rangle+|0\\rangle|1\\rangle+|1\\rangle|0\\rangle+|1\\rangle|1\\rangle) \\\\ &=\\frac{1}{\\sqrt{2}}(|0\\rangle+|1\\rangle) \\otimes \\frac{1}{\\sqrt{2}}(|0\\rangle+|1\\rangle) \\\\ &=|++\\rangle \\end{aligned}$\n",
        "\n",
        "> $\\begin{aligned} \\operatorname{CNOT}(H \\otimes H(|01\\rangle)) &=\\frac{1}{2}\\left[\\begin{array}{cccc}1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & -1 & -1 & 1 \\\\ 1 & 1 & -1 & -1\\end{array}\\right] \\cdot\\left[\\begin{array}{l}0 \\\\ 1 \\\\ 0 \\\\ 0\\end{array}\\right]=\\frac{1}{2}\\left[\\begin{array}{c}1 \\\\ -1 \\\\ -1 \\\\ 1\\end{array}\\right] \\\\ &=\\frac{1}{2}(|0\\rangle|0\\rangle-|0\\rangle|1\\rangle-|1\\rangle|0\\rangle+|1\\rangle|1\\rangle) \\\\ &=\\frac{1}{\\sqrt{2}}(|0\\rangle-|1\\rangle) \\otimes \\frac{1}{\\sqrt{2}}(|0\\rangle-|1\\rangle) \\\\ &=|--\\rangle \\end{aligned}$\n",
        "\n",
        "> $\\begin{aligned} \\operatorname{CNOT}(H \\otimes H(|10\\rangle)) &=\\frac{1}{2}\\left[\\begin{array}{cccc}1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & -1 & -1 & 1 \\\\ 1 & 1 & -1 & -1\\end{array}\\right] \\cdot\\left[\\begin{array}{l}0 \\\\ 0 \\\\ 1 \\\\ 0\\end{array}\\right]=\\frac{1}{2}\\left[\\begin{array}{c}1 \\\\ 1 \\\\ -1 \\\\ -1\\end{array}\\right] \\\\ &=\\frac{1}{2}(|0\\rangle|0\\rangle+|0\\rangle|1\\rangle-|1\\rangle|0\\rangle-|1\\rangle|1\\rangle) \\\\ &=\\frac{1}{\\sqrt{2}}(|0\\rangle-|1\\rangle) \\otimes \\frac{1}{\\sqrt{2}}(|0\\rangle+|1\\rangle) \\\\ &=|-+\\rangle \\end{aligned}$\n",
        "\n",
        "> $\\begin{aligned} \\operatorname{CNOT}(H \\otimes H(|11\\rangle)) &=\\frac{1}{2}\\left[\\begin{array}{cccc}1 & 1 & 1 & 1 \\\\ 1 & -1 & 1 & -1 \\\\ 1 & -1 & -1 & 1 \\\\ 1 & 1 & -1 & -1\\end{array}\\right] \\cdot\\left[\\begin{array}{l}0 \\\\ 0 \\\\ 0 \\\\ 1\\end{array}\\right]=\\frac{1}{2}\\left[\\begin{array}{c}1 \\\\ -1 \\\\ 1 \\\\ -1\\end{array}\\right] \\\\ &=\\frac{1}{2}(|0\\rangle|0\\rangle-|0\\rangle|1\\rangle+|1\\rangle|0\\rangle-|1\\rangle|1\\rangle) \\\\ &=\\frac{1}{\\sqrt{2}}(|0\\rangle+|1\\rangle) \\otimes \\frac{1}{\\sqrt{2}}(|0\\rangle-|1\\rangle) \\\\ &=|+-\\rangle \\end{aligned}$\n",
        "\n",
        "In short, we can say:\n",
        "\n",
        "> $\\operatorname{CNOT}(|++\\rangle)=|++\\rangle$\n",
        "\n",
        "> $\\operatorname{CNOT}(|+-\\rangle)=|--\\rangle$\n",
        "\n",
        "> $\\operatorname{CNOT}(|-+\\rangle)=|-+\\rangle$\n",
        "\n",
        "> $\\operatorname{CNOT}(|--\\rangle)=|+-\\rangle$\n",
        "\n",
        "The two states |+⟩ and |−⟩ have the same measurement probabilities of |0⟩ and |1⟩. They result in either value with a probability of 0.5. **So, the CNOT-gate does not have any directly measurable implications**. <font color=\"blue\">However, the control qubit switches its phase. It takes on the phase of the controlled (target) qubit.</font>\n",
        "\n",
        "> For the phase of the target qubit is kicked up to the control qubit, we call this phenomenon phase kickback.\n",
        "\n",
        "We learned the CNOT-gate is not a one-sided operation. It clearly has the potential to affect the state of the control qubit. Even though the phase is not directly measurable, there are ways to exploit differences in the phase between states. In fact, prominent algorithms, such as Grover’s search algorithm, exploit this effect.\n"
      ],
      "metadata": {
        "id": "Tg8PpY31YMh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\">**Phase Kickback: Control qubit changes:**\n",
        "* from 0 to 1 or from 1 to 0 if target qubit was in state 1,\n",
        "* from (+) to (-) or from (-) to (+) if the target was in (-)"
      ],
      "metadata": {
        "id": "9Z_IIWzYdHD3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZwuxaKm4lF2"
      },
      "source": [
        "**Quantum Phase Estimation**\n",
        "\n",
        "* algorithm for determining the eigenvalues of a unitary operator\n",
        "\n",
        "* the [quantum phase estimation algorithm](https://en.m.wikipedia.org/wiki/Quantum_phase_estimation_algorithm) (also referred to as quantum eigenvalue estimation algorithm), is a quantum algorithm to estimate the phase (or eigenvalue) of an eigenvector of a unitary operator.\n",
        "\n",
        "* More precisely, given a unitary matrix $U$ and a quantum state $|\\psi\\rangle$ such that $U|\\psi\\rangle=e^{2 \\pi i \\theta}|\\psi\\rangle$, the algorithm estimates the value of $\\theta$ with high probability within additive error $\\varepsilon$, using $O(\\log (1 / \\varepsilon))$ qubits (without counting the ones used to encode the eigenvector state) and $O(1 / \\varepsilon)$ controlled- $U$ operations.\n",
        "\n",
        "* The algorithm was initially introduced by Alexei Kitaev in 1995.\n",
        "\n",
        "* Phase estimation is frequently used as a subroutine in other quantum algorithms, such as Shor's algorithm and the quantum algorithm for linear systems of equations.\n",
        "\n",
        "<font color=\"blue\">*One Qubit Phase Estimation (with Hadamard Gate):*\n",
        "\n",
        "![gg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_117.png)\n",
        "\n",
        "<font color=\"blue\">*Multi-Qubit Phase Estimation (with inverse Quantum Fourier Transform):*\n",
        "\n",
        "![gg](https://upload.wikimedia.org/wikipedia/commons/a/a5/PhaseCircuit-crop.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f7UKWz2y03L"
      },
      "source": [
        "Remember in **Quantum Fourier Transform**:\n",
        "\n",
        "\n",
        "> x1 = $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{\\mathrm{x}_{1}}{2}+\\frac{x_{2}}{4}+\\frac{x_{3}}{8}\\right)}|1\\rangle\\right)$\n",
        "\n",
        "* <font color=\"blue\">$e^{2\\pi i}$ = 1 = identity</font>\n",
        "\n",
        "* In Quantum Fourier Transform we change the phase <font color=\"blue\">$\\theta$ in $e^{2\\pi i}$</font> <font color=\"red\">$^{\\theta}$</font>\n",
        "\n",
        "  * <font color=\"red\">= Eigenvalue of Oracle function $U$ associated with an eigenvector |u⟩</font>\n",
        "\n",
        "* Phase <font color=\"blue\">$\\theta$ is $\\frac{x_n}{2^{k}}$ with $x_n$ 0 or 1</font> state and $k$ number of Qubits.\n",
        "\n",
        "* A controlled-R quantum gate applies a relative phase change to |1>. The matrix form of this operator is: <font color=\"blue\">$\\hat{R}_{k}=\\left(\\begin{array}{cc}1 & 0 \\\\ 0 & e^{2 \\pi i / 2^{k}}\\end{array}\\right)$\n",
        "\n",
        "**Now in Phase Estimation**:\n",
        "\n",
        "> In $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{\\mathrm{x}_{1}}{2}+\\frac{x_{2}}{4}+\\frac{x_{3}}{8}\\right)}|1\\rangle\\right)$ dieser Teil ist die **Phase $\\theta$** = $(\\frac{\\mathrm{x}_{1}}{2}+\\frac{x_{2}}{4}+\\frac{x_{3}}{8})$ mit dem Operator: $U^{2^n} = \\phi$\n",
        "\n",
        "Quantum phase estimation addresses the following problem:\n",
        "* We have a $n$-qubit oracle function $U$, encoded in the form of a controlled- $U$ unitary.\n",
        "* **$U$ has an eigenvalue $e^{2 \\pi i \\phi}$, associated with an eigenvector $|u\\rangle$ which we can prepare.**\n",
        "* <font color=\"red\">**We wish to estimate the phase, $\\phi$, of the eigenvalue to $t$ bits of precision.**\n",
        "\n",
        "> <font color=\"blue\">**Given a unitary operator $U$, the algorithm estimates $\\theta$ in $U|\\psi\\rangle=e^{2 \\pi i \\theta}|\\psi\\rangle$** $\\quad$ (based on Eigenvalue equation)</font>\n",
        "\n",
        "* Here $|\\psi\\rangle$ is an eigenvector / eigenstate and $e^{2 \\pi i \\theta}$ is the corresponding eigenvalue.\n",
        "\n",
        "* <font color=\"red\">For example: the eigenvalues of X are −1 and 1 and have the eigenvectors |−⟩ and |+⟩ respectively.*</font>\n",
        "\n",
        "*Since $U$ is unitary, all of its eigenvalues have a norm of 1.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG-6ThVrEdXJ"
      },
      "source": [
        "Reminder: QFT\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_084.png)\n",
        "\n",
        ">**See below: <font color=\"red\">Remember that a unitary matrix has eigenvalues of the form $e^{i \\theta_{\\psi}}$ (ohne $2 \\pi$ wie oben bei QFT) and that it has eigenvectors that form an orthonormal basis**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_083.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p-zzXyW-tU6"
      },
      "source": [
        "The problem: in both cases the probability is 0,5, just differs by the phase added: $=e^{\\frac{i \\pi}{2}}$\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_078.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSvCLdgF_YQC"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_079.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rHCBrjo_ZWr"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_080.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scRiAADhBR3t"
      },
      "source": [
        "**The probability of measuring 0 and 1 is each 0,5, but there is a small factor that makes them differ from 0,5, depending on the phase (angle):**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_081.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0oYz_yZBCoU"
      },
      "source": [
        "> **In the different between the probability of measuring 0 or 1, you've encoded that phase! (In other words: you've taken that phase information and turned it into and amplitude that you can measure.**\n",
        "\n",
        "* How to do this experimentally: you do a million shots of the experiment, collect statistics and check what the statistics say. How many times did I get zero? How many times did I get one? The hope is that the difference between the statistics of zero and one would allow us to back out theta\n",
        "\n",
        "* Next level: now getting more precision with more qubits: (there is another circuit to prepare Psi yet, which is assumed to be given here)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_082.png)\n",
        "\n",
        "writing out the calculation:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_085.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib1qf44PHLJJ"
      },
      "source": [
        "**Comparing QPE with QFT (QPE is the same as QFT with a different phase):**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_086.png)\n",
        "\n",
        "It's like applying a QFT of something (of a special phase $\\frac{\\theta_{\\psi}}{2^{n}} 2 \\pi$, the green box above!), and in order to get back to the original state you need to apply an inverse QFT at the end:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_087.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step 1: Set up the unitary and number of bits to use in phase estimation*\n",
        "\n",
        "<font color=\"blue\">*Let's take as an example the T-gate, and use Quantum Phase Estimation to estimate its phase.*\n",
        "\n",
        "You will remember that the $T$-gate adds a phase of $e^{\\frac{i \\pi}{4}}$ to the state $|1\\rangle$ :\n",
        "\n",
        "$\n",
        "T|1\\rangle=\\left[\\begin{array}{ll}\n",
        "1 & 0 \\\\\n",
        "0 & e^{\\frac{i \\pi}{4}}\n",
        "\\end{array}\\right]\\left[\\begin{array}{l}\n",
        "0 \\\\\n",
        "1\n",
        "\\end{array}\\right]=e^{\\frac{i \\pi}{4}}|1\\rangle\n",
        "$\n",
        "\n",
        "Since QPE will give us $\\theta$ where: $\n",
        "T|1\\rangle=e^{2 i \\pi \\theta}|1\\rangle\n",
        "$\n",
        "\n",
        "<font color=\"red\">We expect to find theta: $\n",
        "\\theta=\\frac{1}{8}\n",
        "$\n",
        "\n",
        "We first perform a Hadamard gate on the first qubit to get the state\n",
        "\n",
        "  * Original state of both qubits: $|0\\rangle \\otimes|\\psi\\rangle$\n",
        "\n",
        "  * Hadamard on first qubit: $|+\\rangle \\otimes|\\psi\\rangle$ =\n",
        "\n",
        "  * <font color=\"red\">Distribute superposition: $|0\\rangle|\\psi\\rangle+|1\\rangle|\\psi\\rangle$</font>\n",
        "\n",
        "  * <font color=\"blue\">this part above is the rule from tensor products: If the state of the first particle is a superposition of two states, the state of the two-particle system is also a superposition: $\\left(v_{1}+v_{2}\\right) \\otimes w=v_{1} \\otimes w+v_{2} \\otimes w$\n",
        "</font>\n",
        "\n",
        "    * The Hadamard states ∣+⟩ and ∣−⟩ are considered superposition states because they are a combination of the two computational states:\n",
        "\n",
        "    * State: $|\\pm\\rangle=\\frac{1}{\\sqrt{2}}|0\\rangle \\pm \\frac{1}{\\sqrt{2}}|1\\rangle$ so for + it is: $|\\+\\rangle=\\frac{1}{\\sqrt{2}}|0\\rangle + \\frac{1}{\\sqrt{2}}|1\\rangle$\n",
        "\n",
        "  * we have intentionally omitted the normalization factor of 1/√2 for clarity\n",
        "\n",
        "> $|+\\rangle \\otimes|\\psi\\rangle = \\frac{1}{\\sqrt{2}}\\left[\\begin{array}{l}1 \\\\ 1\\end{array}\\right] \\otimes\\left[\\begin{array}{l}\\psi\\end{array}\\right]= \\frac{1}{\\sqrt{2}}\\left[\\begin{array}{l}1 \\, [\\psi] \\\\ 1 \\, [\\psi]\\end{array}\\right]$\n",
        "\n",
        "Remember: Apply Hadamard gate on a qubit that is in the |0> state:\n",
        "\n",
        "> $|+\\rangle$ = $\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right)\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{l}1 \\\\ 1\\end{array}\\right]$ =  $\\frac{1}{\\sqrt{2}}|0\\rangle + \\frac{1}{\\sqrt{2}}|1\\rangle$"
      ],
      "metadata": {
        "id": "mV4nEZ1l2VMu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zxsy6Cc5Wrx"
      },
      "source": [
        "# Value of θ which appears in the definition of the unitary U above.\n",
        "# Try different values.\n",
        "theta = 0.125\n",
        "\n",
        "# Define the unitary U-Gate:\n",
        "U = cirq.Z ** (2 * theta)\n",
        "\n",
        "# Accuracy of the estimate for theta. Try different values.\n",
        "n_bits = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8u3NsIlTNsO"
      },
      "source": [
        "Here details about unitary U-Gate:\n",
        "\n",
        "$U$ = $Z^{2^{n-n}}$\n",
        "\n",
        "Z = $e^{\\pi}$\n",
        "\n",
        "* $Z$ entspricht $\\pi$ (ein halber Kreis, zB von +1 zu -1 auf X-Achse)\n",
        "\n",
        "\n",
        "then:\n",
        "\n",
        "> <font color=\"blue\">$U$ = $e^{\\pi * 2^{n-n}}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step 2: Build the first part of the circuit for phase estimation with controlled U-gate (Phase Kickback)*\n",
        "\n",
        "We then perform a controlled U operation, which we have written as $U^{2^0}$. Here applies the **Phase Kickback!**\n",
        "\n",
        "  * $|0\\rangle|\\psi\\rangle+|1\\rangle$ <font color=\"red\">$U$</font> $|\\psi\\rangle$ =\n",
        "\n",
        "  * $|0\\rangle|\\psi\\rangle+$ <font color=\"red\">$e^{2 \\pi i 0. \\phi_{1}}$</font> $|1\\rangle|\\psi\\rangle$ =\n",
        "\n",
        "  * $|0\\rangle+$ <font color=\"red\">$e^{2 \\pi i 0. \\phi_{1}}$</font> $|1\\rangle) \\otimes|\\psi\\rangle$\n",
        "\n",
        "* Here are 2 things very important:\n",
        "\n",
        "    * The second qubit register containing |ψ⟩ hasn’t changed. We shouldn’t expect it to, **since |ψ⟩ is an eigenstate of U (Remember: <font color=\"blue\">**Given a unitary operator $U$, the algorithm estimates $\\theta$ in $U|\\psi\\rangle=e^{2 \\pi i \\theta}|\\psi\\rangle$ based on the Eigenvalue equation**</font>). Thus, no matter how many times we apply U to this register, nothing happens to |ψ⟩**. But if we apply it more often it will 'amplify' the phase (Not in the sense of amplitude amplification) - we amplify it with adding more qubits and hence more $\\phi$ to get more precision\n",
        "\n",
        "    * what’s the point of applying U then? The effect was that **it wrote some information about the eigenvalue into the relative phase of the first qubit**. Namely, the entire effect was to\n",
        "map: $|0\\rangle+|1\\rangle \\mapsto|0\\rangle+e^{2 \\pi i 0. \\phi_{1}}|1\\rangle$"
      ],
      "metadata": {
        "id": "iQE_Unsl2YXo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMG3fjxw5aXU"
      },
      "source": [
        "# Get qubits for the phase estimation circuit.\n",
        "qubits = cirq.LineQubit.range(n_bits)\n",
        "u_bit = cirq.NamedQubit('u')\n",
        "\n",
        "# Build the first part of the phase estimation circuit.\n",
        "phase_estimator = cirq.Circuit(cirq.H.on_each(*qubits))\n",
        "\n",
        "# Set the input state of the eigenvalue register: Add gate to change initial state to |1>\n",
        "phase_estimator.insert(0, cirq.X(u_bit))\n",
        "\n",
        "# bit = cirq.LineQubit\n",
        "for i, bit in enumerate(qubits):\n",
        "    phase_estimator.append(cirq.ControlledGate(U).on(bit, u_bit) ** (2 ** (n_bits - i - 1)))\n",
        "    # explanation: U-rot control aktiviert wenn entsprechendes qubit in state 1 (??)\n",
        "    # dann aktiviere formel: U^2^(n-1) ...U^2^(n-2) ...U^2^(n-n)\n",
        "\n",
        "print(phase_estimator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoxXF9-W9orx"
      },
      "source": [
        "> <font color=\"blue\">$U$ = $Z^{2^{n-n}}$ = $e^{\\pi * 2^{n-n}}$ fur das erste Gate: = $e^{\\pi * (-0.128)}$ ????\n",
        "\n",
        "\n",
        "*Why are we adding Pauli-X? The initial state for u_bit is the  state, but the phase for this state is trivial with the operator we chose. Inserting a Pauli  operator at the begining of the circuit changes this to the  state, which has the nontrivial  phase.*\n",
        "\n",
        "*The controlled u gate*:\n",
        "\n",
        "$|00\\rangle \\mapsto|00\\rangle$\n",
        "\n",
        "$|01\\rangle \\mapsto|01\\rangle$\n",
        "\n",
        "$|10\\rangle \\mapsto|1\\rangle \\otimes U|0\\rangle=|1\\rangle \\otimes\\left(u_{00}|0\\rangle+u_{10}|1\\rangle\\right)$\n",
        "\n",
        "$|11\\rangle \\mapsto|1\\rangle \\otimes U|1\\rangle=|1\\rangle \\otimes\\left(u_{01}|0\\rangle+u_{11}|1\\rangle\\right)$\n",
        "\n",
        "The matrix representing the controlled $U$ is\n",
        "\n",
        ">$\n",
        "\\mathrm{C} U=\\left[\\begin{array}{cccc}\n",
        "1 & 0 & 0 & 0 \\\\\n",
        "0 & 1 & 0 & 0 \\\\\n",
        "0 & 0 & u_{00} & u_{01} \\\\\n",
        "0 & 0 & u_{10} & u_{11}\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n",
        "**When U is one of the Pauli operators, X,Y, Z, the respective terms \"controlled-X\", \"controlled-Y\", or \"controlled-Z\" are sometimes used**.\n",
        "Sometimes this is shortened to just CX, CY and CZ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti0MmESYOnrd"
      },
      "source": [
        "<font color=\"blue\">*Why should we use more than one control Qubit?*\n",
        "\n",
        "**Remember from Eigenvalue problem: Ax = λx in our case with the unitary operator: Ux = λx**\n",
        "\n",
        "> $Ux =$ <font color=\"red\">$e^{2πi*0.\\varphi_{1} \\varphi_{2} \\cdots \\varphi_{n} }$</font> $x$\n",
        "\n",
        "> Beispiel: Wenn $0.\\varphi_{1} \\varphi_{2} \\cdots \\varphi_{n} = 0$, dann ist $e^{2πi*0}$ = λ = 1, so dass Ux = 1x. Damit ist λ = 1 ist der Eigenwert von f.\n",
        "\n",
        "* Since |λ| = 1, we can write it without loss of generality as λ = $e^{2πiφ}$, where <font color=\"red\">$e^{2πi}$ = 1 (= identity, if you insert 2*π*i into exponent at random, you will not change the result. Sometimes it can be a useful identity [Source](https://www.physicsforums.com/threads/e-2-pi-i-where-from.430393/), from Euler identity)</font> and **0 ≤ φ ≤ 1 is called the phase. This is what we want to estimate!**\n",
        "\n",
        "* We saw that in QFT, φ being between 0 and 1 $\\rightarrow$ $\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{\\mathrm{x}_{1}}{2}+\\frac{x_{2}}{4}+\\frac{x_{3}}{8}\\right)}$\n",
        "\n",
        "> **The term “estimation” comes about not from the fact that quantum computation is probabilistic, but rather in the degree of precision that we are going to compute, or estimate, the phase to.**\n",
        "\n",
        "* The phase φ is going to be between zero and one, so we can write it as a decimal in binary notation as follows: $φ = 0.φ_1 φ_2 ···φ_n$, where each φi is either zero or one\n",
        "\n",
        "  * The expression $\\phi=0 . \\phi_{1} \\phi_{2} \\cdots \\phi_{n}$ is equivalent to $\\phi=0 . \\phi_{1} \\phi_{2} \\cdots \\phi_{n} \\Longleftrightarrow \\phi=\\sum_{k=1}^{n} \\phi_{k} 2^{-k}$. Some numbers as binary decimals:\n",
        "\n",
        "    * <font color=\"blue\">The number 0.5 in decimal is 0.1 in binary, since 0.1 ≡ (1) · $2^{−1}$ = 1/2 = 0.5. So: $0.5_{10} = 0.1_2$. Note that 0.1 is the same as 0.100000....</font>\n",
        "\n",
        "    * <font color=\"blue\">The number 0.75 in decimal is 0.11 in binary, since 0.11 ≡ (1)·$2^{−1}$ +1·$2^{−2}$ = 1/2+1/4 = 3/4 = 0.75. To get this we need 2 Qubits. So we get more precision with more qubits</font>\n",
        "\n",
        "    * 0.111 = 0.875\n",
        "\n",
        "    * 0.1111 = 0.9375 in decimal, because: $0 \\cdot 2^{0}+1 \\cdot 2^{-1}+1 \\cdot 2^{-2}+1 \\cdot 2^{-3}+1 \\cdot 2^{-4}=0 \\cdot 1+1 \\cdot 0.5+1 \\cdot 0.25+1 \\cdot 0.125+1 \\cdot 0.0625=0+0.5+0.25+0.125+0.0625=0.937510$\n",
        "\n",
        "  * Check also what is the value of the infinitely repeating binary decimal 0.1111111...\n",
        "\n",
        "  * If it needed to be proved, the above exercise proves that 0 ≤ 0.φ1φ2 · · · ≤ 1\n",
        "\n",
        "\n",
        "*Operator $U^{2^n}$ in QPE*\n",
        "\n",
        "* $U^{2^0}$: 1 (decimal) = 00001\n",
        "\n",
        "* $U^{2^1}$: 2 (decimal) = 00010\n",
        "\n",
        "* $U^{2^2}$: 4 (decimal) = 00100\n",
        "\n",
        "* $U^{2^3}$: 8 (decimal) = 01000\n",
        "\n",
        "* $U^{2^4}$: 16 (decimal) = 10000\n",
        "\n",
        "\n",
        "**So for falls die Phase 0.111 ist, wuerde bei 3 Qubits QPE berechnen:**\n",
        "\n",
        "* $e^{2 \\pi i 0. \\varphi_{1} \\varphi_{2} \\varphi_{3}}$</font> = $e^{2 \\pi i 0.(U^{2^0} + U^{2^1} + U^{2^2})}$  = <font color=\"red\">$e^{2 \\pi i 0.001 + 010 + 100)}$</font>  = $e^{2 \\pi i 0.111}$\n",
        "\n",
        "  * $2^0$ = 1 in decimal = 001 in binary\n",
        "\n",
        "  * $2^1$ = 2 in decimal = 010 in binary\n",
        "\n",
        "  * $2^2$ = 4 in decimal = 100 in binary\n",
        "\n",
        "* in this case the phase $\\theta$ = 0.111\n",
        "\n",
        "\n",
        "**Compare that with Quantum Fourier Transform:**\n",
        "\n",
        "* In $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle+\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{\\mathrm{x}_{1}}{2}+\\frac{x_{2}}{4}+\\frac{x_{3}}{8}\\right)}|1\\rangle\\right)$ dieser Teil ist die **Phase $\\theta$** = $(\\frac{\\mathrm{x}_{1}}{2}+\\frac{x_{2}}{4}+\\frac{x_{3}}{8})$\n",
        "\n",
        "* Let's say all $x_1, x_2$ and $x_3$ = 1 $\\rightarrow$ $\\mathrm{e}^{2 \\pi \\mathrm{i}\\left(\\frac{{1}}{2}+\\frac{1}{4}+\\frac{1}{8}\\right)}$ = $\\mathrm{e}^{2 \\pi \\mathrm{i}(0.5+0.25+0.125)}$ and in binary form: <font color=\"red\">$\\mathrm{e}^{2 \\pi \\mathrm{i}(0.100+0.010+0.001)}$</font>\n",
        "\n",
        "* **We see that in QFT and QPE it's the same (both in red)!**\n",
        "\n",
        "<font color=\"red\">Jedes $U^{2^n}$ wird immer dann aktiviert, wenn im Control-Qubit oben eine 1 gemessen wird (siehe Bild hier unten):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzz61dyQB_6X"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_118.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et3XRupiWg0n"
      },
      "source": [
        "*Step 3: Perform the inverse QFT on the estimation qubits and measure them*\n",
        "\n",
        "\n",
        "How can we read out this information from the quantum state? Consider the effect of applying another Hadamard transformation on the first qubit (without another H we will always measure 50/50 % a 0 or 1), which will produce (ignoring the normalization factor of 1/2):\n",
        "\n",
        "  * $H(|0\\rangle+$ <font color=\"red\">$e^{2 \\pi i 0 \\cdot \\phi_{1}}$</font> $|1\\rangle)=$ $(1+$<font color=\"red\">$e^{2 \\pi i 0. \\phi_{1}}$</font>$)|0\\rangle$ + $(1-$<font color=\"red\">$e^{2 \\pi i 0 . \\phi_{1}}$</font>$)|1\\rangle$\n",
        "\n",
        "  * this shares the phase with the first Qubit and allows us to read it out\n",
        "\n",
        "  * Now, $\\phi_{1}$ can only be zero or one. In the case that $\\phi_{1}=0, e^{2 \\pi i 0 . \\phi_{1}}=1$, hence the state is exactly $|0\\rangle$: $(\\frac{1}{2}\\left(1+e^{2 \\pi i 0 . 0}\\right)|0\\rangle+\\frac{1}{2}\\left(1-e^{2 \\pi i 0 . 0}\\right)|1\\rangle$ = $\\frac{1}{2}\\left(1+1\\right)|0\\rangle+\\frac{1}{2}\\left(1-1\\right)|1\\rangle$ = $|0\\rangle$\n",
        "\n",
        "  * these values in front of $|0\\rangle$ and $|1\\rangle$ are probabilities (here 0 has probability of being measured = 1, but small differences her reveal the phase and hence the Eigenvalue in other cases. See here:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_081.png)\n",
        "\n",
        "* **For 1 Qubit we can use a Hadamard Gate, and for more than 1 Qubit we use the inverse Fourier Transform**: on Quantum Phase Estimation $\\frac{1}{2^{\\frac{n}{2}}} \\sum_{k=0}^{2^{n}-1} e^{2 \\pi i \\theta k}$ then the inverse Quantum Fourier transform:  <font color=\"red\">$ \\frac{1}{2^{\\frac{n}{2}}} \\sum_{x=0}^{2^{n}-1} e^{\\frac{-2 \\pi i k x}{2^{n}}}|x\\rangle$</font> so that: $\\frac{1}{2^{\\frac{n}{2}}} \\sum_{k=0}^{2^{n}-1} e^{2 \\pi i \\theta k}$ <font color=\"red\">$ \\frac{1}{2^{\\frac{n}{2}}} \\sum_{x=0}^{2^{n}-1} e^{\\frac{-2 \\pi i k x}{2^{n}}}|x\\rangle$</font>\n",
        "\n",
        "  * inverse QFT for 1 Qubit is: $ \\frac{1}{2^{\\frac{1}{2}}} \\sum_{x=0}^{2^{1}-1} e^{\\frac{-2 \\pi i k x}{2^{1}}}|x\\rangle$ = $\\frac{1}{\\sqrt{2}} e^{-1 \\pi i k x}$ fur $k$ = $\\varphi$ = 0 and $x$ = 0. --> somehting is not right here yet!\n",
        "\n",
        "Thus, we measure with certainty (i.e., not probabilistically) a state that tells us exactly what the phase,\n",
        "and hence the eigenvalue, is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv_xQnY__HDH"
      },
      "source": [
        "def make_qft_inverse(qubits):\n",
        "    \"\"\"Generator for the inverse QFT on a list of qubits.\"\"\"\n",
        "    qreg = list(qubits)[::-1]\n",
        "    while len(qreg) > 0:\n",
        "        q_head = qreg.pop(0)\n",
        "        yield cirq.H(q_head)\n",
        "        for i, qubit in enumerate(qreg):\n",
        "            yield (cirq.CZ ** (-1 / 2 ** (i + 1)))(qubit, q_head)\n",
        "\n",
        "# Do the inverse QFT\n",
        "phase_estimator.append(make_qft_inverse(qubits[::-1]))\n",
        "\n",
        "# Add measurements to the end of the circuit\n",
        "phase_estimator.append(cirq.measure(*qubits, key='m'))\n",
        "print(phase_estimator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Syntax explanation for list(qubits)[::-1]: list[<start>:<stop>:<step>]\n",
        "# So, when you do a[::-1], it starts from the end towards the first taking each element.\n",
        "# So it reverses a. This is applicable for lists/tuples as well.\n",
        "# Example: >>> a = '1234' >>> a[::-1] will get you: '4321'"
      ],
      "metadata": {
        "id": "4GAmFOoFH6wN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step 4: Simulate the circuit and convert from measured bit values to estimated θ values*"
      ],
      "metadata": {
        "id": "oJVEbP4OGB6p"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPBFj8JyDYCd"
      },
      "source": [
        "# Simulate the circuit.\n",
        "sim = cirq.Simulator()\n",
        "result = sim.run(phase_estimator, repetitions=10)\n",
        "\n",
        "# Convert from output bitstrings to estimate θ values.\n",
        "theta_estimates = np.sum(2 ** np.arange(n_bits) * result.measurements['m'], axis=1) / 2**n_bits\n",
        "print(theta_estimates)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Plot the results.\"\"\"\n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "\n",
        "plt.plot(theta_estimates, \"--o\", label=\"Phase estimation\")\n",
        "plt.axhline(theta, label=\"True value\", color=\"black\")\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"Number of trials\")\n",
        "plt.ylabel(r\"$\\theta$\");"
      ],
      "metadata": {
        "id": "7kifm9aPIcJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2iff49oDyK9"
      },
      "source": [
        "def phase_estimation(theta, n_bits, n_reps=10, prepare_eigenstate_gate=cirq.X):\n",
        "    # Define qubit registers.\n",
        "    qubits = cirq.LineQubit.range(n_bits)\n",
        "    u_bit = cirq.NamedQubit('u')\n",
        "\n",
        "    # Define the unitary U.\n",
        "    U = cirq.Z ** (2 * theta)\n",
        "\n",
        "    # Start with Hadamards on every qubit.\n",
        "    phase_estimator = cirq.Circuit(cirq.H.on_each(*qubits))\n",
        "\n",
        "    # Do the controlled powers of the unitary U.\n",
        "    for i, bit in enumerate(qubits):\n",
        "        phase_estimator.append(cirq.ControlledGate(U).on(bit, u_bit) ** (2 ** (n_bits - 1 - i)))\n",
        "\n",
        "    # Do the inverse QFT.\n",
        "    phase_estimator.append(make_qft_inverse(qubits[::-1]))\n",
        "\n",
        "    # Add measurements.\n",
        "    phase_estimator.append(cirq.measure(*qubits, key='m'))\n",
        "\n",
        "    # Gate to choose initial state for the u_bit. Placing X here chooses the |1> state.\n",
        "    phase_estimator.insert(0, prepare_eigenstate_gate.on(u_bit))\n",
        "\n",
        "    # Code to simulate measurements\n",
        "    sim = cirq.Simulator()\n",
        "    result = sim.run(phase_estimator, repetitions=n_reps)\n",
        "\n",
        "    # Convert measurements into estimates of theta\n",
        "    theta_estimates = np.sum(2**np.arange(n_bits)*result.measurements['m'], axis=1)/2**n_bits\n",
        "\n",
        "    return theta_estimates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Analyze convergence vs n_bits.\"\"\"\n",
        "# Set the value of theta. Try different values.\n",
        "theta = 0.123456\n",
        "\n",
        "max_nvals = 16\n",
        "nvals = np.arange(1, max_nvals, step=1)\n",
        "\n",
        "# Get the estimates at each value of n.\n",
        "estimates = []\n",
        "for n in nvals:\n",
        "    estimate = phase_estimation(theta=theta, n_bits=n, n_reps=1)[0]\n",
        "    estimates.append(estimate)\n",
        "\n",
        "print(theta_estimates)\n",
        "print(estimates)\n",
        "\n",
        "\"\"\"Plot the results.\"\"\"\n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "\n",
        "plt.plot(nvals, estimates, \"--o\", label=\"Phase estimation\")\n",
        "plt.axhline(theta, label=\"True value\", color=\"black\")\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"Number of bits\")\n",
        "plt.ylabel(r\"$\\theta$\");"
      ],
      "metadata": {
        "id": "N5ZJqQs63tbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Step 5: Compute the Eigenvalues from the theta value*\n",
        "\n",
        "Eigenvalue: $e^{2 \\pi i \\theta}$ is the corresponding eigenvalue, so for $\\theta$ = 0.125 $\\rightarrow$ $e^{2 * \\pi * i * 0.125}$ = <font color=\"blue\">0.707106781 + 0.707106781 i (Eigenvalue of T-gate)</font>\n",
        "\n",
        "* Verification: $\n",
        "T|1\\rangle=\\left[\\begin{array}{ll}\n",
        "1 & 0 \\\\\n",
        "0 & e^{\\frac{i \\pi}{4}}\n",
        "\\end{array}\\right]\\left[\\begin{array}{l}\n",
        "0 \\\\\n",
        "1\n",
        "\\end{array}\\right]=e^{\\frac{i \\pi}{4}}|1\\rangle\n",
        "$ $\\rightarrow$ <font color=\"blue\">$e^{\\frac{i \\pi}{4}}$ is the same as $e^{2 * \\pi * i * 0.125}$ bzw. $e^{\\frac{2 * \\pi * i}{8}}$</font>\n",
        "\n",
        "* $e^{2 \\pi i 0. \\varphi_{1} \\varphi_{2} \\varphi_{3}}$</font> = $e^{2 \\pi i 0.(U^{2^0} + U^{2^1} + U^{2^2})}$  = <font color=\"red\">$e^{2 \\pi i 0.001 + 010 + 100)}$</font>  = $e^{2 \\pi i 0.111}$\n",
        "\n",
        "* ps: $e^{2 \\pi i}$ =  1 (identity) - ohne theta, die phase\n",
        "\n",
        "* From Eigenvalue euqation: $Ux =$ <font color=\"red\">$e^{2πi*0.\\varphi_{1} \\varphi_{2} \\cdots \\varphi_{n} }$</font> $x$. Beispiel: Wenn $0.\\varphi_{1} \\varphi_{2} \\cdots \\varphi_{n} = 0$, dann ist $e^{2πi*0}$ = λ = 1, so dass Ux = 1x. Damit ist λ = 1 ist der Eigenwert von f.\n",
        "\n",
        "* https://quantumcomputing.stackexchange.com/questions/9577/how-to-find-eigenvalues-and-eigenvector-for-a-quantum-gate\n",
        "\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_115.png)\n"
      ],
      "metadata": {
        "id": "DvJzmiWfKQi0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Harrow-Hassidim-Lloyd Algorithm (HHL)*"
      ],
      "metadata": {
        "id": "w9lDedY3fgnk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\">**Solving a system of linear equations with a quantum computer (HHL)**\n",
        "\n",
        "* **Given a matrix $A \\in \\mathbb{C}^{N \\times N}$ and a vector $\\vec{b} \\in \\mathbb{C}^{N}$, find $\\vec{x} \\in \\mathbb{C}^{N}$ satisfying $A \\vec{x}=\\vec{b}$**\n",
        "\n",
        "* The spectrum of $A$ is given by: $A\\left|v_{j}\\right\\rangle=\\lambda_{j}\\left|v_{j}\\right\\rangle, 1 \\geq\\left|\\lambda_{j}\\right| \\geq 1 / \\kappa$\n",
        "\n",
        "\n",
        "**Objective: We want to solve a system of linear equations by finding $\\vec{x}$**\n",
        "\n",
        "* Familiar methods of solutions: Substitution method, Graphical method, Matrix method, Cramer's rule, Gaussian elimination\n",
        "\n",
        "* The classical algorithm returns the full solution, while the HHL can only approximate functions of the solution vector.\n",
        "\n",
        "\n",
        "> $A \\vec{x} = \\vec{b}$\n",
        "\n",
        "Classically you would take the inverse of $A$ (via spectral decomposition / eigendecomposition):\n",
        "\n",
        "> $\\vec{x} = A^{-1} \\vec{b}$\n",
        "\n",
        "The first step towards solving a system of linear equations with a quantum computer is to encode the problem in the quantum language.\n",
        "\n",
        "* By rescaling the system, we can assume $\\vec{b}$ and $\\vec{x}$ to be normalised and map them to the respective quantum states $|b\\rangle$ and $|x\\rangle$.\n",
        "\n",
        "* Usually the mapping used is such that $i^{\\text {th }}$ component of $\\vec{b}$ (resp. $\\vec{x}$ ) corresponds to the amplitude of the $i^{\\text {th }}$ basis state of the quantum state $|b\\rangle$ (resp. $|x\\rangle$ ).\n",
        "\n",
        "From now on, we will focus on the rescaled problem\n",
        "\n",
        "><font color=\"blue\">$A|x\\rangle=|b\\rangle\n",
        "$</font> $\\quad$ (System of linear equations in a quantum state)\n",
        "\n",
        "And we want to find this:\n",
        "\n",
        "><font color=\"blue\">$|x\\rangle=A^{-1}|b\\rangle$</font> $\\quad$ (the solution is: $|x\\rangle = \\sum_{j=0}^{N-1} \\lambda_{j}^{-1} b_{j}\\left|u_{j}\\right\\rangle$)\n",
        "\n",
        "We need to find the inverse matrix $A^{-1}$. We can get the matrix inverse via eigendecomposition. Since $A$ is Hermitian (normal!), it has a spectral decomposition:\n",
        "\n",
        ">$\n",
        "A=\\sum_{j=0}^{N-1} \\lambda_{j}\\left|u_{j}\\right\\rangle\\left\\langle u_{j}\\right|, \\quad \\lambda_{j} \\in \\mathbb{R}\n",
        "$\n",
        "\n",
        "where $\\left|u_{j}\\right\\rangle$ is the $j^{t h}$ eigenvector of $A$ with respective eigenvalue $\\lambda_{j}$. Then,\n",
        "\n",
        ">$\n",
        "A^{-1}=\\sum_{j=0}^{N-1} \\lambda_{j}^{-1}\\left|u_{j}\\right\\rangle\\left\\langle u_{j}\\right|\n",
        "$\n",
        "\n",
        "and the right hand side of the system can be written in the eigenbasis of $A$ as\n",
        "\n",
        ">$\n",
        "|b\\rangle=\\sum_{j=0}^{N-1} b_{j}\\left|u_{j}\\right\\rangle, \\quad b_{j} \\in \\mathbb{C}\n",
        "$\n",
        "\n",
        "It is useful to keep in mind that the goal of the HHL is to exit the algorithm with the readout register in the state\n",
        "\n",
        ">$\n",
        "|x\\rangle=A^{-1}|b\\rangle=\\sum_{j=0}^{N-1} \\lambda_{j}^{-1} b_{j}\\left|u_{j}\\right\\rangle\n",
        "$\n",
        "\n",
        "Note that here we already have an implicit normalisation constant since we are talking about a quantum state."
      ],
      "metadata": {
        "id": "KM2Pu-BkaiCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HHL-Algorithm**\n",
        "\n",
        "*Main Subroutines in HHL: Hamiltonian simulation, Phase estimation (newer: linear combination of unitaries) and (Variable-time) amplitude amplification*\n",
        "\n",
        "1. Prepare the initial state $|b\\rangle$. Note that $|b\\rangle=\\sum_{j} c_{j}\\left|v_{j}\\right\\rangle$.\n",
        "\n",
        "2. Use the so-called phase estimation algorithm to perform the map\n",
        "$|b\\rangle \\rightarrow \\sum_{j} c_{j}\\left|v_{j}\\right\\rangle\\left|\\tilde{\\lambda}_{j}\\right\\rangle$\n",
        "\n",
        "* $|\\tilde{\\lambda}_{j}\\rangle$ -> This register contains the eigenvalue estimates.\n",
        "\n",
        "3. Apply a one-qubit conditional rotation to perform the map\n",
        "$|0\\rangle \\rightarrow \\frac{1}{\\kappa \\tilde{\\lambda}_{j}}|0\\rangle+\\sqrt{1-\\frac{1}{\\kappa^{2} \\tilde{\\lambda}_{j}^{2}}}|1\\rangle$\n",
        "\n",
        "4. Undo step 2 - apply the inverse of phase estimation\n",
        "$\\sum_{j} \\frac{c_{j}}{\\kappa \\tilde{\\lambda}_{j}}\\left|v_{j}\\right\\rangle|0\\rangle+|\\mathrm{bad}\\rangle|1\\rangle \\approx \\frac{1}{\\kappa A}|b\\rangle|0\\rangle+|\\mathrm{bad}\\rangle|1\\rangle$\n",
        "\n",
        "5. Use amplitude amplification to get rid of the „bad“ part of the state with |1>\n"
      ],
      "metadata": {
        "id": "eMEyUUJGasUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pylint: disable=wrong-or-nonexistent-copyright-notice\n",
        "# https://github.com/quantumlib/Cirq/blob/main/examples/hhl.py\n",
        "\n",
        "\"\"\"Demonstrates the algorithm for solving linear systems by Harrow, Hassidim, Lloyd (HHL).\n",
        "\n",
        "The HHL algorithm solves a system of linear equations, specifically equations of the form Ax = b,\n",
        "where A is a Hermitian matrix, b is a known vector, and x is the unknown vector. To solve on a\n",
        "quantum system, b must be rescaled to have magnitude 1, and the equation becomes:\n",
        "\n",
        "|x> = A**-1 |b> / || A**-1 |b> ||\n",
        "\n",
        "The algorithm uses 3 sets of qubits: a single ancilla qubit, a register (to store eigenvalues of\n",
        "A), and memory qubits (to store |b> and |x>). The following are performed in order:\n",
        "1) Quantum phase estimation to extract eigenvalues of A\n",
        "2) Controlled rotations of ancilla qubit\n",
        "3) Uncomputation with inverse quantum phase estimation\n",
        "\n",
        "For details about the algorithm, please refer to papers in the REFERENCE section below. The\n",
        "following description uses variables defined in the HHL paper.\n",
        "\n",
        "This example is an implementation of the HHL algorithm for arbitrary 2x2 Hermitian matrices. The\n",
        "output of the algorithm are the expectation values of Pauli observables of |x>. Note that the\n",
        "accuracy of the result depends on the following factors:\n",
        "* Register size\n",
        "* Choice of parameters C and t\n",
        "\n",
        "The result is perfect if\n",
        "* Each eigenvalue of the matrix is in the form\n",
        "\n",
        "  2π/t * k/N,\n",
        "\n",
        "  where 0≤k<N, and N=2^n, where n is the register size. In other words, k is a value that can be\n",
        "  represented exactly by the register.\n",
        "* C ≤ 2π/t * 1/N, the smallest eigenvalue that can be stored in the circuit.\n",
        "\n",
        "The result is good if the register size is large enough such that for every pair of eigenvalues,\n",
        "the ratio can be approximated by a pair of possible register values. Let s be the scaling factor\n",
        "from possible register values to eigenvalues. One way to set t is\n",
        "\n",
        "t = 2π/(sN)\n",
        "\n",
        "For arbitrary matrices, because properties of their eigenvalues are typically unknown, parameters C\n",
        "and t are fine-tuned based on their condition number.\n",
        "\n",
        "\n",
        "=== REFERENCE ===\n",
        "Harrow, Aram W. et al. Quantum algorithm for solving linear systems of\n",
        "equations (the HHL paper)\n",
        "https://arxiv.org/abs/0811.3171\n",
        "\n",
        "Coles, Eidenbenz et al. Quantum Algorithm Implementations for Beginners\n",
        "https://arxiv.org/abs/1804.03719\n",
        "\n",
        "=== CIRCUIT ===\n",
        "Example of circuit with 2 register qubits.\n",
        "\n",
        "(0, 0): ─────────────────────────Ry(θ₄)─Ry(θ₁)─Ry(θ₂)─Ry(θ₃)──────────────M──\n",
        "                     ┌──────┐    │      │      │      │ ┌───┐\n",
        "(1, 0): ─H─@─────────│      │──X─@──────@────X─@──────@─│   │─────────@─H────\n",
        "           │         │QFT^-1│    │      │      │      │ │QFT│         │\n",
        "(2, 0): ─H─┼─────@───│      │──X─@────X─@────X─@────X─@─│   │─@───────┼─H────\n",
        "           │     │   └──────┘                           └───┘ │       │\n",
        "(3, 0): ───e^iAt─e^2iAt───────────────────────────────────────e^-2iAt─e^-iAt─\n",
        "\n",
        "Note: QFT in the above diagram omits swaps, which are included implicitly by\n",
        "reversing qubit order for phase kickbacks.\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import sympy\n",
        "import cirq\n",
        "\n",
        "\n",
        "class PhaseEstimation(cirq.Gate):\n",
        "    \"\"\"A gate for Quantum Phase Estimation.\n",
        "\n",
        "    The last qubit stores the eigenvector; all other qubits store the estimated phase,\n",
        "    in big-endian.\n",
        "\n",
        "    Args:\n",
        "        num_qubits: The number of qubits of the unitary.\n",
        "        unitary: The unitary gate whose phases will be estimated.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_qubits, unitary):\n",
        "        self._num_qubits = num_qubits\n",
        "        self.U = unitary\n",
        "\n",
        "    def num_qubits(self):\n",
        "        return self._num_qubits\n",
        "\n",
        "    def _decompose_(self, qubits):\n",
        "        qubits = list(qubits)\n",
        "        yield cirq.H.on_each(*qubits[:-1])\n",
        "        yield PhaseKickback(self.num_qubits(), self.U)(*qubits)\n",
        "        yield cirq.qft(*qubits[:-1], without_reverse=True) ** -1\n",
        "\n",
        "\n",
        "class HamiltonianSimulation(cirq.EigenGate):\n",
        "    \"\"\"A gate that represents e^iAt.\n",
        "\n",
        "    This EigenGate + np.linalg.eigh() implementation is used here purely for demonstrative\n",
        "    purposes. If a large matrix is used, the circuit should implement actual Hamiltonian\n",
        "    simulation, by using the linear operators framework in Cirq, for example.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, A, t, exponent=1.0):\n",
        "        cirq.EigenGate.__init__(self, exponent=exponent)\n",
        "        self.A = A\n",
        "        self.t = t\n",
        "        ws, vs = np.linalg.eigh(A)\n",
        "        self.eigen_components = []\n",
        "        for w, v in zip(ws, vs.T):\n",
        "            theta = w * t / math.pi\n",
        "            P = np.outer(v, np.conj(v))\n",
        "            self.eigen_components.append((theta, P))\n",
        "\n",
        "    def _num_qubits_(self) -> int:\n",
        "        return 1\n",
        "\n",
        "    def _with_exponent(self, exponent):\n",
        "        return HamiltonianSimulation(self.A, self.t, exponent)\n",
        "\n",
        "    def _eigen_components(self):\n",
        "        return self.eigen_components\n",
        "\n",
        "\n",
        "class PhaseKickback(cirq.Gate):\n",
        "    \"\"\"A gate for the phase kickback stage of Quantum Phase Estimation.\n",
        "\n",
        "    It consists of a series of controlled e^iAt gates with the memory qubit as the target and\n",
        "    each register qubit as the control, raised to the power of 2 based on the qubit index.\n",
        "    unitary is the unitary gate whose phases will be estimated.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_qubits, unitary):\n",
        "        super(PhaseKickback, self)\n",
        "        self._num_qubits = num_qubits\n",
        "        self.U = unitary\n",
        "\n",
        "    def num_qubits(self):\n",
        "        return self._num_qubits\n",
        "\n",
        "    def _decompose_(self, qubits):\n",
        "        qubits = list(qubits)\n",
        "        memory = qubits.pop()\n",
        "        for i, qubit in enumerate(qubits):\n",
        "            yield cirq.ControlledGate(self.U ** (2**i))(qubit, memory)\n",
        "\n",
        "\n",
        "class EigenRotation(cirq.Gate):\n",
        "    \"\"\"Perform a rotation on an ancilla equivalent to division by eigenvalues of a matrix.\n",
        "\n",
        "    EigenRotation performs the set of rotation on the ancilla qubit equivalent to division on the\n",
        "    memory register by each eigenvalue of the matrix. The last qubit is the ancilla qubit; all\n",
        "    remaining qubits are the register, assumed to be big-endian.\n",
        "\n",
        "    It consists of a controlled ancilla qubit rotation for each possible value that can be\n",
        "    represented by the register. Each rotation is a Ry gate where the angle is calculated from\n",
        "    the eigenvalue corresponding to the register value, up to a normalization factor C.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_qubits, C, t):\n",
        "        super(EigenRotation, self)\n",
        "        self._num_qubits = num_qubits\n",
        "        self.C = C\n",
        "        self.t = t\n",
        "        self.N = 2 ** (num_qubits - 1)\n",
        "\n",
        "    def num_qubits(self):\n",
        "        return self._num_qubits\n",
        "\n",
        "    def _decompose_(self, qubits):\n",
        "        for k in range(self.N):\n",
        "            kGate = self._ancilla_rotation(k)\n",
        "\n",
        "            # xor's 1 bits correspond to X gate positions.\n",
        "            xor = k ^ (k - 1)\n",
        "\n",
        "            for q in qubits[-2::-1]:\n",
        "                # Place X gates\n",
        "                if xor % 2 == 1:\n",
        "                    yield cirq.X(q)\n",
        "                xor >>= 1\n",
        "\n",
        "                # Build controlled ancilla rotation\n",
        "                kGate = cirq.ControlledGate(kGate)\n",
        "\n",
        "            yield kGate(*qubits)\n",
        "\n",
        "    def _ancilla_rotation(self, k):\n",
        "        if k == 0:\n",
        "            k = self.N\n",
        "        theta = 2 * math.asin(self.C * self.N * self.t / (2 * math.pi * k))\n",
        "        return cirq.ry(theta)\n",
        "\n",
        "\n",
        "def hhl_circuit(A, C, t, register_size, *input_prep_gates):\n",
        "    \"\"\"Constructs the HHL circuit.\n",
        "\n",
        "    Args:\n",
        "        A: The input Hermitian matrix.\n",
        "        C: Algorithm parameter, see above.\n",
        "        t: Algorithm parameter, see above.\n",
        "        register_size: The size of the eigenvalue register.\n",
        "        *input_prep_gates: A list of gates to be applied to |0> to generate the desired input\n",
        "            state |b>.\n",
        "\n",
        "    Returns:\n",
        "        The HHL circuit. The ancilla measurement has key 'a' and the memory measurement is in key\n",
        "        'm'.  There are two parameters in the circuit, `exponent` and `phase_exponent` corresponding\n",
        "        to a possible rotation  applied before the measurement on the memory with a\n",
        "        `cirq.PhasedXPowGate`.\n",
        "    \"\"\"\n",
        "\n",
        "    ancilla = cirq.LineQubit(0)\n",
        "    # to store eigenvalues of the matrix\n",
        "    register = [cirq.LineQubit(i + 1) for i in range(register_size)]\n",
        "    # to store input and output vectors\n",
        "    memory = cirq.LineQubit(register_size + 1)\n",
        "\n",
        "    c = cirq.Circuit()\n",
        "    hs = HamiltonianSimulation(A, t)\n",
        "    pe = PhaseEstimation(register_size + 1, hs)\n",
        "    c.append([gate(memory) for gate in input_prep_gates])\n",
        "    c.append(\n",
        "        [\n",
        "            pe(*(register + [memory])),\n",
        "            EigenRotation(register_size + 1, C, t)(*(register + [ancilla])),\n",
        "            pe(*(register + [memory])) ** -1,\n",
        "            cirq.measure(ancilla, key='a'),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    c.append(\n",
        "        [\n",
        "            cirq.PhasedXPowGate(\n",
        "                exponent=sympy.Symbol('exponent'), phase_exponent=sympy.Symbol('phase_exponent')\n",
        "            )(memory),\n",
        "            cirq.measure(memory, key='m'),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return c\n",
        "\n",
        "\n",
        "def simulate(circuit):\n",
        "    simulator = cirq.Simulator()\n",
        "\n",
        "    # Cases for measuring X, Y, and Z (respectively) on the memory qubit.\n",
        "    params = [\n",
        "        {'exponent': 0.5, 'phase_exponent': -0.5},\n",
        "        {'exponent': 0.5, 'phase_exponent': 0},\n",
        "        {'exponent': 0, 'phase_exponent': 0},\n",
        "    ]\n",
        "\n",
        "    results = simulator.run_sweep(circuit, params, repetitions=5000)\n",
        "\n",
        "    for label, result in zip(('X', 'Y', 'Z'), list(results)):\n",
        "        # Only select cases where the ancilla is 1.\n",
        "        # TODO: optimize using amplitude amplification algorithm.\n",
        "        # Github issue: https://github.com/quantumlib/Cirq/issues/2216\n",
        "        expectation = 1 - 2 * np.mean(result.measurements['m'][result.measurements['a'] == 1])\n",
        "        print(f'{label} = {expectation}')\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"The main program loop.\n",
        "\n",
        "    Simulates HHL with matrix input, and outputs Pauli observables of the resulting qubit state |x>.\n",
        "    Expected observables are calculated from the expected solution |x>.\n",
        "    \"\"\"\n",
        "\n",
        "    # Eigendecomposition:\n",
        "    #   (4.537, [-0.971555, -0.0578339+0.229643j])\n",
        "    #   (0.349, [-0.236813, 0.237270-0.942137j])\n",
        "    # |b> = (0.64510-0.47848j, 0.35490-0.47848j)\n",
        "    # |x> = (-0.0662724-0.214548j, 0.784392-0.578192j)\n",
        "    A = np.array(\n",
        "        [\n",
        "            [4.30213466 - 6.01593490e-08j, 0.23531802 + 9.34386156e-01j],\n",
        "            [0.23531882 - 9.34388383e-01j, 0.58386534 + 6.01593489e-08j],\n",
        "        ]\n",
        "    )\n",
        "    t = 0.358166 * math.pi\n",
        "    register_size = 4\n",
        "    input_prep_gates = [cirq.rx(1.276359), cirq.rz(1.276359)]\n",
        "    expected = (0.144130, 0.413217, -0.899154)\n",
        "\n",
        "    # Set C to be the smallest eigenvalue that can be represented by the\n",
        "    # circuit.\n",
        "    C = 2 * math.pi / (2**register_size * t)\n",
        "\n",
        "    # Simulate circuit.\n",
        "    print(\"Expected observable outputs:\")\n",
        "    print(\"X =\", expected[0])\n",
        "    print(\"Y =\", expected[1])\n",
        "    print(\"Z =\", expected[2])\n",
        "    print(\"Actual: \")\n",
        "    simulate(hhl_circuit(A, C, t, register_size, *input_prep_gates))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47vFYyP7bv6S",
        "outputId": "7adf2cd0-32f6-417b-c6f7-eca01b2751c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected observable outputs:\n",
            "X = 0.14413\n",
            "Y = 0.413217\n",
            "Z = -0.899154\n",
            "Actual: \n",
            "X = 0.17136329017517138\n",
            "Y = 0.4664561957379637\n",
            "Z = -0.9179331306990881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applications of HHL**\n",
        "\n",
        "* Systems of linear equations arise naturally in many real-life applications in a wide range of areas, such as in the solution of Partial Differential Equations, the calibration of financial models, fluid simulation or numerical field calculation.\n",
        "\n",
        "* Used in many quantum machine learning algorithms as a building block\n",
        "\n",
        "\n",
        "* The quantum algorithm for linear systems of equations has been applied to a support vector machine, which is an optimized linear or non-linear binary classifier (https://arxiv.org/abs/1307.0471v2)\n",
        "\n",
        "* for Least-squares fitting (https://arxiv.org/abs/1204.5242)\n",
        "\n",
        "* for finite-element-methods (https://arxiv.org/abs/1512.05903) (but only for higher problems which include solutions with higher-order derivatives and large spatial dimensions. For example, problems in many-body dynamics require the solution of equations containing derivatives on orders scaling with the number of bodies, and some problems in computational finance, such as Black-Scholes models, require large spatial dimensions)"
      ],
      "metadata": {
        "id": "EPYugWRQat26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Promise**:\n",
        "\n",
        "* Solving 10,000 linear equation: a classical computer needs in best case 10,000 steps. HHL just 13. The [quantum algorithm for linear systems of equations](https://en.m.wikipedia.org/wiki/Quantum_algorithm_for_linear_systems_of_equations) designed by Aram Harrow, Avinatan Hassidim, and Seth Lloyd: Provided the linear system is sparse and has a low condition number $\\kappa_{1}$ and that the user is interested in the result of a scalar measurement on the solution vector, instead of the values of the solution vector itself, then the algorithm has a runtime of $O\\left(\\log (N) \\kappa^{2}\\right)$, where $N$ is the number of variables in the linear system. This offers an exponential speedup over the fastest classical algorithm, which runs in $O(N \\kappa)$ (or $O(N \\sqrt{\\kappa})$ for positive semidefinite matrices).\n",
        "\n",
        "* Unlike the classical solutions to the Deutsch-Jozsa and search problems, most of our classical methods for matrix manipulation do work in polynomial time. However, as data analysis becomes more and more powerful (and more and more demanding on today’s computers), the size of these matrices can make even polynomial time too long.\n",
        "\n",
        "**Disadvantages:**\n",
        "\n",
        "* solution vector is not yielded (rather it prepares a quantum state that is proportional to the solution): Actually reading out the solution vector would take O(N)time, so we can only maintain the logarithmic runtime by sampling the solution vector like ⟨x|M|x⟩, where M is a quantum-mechanical operator. Therefore, **HHL is useful mainly in applications where only samples from the solution vector are needed**.\n",
        "\n",
        "* Entries of matrix have to be sparse: Additionally, although HHL is exponentially faster than Conjugate Gradient in N, it is polynomially slower in s and 𝜅, so HHL is restricted to only those matrices that are sparse and have low condition numbers.\n",
        "\n",
        "* Must satisfy robust invertibility (means that entries of matrix must all approx. of same size)\n",
        "\n",
        "* Preparation of input vector is complicated\n"
      ],
      "metadata": {
        "id": "rIe_VZCQavl5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Grover Search*"
      ],
      "metadata": {
        "id": "2VU6BC9nYCGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://web.archive.org/web/20171221161408/http://twistedoakstudios.com/blog/Post2644_grovers-quantum-search-algorithm\n",
        "\n",
        "https://www.lesswrong.com/posts/5vZD32EynD9n94dhr/configurations-and-amplitude"
      ],
      "metadata": {
        "id": "pLwQheEKWqG1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkgjkcQ3gZhD"
      },
      "source": [
        "> **[Grover’s algorithm](https://en.m.wikipedia.org/wiki/Grover's_algorithm) teaches us how we can search for an item in an unsorted list without needing to look at each item one by one but by looking at them all at once.**\n",
        "\n",
        "It accomplishes that using two techniques:\n",
        "\n",
        "  * First, it uses a quantum oracle to mark the searched state.\n",
        "\n",
        "  * Second, it uses a diffuser that amplifies the amplitude of the marked state to increase its measurement probability.\n",
        "\n",
        "Grover's Algorithm : Suche in grossen Datenbanken (Squared speedup: get result in the square root of time that on classical computers)\n",
        "\n",
        "* Auf einem klassischen Computer ist der prinzipiell schnellstmögliche Suchalgorithmus in einer unsortierten Datenbank die [lineare Suche](https://de.m.wikipedia.org/wiki/Lineare_Suche), die ${\\mathcal {O}}\\left(N\\right)$ Rechenschritte erfordert (Der Suchaufwand wächst linear mit der Anzahl der Elemente in der Liste.)\n",
        "\n",
        "* Die effizientere [Binäre Suche](https://de.m.wikipedia.org/wiki/Binäre_Suche) kann nur bei geordneten Listen benutzt werden. Die Binäre Suche ist deutlich schneller als die lineare Suche, welche allerdings den Vorteil hat, auch in unsortierten Feldern zu funktionieren. In Spezialfällen kann die [Interpolationssuche](https://de.m.wikipedia.org/wiki/Interpolationssuche) schneller sein als die binäre Suche.\n",
        "\n",
        "* Makes use of Amplitude Amplification, Quantum Walk & Quantum Counting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBmtO9AqRfgC"
      },
      "source": [
        "> Grover's Algorithm uses a phase shift to increase the amplitude of the favorable state and to decrease the amplitudes of all other states (=Phase Flip of Desired Outcome + Probability Amplitudes Inversion about the Mean to Amplify)\n",
        "\n",
        "Grover’s algorithm solves oracles that **add a negative phase to the solution states**. I.e. for any state |x⟩ in the computational basis:\n",
        "\n",
        "> $U_{\\omega}|x\\rangle=\\left\\{\\begin{aligned}|x\\rangle & \\text { if } x \\neq \\omega \\\\-|x\\rangle & \\text { if } x=\\omega \\end{aligned}\\right.$\n",
        "\n",
        "We create a function $f$ that takes a proposed solution $x$, and returns\n",
        "\n",
        "* $f(x)=0$ if $x$ is not a solution ( $x \\neq \\omega)$\n",
        "\n",
        "* $f(x)=1$ for a valid solution $(x=\\omega)$.\n",
        "\n",
        "The oracle can then be described as:\n",
        "\n",
        "> $U_{\\omega}|x\\rangle=(-1)^{f(x)}|x\\rangle$\n",
        "\n",
        "* you can see this is an Eigenvalue equation\n",
        "\n",
        "The oracle's matrix will be a diagonal matrix of the form:\n",
        "\n",
        "> $U_{\\omega}=\\left[\\begin{array}{cccc}(-1)^{f(0)} & 0 & \\cdots & 0 \\\\ 0 & (-1)^{f(1)} & \\cdots & 0 \\\\ \\vdots & 0 & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & (-1)^{f\\left(2^{n}-1\\right)}\\end{array}\\right]$\n",
        "\n",
        "*Source: https://qiskit.org/textbook/ch-algorithms/grover.html*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjEw1xzY4XrR"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_105.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9OKn5QL4ZEt"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_106.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9O3gEWD4ayN"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_107.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vJDLETO4cKX"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_108.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrowEYzZ4Ptk"
      },
      "source": [
        "*Step 1: Hadamard-Operator for Superposition + Assign a Phase -1 to the desired outcome*\n",
        "\n",
        "Start with a balanced superposition, and assign a phase of -1 to the chosen ket, 111). Assigning -1 means applying a Pauli-Z-operator in the superposition to this one !!\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_102.jpg)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_101.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkuU4yrjT4NB"
      },
      "source": [
        "**<font color=\"blue\">More about Amplitude Amplification**\n",
        "\n",
        "* [Amplitude amplification](https://en.m.wikipedia.org/wiki/Amplitude_amplification) is a technique in quantum computing which **generalizes the idea behind the Grover's search algorithm**, and gives rise to a family of quantum algorithms.\n",
        "\n",
        "* In a quantum computer, amplitude amplification can be used to **obtain a quadratic speedup over several classical algorithms**.\n",
        "\n",
        "1. If there are $G$ good entries in the database in total, then we can find them by initializing a quantum register $|\\psi\\rangle$ with $n$ qubits where $2^{n}=N$ into a uniform superposition of all the database elements $N$ such that\n",
        "\n",
        ">$| \\psi \\rangle=\\frac{1}{\\sqrt{N}} \\sum_{k=0}^{N-1}|k\\rangle\n",
        "$\n",
        "\n",
        "2. and running the above algorithm. In this case the overlap of the initial state with the good subspace is equal to the square root of the frequency of the good entries in the database, $\\sin (\\theta)=|P| \\psi\\rangle \\mid=\\sqrt{G / N}$. If $\\sin (\\theta) \\ll 1$,\n",
        "\n",
        "3. we can\n",
        "approximate the number of required iterations as\n",
        "\n",
        ">$\n",
        "n=\\left\\lfloor\\frac{\\pi}{4 \\theta}\\right\\rfloor \\approx\\left\\lfloor\\frac{\\pi}{4 \\sin (\\theta)}\\right\\rfloor=\\left\\lfloor\\frac{\\pi}{4} \\sqrt{\\frac{N}{G}}\\right\\rfloor=O(\\sqrt{N})\n",
        "$\n",
        "\n",
        "Measuring the state will now give one of the good entries with high probability.\n",
        "\n",
        "Since each application of $S_{P}$ requires a single oracle query (assuming that the oracle is implemented as a quantum gate), we can find a good entry with just $O(\\sqrt{N})$ oracle queries, thus obtaining a quadratic speedup over the best possible classical algorithm. (The classical method for searching the database would be to perform the query for every $e \\in\\{0,1, \\ldots, N-1\\}$ until a solution is found, thus costing $O(N)$ queries.) Moreover, we can find all $G$ solutions using $O(\\sqrt{G N})$ queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoynUeh6XX0t"
      },
      "source": [
        "* Now, let’s say four qubits are enough and Mr. Grover is known as |0010⟩. The oracle uses the specific characteristic of this state to identifying it. That is the state has a |1⟩ at the third position and |0⟩ otherwise.\n",
        "\n",
        "* Since the quantum oracle takes all qubits as input, it can easily apply a transformation of this exact state. It doesn’t matter whether we use four qubits or 33. The oracle identifies Mr. Grover in a single turn.\n",
        "\n",
        "* The transformation the oracle applies to the searched state is an inversion of the amplitude.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_109.png)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_110.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELkLvP9cX-_N"
      },
      "source": [
        "* In the representation above representation (the dark one) of the amplitudes, we can clearly see a difference between the searched state and all the other states. We could prematurely declare the search is over.\n",
        "\n",
        "* The only difference is in the sign of the amplitude. For the measurement probability results from the amplitude’ absolute square, the sign does not matter at all.\n",
        "\n",
        "* The amplitude originates from the concept that every quantum entity may be described not only as a particle but also as a wave. The main characteristic of a wave is that it goes up and down as it moves. The amplitude is the distance between the center and the crest of the wave.\n",
        "\n",
        "* If we invert the amplitude of a wave at all positions, the result is the same wave shifted by half of its wavelength.\n",
        "\n",
        "* These two waves differ only in their relative position. This is the phase of the wave. For the outside world, the phase of a wave is not observable. Observed individually, the two waves appear identical. So, the problem is we can’t tell the difference between these two waves.\n",
        "\n",
        "> As a consequence, the system does not appear any different from the outside. Even though the oracle marked the searched state and it, therefore, differs from the other states, all states still have the same measurement probability.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_111.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XWXZNDvSt2X"
      },
      "source": [
        "*Step 2: Invert all probability amplitudes about the mean + Measure*\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_103.jpg)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_103.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WSsCfvzaSx-"
      },
      "source": [
        "* We need to turn the difference into something measurable. We need to increase the measurement probability of the marked state. This is the task of the diffuser. The diffuser applies an inversion about the mean amplitude.\n",
        "\n",
        "* Let’s have a look at the average amplitude.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_112.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n63cW7pbbQVL"
      },
      "source": [
        "* With four qubits, we have 16 different states. Each state has an amplitude of 1/sqrt(16)=1/4. In fact, each but one state — the searched state has this amplitude. The searched state has an amplitude of −1/4. Thus, the average is (15∗1/4−1/4)/16=0.21875.\n",
        "\n",
        "* The average is a little less than the amplitude of all states we did not mark. If we invert these amplitudes by this mean, they end up a little lower than the average at 0.1875.\n",
        "\n",
        "* For the amplitude of the marked state is negative, it is quite far away from the average. The inversion about the mean has a greater effect. It flips the amplitude from −0.25 by 2∗(0.25+0.21875) to 0.6875 (bzw: =0,21875-(-0,25-0,21875)).\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_113.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cZMnRRIbolE"
      },
      "source": [
        "* The inversion about the mean works well if we search for a single or a few negative amplitudes among many positive amplitudes. Then, this operation increases the negative amplitudes we know are the correct ones. And this operation decreases the positive amplitudes, we know are wrong.\n",
        "\n",
        "> This operation increases the negative amplitude by a large amount while decreasing the positive amplitudes by a small amount.\n",
        "\n",
        "* But the more states we have, the lower the overall effect will be. In our example, we calculated the new amplitude of the searched state as 0.6875. The corresponding measurement probability is 0.6875^2=0.47265625. Accordingly, we measure this system only about every other time in the state we are looking for. Otherwise, we measure it in any other case.\n",
        "\n",
        "* Of course, we could now measure the system many times and see our searched state as the most probable one. But running the algorithm so many times would give away any advantage we gained from not searching all the states.\n",
        "\n",
        "> **Instead, we repeat the algorithm. We use the same oracle to negate the amplitude of the searched state. Then we invert all the amplitudes around the mean, again**.\n",
        "\n",
        "However, we must not repeat this process too many times. There is an optimal number of times of repeating this process to get the greatest chance of measuring the correct answer.\n",
        "\n",
        "* The probability of obtaining the correct result grows until we reach about π/4*sqrt(N) with N is the number of states of the quantum system. Beyond this number, the probability of measuring the correct result decreases again.\n",
        "\n",
        "* In our example with four qubits and N=16 states, the optimum number of iterations is 3.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_104.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuIq27h5ge43"
      },
      "source": [
        "https://towardsdatascience.com/towards-understanding-grovers-search-algorithm-2cdc4e885660"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWV-r4APgANP"
      },
      "source": [
        "*Grover Search: Simple Examples (Z-Gate and I-Gate as amplifiers. with H as Diffuser)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y77PyMqZgnEg"
      },
      "source": [
        "**Example 1: Z Gate to switch from 0 to 1**\n",
        "\n",
        "* Let’s say the state |1⟩ depicts the favorable state we want to find. Then, the oracle consists of the Z-gate that switches the amplitude when the corresponding qubit is in state |1⟩.\n",
        "\n",
        "* As a result, we see the amplitude changed for state |1⟩. The qubit is now in state |−⟩. Its two states |0⟩ and |1⟩ are in two different phases, now.\n",
        "\n",
        "* In other words, we flipped the amplitude of state |1⟩ from positive to negative.\n",
        "\n",
        "* Both states still have a measurement probability of 0.5. It is the task of the diffuser to magnify the amplitude to favor the searched state.\n",
        "\n",
        "* **The diffuser in a single-qubit circuit is quite simple. It is another H-gate**. This circuit results in state |1⟩ with absolute certainty.\n",
        "\n",
        "We apply an important sequence on the qubit, the HZH-circuit. This circuit is known as an identity to the NOT-gate (X-gate) that turns state |0⟩ into |1⟩ and vice versa.\n",
        "\n",
        "The following equation proves this identity.\n",
        "\n",
        "> $H Z H=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right]\\left[\\begin{array}{cc}1 & 0 \\\\ 0 & -1\\end{array}\\right] \\frac{1}{\\sqrt{2}}\\left[\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right]=\\left[\\begin{array}{ll}0 & 1 \\\\ 1 & 0\\end{array}\\right]=X$\n",
        "\n",
        "Then, why would we use the HZH-sequence? If it is similar to the NOT-gate, why don’t we use that instead?\n",
        "\n",
        "<font color=\"red\">Simply put, the HZH-sequence is more flexible. It is the simplest form of Grover’s search algorithm.</font> It starts with all states being equal (the first H-gate). It applies an oracle (Z-gate).\n",
        "\n",
        "And, <font color=\"blue\">**it uses a diffuser that amplifies the amplitude of the selected state |1⟩ (the second H-gate)**.\n",
        "\n",
        "> While we could rewrite these two circuits more succinctly, the circuit identities of HZH=X and HIH=I let us use the general structure of Grover’s algorithm. Simply by changing the oracle, we can mark and amplify different states. We don’t need to come up with a new algorithm for each possible state we want to select out of a list. But we only need to find an appropriate oracle. This ability comes in handy the more states our quantum system has.\n",
        "\n",
        "> The search for one of two possible states does not even deserve to be called a search. But the general structure of Grover’s algorithm is not different from this very simple example. **It uses a phase shift to increase the amplitude of the favorable state and to decrease the amplitudes of all other states**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bMTt-MVijqL"
      },
      "source": [
        "**Quantum Counting**\n",
        "\n",
        "> **In quantum counting, we simply use the quantum phase estimation algorithm to find an eigenvalue of a Grover search iteration.**\n",
        "\n",
        "* how many solutions exist?\n",
        "\n",
        "* does there any solution exist?\n",
        "\n",
        "\n",
        "The percentage number of solutions in our search space affects the difference between $|s\\rangle$ and $\\left|s^{\\prime}\\right\\rangle$. For example, if there are not many solutions, $|s\\rangle$ will be very close to $\\left|s^{\\prime}\\right\\rangle$ and $\\theta$ will be very small. It turns out that the eigenvalues of the Grover iterator are $e^{\\pm i \\theta}$, and **we can extract this using quantum phase estimation (QPE) to estimate the number of solutions $(M)$**.\n",
        "\n",
        "**First we want to get $\\theta$ from measured_int. (phase estimation)**\n",
        "\n",
        "* You will remember that $\\mathrm{QPE}$ gives us a measured value $=2^{n} \\phi$ from the eigenvalue $e^{2 \\pi i \\phi}$,\n",
        "\n",
        "* so to get $\\theta$ we need to do:\n",
        "\n",
        "> $\n",
        "\\theta=\\text { value } \\times \\frac{2 \\pi}{2^{t}}\n",
        "$\n",
        "\n",
        "**Second, we calculate the inner product of $|s\\rangle$ and $\\left|s^{\\prime}\\right\\rangle:$**\n",
        "\n",
        "> $\n",
        "\\left\\langle s^{\\prime} \\mid s\\right\\rangle=\\cos \\frac{\\theta}{2}\n",
        "$\n",
        "\n",
        "* And that $|s\\rangle$ (a uniform superposition of computational basis states) can be written in terms of $|\\omega\\rangle$ and $\\left|s^{\\prime}\\right\\rangle$ as:\n",
        "\n",
        "> $\n",
        "|s\\rangle=\\sqrt{\\frac{M}{N}}|\\omega\\rangle+\\sqrt{\\frac{N-M}{N}}\\left|s^{\\prime}\\right\\rangle\n",
        "$\n",
        "\n",
        "* The inner product of $|s\\rangle$ and $\\left|s^{\\prime}\\right\\rangle$ is:\n",
        "\n",
        "> $\n",
        "\\left\\langle s^{\\prime} \\mid s\\right\\rangle=\\sqrt{\\frac{N-M}{N}}=\\cos \\frac{\\theta}{2}$\n",
        "\n",
        "* From this, we can use some trigonometry and algebra to show:\n",
        "\n",
        "> $\n",
        "N \\sin ^{2} \\frac{\\theta}{2}=M\n",
        "$\n",
        "\n",
        "**Third, calculate number of solutions**\n",
        "\n",
        "* From the Grover's algorithm chapter, you will remember that a common way to create a diffusion operator, $U_{s}$, is actually to implement $-U_{s}$.\n",
        "\n",
        "* This implementation is used in the Grover iteration provided in this chapter. In a normal Grover search, this phase is global and can be ignored, but now we are controlling our Grover iterations, this phase does have an effect.\n",
        "\n",
        "* The result is that we have effectively searched for the states that are not solutions, and our quantum counting algorithm will tell us how mâny states are not solutions. To fix this, we simply calculate\n",
        "\n",
        "> $N-M$\n",
        "\n",
        "The ability to perform quantum counting efficiently is needed in order to use Grover's search algorithm (because running Grover's search algorithm requires knowing how many solutions exist). Moreover, this algorithm solves the quantum existence problem (namely, deciding whether any solution exists) as a special case."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Monte Carlo*"
      ],
      "metadata": {
        "id": "a1VNgmJMpYSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/amazon-braket/amazon-braket-examples/blob/feature/quantum-monte-carlo/examples/hybrid_quantum_algorithms/Quantum_Monte_Carlo_Chemistry/Quantum_Monte_Carlo_Chemistry.ipynb\n",
        "\n",
        "https://aws.amazon.com/blogs/quantum-computing/quantum-monte-carlo-on-quantum-computers/"
      ],
      "metadata": {
        "id": "TNI1a1u6wSKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Chaos*"
      ],
      "metadata": {
        "id": "_ZLCspR7YR3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "revelant for black holes and other things\n",
        "\n",
        "Absolutely! There's a fascinating connection between quantum chaos and black holes. Here's why:\n",
        "\n",
        "**Black Holes as Chaotic Systems**\n",
        "\n",
        "* **Scrambling:** Black holes are believed to be the fastest \"scramblers\" of information in the universe. Anything falling into a black hole essentially has its information rapidly encoded and spread across the black hole's event horizon. This scrambling is seen as analogous to chaos in classical systems.\n",
        "* **Entropy & Thermodynamics:** Black holes possess entropy, a thermodynamic property often associated with disorder and chaos. The connection between a black hole's entropy and its microscopic characteristics remains a key mystery.\n",
        "\n",
        "**Quantum Chaos & Black Holes**\n",
        "\n",
        "* **Information Paradox:**  Black holes challenge a fundamental law of quantum mechanics – information can't be destroyed. Quantum chaos may help resolve this paradox. It offers possible mechanisms on how information could be 'hidden' within seemingly random features on the event horizon and potentially retrieved through subtle effects associated with Hawking radiation.\n",
        "* **Holographic Duality:** Some theoretical models, like the AdS/CFT correspondence, suggest a deep connection between the physics of black holes in specific spacetimes and certain quantum field theories without gravity. These theories may use notions from quantum chaos to establish this link.\n",
        "* **Understanding the Early Universe:** The extremely hot and dense state of the early universe might have had properties related to quantum chaos.  \n",
        "\n",
        "**Current Research**\n",
        "\n",
        "* **Out-of-Time-Order-Correlators (OTOCs):**  OTOCs are tools used to measure how quickly information scrambles or spreads in a system. They're applied to study quantum chaos and are showing promise in understanding black hole dynamics.\n",
        "* **Spectral Statistics:** Researchers examine the statistics of energy levels in systems related to black holes, looking for signatures of quantum chaos with features like 'level repulsion'.\n",
        "\n",
        "**In Summary**\n",
        "\n",
        "The complex nature of black holes makes them a testing ground for ideas connected to quantum chaos. The research aims to use the chaotic nature of black holes to potentially resolve fundamental issues in physics like the information paradox, and even gain insights into how physics worked during the earliest moments of our universe.\n",
        "\n",
        "**Let me know if you want more details on any of these connections!**\n"
      ],
      "metadata": {
        "id": "-KarkScz8S6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "video: [Quantum learning for quantum chaos](https://www.youtube.com/watch?v=d1iZ-ov5QOI&list=WL&index=9&t=163s)"
      ],
      "metadata": {
        "id": "VoyXxYS28U5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a breakdown of quantum chaos, including the key ideas and why it matters:\n",
        "\n",
        "**What is Quantum Chaos?**\n",
        "\n",
        "Quantum chaos is a field of physics that explores the connections between quantum mechanics (the physics of the very small, like atoms and particles) and classical chaos (the behavior of systems that are highly sensitive to starting conditions).\n",
        "\n",
        "**Key Concepts:**\n",
        "\n",
        "* **Classical Chaos:** Systems like the weather or a double pendulum are \"chaotic\" because tiny changes in the initial conditions can lead to wildly different outcomes over time. This is the famous \"butterfly effect\".\n",
        "* **Quantum Mechanics:** In the quantum world, things like energy and position aren't precisely defined. Instead, they exist in fuzzy probabilities and wave-like behavior.\n",
        "* **The Correspondence Principle:**  In general, quantum mechanics should align with classical mechanics in the limit of large systems. Quantum chaos asks: if classical systems can be chaotic, can their quantum counterparts exhibit similar behavior?\n",
        "\n",
        "**How Does Quantum Chaos Manifest?**\n",
        "\n",
        "It turns out that while true chaos can't fully exist in quantum systems, there are interesting ways the \"fingerprint\" of chaos can show up:\n",
        "\n",
        "* **Energy Levels:** In chaotic classical systems, the energy levels tend to be more irregular and bunched up. Similar patterns can be found in the energy levels of certain quantum systems.\n",
        "* **Wavefunctions:** Instead of chaotic trajectories like in classical systems, we look at quantum wavefunctions (which describe the probability of finding a particle somewhere). Wavefunctions of chaotic quantum systems tend to be highly irregular and spread out.\n",
        "* **Level Repulsion:**  In chaotic quantum systems, energy levels tend to \"repel\" each other, in contrast to more predictable, evenly spaced levels seen in regular quantum systems.\n",
        "\n",
        "**Why Does Quantum Chaos Matter?**\n",
        "\n",
        "Quantum chaos research has applications in:\n",
        "\n",
        "* **Understanding Complex Systems:** Studying the ways chaos emerges in the quantum world helps us understand the behavior of complex systems like atoms with many electrons, or the properties of certain materials.\n",
        "* **Quantum Computing:** The properties of quantum chaos could have implications for designing more robust quantum computers.\n",
        "* **Fundamental Physics:** Quantum chaos helps us explore the boundaries between quantum and classical physics, potentially leading to new insights about the fundamental nature of reality.\n",
        "\n",
        "**Let me know if you want a deeper dive into any of these aspects, or if you'd like some examples!**\n"
      ],
      "metadata": {
        "id": "B-kQaiajieIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's how quantum chaos impacts the world of quantum computing:\n",
        "\n",
        "**The Challenge of Decoherence**\n",
        "\n",
        "* Quantum computers rely on fragile quantum states for computation. These states are easily disrupted by outside interactions (think of them as very delicate superpositions). This loss of quantum information is called \"decoherence\".\n",
        "* Decoherence leads to errors in computation and is one of the major obstacles to making large-scale, reliable quantum computers.\n",
        "\n",
        "**How Chaos Plays a Role**\n",
        "\n",
        "* **Sensitivity to Errors:** Systems exhibiting quantum chaos can be incredibly sensitive to even tiny errors or perturbations. This means they could be much more prone to decoherence.\n",
        "* **Scrambling of Information:** A central feature of quantum chaos is the rapid \"scrambling\" of quantum information. This makes the recovery of information and correction of errors significantly harder.\n",
        "\n",
        "**Implications for Quantum Computing**\n",
        "\n",
        "* **Limits of Fault Tolerance:**  Quantum chaos may pose limits on how effective traditional error correction techniques can be in quantum computers.\n",
        "* **Designing Robust Gates:** Understanding quantum chaos could aid in designing quantum gates (the building blocks of quantum computations) and algorithms that are less susceptible to chaotic effects and decoherence.\n",
        "* **Hardware Design:** The implications of quantum chaos could even influence the physical design of quantum computer hardware to try and minimize its impact.\n",
        "\n",
        "**Ongoing Research**\n",
        "\n",
        "* **Quantifying Chaos:** Researchers are developing rigorous ways to measure and quantify quantum chaos in actual quantum computing systems. This will help us to understand its impact better.\n",
        "* **Chaos as a Tool (Possibly):** Some scientists are exploring whether aspects of quantum chaos can be harnessed for new kinds of quantum algorithms. Although speculative, this is a fascinating new field.\n",
        "\n",
        "**Summary**\n",
        "\n",
        "Quantum chaos poses a significant challenge for building large-scale quantum computers by making them inherently more susceptible to errors and information loss. Research focused on understanding and potentially mitigating quantum chaos is critical for the advancement of quantum computing.\n",
        "\n",
        "**Let me know if you'd like to explore any of these aspects further!**\n"
      ],
      "metadata": {
        "id": "ZJJ5-FDHipjx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Walks*"
      ],
      "metadata": {
        "id": "Fv5NjSY6wPmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If a collection of random walks create a normal distribution, what creates a collection of quantum walks?\n",
        "\n",
        "Black Scholar equation - Verasitum: [The trillion dollar equation](https://youtu.be/A5w-dEgIU1M?si=ogNUOUu32tMc1yqr)"
      ],
      "metadata": {
        "id": "ChcphBZbPNru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantum walks in finance: https://youtu.be/mRIjRbIQyE4?si=AI9NhARYgBT9ZmC9\n",
        "\n",
        "Quantum walks in hierarchical graphs: https://youtu.be/b53G80uQ3t0?si=Nsqov_FaD2t9EbN0"
      ],
      "metadata": {
        "id": "7n_brbbCpT1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/2401.14932: Super-exponential quantum advantage for finding the center of a sphere\n",
        "\n"
      ],
      "metadata": {
        "id": "XmS2tJ73lndF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doubling Efficiency of Hamiltonian Simulation via Generalized Quantum Signal Processing https://arxiv.org/abs/2401.10321\n",
        "\n",
        "Improve quantum walk operator for hamiltonian simulation"
      ],
      "metadata": {
        "id": "g8EDP_1MtfTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum-inspired Algorithms*"
      ],
      "metadata": {
        "id": "dRx4Wa1NZjf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://phys-org.cdn.ampproject.org/c/s/phys.org/news/2024-02-classical-surpass-quantum-counterparts.amp"
      ],
      "metadata": {
        "id": "cw0SiQO4mpum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Topological Data Analysis*"
      ],
      "metadata": {
        "id": "s9R2XXEqZeYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The topology of data hides in quantum thermal states\n",
        "\n",
        "If somebody would tell me that performing topological data analysis and \"cooling down\" quantum system is equivalent, I'll surely ask for some evidence. Yet, we discovered that measuring a purity of thermalized quantum systems gives us Betti numbers (topological features, aka doughnut/pretzel classifiers). For this we embed data (point clouds transformed into simplicial complexes) into jump operators (read – noise). Given that properties of thermalization are distinct from unitary evolution, we get a favorable algorithm complexity scaling with a spectral gap. There are also numerous links emergent links between topology and quantum thermodynamics\n",
        "\n",
        "https://arxiv.org/abs/2402.15633"
      ],
      "metadata": {
        "id": "3en4zxf3QthW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Complexity-Theoretic Limitations on Quantum Algorithms for Topological Data Analysis\n",
        "\n",
        "https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.4.040349"
      ],
      "metadata": {
        "id": "MEICYVfID1Uj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [QIP2023 | Quantifying Quantum Advantage in Topological Data Analysis (Vedran Dunjko)](https://youtu.be/T8ygjc-Lpn0?si=4W1n6iEveTXSbEsD)"
      ],
      "metadata": {
        "id": "4GJyErpahBn2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tandfonline.com/doi/full/10.1080/23746149.2023.2202331"
      ],
      "metadata": {
        "id": "KJyD_mprZuNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Essential Steps in the qTDA Paper**\n",
        "\n",
        "* **Connect Laplacian with TDA**:\n",
        "  * harmonic part of the spectrum (eigenvalues, multiples of zero-th eigenvalue) of the persistent Laplacian fully captures the homological persistence and can thus be used to compute the persistent Betti numbers of filtrations of simplicial complexes. (harmonic part of a spectrum is the set of frequency components whose frequencies are whole number multiples of the fundamental frequency)\n",
        "  * The eigenvalues of the combinatorial Laplacian can be used to measure the topological features of the data. For example, the smallest non-zero eigenvalue of the Laplacian is related to the number of connected components in the data. The second smallest non-zero eigenvalue is related to the number of holes in the data.\n",
        "  * Specifically the **dimension of the kernel of the combinatorial Laplacian for k simplices is the kth Betti number**. (*The kernel is a function that measures the similarity between two data points). In other words, the number of data points that are in the kernel of the Laplacian is equal to the number of holes in the data set.\n",
        "  \n",
        "* The kernel of the combinatorial Laplacian specifically captures connectedness.: The kernel (or null space) of the Laplacian captures the number of connected components in the graph. The combinatorial Laplacian is defined for a graph \\( G \\) with vertex set \\( V \\) and edge set \\( E \\) as \\( L = D - A \\), where \\( D \\) is the degree matrix and \\( A \\) is the adjacency matrix. **The number of zero eigenvalues of the combinatorial Laplacian equals the number of connected components of the graph**. The eigenvectors associated with the zero eigenvalues (which form the kernel of the Laplacian) provide **harmonic functions on the graph**.\n",
        "\n",
        "* Aber: combinatorial laplacian vs persistent laplacian: Persistent homology provides information at multiple scales, while the kernel of the combinatorial Laplacian is typically focused on the connected components of a fixed graph.)\n",
        "\n",
        "* The persistent Laplacian is a graph signal processing tool that can be used to **analyze the harmonic part of a spectrum** (=*harmonic part of a spectrum is the set of frequency components whose frequencies are whole number multiples of the fundamental frequency. These frequencies are known as harmonics. harmonic part of the spectrum is then the set of eigenvalues that remain after all the small eigenvalues have been removed*). The persistent Laplacian is calculated by **taking the Laplacian of a graph, and then iteratively removing the smallest eigenvalues of the Laplacian**.\n",
        "  * The harmonic part of the spectrum is then the set of eigenvalues that remain after all the small eigenvalues have been removed\n",
        "  * this is why we were using the **Chebyshev polynomial to optimally filter the zero eigenvalues** (spectral projector that distinguishes the zero eigenvalue from the remaining nonzero eigenvalues of the Dirac operator)\n",
        "  * ps: spectral projector is a projection operator that projects onto the eigenspace of a self-adjoint operator corresponding to a particular eigenvalue because if you project onto the eigenspace of a matrix corresponding to a particular eigenvalue, you can develop efficient algorithms for solving systems of linear equations, or if you project onto the eigenspace of the Laplacian corresponding to a particular eigenvalue, you can study the behavior of solutions to the differential equation in the long-time limit."
      ],
      "metadata": {
        "id": "C5OhzjViVWHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kernel and Spectral Gap**\n",
        "\n",
        "* there is a connection between kernel and spectral gap. The spectral gap is a measure of how well-separated the eigenvalues of a matrix are. A large spectral gap means that the eigenvalues are well-separated, which means that the matrix is more stable and easier to invert.\n",
        "\n",
        "* The kernel of a matrix is the set of all vectors that are orthogonal to all the eigenvectors of the matrix with eigenvalue 0. In other words, it is the set of all vectors that do not change under the action of the matrix.\n",
        "\n",
        "* The spectral gap of a matrix is related to the kernel of the matrix in the following way: **the larger the spectral gap, the smaller the dimension of the kernel**. This is because if the spectral gap is large, then the eigenvalues of the matrix are well-separated, which means that there are fewer vectors that are orthogonal to all the eigenvectors with eigenvalue 0."
      ],
      "metadata": {
        "id": "tTqWqxscIG1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First Eigenvalue in TDA:\n",
        "* „In ordinary TDA applications one is typically concerned with the computation of the exact count of zero eigenvalues of combinatorial Laplacians“\n",
        "* = number of connected compontents (you cannot break it up any smaller).\n",
        "* „deciding if a combinatorial Laplacian has a trivial or non-trivial kernel (i.e., Betti number zero or non-zero)“\n",
        "\n",
        "Cheeger’s inequality demonstrates that the magnitudes of the small non-zero eigenvalues of the graph Laplacian characterises the connectedness of the graph [20], and similar results hold for combinatorial Laplacians.\n",
        "\n",
        "Higher Eigenvalues and why filter out first Eigenvalue:\n",
        "* Compute spectral gap, large gap = dense graph connectivity\n",
        "* Filtrations in Persistent Homology: In TDA, one often constructs filtrations, which are sequences of growing simplicial complexes. Monitoring how the first non-zero eigenvalue changes throughout a filtration can give insights into how the topological features of the data evolve across scales.\n",
        "* Robustness and Sensitivity: The magnitude of the first non-zero eigenvalue can indicate the robustness or sensitivity of the data's topological features. Smaller values might suggest features that are more sensitive to noise or perturbations.\n",
        "* Dimensionality Reduction: Techniques like Laplacian eigenmaps use the first few eigenvalues and their associated eigenvectors for dimensionality reduction. The first non-zero eigenvalue plays a critical role in capturing the most significant variance or structure in the data in such methods.\n",
        "* Clustering and Segmentation: The first non-zero eigenvalue and its corresponding eigenvector can be useful in clustering or segmenting data. Methods like spectral clustering leverage this property.\n"
      ],
      "metadata": {
        "id": "ziII-FeODo4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Hodge theory](https://de.m.wikipedia.org/wiki/Hodge-Zerlegung): combinatorial laplacian (linear operator) which is a generalization of graph laplacian\n",
        "* The key idea in Hodge theory is that the cohomology groups of a smooth manifold **can be decomposed into a direct sum of spaces of harmonic forms.**\n",
        "* A harmonic form is a differential form that satisfies the Laplace equation. The Laplace equation is a partial differential equation that arises naturally from the study of differential forms.\n",
        "* This theorem has many important consequences, such as the Hodge theorem, which states that the integral of a harmonic form over a closed manifold is zero."
      ],
      "metadata": {
        "id": "n4L44J66OJQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Homology vs Hohomolgy*\n",
        "\n",
        "Homology and cohomology are two closely related concepts in mathematics that are used to study the topology of a space. They are both defined using chain complexes, but they differ in the way that the chain complexes are constructed.\n",
        "\n",
        "In homology, the chain complex is constructed using simplices, which are geometric objects that can be thought of as building blocks for a space. The cochain complex is constructed using cochains, which are functions on the simplices.\n",
        "\n",
        "**The homology groups of a space are the groups of equivalence classes of cycles in the chain complex**. A cycle is a collection of simplices that can be assembled to form a closed loop. The cohomology groups of a space are the groups of equivalence classes of cocycles in the cochain complex. A cocycle is a function on the simplices that satisfies certain conditions.\n",
        "\n",
        "The main difference between homology and cohomology is that homology groups are contravariant functors, while cohomology groups are covariant functors. This means that if you take the opposite of a space, the homology groups of the opposite space are the same as the cohomology groups of the original space.\n",
        "\n",
        "Intuitively, homology can be thought of as a way of counting the number of holes in a space, while cohomology can be thought of as a way of measuring the amount of \"stuff\" in a space.\n",
        "\n",
        "Here is a table that summarizes the key differences between homology and cohomology:\n",
        "\n",
        "| Feature | Homology | Cohomology |\n",
        "|---|---|---|\n",
        "| Construction | Simplicial chain complex | Cochain complex |\n",
        "| Equivalence classes | Cycles | Cocycles |\n",
        "| Functor type | Contravariant | Covariant |\n",
        "| Interpretation | Holes in a space | Stuff in a space |\n",
        "\n",
        "I hope this helps! Let me know if you have any other questions."
      ],
      "metadata": {
        "id": "vUEI23JLMNli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Quantifying Quantum Advantage in Topological Data Analysis*\n",
        "\n",
        "https://arxiv.org/abs/2209.13581\n",
        "\n",
        "QIP2023 | Quantifying Quantum Advantage in Topological Data Analysis (Vedran Dunjko)\n",
        "https://youtu.be/T8ygjc-Lpn0\n",
        "\n",
        "What means in the context of quantum computing: „Block encoding & qubitization instead of time evolution. Use filtering of the zero eigenvalue rather than phase estimation.“\n",
        "\n",
        "To understand this, let's first break down some key concepts in quantum computing:\n",
        "\n",
        "1. **Block Encoding**: In quantum computing, block encoding is a method of representing a matrix in a larger, unitary matrix so that the original matrix becomes a sub-block of this larger matrix. This technique is used to allow us to perform certain operations more easily.\n",
        "\n",
        "2. **Qubitization**: Qubitization is a quantum algorithm technique, which uses the block-encoding of a matrix to perform a quantum walk on it. The method uses significantly fewer resources than other quantum algorithms for similar problems.\n",
        "\n",
        "3. **Time Evolution**: Time evolution in quantum computing typically refers to how a quantum state changes over time according to the Schrödinger equation. It is often used to simulate physical systems in quantum simulations.\n",
        "\n",
        "4. **Phase Estimation**: Quantum Phase Estimation (QPE) is a fundamental algorithm in quantum computing which estimates the phase (or eigenvalue) of an eigenvector of a unitary operator. It's a key component in many quantum algorithms, such as Shor's algorithm and quantum simulation algorithms.\n",
        "\n",
        "5. **Filtering the Zero Eigenvalue**: This refers to the process of isolating or eliminating states with zero eigenvalues. It can be a way of refining results or simplifying calculations in quantum algorithms.\n",
        "\n",
        "Now, to the context you provided: \"Block encoding & qubitization instead of time evolution. Use filtering of the zero eigenvalue rather than phase estimation.\"\n",
        "\n",
        "This essentially suggests a strategy for tackling a quantum computing task. Instead of using the time evolution operator (a more traditional approach to quantum simulations), this is advocating the use of block encoding and qubitization. These methods can provide a more resource-efficient approach for certain types of quantum computations.\n",
        "\n",
        "Similarly, \"using filtering of the zero eigenvalue rather than phase estimation\" suggests a preferential way of isolating the states you're interested in. While phase estimation is a powerful tool, it can be resource-intensive. Filtering the zero eigenvalue might be a more efficient approach in certain contexts, particularly when zero eigenvalues represent \"unwanted\" states that might complicate or slow the computation."
      ],
      "metadata": {
        "id": "nQipY_1efAhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exkurs: how can you use the Chebyshev polynomial to optimally filter the zero eigenvalues?**\n",
        "\n",
        "The Chebyshev polynomials are a family of orthogonal polynomials that can be used to filter the zero eigenvalues of a matrix. The Chebyshev polynomials are defined by the following recursion:\n",
        "\n",
        "$$T_0(x) = 1$$\n",
        "$$T_1(x) = x$$\n",
        "$$T_n(x) = 2xT_{n-1}(x) - T_{n-2}(x)$$\n",
        "\n",
        "for all positive integers $n$.\n",
        "\n",
        "The Chebyshev polynomials have the property that they are orthogonal to the constant function on the interval $[-1,1]$. This means that for any two Chebyshev polynomials $T_n(x)$ and $T_m(x)$, the following inner product is zero:\n",
        "\n",
        "$$\\int_{-1}^1 T_n(x) T_m(x) \\, dx = 0$$\n",
        "\n",
        "where $n \\neq m$.\n",
        "\n",
        "This property can be used to filter the zero eigenvalues of a matrix $A$. The idea is to multiply $A$ by a Chebyshev polynomial $T_n(x)$, where $n$ is large enough so that the Chebyshev polynomial is non-zero at all eigenvalues of $A$ except for the zero eigenvalues. The resulting matrix will have all of its eigenvalues except for the zero eigenvalues scaled by $T_n(x)$. The zero eigenvalues will be filtered out because they will be multiplied by 0.\n",
        "\n",
        "The optimal value of $n$ for filtering the zero eigenvalues depends on the matrix $A$. A good choice for $n$ is the smallest integer such that $T_n(x)$ is non-zero for all eigenvalues of $A$ except for the zero eigenvalues.\n",
        "\n",
        "**The Chebyshev polynomial filter is a powerful tool for filtering the zero eigenvalues of a matrix**. It is simple to implement and it is very effective. The Chebyshev polynomial filter has been used in a variety of applications, including image processing, machine learning, and numerical analysis."
      ],
      "metadata": {
        "id": "soH4k5g-Wc_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\">***Kernel of Combinatorial Laplacians and Betti numbers***"
      ],
      "metadata": {
        "id": "99lWWSlK_kig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The kernel of the combinatorial Laplacian is isomorphic to the first homology group of the simplicial complex. This means that the dimension of the kernel of the Laplacian is equal to the number of connected components of the simplicial complex."
      ],
      "metadata": {
        "id": "8TTHgppL-fMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Persistent homology and the kernel of a combinatorial Laplacian** both arise in the study of topological and geometric properties of data, but they address different aspects and are based on somewhat different concepts.\n",
        "\n",
        "*Kernel of a Combinatorial Laplacian:*\n",
        "\n",
        "1. **Purpose**: The combinatorial Laplacian (or graph Laplacian) is a matrix associated with a graph that gives insights into the properties and structure of the graph. The kernel (or null space) of the Laplacian captures the number of connected components in the graph.\n",
        "\n",
        "2. **Construction**: The combinatorial Laplacian is defined for a graph \\( G \\) with vertex set \\( V \\) and edge set \\( E \\) as \\( L = D - A \\), where \\( D \\) is the degree matrix and \\( A \\) is the adjacency matrix.\n",
        "\n",
        "3. **Output**: The number of zero eigenvalues of the combinatorial Laplacian equals the number of connected components of the graph. The eigenvectors associated with the zero eigenvalues (which form the kernel of the Laplacian) provide harmonic functions on the graph.\n",
        "\n",
        "*Commonalities:*\n",
        "\n",
        "1. **Topology**: Both are tools used to study topological or geometric properties of spaces (or data). While persistent homology studies a wide range of topological features across scales, <font color=\"blue\">the kernel of the combinatorial Laplacian specifically captures connectedness.</font>\n",
        "\n",
        "2. **Graph-based**: Both can be discussed in the context of graphs or networks. Simplicial complexes in persistent homology can be viewed as higher-dimensional generalizations of graphs.\n",
        "\n",
        "*Differences:*\n",
        "\n",
        "1. **Scale**: Persistent homology provides information at multiple scales, while the kernel of the combinatorial Laplacian is typically focused on the connected components of a fixed graph.\n",
        "\n",
        "2. **Features**: While both can capture the number of connected components, persistent homology can also capture other features like loops and voids.\n",
        "\n",
        "3. **Mathematical machinery**: Persistent homology involves techniques from algebraic topology and often requires more sophisticated computational tools. The combinatorial Laplacian involves spectral graph theory and linear algebra.\n",
        "\n",
        "4. **Applications**: While both are used in data analysis, persistent homology has found a broader range of applications in studying the shape of data, while the Laplacian and its kernel are often used in graph theory, network analysis, and spectral clustering.\n",
        "\n",
        "In summary, while both persistent homology and the kernel of the combinatorial Laplacian deal with topological features of spaces or data, they focus on different aspects and are based on somewhat different mathematical concepts."
      ],
      "metadata": {
        "id": "PhPKkNu4RAQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The persistent Laplacian (persistent homology) is a generalization of the combinatorial Laplacian that can be used to compute persistent Betti numbers. Persistent Betti numbers are a way to track the birth and death of topological features in a simplicial complex as a function of a parameter. The persistent Laplacian is closely related to the kernel of the combinatorial Laplacian, and it can be used to compute persistent Betti numbers in a more efficient way.\n",
        "\n",
        "* persistent Laplacian, an extension of the standard combinatorial Laplacian to the setting of pairs: https://epubs.siam.org/doi/10.1137/21M1435471\n",
        "\n"
      ],
      "metadata": {
        "id": "_Av3fQr2-vUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing Betti Numbers via Combinatorial Laplacians\n",
        "\n",
        "https://dl.acm.org/doi/pdf/10.1145/237814.237985\n",
        "\n",
        "omputing homology at present seems hard; currently algorithms require computing the [Smith normal form](https://en.m.wikipedia.org/wiki/Smith_normal_form) of the matrix. The latter can be done in polynomial time\n",
        "[KB79]), but the current polynomial required is still quite large.\n",
        "\n",
        "Normal form: https://en.m.wikipedia.org/wiki/Canonical_form"
      ],
      "metadata": {
        "id": "IXRFkIOG7lQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**why is the kernel also the Betti number in topological data analysis?**\n",
        "\n",
        "* The kernel in topological data analysis is not the same as the Betti number. **The kernel is a function that measures the similarity between two data points**. The Betti number is a topological invariant that measures the number of holes in a data set.\n",
        "\n",
        "> However, there is a connection between the kernel and the Betti number. **The dimension of the kernel of the combinatorial Laplacian for k simplices is the kth Betti number. In other words, the number of data points that are in the kernel of the Laplacian is equal to the number of holes in the data set.**\n",
        "\n",
        "* This connection between the kernel and the Betti number can be used to develop topological data analysis methods that are based on kernel methods. Kernel methods are a type of machine learning method that uses kernels to measure the similarity between data points. By using the kernel of the Laplacian, we can develop kernel methods that are sensitive to topological features in data.\n",
        "\n",
        "* For example, we can use the kernel of the Laplacian to develop a kernel-based clustering algorithm that can cluster data points based on their topological features. We can also use the kernel of the Laplacian to develop a kernel-based classification algorithm that can classify data points based on their topological features.\n",
        "\n",
        "* The connection between the kernel and the Betti number is a powerful tool for topological data analysis. It allows us to use kernel methods to develop machine learning algorithms that are sensitive to topological features in data. This can be helpful for a variety of tasks, such as clustering, classification, and anomaly detection."
      ],
      "metadata": {
        "id": "HWu4pbDRVFQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is the kernel of the combinatorial Laplacian?**\n",
        "\n",
        "* The kernel of the combinatorial Laplacian is the set of all vectors in the vector space that are orthogonal to all the eigenvectors of the Laplacian with eigenvalue 0. In other words, it is the set of all vectors that do not change under the action of the Laplacian.\n",
        "\n",
        "* The kernel of the combinatorial Laplacian is important in topological data analysis because it is isomorphic to the homology groups of the underlying simplicial complex. This means that the kernel can be used to determine the Betti numbers of the simplicial complex, which are topological invariants that measure the number of connected components, holes, and voids in the complex.\n",
        "\n",
        "* For example, the kernel of the combinatorial Laplacian of a circle is one-dimensional, which corresponds to the fact that the circle has one Betti number, namely $\\beta_1=1$. This is because the only vector in the kernel of the Laplacian is the constant vector, which corresponds to the fact that the circle is a connected topological space.\n",
        "\n",
        "* In general, the dimension of the kernel of the combinatorial Laplacian is equal to the sum of the Betti numbers of the simplicial complex. **This means that the kernel can be used to count the number of connected components, holes, and voids in a simplicial complex.**\n",
        "\n",
        "* **The kernel of the combinatorial Laplacian can also be used to define a graph kernel, which is a similarity measure between graphs.** The graph kernel is based on the idea that two graphs are similar if their kernels are similar. This kernel has been shown to be effective for a variety of tasks in machine learning, such as graph classification and clustering.\n"
      ],
      "metadata": {
        "id": "EVXrfLEA43UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Support Vector Machine*"
      ],
      "metadata": {
        "id": "dDeahAqJZZUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/@patrick.huembeli/introduction-into-quantum-support-vector-machines-727f3ccfa2b4\n",
        "\n",
        "https://pennylane.ai/qml/demos/tutorial_kernels_module/\n",
        "\n",
        "https://pennylane.ai/qml/demos/tutorial_kernel_based_training/"
      ],
      "metadata": {
        "id": "FZxoqCVVZZU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum PCA*"
      ],
      "metadata": {
        "id": "dLcMEj-iZUWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.nature.com/articles/nphys3029: Quantum principal component analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "QdfC93gVArrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $\\xi$ be a precision parameter. Let there be efficient quantum access to the top $k$ right singular vectors $\\bar{V}^{(k)} \\in \\mathbb{R}^{m \\times k}$ of a matrix $A=U \\Sigma V^T \\in \\mathbb{R}^{n \\times m}$, such that $\\left\\|V^{(k)}-\\vec{V}^{(k)}\\right\\| \\leq \\frac{\\xi}{\\sqrt{2}}$. Given efficient quantum access to a row $a_i$ of $A$, the quantum state $\\left|\\bar{y}_i\\right\\rangle=\\frac{1}{\\left\\|\\bar{y}_i\\right\\|} \\sum_i^k \\bar{y}_k|i\\rangle$, proportional to its projection onto the PCA space, can be created in time $\\tilde{O}\\left(\\frac{\\left\\|a_i\\right\\|}{\\left\\|\\tilde{y}_i\\right\\|}\\right)$ with probability at least $1-1 / \\operatorname{poly}(m)$ and precision $\\|\\left|y_i\\right\\rangle-\\left|\\bar{y}_i\\right\\rangle \\| \\leq \\frac{\\left\\|a_i\\right\\|}{\\left\\|\\bar{y}_i\\right\\|} \\xi$. An estimate of $\\left\\|\\bar{y}_i\\right\\|$, to relative error $\\eta$, can be computed in $\\widetilde{O}(1 / \\eta)$."
      ],
      "metadata": {
        "id": "mEBPFCERChpO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantum principal component analysis only achieves an exponential speedup because of its state preparation assumptions\n",
        "\n",
        "https://arxiv.org/abs/1811.00414"
      ],
      "metadata": {
        "id": "NdhZ5Ww9DKay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://quantumalgorithms.org/dimensionality-reduction-1.html"
      ],
      "metadata": {
        "id": "mA8V1kp8437-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Neural Network*"
      ],
      "metadata": {
        "id": "nzm9UioSZQMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ddd"
      ],
      "metadata": {
        "id": "d5gl_2mFZOIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *QAOA*"
      ],
      "metadata": {
        "id": "yIEGR7ZtZKfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video [QAOA in 5 min](https://youtu.be/IFIoMs7wffY?si=l-0CdnSuhMHKr7oS)"
      ],
      "metadata": {
        "id": "IliS3d47YeTN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://youtu.be/UP-Zuke7IUg?si=mdlJKh-eb6sq0OOx\n",
        "\n",
        "\n",
        "https://youtu.be/RqGpnRh7rCM?si=IA5CPfisTgsDUCNj\n",
        "\n",
        "Video: [QAOA explained](https://youtu.be/tuGcPup8DjY?si=tdOyGsgvqozGIARY)\n",
        "\n",
        "Video: [QAOA for combinatorial optimization](https://youtu.be/AOKM9BkweVU?si=PrLHcdZ1wDAjYTnY)\n",
        "\n",
        "Video: [QAOA Peter Shor 2018]()https://youtu.be/HHIWUi3GmdM?si=c1hLXgeLCEkme_6R)"
      ],
      "metadata": {
        "id": "bs3zZ-DCQxps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://aws.amazon.com/de/blogs/quantum-computing/citi-and-classiq-advance-quantum-solutions-for-portfolio-optimization/\n",
        "\n",
        "> From a computational point of view, the portfolio **optimization problem is NP-hard for minimization over binary or integer domains with additional constraints**. In simpler words, **the runtime to solve this problem grows exponentially as we increase the number of assets** (the size of ω). Therefore, finding ways of improving the runtime and the quality of the results is important when the number of assets is large.\n",
        "\n",
        "* QAOA is a hybrid algorithm, which means it combines both classical and quantum computation. The algorithm searches through all potential solutions using a mixer layer (which shuffles between alternative solutions) and a cost layer (which favors good ones). The circuit parameters are fine-tuned classically in an iterative manner, converging toward their optimal values with each run of QAOA.\n",
        "\n"
      ],
      "metadata": {
        "id": "iIVULjq3XGQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://quantumai.google/cirq/experiments/qaoa/example_problems"
      ],
      "metadata": {
        "id": "585EyhGnpmt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum Computers for Combinatorial Optimization**\n",
        "\n",
        "https://arxiv.org/abs/2210.14936: A super-polynomial quantum-classical separation for density modelling\n",
        "\n",
        "* An in-principle super-polynomial quantum advantage for approximating combinatorial optimization problems via computational learning theory\n",
        "\n",
        "* It is unclear to what extent quantum algorithms can outperform classical algorithms for problems of combinatorial optimization. In this work, by resorting to computational learning theory and cryptographic notions, we give a fully constructive proof that hashtag#quantumcomputers feature a super-polynomial advantage over classical computers in approximating combinatorial hashtag#optimization problems. Specifically, by building on seminal work by Kearns and Valiant, we provide special instances that are hard for classical computers to approximate up to polynomial factors. Simultaneously, we give a quantum algorithm that can efficiently approximate the optimal solution within a polynomial factor. The quantum advantage in this work is ultimately borrowed from Shor’s quantum algorithm for factoring. We introduce an explicit and comprehensive end-to-end construction for the advantage bearing instances. For such instances, quantum computers have, in principle, the power to approximate combinatorial optimization solutions beyond the reach of classical efficient algorithms.\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1702.jpg)"
      ],
      "metadata": {
        "id": "txLRsGwpWWwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Categorization of Optimization Problem with different orders of their objective function**\n",
        "* Einführung: [Optimization_problem](https://en.m.wikipedia.org/wiki/Optimization_problem)\n",
        "* **First order**: [Linear optimization](https://en.m.wikipedia.org/wiki/Linear_programming): Many practical problems in [operations research](https://en.m.wikipedia.org/wiki/Operations_research) can be expressed as linear programming problems. See [Simplex_algorithm](https://en.m.wikipedia.org/wiki/Simplex_algorithm)\n",
        "* **Second Order**: [Quadratic optimization (Quadratic programming)](https://en.m.wikipedia.org/wiki/Quadratic_programming): finance (for portfolio optimization), machine learning (for support vector machines), and operations research. Example: In the Markowitz model, the objective function to be minimized is the portfolio variance, which is a quadratic function of the decision variables (asset weights in the portfolio), given the covariance matrix of the returns of the assets.\n",
        "* **Higher Order**: Polynomial optimization problems or non-linear optimization problems (optimize design of a machine part, where the objective function includes terms related to the volume of material used which might be cubic if we're considering three-dimensional parts. Often require more advanced techniques, such as [interior-point methods](https://de.m.wikipedia.org/wiki/Innere-Punkte-Verfahren), branch-and-bound techniques, or heuristic methods."
      ],
      "metadata": {
        "id": "zsVPCyezZKfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Optimization Algorithms*"
      ],
      "metadata": {
        "id": "cS920zuu5gBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantum Approximate Optimization Algorithm (QAOA)\n",
        "\n",
        "https://en.wikipedia.org/wiki/Quantum_optimization_algorithms\n",
        "\n",
        "Farhi, Edward; Goldstone, Jeffrey; Gutmann, Sam (2014). \"A Quantum Approximate Optimization Algorithm\"\n",
        "\n",
        " arXiv:1411.4028: https://arxiv.org/abs/1411.4028"
      ],
      "metadata": {
        "id": "6BoAS_DV5laX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QAOA** (Ryan)\n",
        "\n",
        "https://arxiv.org/pdf/2011.04149.pdf\n",
        "\n",
        "https://arxiv.org/pdf/2004.04197.pdf\n",
        "\n",
        "https://journals.aps.org/prx/abstract/10.1103/PhysRevX.6.031015\n",
        "\n",
        "https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.1.020312\n",
        "\n",
        "10^53\n",
        "\n",
        "Research team has done a lot of optimisation\n",
        "\n",
        "Killer app - almost all business have logistics, scheduling, load balancing, portfolio optimisation - holy grail application, because it’s broad\n",
        "\n",
        "Team has some attention on this topic, 2013 had most focus, at that time annealing /adbatic QC at that time\n",
        "\n",
        "In real world: problem only on a couple of hundred bits, dicciutl to find good solution classically, formlery NP hard,determistic algorithm, formerly exponentially scaling, - classicl herutsics algorithm (simulated annealing) very good, have exponential runtime, contrast: algorithims that run exactly: but run in practice too long, in practice more heuristics,\n",
        "\n",
        "Just hundreds of bits: classical easy. Thousands bits to have truly challenging instances. Optimisation variable surely binary. But normally: real variable or multiple instances, need to map to binary qubits is difficult.\n",
        "\n",
        "The other things why so difficult: how dense , cost function being expressed as sum of products of bits, sum of pairwise products bits, like quadratic optimisation problem - quantum annealing: can just solve quadratic optimisation problem. There or four body (bits) problems, can be mapped to qudrtica function with 2 in qubits, but this causes overhead that increase asymptocatily like n to n^2 bits.\n",
        "\n",
        "Connectivity of graph - some optimisation have direst neuhbors on grid - turns out to be csolved easily classical. If local nature of connections. So you need problems, where the graph is not sparse and non local. If you use annealing: map problem hmailtoian to hardware graph, causes tons of overhead and qubits to get that plane. If you have digital approach like for qAOA or fault tolerant, increases number of swap gates (but not bits).\n",
        "\n",
        "contrast: quantum chemistry simulation: true quantum nature not easy to solve on 16 or 18 bits, solution is single bit string (expressing). Optimisation: finding the solution is easy, but you can’t express it easily n^80, you can’t write down the quantum wave function. You need 10^100 more bits than you would for other applications in simulation, like quantum chemist than on optimisation.\n",
        "\n",
        "Annealer some advantages for long range couples, sparse d of graph is increasing: but not practicalto engineer, our devices have this property. Requires number of wires  between wqubits increases with more qubits, which is impracticable.\n",
        "\n",
        "For error corrected otpimuzation : e don’t have the computers, but what we can prove? The problems are non oracular -\n",
        "\n",
        "You have to go to astronomical sizes to have advantages in error corrected with quadratic speedups\n",
        "\n",
        "Introduce energy landscape to cquamtum computer - diagonal hamitlionaina under the cost function, in all forms of quantum optimisation. Every cost function has to have order n term in it (edges), you need high connectivity\n",
        "\n",
        "Many hard problems are not even graphs, n^3 don’t need any edges, but n^1,5 you can’t have a sparse graphs. N needs to be order of thousands, number of bits, number of edges n^1,5 = 160.000, each of those edges needs at least x seizes. 300.000 edges (with rotations?), QC has 0.995 fidelity: 300.000 gates with that, raise that to power of 300.000 -> going against zero. 10^-220. 5 times n edges, we have 5000 edges, 2 seizes er edge=. 10..000 gates. I get 10^-22 fidelity. Number of circuit repetition required before seeing one error is over that, 5^25, repeated QC so many times, not going to happen.\n",
        "\n",
        "NISQ: is not scalable to 2000 qubits, not simulation, not optimisation, you have to have error correction. 50 -150 bits would be classically intractable, 0.995^300 = 0.2 fidelity, that sounds reasonable. Or 0.995^3000, we used a hundred bits, plus edges 2 seizes per edge, 2000 gates as result with 0.995 dfeiltiy, 4* 10^-5 = 22.000 samples in 2 seconds, something with hundred bit is ok, with thousands of bits is incredible.\n",
        "\n",
        "Runtime of exact classuical alrogrhtm with heuristics algorithms compare - wrong!!\n",
        "\n",
        "Maybe future for optimisation, but better approach apply QAOA to new problem is not going change speedup, you really need a close match between structure of algorithm and problem."
      ],
      "metadata": {
        "id": "5NxB9AolItWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimisation\n",
        "\n",
        "\n",
        "\n",
        "https://arxiv.org/pdf/2011.04149.pdf\n",
        "\n",
        "https://arxiv.org/pdf/2004.04197.pdf\n",
        "\n",
        "https://journals.aps.org/prx/abstract/10.1103/PhysRevX.6.031015\n",
        "\n",
        "https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.1.020312\n",
        "\n",
        "10^53\n",
        "\n",
        "Research team has done a lot of optimisation\n",
        "\n",
        "Killer app - almost all business have logistics, scheduling, load balancing, portfolio optimisation - holy grail application, because it’s broad\n",
        "\n",
        "Team has some attention on this topic, 2013 had most focus, at that time annealing /adbatic QC at that time\n",
        "\n",
        "In real world: problem only on a couple of hundred bits, dicciutl to find good solution classically, formlery NP hard,determistic algorithm, formerly exponentially scaling, - clasislcayl herutsics algorithm (simulated annealing) very good, have exponential runtime, contrast: glorothims that run exactly: but run in practice too long, in practice more heuristics,\n",
        "\n",
        "Just hundreds of bits: classical easy. Thousands bits to have truly challenging instances. Optimisation variable surely binary, more: real variable or multiple instances, need to map to binary qubits is difficult.\n",
        "\n",
        "The other things why so difficult: how dense , cost function being expressed as sum of products of bits, sum of pairwise products bits, like quadratic optimisation problem - quantum annealing: can just solve quadratic optimisation problem. There or four body (bits) problems, can be mapped to qudrtica function with 2 in qubits, but causes overhead increased asymptocatily like n to n^2 bits. Connectivity of graph - some optimisation have direst neuhbors on grid - turns out to be csolved easily classical. If local nature of connections. So you need problems, where the graph is not sparse and non local. If you use annealing: map problem hmailtoian to hardware graph, causes tons of overhead and qubits to get that plane. If you have digital approach like for qAOA or fault tolerant, increases number of swap gates (but not bits).\n",
        "\n",
        "contrast: quantum chemistry simulation: true quantum nature not easy to solve on 16 or 18 bits, solution is single bit string (expressing). Optimisation: finding the solution is easy, but you can’t express it easily n^80, you can’t write down the quantum wave function. You need 10^100 more bits than you would for other applications in simulation, like quantum chemist than on optimisation.\n",
        "\n",
        "Annealer some advantages for long range couples, sparse d of graph is increasing: but not practical engineer, our devices have this property. Required number of wires between qubits increases with more qubits, which is impracticable.\n",
        "\n",
        "For error corrected otpimuzation : e don’t have the computers, but what we can prove? The problems are non oracular -\n",
        "\n",
        "\n",
        "You have to go to astronomical sizes to have advantages in error corrected with quadratic speedups\n",
        "\n",
        "Introduce energy landscape to cquamtum computer - diagonal hamitlionaina under the cost function, in all forms of quantum optimisation. Every cost function has to have order n term in it (edges), you need high connectivity\n",
        "\n",
        "Many hard problems are not even graphs, n^3 don’t need any edges, but n^1,5 you can’t have a sparse graphs. N needs to be order of thousands, number of bits, number of edges n^1,5 = 160.000, each of those edges needs at least x seizes. 300.000 edges (with rotations?), QC has 0.995 fidelity: 300.000 gates with that, raise that to power of 300.000 -> going against zero. 10^-220. 5 times n edges, we have 5000 edges, 2 seizes er edge=. 10..000 gates. I get 10^-22 fidelity. Number of circuit repetition required before seeing one error is over that, 5^25, repeated QC so many times, not going to happen.\n",
        "\n",
        "NISQ: is not scalable to 2000 qubits, not simulation, not optimisation, you have to have error correction. 50 -150 bits would be classically intractable, 0.995^300 = 0.2 fidelity, that sounds reasonable. Or 0.995^3000, we used a hundred bits, plus edges 2 seizes per edge, 2000 gates as result with 0.995 dfeiltiy, 4* 10^-5 = 22.000 samples in 2 seconds, something with hundred bit is ok, with thousands of bits is incredible.\n",
        "\n",
        "Runtime of exact classuical alrogrhtm with heuristics algorithms compare - wrong!!\n",
        "\n",
        "Maybe future for optimisation, but better approach apply QAOA to new problem is not going change speedup, you really need a close match between structure of algorithm and problem.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SxjKemSUmire"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imaginary time evolution**\n",
        "\n",
        "\n",
        "https://physics.stackexchange.com/questions/557225/why-do-we-use-the-imaginary-time-evolution-in-simulations-of-some-quantum-system\n",
        "\n",
        "Imaginary time is a concept derived from quantum mechanics and statistical mechanics. It introduces the idea of replacing \"real time\" with \"imaginary time\" by a Wick rotation in the complex plane. That is, the time variable 't' is replaced with an imaginary number 'it', where 'i' is the imaginary unit.\n",
        "\n",
        "Imaginary time evolution plays a significant role in several areas of physics, including quantum field theory, statistical mechanics, and quantum computing.\n",
        "\n",
        "1. **Quantum Field Theory and Statistical Mechanics**: In these fields, the use of imaginary time is often a mathematical trick that simplifies calculations. By transforming to imaginary time, the calculations of quantum mechanics often become calculations in statistical mechanics. This is utilized in the technique called \"path integral formulation,\" where the evolution of a system in imaginary time makes the system go to its lowest energy state or the ground state.\n",
        "\n",
        "2. **Quantum Computing**: In quantum computing, the idea of imaginary time evolution can be used to design quantum algorithms for tasks such as finding the ground state of a system. This is used in the Quantum Approximate Optimization Algorithm (QAOA) and the Quantum Imaginary Time Evolution (QITE) algorithm.\n",
        "\n",
        "Remember that \"imaginary time\" is not about time in the sense that we experience it. Instead, it's a mathematical construct that physicists use to solve certain types of problems.\n",
        "\n",
        "Imaginary time is an unphysical, yet powerful, mathematical concept. It has been utilised in numerous physical domains, including quantum mechanics, statistical mechanics and cosmology. Often referred to as performing a ‘Wick rotation’\n",
        "\n",
        "https://www.nature.com/articles/s41534-019-0187-2"
      ],
      "metadata": {
        "id": "KL1eEEfd9csH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Boltzmann Machine*"
      ],
      "metadata": {
        "id": "RbnAnPCJZDh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/@roysuman088/advancing-machine-learning-with-quantum-boltzmann-machines-a-new-paradigm-dcf5d3aa7e74\n",
        "\n",
        "https://arxiv.org/abs/2304.08631: Training Quantum Boltzmann Machines with the β-Variational Quantum Eigensolver\n",
        "\n",
        "https://arxiv.org/abs/1601.02036: Quantum Boltzmann Machine\n",
        "\n",
        "Short video: https://www.youtube.com/watch?v=52Ylq3aDU8o"
      ],
      "metadata": {
        "id": "4z30NyT33Sue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Annealer and Adiabatic Algorithms*"
      ],
      "metadata": {
        "id": "SfaztpziY2sb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/2403.00910: Computational supremacy in quantum simulation"
      ],
      "metadata": {
        "id": "WI3oZ_mYPQg4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*QUBO*"
      ],
      "metadata": {
        "id": "egmKQRu3GHft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/mdr-inc/quadratic-unconstrained-binary-optimization-qubo-on-dwave-chimera-graph-part-1-a7eb05e3f155"
      ],
      "metadata": {
        "id": "RiSZ_jhPGJL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Quantum Speedup in Combinatorial Optimization*"
      ],
      "metadata": {
        "id": "tnFQtxBD9KEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum Speedup in Combinatorial Optimization: the status**\n",
        "\n",
        "A pivotal challenge in quantum information science's ever-evolving realm is designing quantum algorithms that outpace their classical counterparts. A recent experimental observation showcased a superlinear quantum speedup in solving the Maximum Independent Set problem on specific graph instances. This has spurred the development of a comprehensive theoretical framework to compare the performance of quantum adiabatic algorithms and classical Markov chain Monte Carlo algorithms.\n",
        "\n",
        "The Quantum-Classic Conundrum\n",
        "\n",
        "Combinatorial optimization problems, foundational to modern computer science, encompass NP-hard problems that remain elusive to efficient solutions through known algorithms. While classical combinatorial optimization algorithms focus on minimizing a cost function over bit strings, Quantum adiabatic algorithms (QAAs) serve as their quantum analogs, preparing low-energy states of a classical cost Hamiltonian through adiabatic evolution. However, the relative efficacy of QAA and classical counterparts like simulated annealing (SA) remains a topic of debate and exploration.\n",
        "\n",
        "From Theory to Application\n",
        "\n",
        "The recent experimental results, particularly the superlinear speedup observed using a programmable Rydberg atom array, have ignited a renewed interest in this domain. This study presents a theoretical framework that zeroes in on problem instances characterized by flat energy landscapes. Here, the quantum algorithm's performance hinges on the (de)localization of the low-energy eigenstates of the adiabatic Hamiltonian. When these eigenstates are delocalized and the quantum evolution is optimized, the QAA can achieve a significant speedup over classical algorithms like SA.\n",
        "\n",
        "Toward a Quantum Future\n",
        "\n",
        "Building on this foundation, the researchers introduce a modified QAA that showcases a quadratic speedup over SA on specific problem instances. This algorithm employs local Hamiltonians without a sign problem, making them more amenable to quantum Monte Carlo simulations. The study concludes by applying these insights to interpret experimental observations, identifying instances where quantum algorithms either outperform or underperform classical ones due to the localization properties of the low-energy eigenstates.\n",
        "\n",
        "In Summary\n",
        "\n",
        "This work offers a deep dive into the intricate dance between quantum and classical algorithms in the context of combinatorial optimization. Shedding light on the conditions under which quantum algorithms can achieve a speedup paves the way for further advancements in the quantum computing landscape.\n",
        "\n",
        "Link to the publication:\n",
        "\n",
        "https://arxiv.org/pdf/2306.13123.pdf\n"
      ],
      "metadata": {
        "id": "gh1J-ajfc5_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Quantum annealing is a quantum computing algorithm that can be used to solve a variety of problems, including NP-hard problems.\n",
        "* However, the efficiency of quantum annealing is limited by the **exponential closing of the spectral gap with increasing system size.**\n",
        "* The spectral gap is a measure of the connectivity of a quantum system. **A large spectral gap means that the system is well-connected, while a small spectral gap means that the system is poorly connected**. The exponential closing of the spectral gap means that the spectral gap decreases exponentially with increasing system size.\n",
        "* This means that quantum annealing becomes exponentially slow for solving NP-hard problems as the system size increases. This is because **the quantum system becomes more and more poorly connected as the system size increases, and it takes longer and longer for the system to reach its ground state**.\n",
        "* There are a number of ways to address the problem of exponential closing of the spectral gap. One approach is to use a technique called adiabatic quantum computation. Adiabatic quantum computation is a variation of quantum annealing that uses a slower annealing schedule. This can help to prevent the spectral gap from closing too quickly.\n",
        "* Another approach to addressing the problem of exponential closing of the spectral gap is to use a technique called quantum error correction. Quantum error correction is a technique that can be used to protect quantum systems from noise. This can help to prevent the quantum system from becoming too poorly connected as the system size increases.\n",
        "* The problem of exponential closing of the spectral gap is a major challenge for quantum annealing. However, there are a number of promising approaches to addressing this problem. As quantum annealing technology continues to develop, it is possible that quantum annealing will become a viable solution for solving NP-hard problems.\n"
      ],
      "metadata": {
        "id": "8eSN4dg5Y2sd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Kerr ising model*"
      ],
      "metadata": {
        "id": "_UQPJ8Oz9iXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kerr and ising gate: non linear gates\n",
        "\n",
        "* The Kerr gate is a gate that introduces nonlinearity into a quantum system. The Kerr gate can be used to implement a variety of quantum operations, such as quantum logic gates and quantum simulations.\n",
        "\n",
        "* The quartic gate is a gate that introduces even higher-order nonlinearity into a quantum system. The quartic gate can be used to implement a variety of quantum operations, such as quantum error correction and quantum machine learning.\n",
        "\n",
        "* The cubic gate is a gate that introduces cubic nonlinearity into a quantum system. The cubic gate can be used to implement a variety of quantum operations, such as quantum cryptography and quantum teleportation."
      ],
      "metadata": {
        "id": "9nkXUBDaY2sd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is the Kerr ising model?**\n",
        "\n",
        "\n",
        "The Kerr Ising model (KIM) is a quantum many-body model that combines the features of the Ising model and the Kerr nonlinearity. The Ising model is a classical model of interacting spins, while the Kerr nonlinearity is a quantum effect that describes the interaction of light with matter.\n",
        "\n",
        "The KIM is described by the following Hamiltonian:\n",
        "\n",
        "> $H = -\\sum_{i,j} J_{ij} \\sigma^z_i \\sigma^z_j - \\sum_i \\frac{\\alpha}{2} \\sigma^x_i^2$\n",
        "\n",
        "where $\\sigma^z_i$ and $\\sigma^x_i$ are Pauli matrices that represent the spin of the $i$th qubit, $J_{ij}$ is the Ising coupling strength between the $i$th and $j$th qubits, and $\\alpha$ is the Kerr nonlinearity coefficient.\n",
        "\n",
        "The KIM has been studied in a variety of contexts, including quantum annealing, quantum simulation, and quantum information processing. It has been shown that the KIM can be used to solve certain NP-complete problems, and it can also be used to simulate the dynamics of other quantum many-body systems.\n",
        "\n",
        "Here are some of the key features of the Kerr Ising model:\n",
        "\n",
        "* It is a quantum many-body model that combines the features of the Ising model and the Kerr nonlinearity.\n",
        "* It has been shown to be useful for quantum annealing, quantum simulation, and quantum information processing.\n",
        "* It has been studied in a variety of contexts, including theoretical studies and experimental implementations.\n",
        "\n",
        "The Kerr Ising model is a promising platform for a variety of quantum applications. As our understanding of the model continues to grow, we can expect to see even more exciting applications in the future.\n",
        "\n",
        "https://iopscience.iop.org/article/10.1088/1367-2630/ab7255"
      ],
      "metadata": {
        "id": "nMEaxCxVY2se"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*adiabatic quantum computing and quantum annealing*"
      ],
      "metadata": {
        "id": "JFVnpVvY9T1w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is the difference between adiabatic quantum computing and quantum annealing?**\n",
        "\n",
        "Adiabatic quantum computing (AQC) and quantum annealing (QA) are both approaches to quantum computing that use a time-dependent Hamiltonian to solve problems. However, there are some key differences between the two approaches.\n",
        "\n",
        "In AQC, the Hamiltonian is slowly varied from an initial Hamiltonian that is easy to prepare to a final Hamiltonian that encodes the solution to the problem. The system is then allowed to evolve adiabatically, meaning that it remains in its ground state throughout the evolution. This ensures that the system will end up in the ground state of the final Hamiltonian, which is the solution to the problem.\n",
        "\n",
        "In QA, the Hamiltonian is also slowly varied from an initial Hamiltonian to a final Hamiltonian. However, the final Hamiltonian does not necessarily encode the solution to the problem. Instead, the goal of QA is to find the ground state of the final Hamiltonian, which is a global minimum of the energy landscape. This can be useful for solving optimization problems, where the goal is to find the minimum value of a function.\n",
        "\n",
        "Another difference between AQC and QA is that AQC is a universal model of quantum computation, while QA is not. This means that AQC can be used to solve any problem that can be solved by a classical computer, while QA is only able to solve optimization problems.\n",
        "\n",
        "In practice, QA is often used to solve problems that are difficult for classical computers to solve. This is because the adiabatic evolution can help the system to tunnel through energy barriers that would be insurmountable for a classical computer. However, there is still some debate about whether QA is truly a quantum-mechanical phenomenon, or whether it can be explained by classical physics.\n",
        "\n",
        "Here is a table that summarizes the key differences between AQC and QA:\n",
        "\n",
        "| Feature | Adiabatic Quantum Computing | Quantum Annealing |\n",
        "|---|---|---|\n",
        "| Hamiltonian | Varied slowly from an easy-to-prepare initial Hamiltonian to a final Hamiltonian that encodes the solution to the problem. | Varied slowly from an easy-to-prepare initial Hamiltonian to a final Hamiltonian that is a global minimum of the energy landscape. |\n",
        "| Universality | Yes | No |\n",
        "| Applications | Any problem that can be solved by a classical computer | Optimization problems |\n",
        "| Quantum-mechanical phenomenon | Yes | Possibly |\n"
      ],
      "metadata": {
        "id": "rbIyjx5hY2se"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Quantum Adiabatic Evolution Algorithm Applied to Random Instances of an NP-Complete Problem\n",
        "\n",
        "https://arxiv.org/abs/quant-ph/0104129"
      ],
      "metadata": {
        "id": "wRJv1ngPY2se"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Exponential Closing of Spectral Gap*"
      ],
      "metadata": {
        "id": "QnYJ0XpX82sX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/math-ph/0507008: Spectral Gap and Exponential Decay of Correlations\n",
        "\n",
        "https://arxiv.org/abs/2212.13649 : Why Adiabatic Quantum Annealing is unlikely to yield speed-up"
      ],
      "metadata": {
        "id": "ZlZovX7quE9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connectivity and Solution Finding in Quantum Annealing**\n",
        "\n",
        "Quantum annealing is a quantum computing technique used to find the minimum value of a given objective function over a defined set of possible solutions. It draws inspiration from classical annealing, a process in which a system is gradually cooled to find its lowest energy state. The hope in quantum annealing is to leverage quantum properties, such as superposition and tunneling, to more efficiently explore the solution space and find the ground state, which represents the minimum of the objective function.\n",
        "\n",
        "Connectivity plays an essential role in this process. Let's understand this with a few key points:\n",
        "\n",
        "1. **Local Minima and Global Minima**: In complex optimization problems, there are often many local minima. Finding the global minimum (or a sufficiently good approximation of it) is the main challenge. High connectivity means that the system can more easily explore the solution space, jumping from one potential solution to another and avoiding getting trapped in local minima.\n",
        "\n",
        "2. **Quantum Tunneling**: One of the primary advantages of quantum annealing over classical annealing is quantum tunneling. Tunneling allows the system to \"pass through\" barriers between states, meaning that the system can more easily escape local minima and move towards the global minimum. If the quantum system's connectivity is low, the benefit from quantum tunneling can be diminished.\n",
        "\n",
        "3. **Effective Exploration of Solution Space**: In a highly connected system, any given qubit (quantum bit) is more likely to interact with many other qubits. <font color=\"blue\">This allows for a richer exploration of the solution space. With fewer connections, the qubits are limited in their interactions, making the exploration less effective.</font>\n",
        "\n",
        "4. **Scaling Issues**: <font color=\"blue\">as the system size increases, maintaining high connectivity becomes more challenging. The difficulty in keeping high connectivity in larger systems is one reason why quantum annealing's efficiency decreases for more complex NP-hard problems</font>. The sparser the connectivity, the less able the system is to effectively leverage quantum effects.\n",
        "\n",
        "5. **Error Correction and Noise**: Highly connected quantum systems can be more susceptible to certain types of errors or noise. So, while high connectivity can aid in the exploration of solution space, it can also introduce challenges in terms of maintaining the coherence and reliability of the quantum information.\n",
        "\n",
        "In summary, high connectivity in quantum annealing is crucial for effectively exploring the solution space, leveraging quantum effects like tunneling, and ensuring the system doesn't get trapped in local minima. As system sizes increase, maintaining this connectivity becomes more challenging, which contributes to the reduced efficiency of quantum annealing for large NP-hard problems."
      ],
      "metadata": {
        "id": "IKNrTGMaY2sf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> *Does spectral gap stand in quantum annealing for difference between global and local optimum, or graph connectivity?* For graph connectivity it would be bad to have a small spectral gap, meanhwile for optimum it would be potentially good.\n",
        "\n",
        "*Spectral gap stands for graph connectivity. if that is low, then there are fewer connections in the graph, and that results that it's harder to find the global optimum*"
      ],
      "metadata": {
        "id": "7eO90_7EY2sf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Around the same time, it was argued that QA is exponentially slow for solving NP-hard problems due to exponential closing of the spectral gap with increasing system size*\n",
        "https://arxiv.org/pdf/2212.13649.pdf\n",
        "\n",
        "[20]  Jorg, T., Krzakala, F., Kurchan, J. & Maggs, A. Simple glass models and their quantum annealing. Physical review letters 101, 147204 (2008).\n",
        "[21]  Altshuler, B., Krovi, H. & Roland, J. Adiabatic quantum optimization fails for random in- stances of np-complete problems. arXiv preprint arXiv:0908.2782 (2009).\n",
        "\n",
        "*exponential closing of the quantum gap with increasing problem size* https://www.nature.com/articles/s41467-018-05239-9\n",
        "\n",
        "*The efficiency of Adiabatic Quantum Annealing is limited by the scaling with system size of the minimum gap that appears between the ground and first excited state in the annealing energy spectrum. In general the algorithm is unable to find the solution to an optimisation problem in polynomial time due to the presence of avoided level crossings at which the gap size closes exponentially with system size.* https://arxiv.org/pdf/2203.06779.pdf\n",
        "  * A particular problem which has been highlighted is the potential for so called perturbative crossings to form between the low energy eigenstates of the problem Hamiltonian towards the end of the anneal [11, 12]. The corresponding energy gap has been found to be exponentially small with the Hamming distance between the eigenstates, which can generally be expected to grow with the system size [11]."
      ],
      "metadata": {
        "id": "IQZSg2D4Y2sf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In quantum annealing, an exponential spectral gap generally presents a challenge** = energy difference between ground state and first excited state is very small. This small gap can make it harder for the quantum annealer to distinguish between the two states, especially when there's noise in the system. \"However, efficiency of quantum annealing is limited by the exponential closing of the spectral gap with increasing system size.\" Problems:\n",
        "  * In order to stay close to ground state throughout annealing process, evolution parameter \\( s \\) or \\( t \\) needs to change very slowly. This can lead to very long quenching times, making annealing process computationally inefficient.\n",
        "  * Thermal Excitations: thermal fluctuations can easily push system out of ground state because energy difference is small. This makes finding the correct solution (the ground state) less likely.\n",
        "  * Small spectral gap implies sensitivity to external noise. Small gap can cause system to be easily perturbed away from desired evolution.\n",
        "  * Techniques and strategies, like optimized annealing schedules or error-correction methods, may be needed to cope with these challenges.\n",
        "* An exponential spectral gap might mean that the first excited state is close to ground state in terms of energy, the implications for solution quality can vary. Depending on the problem, this could mean you have a nearly optimal solution, or it could mean you're still far from the best possible configuration.\n",
        "  1. **Nature of the Problem**: The importance of the energy difference can vary depending on the nature of the problem you're trying to solve. In some optimization problems, even a small energy difference might correspond to a significant difference in solution quality. In others, the difference might be negligible in practical terms.\n",
        "  2. **Many-body Systems**: Quantum annealing is often applied to complex many-body systems. In these systems, the difference in energy between the ground state and the first excited state might correspond to a complex reconfiguration of many particles or spins. So, the \"distance\" between these states in terms of system configuration might be significant even if their energy difference is small.\n",
        "  3. **Landscapes with Many Local Minima**: In complex optimization problems, there can be many local minima (sub-optimal solutions that are better than their immediate neighbors). The presence of an exponential spectral gap might indicate that the system is easily getting trapped in one of these local minima. While the first excited state might be close in energy to the ground state, there might be other states with much higher energies that are also close in terms of the system's configuration.\n",
        "  4. **Goal of Quantum Annealing**: The primary goal of quantum annealing is to find the global minimum (or a very close approximation to it). So, while the first excited state might offer a \"good\" solution, the aim is typically to find the \"best\" solution, especially in problems where small differences can have amplified outcomes.\n",
        "\n"
      ],
      "metadata": {
        "id": "sDrzyqJlY2sg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Scott Aaronson - Dismantling quantum hype](https://youtu.be/qs0D9sdbKPU)"
      ],
      "metadata": {
        "id": "A8U-2gdBY2sg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/@quantum_wa/quantum-annealing-cdb129e96601\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Annealing_(materials_science)"
      ],
      "metadata": {
        "id": "rneoSBMUY2sg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spectral Gap (and and Combinatorial (Graph) Laplacians)**\n",
        "\n",
        "* Spectral gap = **measure of connectivity of a quantum system** and **difference between second smallest and smallest eigenvalues** of normalized Laplacian matrix of graph (smallest eigenvalue is always zero for connected graphs)\n",
        "\n",
        "* Eigenvalues: $\\lambda_0 \\leq \\lambda_1 \\leq \\lambda_2 \\leq \\dots \\leq \\lambda_{n-1}$, $n$ is number of nodes (vertices) in graph. Spectral gap: $ \\lambda_1$ = smallest non-zero eigenvalue.\n",
        "\n",
        "* Graph with large spectral gap $\\lambda_1 >> 0$ is well-connected. Graph with a small spectral gap is poorly connected.\n",
        "  * It is related to the graph's **Cheeger constant**: The Cheeger constant is a measure of the graph's connectivity that is closely related to the spectral gap.\n",
        "  * It is related to the **graph's mixing time**: The mixing time is the time it takes for a random walk on the graph to converge to its **stationary distribution**. A graph with a **large spectral gap has a short mixing time**, while a graph with a small spectral gap has a long mixing time (relevant in quantum annealing). Similar: **Markov Chains**: In the study of Markov chains, the spectral gap is related to the rate of convergence to the stationary distribution. A larger spectral gap typically means faster convergence.\n",
        "  * Cluster analysis: The spectral gap can be used to find clusters in graphs.\n",
        "  * Graph partitioning: The spectral gap can be used to partition graphs into two pieces with similar properties.\n",
        "  * Random walks: The spectral gap can be used to analyze the behavior of random walks on graphs.\n",
        "  * Diffusion processes: The spectral gap can be used to analyze the behavior of diffusion processes on graphs.\n",
        "* In TDA the smallest non-zero eigenvalue of combinatorial Laplacian is related to number of connected components in the data. The second smallest non-zero eigenvalue is related to the number of holes in the data.\n",
        "  * In gene expression data analysis, the combinatorial Laplacian can be used to identify clusters of genes that are co-expressed. This can be helpful for finding genes that are involved in the same biological process.\n",
        "  * In protein interaction data analysis, the combinatorial Laplacian can be used to identify protein complexes. This can be helpful for understanding how proteins interact with each other to carry out biological functions.\n",
        "  * In image data analysis, the combinatorial Laplacian can be used to identify objects in images. This can be helpful for image segmentation and classification."
      ],
      "metadata": {
        "id": "EeisMgf-84pk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exponential Spectral Gap**\n",
        "\n",
        "* Exponential spectral gap: spectral gap decreases exponentially with respect to some parameter of system.\n",
        "As system size grows, **difference between ground state energy (lowest eigenvalue) and first excited state (next smallest eigenvalue) might decrease exponentially**. This can have important implications for the system's behavior, especially in the context of quantum phase transitions or the computational hardness of approximating certain states.\n",
        "\n",
        "* **The exact interpretation and importance of an exponential spectral gap can vary depending on the context**. In some cases, having such a gap is favorable for certain properties or behaviors, while in other contexts, it might pose challenges or signal specific types of behavior.\n",
        "\n",
        "* In spectral graph theory, an exponential spectral gap is a property of a graph that ensures that the mixing time of a random walk on the graph is exponentially small in the number of vertices. This means that the random walk will converge to its stationary distribution very quickly. Exponential spectral gaps are important for a number of applications, including:\n",
        "  * A graph has an exponential spectral gap if the second smallest eigenvalue of its normalized Laplacian matrix is exponentially small in the number of vertices. This means that the graph is very well-connected, and that the random walk will quickly spread throughout the graph.\n",
        "  * Distributed algorithms: Exponential spectral gaps can be used to design distributed algorithms that are efficient and scalable.\n",
        "  * Communication networks: Exponential spectral gaps can be used to design communication networks that are reliable and efficient.\n",
        "  * Machine learning: Exponential spectral gaps can be used to design machine learning algorithms that are robust to noise and outliers.\n",
        "  * Here are some examples of graphs with exponential spectral gaps:\n",
        "    * Expander graphs: Expander graphs are graphs that have good connectivity properties. They are often used in the design of distributed algorithms and communication networks.\n",
        "    * Ramanujan graphs: Ramanujan graphs are a special type of expander graph that has an exponential spectral gap. They are often used in the design of cryptography protocols.\n",
        "    * Random graphs: Random graphs with a large number of vertices have an exponential spectral gap with high probability. This means that they can be used to design efficient and scalable algorithms for a variety of problems."
      ],
      "metadata": {
        "id": "sMd8jEF587Ka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kernel and Spectral Gap**\n",
        "\n",
        "* there is a connection between kernel and spectral gap. The spectral gap is a measure of how well-separated the eigenvalues of a matrix are. A large spectral gap means that the eigenvalues are well-separated, which means that the matrix is more stable and easier to invert.\n",
        "\n",
        "* The kernel of a matrix is the set of all vectors that are orthogonal to all the eigenvectors of the matrix with eigenvalue 0. In other words, it is the set of all vectors that do not change under the action of the matrix.\n",
        "\n",
        "* The spectral gap of a matrix is related to the kernel of the matrix in the following way: the larger the spectral gap, the smaller the dimension of the kernel. This is because if the spectral gap is large, then the eigenvalues of the matrix are well-separated, which means that there are fewer vectors that are orthogonal to all the eigenvectors with eigenvalue 0.\n",
        "\n",
        "* This connection between kernel and spectral gap has implications for machine learning. Kernel methods are a type of machine learning algorithm that use kernels to compute the similarity between two data points. The spectral gap of the kernel matrix is related to the generalization performance of kernel methods. In general, kernel methods with a larger spectral gap have better generalization performance.\n",
        "\n",
        "* In addition, the kernel of a matrix can be used to define a graph kernel. Graph kernels are a type of similarity measure between graphs. The graph kernel is based on the idea that two graphs are similar if their kernels are similar. The spectral gap of the kernel matrix is related to the quality of the graph kernel. In general, graph kernels with a larger spectral gap have better quality.\n",
        "\n",
        "* Overall, the kernel and spectral gap are two important concepts in machine learning. They are related to each other in a number of ways, and they both have implications for the performance of machine learning algorithms."
      ],
      "metadata": {
        "id": "toLEwiEj89GB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**More on Spectral theory**\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Laplacian_matrix\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Discrete_Laplace_operator\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Spectral_graph_theory\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Spectral_shape_analysis\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Spectral_clustering\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Laplace_operator"
      ],
      "metadata": {
        "id": "gUQX_Eay8_JY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Dequantization and Quantum-Inspired Algorithms*"
      ],
      "metadata": {
        "id": "mL9gnsMGYrOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paper: [Ewin Tang: Quantum Machine Learning Without Any Quantum](https://inspirehep.net/literature/2716091)"
      ],
      "metadata": {
        "id": "OuJiSsXIeITe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Dequantization*"
      ],
      "metadata": {
        "id": "GUue56lG_YaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A quantum-inspired classical algorithm for recommendation systems - Ewin Tang\n",
        "\n",
        "https://arxiv.org/abs/1807.04271"
      ],
      "metadata": {
        "id": "9dbIAh0C5FjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ewan Tang is known for finding a classical algorithm that solves the problem of recommendation systems as efficiently as the best-known quantum algorithm. The quantum version of the problem was solved using an algorithm called Quantum Singular Value Transformation (QSVD). The classical version, however, had no known efficient algorithm, until Tang's work.\n",
        "\n",
        "Ewan Tang's dequantization approach takes advantage of the structure of the QSVD algorithm. He noted that the QSVD operates on sparse, low-rank matrices, and developed a classical algorithm that could handle this structure efficiently.\n",
        "\n",
        "Here's a simplified overview of Tang's algorithm:\n",
        "\n",
        "1. **Input Data Conversion**: Transform the input data into a sparse, low-rank format. In the context of recommendation systems, this might mean constructing a matrix where the rows correspond to users, the columns correspond to products, and each entry reflects the user's preference for the product.\n",
        "\n",
        "2. **Sampling Procedure**: Use a randomized sampling procedure to select a small number of \"landmark\" columns (products). The selection probability for each column is proportional to its contribution to the total preference scores.\n",
        "\n",
        "3. **Low-Rank Approximation**: Construct a low-rank approximation of the original preference matrix based on the sampled columns.\n",
        "\n",
        "4. **Estimation**: Use the low-rank approximation to estimate the user's preferences for all other products.\n",
        "\n",
        "This is a simplified version of the process. The actual algorithm involves a lot of linear algebra, randomization, and complexity analysis. If you're interested in the full technical details, you can look up Ewan Tang's paper \"A quantum-inspired classical algorithm for recommendation systems\".\n",
        "\n",
        "To summarize, the dequantization process involved taking a quantum algorithm and identifying the aspects of the quantum algorithm that could be implemented classically, thereby creating a classical version of the algorithm with similar efficiency."
      ],
      "metadata": {
        "id": "BNQYlE1k42Ss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum-inspired Algorithms**\n",
        "\n",
        "* quantum computers still exhibit an exponential speedup over all known classical algorithms for **sparse, full-rank matrix problems**, including the quantum Fourier transform, eigenvector and eigenvalue analysis, linear systems, and others https://arxiv.org/abs/1905.10415\n",
        "* Quantum algorithms for linear algebra are a flagship application of quantum computing, partic- ularly due to their relevance in machine learning. These algorithms typically [scale polylogarithmically](https://en.wikipedia.org/wiki/Polylogarithmic_function) with dimension, which, at the time they were reported, implied an asymptotic exponential speedup compared to state-of-the-art classical methods. For this reason, significant interest has been generated in the dequantization approach that led to breakthrough quantum- inspired classical algorithms for linear algebra problems with sublinear complexity https://arxiv.org/abs/1905.10415\n",
        "\n",
        "* https://crypto.stackexchange.com/questions/48638/whats-the-difference-between-polylogarithmic-and-logarithmic\n",
        "\n",
        "* For example, matrix chain ordering can be solved in polylogarithmic time on a Parallel Random Access Machine."
      ],
      "metadata": {
        "id": "mUzaGhCi1Y26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dequantization a quantum algorithm**\n",
        "* Not all problems are amenable to quantum speed-up. Quantum algorithms are specifically efficient for problems where a superposition of solutions can be created and manipulated. Linear algebra problems, especially in high dimensions, may not easily lend themselves to such superposition-based speed-ups.\n",
        "* **Output limitations**: Even if a quantum computer can perform a computation faster, it might not be able to provide the result in a way that's useful or can be checked in a reasonable time by a classical computer. This limitation is a crucial aspect in quantum linear algebra problems. For example, **you can load a vector into a quantum state exponentially faster, but you cannot read out all the entries in less than exponential time due to the 'no-cloning' theorem of quantum mechanics.** (limits ability to fully read out the state of a quantum system: each measurement only gives you a tiny piece of the picture, and you would have to repeat the process an exponential number of times to see the full state.)\n",
        "* Tang’s algorithm builds on a classical data structure called a \"tree of singular vectors,\" which is used to approximate the product of the preference matrix with a vector that represents a new user's preferences. This approximation is good enough to recommend items in a way that's nearly as good as the quantum algorithm.\n",
        "* The approach relies on a form of algorithm called \"randomized sampling algorithms\" and works by creating a probability distribution that closely matches the one that would have been created by a quantum computer. By cleverly sampling from this distribution, Tang's algorithm can estimate the answers to the recommendation problem almost as accurately as the quantum version.\n",
        "* Tang's algorithm relies heavily on the specifics of the recommendation system problem: the user-product preference matrix is \"low rank.\" Therefore, it doesn't mean that all quantum algorithms can be dequantized in the same way.\n",
        "* https://arxiv.org/abs/1905.10415 with https://www.math.cmu.edu/~af1p/Texfiles/SVD.pdf\n",
        "* There are two ways to compute the average of many values. A first method is to add all of them together and divide the result by the total number of values. An alternative approach is to select a few values at random, then compute their average using the first method. Of course, in the second case we get only an approximation of the true average, but in many cases that is good enough and can be done in significantly less time.\n",
        "* **This is the strategy of quantum-inspired algorithms: the coefficients of the solution vector are inner products between vectors, which can be expressed as the average of a collection of numbers that depend on the entries of the vectors**. Instead of directly computing this average (which takes linear time) we select a few of the values at random and compute their average instead.\n",
        "* The question is, how many values do we need to sample to get a good approximation? It turns out that **the number of samples grows with the precision of the approximation, the rank, and the condition number of the input matrix.**\n",
        "* In practice, this estimation method is only faster than a direct calculation of the coefficients if (i) precision, rank, and condition number are small, and (ii) the input matrix has a colossal dimension.\n",
        "* In practice, it pays off to be slightly more sophisticated: we keep each number with likelihood proportional to its value, such that large numbers are kept with high probability and small numbers with low probability. This is the basis of a technique called [rejection sampling](https://en.m.wikipedia.org/wiki/Rejection_sampling), **which is employed in quantum-inspired algorithms to sample from the solution vectors**. Once the approximate singular value decomposition has been obtained and the coefficients have been estimated, it is possible to query any entry of the solution vector in sublinear time.\n",
        "* https://medium.com/xanaduai/everything-you-always-wanted-to-know-about-quantum-inspired-algorithms-38ee1a0e30ef\n",
        "* https://cstheory.stackexchange.com/questions/42338/list-of-quantum-inspired-algorithms\n",
        "* https://github.com/XanaduAI/quantum-inspired-algorithms"
      ],
      "metadata": {
        "id": "w5EmlC2n2rN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Tensor Networks*"
      ],
      "metadata": {
        "id": "vUaRXgHIgW2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://iopscience.iop.org/article/10.1088/2058-9565/aaea94\n",
        "\n",
        "https://pennylane.ai/qml/demos/tutorial_tn_circuits#huggins"
      ],
      "metadata": {
        "id": "TJ5Ir5fTM-DK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor networks applied in quantum-inspired algorithms?** Solving Optimization Problems: Tensor networks can also be used to solve optimization problems. By mapping the problem onto a tensor network, we can use techniques like the Density Matrix Renormalization Group (DMRG) to find the optimal solution. This is particularly useful for problems where the number of variables is large, as is often the case in optimization problems."
      ],
      "metadata": {
        "id": "VyCQ6sLRpzRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**are Tensor Networks a form of quantum-inspired algorithm or not?**\n",
        "\n",
        "Tensor networks are a mathematical tool widely used in many-body quantum physics and quantum information theory. They provide a way to efficiently represent and manipulate high-dimensional tensors (or high-dimensional arrays of numbers), which frequently occur in these fields.\n",
        "\n",
        "Quantum many-body systems, which involve multiple interacting quantum particles, give rise to high-dimensional tensors. When these interactions are local, it turns out that the resulting state of the system can be represented more efficiently with a tensor network, allowing for computational tractability.\n",
        "\n",
        "However, tensor networks are not inherently quantum-inspired algorithms. They are more of a framework or a technique for representing complex multi-dimensional data structures, which can be used in the development of algorithms for quantum and classical computations.\n",
        "\n",
        "Where the quantum inspiration comes in is their application: tensor networks are extensively used to study quantum systems. For instance, they are used in algorithms for simulating quantum systems, understanding quantum entanglement, quantum error correction, and so on. They have also found applications beyond quantum physics, such as machine learning and artificial intelligence.\n",
        "\n",
        "In summary, tensor networks themselves are not quantum-inspired algorithms, but they are a critical tool in the development and application of algorithms (including quantum-inspired ones) used in quantum physics and quantum computing."
      ],
      "metadata": {
        "id": "Zn8-X-V23faS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* tensor networks are mathematical constructs that are used to represent and manipulate quantum states, particularly those with many parts or \"qubits\".\n",
        "\n",
        "* In the context of quantum computing, each number in the tensor can represent an amplitude of a quantum state.\n",
        "\n",
        "* A tensor network is a particular way of organizing and manipulating these tensors. In a tensor network, each tensor is represented as a node, and the indices of the tensor are represented as edges connecting the nodes. By organizing the tensors in this way, **certain computations can be performed more efficiently, particularly those involving high-dimensional tensors**.\n",
        "\n",
        "* The real power of tensor networks comes from their ability to efficiently represent and manipulate certain types of quantum states, particularly those that exhibit some form of entanglement. **In many physical systems, and particularly in systems that are near their ground state, the quantum state of the system can be well approximated by a tensor network with a relatively simple structure**.\n",
        "\n",
        "* This makes **tensor networks a very useful tool for simulating such systems on a classical computer**.\n",
        "\n",
        "* For instance, the class of states that can be efficiently represented by a tensor network includes many states that arise in condensed matter physics and quantum chemistry, as well as some states that are used in quantum error correction and quantum computing.\n",
        "\n",
        "* One common type of tensor network is the [Matrix Product State](https://en.m.wikipedia.org/wiki/Matrix_product_state) (MPS), which is used in the [Density Matrix Renormalization Group](https://en.m.wikipedia.org/wiki/Density_matrix_renormalization_group) (DMRG) method, a powerful method for simulating one-dimensional quantum systems.\n",
        "\n",
        "  * The density matrix renormalization group (DMRG) is a numerical variational technique devised to obtain the [low-energy physics](https://en.m.wikipedia.org/wiki/Macroscopic_scale) of quantum many-body systems with high accuracy. As a variational method, DMRG is an efficient algorithm that attempts to find the lowest-energy matrix product state wavefunction of a Hamiltonian.\n",
        "\n",
        "( Other types of tensor networks include the Projected Entangled Pair State (PEPS), the Multi-scale Entanglement Renormalization Ansatz (MERA), and others."
      ],
      "metadata": {
        "id": "vtMw-E_BgcNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Variational Quantum Eigensolver*"
      ],
      "metadata": {
        "id": "pqNjjLBMYen-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introduction to Variational Quantum Algorithms, Michał Stęchły: https://arxiv.org/abs/2402.15879"
      ],
      "metadata": {
        "id": "2ljmkwo_KEVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [Molecular Simulation with VQE](https://youtu.be/fJUzXbr5MTo?si=1JMrO5SZ0LRPjtYK)\n",
        "\n",
        "Pennylane: [A brief overview of VQE](https://pennylane.ai/qml/demos/tutorial_vqe/)\n",
        "\n",
        "Pennylane: [Accelerating VQEs with quantum natural gradient](https://pennylane.ai/qml/demos/tutorial_vqe_qng/)\n",
        "\n",
        "Science: [The Variational Quantum Eigensolver: A review of methods and best practices](https://www.sciencedirect.com/science/article/pii/S0370157322003118)"
      ],
      "metadata": {
        "id": "U17xCMOzQVGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane\n",
        "import pennylane as qml"
      ],
      "metadata": {
        "id": "qflJUgxEoaRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cirq -q\n",
        "import cirq"
      ],
      "metadata": {
        "id": "Y_exZOM0olAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from jax import numpy as np\n",
        "import jax\n",
        "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
        "jax.config.update('jax_enable_x64', True)\n",
        "\n",
        "symbols = [\"H\", \"H\"]\n",
        "coordinates = np.array([0.0, 0.0, -0.6614, 0.0, 0.0, 0.6614])"
      ],
      "metadata": {
        "id": "WL3XibcPop69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H, qubits = qml.qchem.molecular_hamiltonian(symbols, coordinates)\n",
        "print(\"Number of qubits = \", qubits)\n",
        "print(\"The Hamiltonian is \", H)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCxAGQMZoUC8",
        "outputId": "b4b0ccf4-c394-41e0-882b-1109b7f78836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of qubits =  4\n",
            "The Hamiltonian is    (-0.2427450126094144) [Z2]\n",
            "+ (-0.2427450126094144) [Z3]\n",
            "+ (-0.042072551947439224) [I0]\n",
            "+ (0.1777135822909176) [Z0]\n",
            "+ (0.1777135822909176) [Z1]\n",
            "+ (0.12293330449299361) [Z0 Z2]\n",
            "+ (0.12293330449299361) [Z1 Z3]\n",
            "+ (0.16768338855601356) [Z0 Z3]\n",
            "+ (0.16768338855601356) [Z1 Z2]\n",
            "+ (0.17059759276836803) [Z0 Z1]\n",
            "+ (0.1762766139418181) [Z2 Z3]\n",
            "+ (-0.044750084063019925) [Y0 Y1 X2 X3]\n",
            "+ (-0.044750084063019925) [X0 X1 Y2 Y3]\n",
            "+ (0.044750084063019925) [Y0 X1 X2 Y3]\n",
            "+ (0.044750084063019925) [X0 Y1 Y2 X3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev = qml.device(\"lightning.qubit\", wires=qubits)"
      ],
      "metadata": {
        "id": "lNzMZ21Ro9KD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "electrons = 2\n",
        "hf = qml.qchem.hf_state(electrons, qubits)\n",
        "print(hf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0XkmxHrpcA_",
        "outputId": "b47538a5-7ca1-459c-c68f-7819b145e1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@qml.qnode(dev)\n",
        "def circuit(param, wires):\n",
        "    qml.BasisState(hf, wires=wires)\n",
        "    qml.DoubleExcitation(param, wires=[0, 1, 2, 3])\n",
        "    return qml.expval(H)"
      ],
      "metadata": {
        "id": "9D8Tz5KLpZ0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_fn(param):\n",
        "    return circuit(param, wires=range(qubits))"
      ],
      "metadata": {
        "id": "SC484qkipfCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The library [optax](https://optax.readthedocs.io/en/latest/) offers different optimizers. Here we use a basic gradient-descent optimizer."
      ],
      "metadata": {
        "id": "lSRK_jEbpj85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optax\n",
        "\n",
        "max_iterations = 100\n",
        "conv_tol = 1e-06\n",
        "\n",
        "opt = optax.sgd(learning_rate=0.4)"
      ],
      "metadata": {
        "id": "JIocB1FFpiNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "theta = np.array(0.)\n",
        "\n",
        "# store the values of the cost function\n",
        "energy = [cost_fn(theta)]\n",
        "\n",
        "# store the values of the circuit parameter\n",
        "angle = [theta]\n",
        "\n",
        "opt_state = opt.init(theta)\n",
        "\n",
        "for n in range(max_iterations):\n",
        "\n",
        "    gradient = jax.grad(cost_fn)(theta)\n",
        "    updates, opt_state = opt.update(gradient, opt_state)\n",
        "    theta = optax.apply_updates(theta, updates)\n",
        "\n",
        "    angle.append(theta)\n",
        "    energy.append(cost_fn(theta))\n",
        "\n",
        "    conv = np.abs(energy[-1] - energy[-2])\n",
        "\n",
        "    if n % 2 == 0:\n",
        "        print(f\"Step = {n},  Energy = {energy[-1]:.8f} Ha\")\n",
        "\n",
        "    if conv <= conv_tol:\n",
        "        break\n",
        "\n",
        "print(\"\\n\" f\"Final value of the ground-state energy = {energy[-1]:.8f} Ha\")\n",
        "print(\"\\n\" f\"Optimal value of the circuit parameter = {angle[-1]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_-Pae1dpxIX",
        "outputId": "3125c07b-6da0-4347-8aa2-9d7e3ada3d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pennylane/math/utils.py:227: UserWarning: Contains tensors of types {'jax', 'autograd'}; dispatch will prioritize TensorFlow, PyTorch, and  Jax over Autograd. Consider replacing Autograd with vanilla NumPy.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step = 0,  Energy = -1.12799983 Ha\n",
            "Step = 2,  Energy = -1.13466246 Ha\n",
            "Step = 4,  Energy = -1.13590595 Ha\n",
            "Step = 6,  Energy = -1.13613667 Ha\n",
            "Step = 8,  Energy = -1.13617944 Ha\n",
            "Step = 10,  Energy = -1.13618736 Ha\n",
            "Step = 12,  Energy = -1.13618883 Ha\n",
            "\n",
            "Final value of the ground-state energy = -1.13618883 Ha\n",
            "\n",
            "Optimal value of the circuit parameter = 0.2089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.set_figheight(5)\n",
        "fig.set_figwidth(12)\n",
        "\n",
        "# Full configuration interaction (FCI) energy computed classically\n",
        "E_fci = -1.136189454088\n",
        "\n",
        "# Add energy plot on column 1\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax1.plot(range(n + 2), energy, \"go\", ls=\"dashed\")\n",
        "ax1.plot(range(n + 2), np.full(n + 2, E_fci), color=\"red\")\n",
        "ax1.set_xlabel(\"Optimization step\", fontsize=13)\n",
        "ax1.set_ylabel(\"Energy (Hartree)\", fontsize=13)\n",
        "ax1.text(0.5, -1.1176, r\"$E_\\mathrm{HF}$\", fontsize=15)\n",
        "ax1.text(0, -1.1357, r\"$E_\\mathrm{FCI}$\", fontsize=15)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "# Add angle plot on column 2\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(range(n + 2), angle, \"go\", ls=\"dashed\")\n",
        "ax2.set_xlabel(\"Optimization step\", fontsize=13)\n",
        "ax2.set_ylabel(\"Gate parameter $\\\\theta$ (rad)\", fontsize=13)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "plt.subplots_adjust(wspace=0.3, bottom=0.2)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "H3oayNtGp1RT",
        "outputId": "8c085e3c-52d8-4eea-9200-2d95c8328d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMsbZlxPt-Ec"
      },
      "source": [
        "###### *Basics*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cirq -q"
      ],
      "metadata": {
        "id": "-9RCNq3pbJLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrsTqiiWae2Z"
      },
      "outputs": [],
      "source": [
        "import cirq\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Simple Addition & Multiplication with Qubits*"
      ],
      "metadata": {
        "id": "2g4g4-lesqTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://summerofcode.withgoogle.com/programs/2022/projects/bYQLcqgf"
      ],
      "metadata": {
        "id": "5WtoVBcTbptm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfGBWIy6S_V6"
      },
      "source": [
        "**Task 1: Addition of 1 + 0 + 0 = 1 (01 in binary): We flip q0 and q1 from 0 to 1 with Pauli-X**\n",
        "\n",
        "**Task 2: Addition of 1 + 1 + 0 = 2 (10 in binary): We flip q0 and q1 from 0 to 1 with Pauli-X**\n",
        "\n",
        "**Task 3: Addition of 1 + 1 + 1 = 3 (11 in binary): We flip q0, q1 and q2 from 0 to 1 with Pauli-X**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF7MxZrjaXod"
      },
      "source": [
        "https://qiskit.org/textbook/ch-states/atoms-computation.html#adder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKzohJI59hm1"
      },
      "source": [
        "0+0 = 00 (in decimal, this is 0+0=0)\n",
        "\n",
        "0+1 = 01 (in decimal, this is 0+1=1)\n",
        "\n",
        "1+0 = 01 (in decimal, this is 1+0=1)\n",
        "\n",
        "1+1 = 10 (in decimal, this is 1+1=2)\n",
        "\n",
        "This is called a half adder. If our computer can implement this, and if it can chain many of them together, it can add anything.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4ktOROmyohu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6dcbf27-7547-4ca7-f22d-5afd6282ce27"
      },
      "source": [
        "# Create Circuit object\n",
        "circuit = cirq.Circuit()\n",
        "\n",
        "# Define 2 qubits - They start with 0 (if you measure no, you'll see a 0 in both)\n",
        "(q0, q1, q2, q3) = cirq.LineQubit.range(4)\n",
        "\n",
        "\n",
        "\n",
        "## Set up calculation:\n",
        "\n",
        "# We flip q0 from 0 to 1 with Pauli-X\n",
        "circuit.append([cirq.X(q0)])\n",
        "\n",
        "# We flip q1 from 0 to 1 with Pauli-X\n",
        "#circuit.append([cirq.X(q1)])\n",
        "\n",
        "# We flip q2 from 0 to 1 with Pauli-X\n",
        "#circuit.append([cirq.X(q2)])\n",
        "\n",
        "\n",
        "\n",
        "# CNOT (Controlled Pauli X) for input q2 and target q0 (0 is same, 1 if different for target)\n",
        "# since q2 is 0 and q0 is 1, result will stay 1\n",
        "circuit.append([cirq.CNOT(q0, q2)])\n",
        "\n",
        "# CNOT (Controlled Pauli X) for input q2 and target q1 (0 is same, 1 if different for target)\n",
        "# since q2 is 0 and q1 is 1, result will stay 1\n",
        "circuit.append([cirq.CNOT(q1, q2)])\n",
        "\n",
        "# Toffoli (CCNOT) gate on q3 (if both inputs are equal, write 1, else 0) (perform a NOT on target qubit when both controls are in state 1)\n",
        "circuit.append([cirq.CCX(q0, q1, q3)])\n",
        "\n",
        "# Measure output quantum bits q2 and q3\n",
        "circuit.append([cirq.measure(q2), cirq.measure(q3)])\n",
        "\n",
        "# See what circuit has been produced (optional)\n",
        "print(circuit)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  ┌──┐\n",
            "0: ───X───@────────@─────────\n",
            "          │        │\n",
            "1: ───────┼───@────@─────────\n",
            "          │   │    │\n",
            "2: ───────X───X────┼M────────\n",
            "                   │\n",
            "3: ────────────────X─────M───\n",
            "                  └──┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xKYREY8qEe-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d99a1a1-b3d5-499c-9ecb-7f6a9feb68a8"
      },
      "source": [
        "# Step 6: Perform simulation of the circuit and read out result\n",
        "sim = cirq.Simulator()\n",
        "results = sim.run(circuit, repetitions=10)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2=1111111111\n",
            "3=0000000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb80-XsV-uXr"
      },
      "source": [
        "> Read from rightmost qubit first (q3) and then next left (q2): result is 10 (binary) = 2 in decimal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIJxNgdxui1J"
      },
      "source": [
        "<font color=\"blue\">**Simple Multiplication with Qubits**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://csferrie.medium.com/the-stupidest-most-technologically-and-resource-inefficient-way-to-multiply-by-two-fd6d0290f7b6"
      ],
      "metadata": {
        "id": "ii5DgpBfsuVf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFxhMEfyzVCn"
      },
      "source": [
        "*Superdense Coding (Bell State): 1 Qubit - Tensor Product of two Parallel Gates (Superposition in Multiple Qubits)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUeRMCzt8AQm"
      },
      "source": [
        "# Create Vanilla Qubits\n",
        "# Named Qubit\n",
        "a = cirq.NamedQubit(\"a\")\n",
        "b = cirq.NamedQubit(\"b\")\n",
        "\n",
        "#Line-Qubit\n",
        "qubits = cirq.LineQubit.range(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_44NH72uf_p"
      },
      "source": [
        "The tensor product (or Kronecker product) of two quantum gates is the gate that is equal to the two gates in parallel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK6sea6xzzpq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33d8d5b-b5f6-4801-9e3c-f9d099bab71a"
      },
      "source": [
        "# Define operations\n",
        "ops=[cirq.Y(a), # Superposition\n",
        "     cirq.X(b), # Entanglement\n",
        "     cirq.measure(a,b)] # Measurement\n",
        "\n",
        "# Build circuit\n",
        "circuit=cirq.Circuit(ops)\n",
        "\n",
        "print(circuit)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: ───Y───M───\n",
            "          │\n",
            "b: ───X───M───\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg7C-Rrfu0ta"
      },
      "source": [
        "*Two gates $Y$ and $X$ in parallel is equivalent to the gate $Y\\otimes X$*\n",
        "\n",
        "![ggg](https://upload.wikimedia.org/wikipedia/commons/d/d5/Parallel_quantum_logic_gates.png)\n",
        "\n",
        "If we, as in the picture, combine the Pauli-Y gate with the Pauli-X gate in parallel, then this can be written as:\n",
        "\n",
        "> $C=Y \\otimes X=\\left[\\begin{array}{cc}0 & -i \\\\ i & 0\\end{array}\\right] \\otimes\\left[\\begin{array}{ll}0 & 1 \\\\ 1 & 0\\end{array}\\right]=\\left[\\begin{array}{ll}0\\left[\\begin{array}{ll}0 & 1 \\\\ 1 & 0\\end{array}\\right] & -i\\left[\\begin{array}{ll}0 & 1 \\\\ 1 & 0\\end{array}\\right] \\\\ i\\left[\\begin{array}{ll}0 & 1 \\\\ 1 & 0\\end{array}\\right] & 0\\left[\\begin{array}{ll}0 & 1 \\\\ 1 & 0\\end{array}\\right]\\end{array}\\right]=\\left[\\begin{array}{cccc}0 & 0 & 0 & -i \\\\ 0 & 0 & -i & 0 \\\\ 0 & i & 0 & 0 \\\\ i & 0 & 0 & 0\\end{array}\\right]$\n",
        "\n",
        "Both the Pauli-X and the Pauli-Y gate act on a single qubit. The resulting gate $C$ act on two qubits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvYfx3Klz9uZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfcf89f5-ae06-4f5f-c592-8fb0c9a9de70"
      },
      "source": [
        "# Run Simulations & Measurements\n",
        "simulator = cirq.Simulator()\n",
        "result = simulator.run(circuit,repetitions=10)\n",
        "print('Measurement results')\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Measurement results\n",
            "a,b=1111111111, 1111111111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd5HWgP-0BOc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1a4b69ee-bdb8-4ddd-fd21-2c841a21961e"
      },
      "source": [
        "# Visualization\n",
        "# After doing that, you should see the quantum state become ∣00⟩+∣11⟩\n",
        "_ = cirq.vis.plot_state_histogram(result) #, plt.subplot())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8IiwYzr0C6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ff3405-83d1-4d9e-c94b-78477665c1ce"
      },
      "source": [
        "result.histogram(key=\"a,b\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({3: 10})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn4LwsmviwZx"
      },
      "source": [
        "*Superdense Coding (Bell State): 2 Qubits - CNOT Gate (CX) [and Controlled-U Gate]: Create Bell state (Superposition across Multiple Qubits)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMHUCZ7JW3rD"
      },
      "source": [
        "> CNOT, acting on a two-qubit term $\\left|q_{1} q_{2}\\right\\rangle$, applies the $\\mathbf{N O T}(\\mathbf{X})$ gate to the second qubit only if the first qubit is in state $|1\\rangle$. The first qubit controls the action on the second.\n",
        "\n",
        "> 0 im Output wenn zwei Inputs gleich sind. 1 im Output wenn die Inputs unterschiedlich sind."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaEJwXg_j-Uz"
      },
      "source": [
        "*Entanglement*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uuAkp8gkA0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5caa5014-0742-46c2-aa90-6a31722146d1"
      },
      "source": [
        "cirq.unitary(cirq.CNOT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
              "       [0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j],\n",
              "       [0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j],\n",
              "       [0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khD7BYNRWJXK"
      },
      "source": [
        "The [Controlled NOT gate](https://en.m.wikipedia.org/wiki/Controlled_NOT_gate) (also C-NOT or CNOT, controlled Pauli-X) is a quantum logic gate that is an essential component in the construction of a gate-based quantum computer. **It can be used to entangle and disentangle Bell states**. Any quantum circuit can be simulated to an arbitrary degree of accuracy using a combination of CNOT gates and single qubit rotations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjXVjG5wWjQn"
      },
      "source": [
        ">$\n",
        "\\begin{array}{|c|c|c|c|}\n",
        "\\hline {\\text { Before }} & {\\text { Before }}& {\\text { After }}& {\\text { After }} \\\\\n",
        "\\hline \\text { Control } & \\text { Target } & \\text { Control } & \\text { Target } \\\\\n",
        "\\hline|0\\rangle & |0\\rangle & |0\\rangle & |0\\rangle \\\\\n",
        "\\hline|0\\rangle & |1\\rangle & |0\\rangle & |1\\rangle \\\\\n",
        "\\hline|1\\rangle & |0\\rangle & |1\\rangle & |1\\rangle \\\\\n",
        "\\hline|1\\rangle & |1\\rangle & |1\\rangle & |0\\rangle \\\\\n",
        "\\hline\n",
        "\\end{array}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e7Iu9kdXSdI"
      },
      "source": [
        "A common application of the $\\mathrm{C}_{\\text {NOT }}$ gate is to maximally entangle two qubits into the $\\left|\\Phi^{+}\\right\\rangle$ Bell state; this forms part of the setup of the superdense coding, quantum teleportation, and entangled quantum cryptography algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNsYOdI-A1rh"
      },
      "source": [
        "CNOT or controlled Pauli-X.\n",
        "\n",
        "* **Verschrankt zwei Qubits und invertiert das Ziel-Qubit**, wenn das Kontroll-Qubit 1 ist:\n",
        "\n",
        "> $|00\\rangle \\rightarrow|00\\rangle$\n",
        "\n",
        "> $|01\\rangle \\rightarrow|01\\rangle$\n",
        "\n",
        "> $|10\\rangle \\rightarrow|11\\rangle$\n",
        "\n",
        "> $|11\\rangle \\rightarrow|10\\rangle$\n",
        "\n",
        "Matrix-Darstellung:\n",
        "\n",
        "> $\\left(\\begin{array}{llll}1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0\\end{array}\\right)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj9br36Vk44_"
      },
      "source": [
        "The CNOT (or controlled Pauli- $X$ ) gate can be described as the gate that maps the basis states $|a, b\\rangle \\mapsto|a, a \\oplus b\\rangle$, where $\\oplus$ is XOR.\n",
        "\n",
        "**Controlled-U Gate**\n",
        "\n",
        "More generally if $U$ is a gate that operates on single qubits with matrix representation\n",
        "\n",
        ">$\n",
        "U=\\left[\\begin{array}{ll}\n",
        "u_{00} & u_{01} \\\\\n",
        "u_{10} & u_{11}\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n",
        "then the controlled-U gate is a gate that operates on two qubits in such a way that the first qubit serves as a control.\n",
        "\n",
        "It maps the basis states as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tak_03Fvkl1v"
      },
      "source": [
        "$|00\\rangle \\mapsto|00\\rangle$\n",
        "\n",
        "$|01\\rangle \\mapsto|01\\rangle$\n",
        "\n",
        "$|10\\rangle \\mapsto|1\\rangle \\otimes U|0\\rangle=|1\\rangle \\otimes\\left(u_{00}|0\\rangle+u_{10}|1\\rangle\\right)$\n",
        "\n",
        "$|11\\rangle \\mapsto|1\\rangle \\otimes U|1\\rangle=|1\\rangle \\otimes\\left(u_{01}|0\\rangle+u_{11}|1\\rangle\\right)$\n",
        "\n",
        "The matrix representing the controlled $U$ is\n",
        "\n",
        ">$\n",
        "\\mathrm{C} U=\\left[\\begin{array}{cccc}\n",
        "1 & 0 & 0 & 0 \\\\\n",
        "0 & 1 & 0 & 0 \\\\\n",
        "0 & 0 & u_{00} & u_{01} \\\\\n",
        "0 & 0 & u_{10} & u_{11}\n",
        "\\end{array}\\right]\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFjTkqQokCsL"
      },
      "source": [
        "**When U is one of the Pauli operators, X,Y, Z, the respective terms \"controlled-X\", \"controlled-Y\", or \"controlled-Z\" are sometimes used**.\n",
        "Sometimes this is shortened to just CX, CY and CZ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhT8fxnaNT1l"
      },
      "source": [
        "**Code example: Create Bell state**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqtfaFwR8CEu"
      },
      "source": [
        "# Create Vanilla Qubits\n",
        "# Named Qubit\n",
        "a = cirq.NamedQubit(\"a\")\n",
        "b = cirq.NamedQubit(\"b\")\n",
        "\n",
        "#Line-Qubit\n",
        "qubits = cirq.LineQubit.range(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBdsoUTDg28-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea5bde48-037f-4b01-e04c-2dfb6e8aa2f9"
      },
      "source": [
        "# Define operations\n",
        "ops=[cirq.H(a), # Superposition\n",
        "     cirq.CNOT(a,b), # Entanglement\n",
        "     cirq.H(a),\n",
        "     cirq.measure(a,b)] # Measurement\n",
        "\n",
        "# Build circuit\n",
        "circuit=cirq.Circuit(ops)\n",
        "\n",
        "print(circuit)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: ───H───@───H───M───\n",
            "          │       │\n",
            "b: ───────X───────M───\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxq5eTXkmys2"
      },
      "source": [
        "*More about creating Bell state from superposition & entanglement: [Demystifying Superdense Coding](https://medium.com/qiskit/demystifying-superdense-coding-41d46401910e)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF6YnhaagPp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a0b5fac-578b-46bc-f020-fd9753a885a5"
      },
      "source": [
        "# Run Simulations & Measurements\n",
        "simulator = cirq.Simulator()\n",
        "result = simulator.run(circuit,repetitions=100)\n",
        "print('Measurement results')\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Measurement results\n",
            "a,b=1110010101010110111100101011011111100100110101101101110000110001010000101011100100111110000001011001, 1100000001000011000100101011011000110101101001100111111001101000001100010010100010100100001010100000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMhisVFLhpHX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "17879c7d-4006-4943-b674-5c7805858852"
      },
      "source": [
        "# Visualization\n",
        "# After doing that, you should see the quantum state become ∣00⟩+∣11⟩\n",
        "_ = cirq.vis.plot_state_histogram(result) #, plt.subplot())\n",
        "# https://quantumai.google/cirq/tutorials/state_histograms"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXJ0lEQVR4nO3de7hddX3n8fdHQEFAkOFIwyXGUSqiVcCUS0GLFyqCFph6qVqqFo06ZbxUO0XHKlrbB5/BW2uHGkYLVKT4FBUrKKYOlOIFTRAQjFWL4QEMJApIgvUS/M4fax3dHE5Ods7J2jsn6/16nv2cdf99zzrJZ6/9W2uvlapCktQfDxp3AZKk0TL4JalnDH5J6hmDX5J6xuCXpJ4x+CWpZwx+bfWSXJHkFeOuo0tJ1if5r+OuQ/1g8GuzJFmV5D/boLo9yTlJdhlh+y9LctUmlnl8ks8nuTPJ3UlWJDmunXd0kls3s81K8pg51PyA9ZOcnuSjk+NVtUtV3bSJ7Wx27dJ0DH7NxnOrahfgIOBg4M1jrmeqfwaWAb8GPAJ4LXDPWCuaB5JsN+4aNBoGv2atqm4HLqN5AwAgyeFJvtQeaV+X5OiBeS9LclOSdUm+l+Ql7fT7Hf0mWdQeJW8/2F6SxwF/BxzRfuK4e2pNSfYEHgWcXVU/a19frKqrkuwMfBbYu11/fZK9kxya5MttzauTfDDJg9vtXdlu+rp2+Re205+T5Np2nS8leeJc9uXgp4IkxyX5Zrufbkvyphlqf0iS9yf5fvt6f5KHDGz3f7a/0/eTvGJKO+ckOSvJpUnuBZ6W5PgkX09yT5Jbkpw+zd/l5e28u5K8OslvJrm+3RcfnMt+0IhUlS9fQ7+AVcAz2+F9gW8AH2jH9wF+CBxHc1BxTDs+AexMc9T92HbZBcDj2+HTgY8OtLEIKGD7dvwK4BXt8MuAq2aoL8B3gM8AJwJ7TZl/NHDrlGlPBg4Htm/bXgm8fmB+AY8ZGD8YWAMcBmwHvLTdLw/ZSE33W38jv/MvlwFWA09phx8OHDJD7e8EvkLzyWYC+BLwF+28Y4HbgccDDwU+OqWdc4AfAUe2f68d2zZ+ox1/InAHcOKUv8vftcv+DvAT4FNt+/u0++W3x/3v1NfML4/4NRufSrIOuIXmP/rb2+l/AFxaVZdW1S+qahmwnOaNAOAXwBOS7FRVq6vqxi1dWDUJ9TSaIH4PsDrJlUn2n2GdFVX1laraUFWrgA8Bvz1DM0uAD1XV1VV1X1WdC/yU5s1jY65pj4jvbj+pnDbDsj8HDkzysKq6q6qumWHZlwDvrKo1VbUWeAdwcjvvBcDfV9WNVfVjmjebqS6u5hPRL6rqJ1V1RVV9ox2/HriAB+6Lv2iX/TxwL3BB2/5twL/RvDFqK2bwazZOrKpdaY4ODwD2bKc/Enj+lIA7ClhQVfcCLwReTRPGlyQ5oIviqurWqjq1qh7d1nQvcN7Glk/y60k+056svgf4q4HfaTqPBN445ffcD9h7hnUOqardJ1/AGTMs+3s0b5Y3J/nXJEfMsOzewM0D4zcP1LE3zZvzpMHhaaclOSzJ5UnWJvkRzd9r6r64Y2D4P6cZH9nJfs2Owa9Zq6p/pekuOLOddAvwD4MBV1U7V9UZ7fKXVdUxNN083wLObte7l6YrYtKvzdTsZtZ4C/C3wBNmWP+stp79q+phwFtouow25hbgL6f8ng+tqgs2p7YZav5aVZ1A033yKeDjM9T+fZo3okkL22nQdBntOzBvv+mamzL+MeDTwH5VtRtNt85M+0LzkMGvuXo/cEySJ9H0IT83ybOSbJdkx/YSxH2T7JXkhPYk5U+B9TRdPwDXAk9NsjDJbsx8ldAdwL6TJ1+nSvLwJO9I8pgkD2pP9v4RTT/45Pr/pW1n0q405x/Wt59CXjNNm4PX2J8NvLo9Ok6SnduTorvOuKeGkOTBSV6SZLeq+nlb1+R+mq72C4C3Jplof9e30fwdoHnDeHmSxyV5KPDnQ5SwK3BnVf0kyaHAi+f6O2nrY/BrTtp+5fOAt7VH1yfQHDGvpTky/lOaf2cPAv6E5mj0Tpp+49e021gGXAhcD6ygOTG7Mf8PuBG4PckPppn/M5qTkP9CE5o30LzRvKxt61s0YXlT202zN/AmmoBbRxPqF07Z5unAue3yL6iq5cArgQ8CdwHfndz+FnIysKrtdno1TT/+xmp/F815lOtpTrRf006jqj4L/DVweVvj5JvfT2do+78D72zP4byNX33a0DYkzbkwSdu6NJfD3kBz9dGGcdej8fGIX9qGJTmpvdb/4cC7gX829GXwS9u2V9FccvsfwH088PyFesiuHknqGY/4Jalntt/0IuO355571qJFi8ZdhiTNKytWrPhBVU1MnT4vgn/RokUsX7583GVI0ryS5ObpptvVI0k9Y/BLUs8Y/JLUMwa/JPWMwS9JPWPwS1LPGPyS1DMGvyT1jMEvST0zL765OxeLTrtk3CWM1aozjh93CZK2Mh7xS1LPGPyS1DMGvyT1jMEvST1j8EtSzxj8ktQzBr8k9YzBL0k901nwJ9kxyVeTXJfkxiTvaKc/KsnVSb6b5MIkD+6qBknSA3V5xP9T4OlV9STgIODYJIcD7wbeV1WPAe4CTumwBknSFJ0FfzXWt6M7tK8Cng78Uzv9XODErmqQJD1Qp338SbZLci2wBlgG/Adwd1VtaBe5FdinyxokSffXafBX1X1VdRCwL3AocMCw6yZZkmR5kuVr167trEZJ6puRXNVTVXcDlwNHALsnmbwr6L7AbRtZZ2lVLa6qxRMTE6MoU5J6ocureiaS7N4O7wQcA6ykeQN4XrvYS4GLu6pBkvRAXd6PfwFwbpLtaN5gPl5Vn0nyTeAfk7wL+Drw4Q5rkCRN0VnwV9X1wMHTTL+Jpr9fkjQGfnNXknrG4JeknjH4JalnDH5J6hmDX5J6xuCXpJ4x+CWpZwx+SeqZLr+5K/XeotMuGXcJY7XqjOPHXYKm4RG/JPWMwS9JPWPwS1LPGPyS1DMGvyT1jMEvST1j8EtSzxj8ktQzBr8k9YzBL0k9Y/BLUs8Y/JLUMwa/JPWMwS9JPWPwS1LPdBb8SfZLcnmSbya5Mcnr2umnJ7ktybXt67iuapAkPVCXD2LZALyxqq5JsiuwIsmydt77qurMDtuWJG1EZ8FfVauB1e3wuiQrgX26ak+SNJyRPHoxySLgYOBq4Ejg1CR/CCyn+VRw1zTrLAGWACxcuHAUZUrayvT90ZXQzeMrOz+5m2QX4CLg9VV1D3AW8GjgIJpPBO+Zbr2qWlpVi6tq8cTERNdlSlJvdBr8SXagCf3zq+oTAFV1R1XdV1W/AM4GDu2yBknS/XV5VU+ADwMrq+q9A9MXDCx2EnBDVzVIkh6oyz7+I4GTgW8kubad9hbgRUkOAgpYBbyqwxokSVN0eVXPVUCmmXVpV21KkjbNb+5KUs8Y/JLUMwa/JPWMwS9JPWPwS1LPGPyS1DMGvyT1jMEvST1j8EtSzxj8ktQzBr8k9YzBL0k9Y/BLUs8Y/JLUMwa/JPWMwS9JPWPwS1LPGPyS1DMGvyT1zCaDP8nzh5kmSZofhjnif/OQ0yRJ88D2G5uR5NnAccA+Sf56YNbDgA1dFyZJ6sZGgx/4PrAc+F1gxcD0dcAbuixKktSdjQZ/VV0HXJfkY1X1883dcJL9gPOAvYACllbVB5LsAVwILAJWAS+oqrtmUbskaRaG6eM/NMmyJN9OclOS7yW5aYj1NgBvrKoDgcOBP05yIHAa8IWq2h/4QjsuSRqRmbp6Jn2YpmtnBXDfsBuuqtXA6nZ4XZKVwD7ACcDR7WLnAlcAfzZ0xZKkORkm+H9UVZ+dSyNJFgEHA1cDe7VvCgC303QFTbfOEmAJwMKFC+fSvCRpwDBdPZcn+d9JjkhyyORr2AaS7AJcBLy+qu4ZnFdVRdP//wBVtbSqFlfV4omJiWGbkyRtwjBH/Ie1PxcPTCvg6ZtaMckONKF/flV9op18R5IFVbU6yQJgzeYULEmam00Gf1U9bTYbThKa8wMrq+q9A7M+DbwUOKP9efFsti9Jmp1NBn+St003vareuYlVjwROBr6R5Np22ltoAv/jSU4BbgZeMHy5kqS5Gqar596B4R2B5wArN7VSVV0FZCOznzFEu5KkDgzT1fOewfEkZwKXdVaRJKlTs7kt80OBfbd0IZKk0Rimj/8b/OqSy+2ACWBT/fuSpK3UMH38zxkY3gDcUVXenVOS5qlNdvVU1c3A7sBzgZOAA7suSpLUnWGewPU64HzgEe3r/CT/o+vCJEndGKar5xTgsKq6FyDJu4EvA3/TZWGSpG4Mc1VPuP9dOe9j49fnS5K2csMc8f89cHWST7bjJ9LcikGSNA8N8wWu9ya5AjiqnfTyqvp6p1VJkjozzHX8hwM3VtU17fjDkhxWVVd3Xp0kaYsbpo//LGD9wPj6dpokaR4a6uRu+8AUAKrqFwx3bkCStBUaJvhvSvLaJDu0r9cBwzxsXZK0FRom+F8N/BZwG3ArzRO5lnRZlCSpO8Nc1bMG+P0R1CJJGoHZ3JZZkjSPGfyS1DPD3KTtUcNMkyTND8Mc8V80zbR/2tKFSJJGY6Mnd5McADwe2C3JfxuY9TCah65Lkuahma7qeSzN07cmH8IyaR3wyi6LkiR1Z6PBX1UXAxcnOaKqvjzCmiRJHZqpq+dvaB+ynuRFU+dX1Ws7rEuS1JGZunqWz2XDST5C01W0pqqe0E47naabaG272Fuq6tK5tCNJ2jwzdfWcO8dtnwN8EDhvyvT3VdWZc9y2JGmWhrkf/+W0XT6DqurpM61XVVcmWTTryiRJnRjm9spvGhjeEfg9YMMc2jw1yR/SdCW9sarumm6hJEtobwa3cOHCOTSnuVh02iXjLmGsVp1x/LhLkLa4TX6Bq6pWDLy+WFV/Ahw9y/bOAh4NHASsBt4zQ7tLq2pxVS2emJiYZXOSpKmG6erZY2D0QcCTgd1m01hV3TGw3bOBz8xmO5Kk2Rumq2cFTR9/aLp4vgecMpvGkiyoqtXt6EnADbPZjiRp9oa5H/+sbsiW5AKaLqE9k9wKvB04OslBNG8kq4BXzWbbkqTZG6ar5/nA56pqXZK3AocA76qqa2Zar6oe8KUv4MOzK1OStKUMc3fOP29D/yjgmTThfVa3ZUmSujJM8N/X/jweWFpVlwAP7q4kSVKXhgn+25J8CHghcGmShwy5niRpKzRMgL8AuAx4VlXdDewB/GmnVUmSOjPMF7h+DKwBjmonbQC+02VRkqTuDPPM3bcDfwa8uZ20A/DRLouSJHVnmK6ek4DfBe4FqKrvA7t2WZQkqTvDBP/Pqqr41UNZdu62JElSl4YJ/o+3V/XsnuSVwL8AZ3dbliSpKzN+czdJgAuBA4B7aB7A/raqWjaC2iRJHZgx+KuqklxaVb8BGPaStA0YpqvnmiS/2XklkqSRGOa2zIcBL0lyM82VPaH5MPDETiuTJHVimOB/VudVSJJGZpj78d88ikIkSaPhzdYkqWcMfknqGYNfknrG4JeknjH4JalnDH5J6hmDX5J6xuCXpJ7pLPiTfCTJmiQ3DEzbI8myJN9pfz68q/YlSdPr8oj/HODYKdNOA75QVfsDX2jHJUkj1FnwV9WVwJ1TJp8AnNsOnwuc2FX7kqTpjbqPf6+qWt0O3w7stbEFkyxJsjzJ8rVr146mOknqgbGd3B18ju9G5i+tqsVVtXhiYmKElUnStm3UwX9HkgUA7c81I25fknpv1MH/aeCl7fBLgYtH3L4k9V6Xl3NeAHwZeGySW5OcApwBHJPkO8Az23FJ0ggN8wSuWamqF21k1jO6alOStGl+c1eSesbgl6SeMfglqWcMfknqGYNfknrG4JeknjH4JalnDH5J6hmDX5J6xuCXpJ4x+CWpZwx+SeoZg1+Sesbgl6SeMfglqWcMfknqGYNfknrG4JeknjH4JalnDH5J6hmDX5J6xuCXpJ4x+CWpZ7YfR6NJVgHrgPuADVW1eBx1SFIfjSX4W0+rqh+MsX1J6iW7eiSpZ8YV/AV8PsmKJEumWyDJkiTLkyxfu3btiMuTpG3XuIL/qKo6BHg28MdJnjp1gapaWlWLq2rxxMTE6CuUpG3UWIK/qm5rf64BPgkcOo46JKmPRh78SXZOsuvkMPA7wA2jrkOS+mocV/XsBXwyyWT7H6uqz42hDknqpZEHf1XdBDxp1O1KkhpezilJPWPwS1LPGPyS1DMGvyT1jMEvST1j8EtSzxj8ktQzBr8k9YzBL0k9Y/BLUs8Y/JLUMwa/JPWMwS9JPWPwS1LPGPyS1DMGvyT1jMEvST1j8EtSzxj8ktQzBr8k9YzBL0k9Y/BLUs8Y/JLUMwa/JPXMWII/ybFJ/j3Jd5OcNo4aJKmvRh78SbYD/hZ4NnAg8KIkB466Dknqq3Ec8R8KfLeqbqqqnwH/CJwwhjokqZdSVaNtMHkecGxVvaIdPxk4rKpOnbLcEmBJO/pY4N9HWuiWsyfwg3EXMY+5/+bG/Tc3833/PbKqJqZO3H4clQyjqpYCS8ddx1wlWV5Vi8ddx3zl/psb99/cbKv7bxxdPbcB+w2M79tOkySNwDiC/2vA/kkeleTBwO8Dnx5DHZLUSyPv6qmqDUlOBS4DtgM+UlU3jrqOEZr33VVj5v6bG/ff3GyT+2/kJ3clSePlN3clqWcMfknqGYO/Q96aYvaSfCTJmiQ3jLuW+SjJfkkuT/LNJDcmed24a5pPkuyY5KtJrmv33zvGXdOWZB9/R9pbU3wbOAa4leZqphdV1TfHWtg8keSpwHrgvKp6wrjrmW+SLAAWVNU1SXYFVgAn+u9vOEkC7FxV65PsAFwFvK6qvjLm0rYIj/i7460p5qCqrgTuHHcd81VVra6qa9rhdcBKYJ/xVjV/VGN9O7pD+9pmjpIN/u7sA9wyMH4r/sfTGCRZBBwMXD3eSuaXJNsluRZYAyyrqm1m/xn80jYsyS7ARcDrq+qecdczn1TVfVV1EM3dBQ5Nss10ORr83fHWFBqrtm/6IuD8qvrEuOuZr6rqbuBy4Nhx17KlGPzd8dYUGpv25OSHgZVV9d5x1zPfJJlIsns7vBPNRRrfGm9VW47B35Gq2gBM3ppiJfDxbfzWFFtUkguALwOPTXJrklPGXdM8cyRwMvD0JNe2r+PGXdQ8sgC4PMn1NAdxy6rqM2OuaYvxck5J6hmP+CWpZwx+SeoZg1+Sesbgl6SeMfglqWcMfglI8rIkH9zIvC+1PxclefFmbvctW3I5aUsw+KVNqKrfagcXAZsV/MCwgW7wa2QMfm2TkvyvJN9OclWSC5K8qZ1+RZLF7fCeSVYNrLZfO/87Sd4+sK3JuzSeATyl/TLUG6a0tyDJle28G5I8JckZwE7ttPPb5T6VZEV7j/cl7bTplvuD9n7w1yb5UHubb2mLGPnD1qWuJXkyzS0yDqL5N34Nzf3oN+VQ4AnAj4GvJbmkqpYPzD8NeFNVPWeadV8MXFZVf9mG9EOr6t+SnNre6GvSH1XVne1tAL6W5KKqOm1wuSSPA14IHFlVP0/yf4CXAOdtzn6QNsbg17boKcAnq+rHAEmGvUfSsqr6YbvOJ4CjgOUzr/JLXwM+0t4Y7VNVde1GlnttkpPa4f2A/YEfTlnmGcCTad4YAHaiuTWwtEUY/OqbDfyqi3PHKfOm3r9k6PuZVNWV7VPDjgfOSfLeqrrfEXqSo4FnAkdU1Y+TXDFNDQABzq2qNw/bvrQ57OPXtuhK4MQkO7WPHXzuwLxVNEfTAM+bst4xSfZou2FOBL44Zf46YNfpGkzySOCOqjob+L/AIe2sn7efAgB2A+5qQ/8A4PCBTQwu9wXgeUke0W57j3b70hZh8Gub0z5y8ELgOuCzNN0wk84EXpPk68CeU1b9Ks39668HLprSv087/b72AdxvmDLvaOC6drsvBD7QTl8KXN+etP0csH2SlTQnigef3/rL5drn4r4V+Hx7d8hlNHeLlLYI786pbV6S04H1VXXmuGuRtgYe8UtSz3jEL0k94xG/JPWMwS9JPWPwS1LPGPyS1DMGvyT1zP8Hg1TecKOskjUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZgU_Al4jz7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b0b9a45-725e-4ac8-cf81-68ffd08d4b31"
      },
      "source": [
        "result.histogram(key=\"a,b\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 32, 1: 15, 2: 28, 3: 25})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8esNV4PbrpS7"
      },
      "source": [
        "**Make Bell state operations reverse**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pexUpicI8DgZ"
      },
      "source": [
        "# Create Vanilla Qubits\n",
        "# Named Qubit\n",
        "a = cirq.NamedQubit(\"a\")\n",
        "b = cirq.NamedQubit(\"b\")\n",
        "\n",
        "#Line-Qubit\n",
        "qubits = cirq.LineQubit.range(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykAgwQkAtveF"
      },
      "source": [
        "*Operators are unitary*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaXrr6z2rbz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9599073c-ccd4-4a91-d99e-945ebe9a7722"
      },
      "source": [
        "# Define operations\n",
        "ops=[cirq.H(a), # Superposition\n",
        "     cirq.CNOT(a,b), # Entanglement\n",
        "     cirq.CNOT(a,b),\n",
        "     cirq.H(a),\n",
        "     cirq.measure(a,b)] # Measurement\n",
        "\n",
        "# Build circuit\n",
        "circuit=cirq.Circuit(ops)\n",
        "\n",
        "print(circuit)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: ───H───@───@───H───M───\n",
            "          │   │       │\n",
            "b: ───────X───X───────M───\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eW2mzWkTrvuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe1bb4c-48f5-45e3-8367-68f05a15f430"
      },
      "source": [
        "# Run Simulations & Measurements\n",
        "# Outcome should be same as step 1: 0, back to as if nothing happened\n",
        "simulator = cirq.Simulator()\n",
        "result = simulator.run(circuit,repetitions=100)\n",
        "print('Measurement results')\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Measurement results\n",
            "a,b=0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000, 0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hr1hYZZr4gA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f15896c-9ae0-4c7c-b766-e11de5de2f8c"
      },
      "source": [
        "result.histogram(key=\"a,b\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 100})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH1uLG6ar7Ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e26349e-f5b8-4c61-fe6d-14f4eb8fdb3d"
      },
      "source": [
        "# Visualization\n",
        "# After doing that, you should see the quantum state become ∣00⟩+∣11⟩\n",
        "_ = cirq.vis.plot_state_histogram(result) #, plt.subplot())\n",
        "# https://quantumai.google/cirq/tutorials/state_histograms"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwCqkmcpML45"
      },
      "source": [
        "**Multiple Qubits: Product State vs Entangled State (Bell State)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE-o94B525zt"
      },
      "source": [
        "* As the name implies, entanglement is a property of quantum mechanical systems that only reveals itself when states begin to interact.\n",
        "\n",
        "* When two qubits are brought together and we'd like to consider the new joint system that they form, we use a fancy new symbol: ⊗. This is called the tensor product, but really it just represents a combination of two or more quantum states.\n",
        "\n",
        "**Product States**\n",
        "* States which can be described as a tensor product of two independent superpositions are known as product states.\n",
        "\n",
        "A joint state of two initialized qubits can be represented as\n",
        "\n",
        ">$|0\\rangle\\otimes|0\\rangle$\n",
        "\n",
        "If we apply the Hadamard gate to the first qubit, it transforms but leaves the other qubit unaffected, since the Hadamard is a single qubit gate:\n",
        "\n",
        ">$\n",
        "\\mathbf{H}|0\\rangle \\otimes|0\\rangle=\\left(\\frac{1}{\\sqrt{2}}|0\\rangle+\\frac{1}{\\sqrt{2}}|1\\rangle\\right) \\otimes|0\\rangle\n",
        "$\n",
        "\n",
        "**Exkurs**: wenn ein Gate bei einem Single Qubit mehr Probability als 0,5 hat, kann man das so schreiben (Achtung: Koeffizient ist Wurzel aus Probability),\n",
        "\n",
        "> $\\mathbf{H}|0\\rangle\\ = (0,9) * |0\\rangle + (0,1) * |1\\rangle$\n",
        "\n",
        "* 0,71 ist für 50% Probability (man muss es squared nehmen!)\n",
        "\n",
        "* 0,9 ist für 0,99 Probability\n",
        "\n",
        "* 1 ist für 100% Probability für State 0, der andere Term hat dann 0 % und verschwindet. Es bleibt dann nur noch $|0\\rangle$\n",
        "\n",
        "The tensor product is distributive, which in this case means it acts much like multiplication:\n",
        "\n",
        ">$\n",
        "\\mathbf{H}|0\\rangle \\otimes|0\\rangle=\\frac{1}{\\sqrt{2}}|0\\rangle \\otimes|0\\rangle+\\frac{1}{\\sqrt{2}}|1\\rangle \\otimes|0\\rangle \\text {. }\n",
        "$\n",
        "\n",
        "Using a series of single-qubit gates, we can transform two initialized qubits into two new arbitrary states:\n",
        "\n",
        ">$\n",
        "\\begin{array}{l}\n",
        "\\text { Qubit 1: } \\quad|0\\rangle \\rightarrow a_{1}|0\\rangle+a_{2}|1\\rangle \\\\\n",
        "\\text { Qubit 2: } \\quad|0\\rangle \\rightarrow b_{1}|0\\rangle+b_{2}|1\\rangle .\n",
        "\\end{array}\n",
        "$\n",
        "\n",
        "The resulting 2 -qubit state is usually written as their product using a fancy new symbol:\n",
        "\n",
        ">$|0\\rangle\n",
        "\\otimes|0\\rangle \\rightarrow\\left(a_{1}|0\\rangle+a_{2}|1\\rangle\\right) \\otimes\\left(b_{1}|0\\rangle+b_{2}|1\\rangle\\right)\n",
        "$\n",
        "\n",
        "Another way to express this would be:\n",
        "\n",
        "> $a_{1} b_{1}|0\\rangle \\otimes|0\\rangle+a_{1} b_{2}|0\\rangle \\otimes|1\\rangle+a_{2} b_{1}|1\\rangle \\otimes|0\\rangle+a_{2} b_{2}|1\\rangle \\otimes|1\\rangle$\n",
        "\n",
        "**Bell state (Entangled State)**\n",
        "\n",
        "* To simplify notations, we sometimes omit the $\\otimes$ sign and only **write $|00\\rangle$ to denote that both the first qubit and the second qubit are in the $|0\\rangle$ state**.\n",
        "\n",
        "* There are four total 2 -qubit combinations, including $|01\\rangle=|0\\rangle \\otimes|1\\rangle$, and so on.\n",
        "\n",
        "With this simplified notation, a general 2 -qubit joint state can be written as an arbitrary linear combination of four 2 -qubit computational states:\n",
        "\n",
        ">$\n",
        "a|00\\rangle+b|01\\rangle+c|10\\rangle+d|11\\rangle\n",
        "$\n",
        "\n",
        "This is quite a bit different than the joint state found by preparing both qubits into independent single-qubit superpositions:\n",
        "\n",
        ">$\n",
        "\\left(a_{1}|0\\rangle+a_{2}|1\\rangle\\right) \\otimes\\left(b_{1}|0\\rangle+b_{2}|1\\rangle\\right)=a_{1} b_{1}|00\\rangle+a_{1} b_{2}|01\\rangle+a_{2} b_{1}|10\\rangle+\n",
        "$\n",
        "\n",
        "* simple and well-known joint state called the Bell state:\n",
        "\n",
        "> $\\frac{1}{\\sqrt{2}}|00\\rangle+\\frac{1}{\\sqrt{2}}|11\\rangle$\n",
        "\n",
        "* you can NOT write the Bell state as a product of two single-qubit states\n",
        "\n",
        "Entangled States\n",
        "* The Bell state is the prototypical example of an entangled state.\n",
        "* Two qubits which are entangled can never be separated into two independent states: their coefficients are a tangled-up mess:\n",
        "\n",
        "> $|\\psi\\rangle_{\\text {Bell }}=\\frac{1}{\\sqrt{2}}(|00\\rangle+|11\\rangle)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ml34dkmRTZb"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_036.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwxQFhNvRcfh"
      },
      "source": [
        "* We can contrast this with n-qubit product states, where the state of every qubit is known and they have only 2n independent amplitudes. This is a vast difference!\n",
        "\n",
        "* This means that most of the n-qubit space is populated by entangled states, ones that can't be written as a simple product of its components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te53NAyORwK7"
      },
      "source": [
        "* We will see in a bit that with only two parameterized gates, we could transform an initialized qubit into any possible single qubit state on the surface of the Bloch sphere:\n",
        "\n",
        "> $\\mathcal{R}_{\\phi} \\mathcal{R}_{\\theta}|0\\rangle=a_{1}|0\\rangle+a_{2}|1\\rangle$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uljvt0GuUJ20"
      },
      "source": [
        "**How to get to an Entanglement Circuit?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzip0tFBUn9u"
      },
      "source": [
        "To start, we can prepare two qubits in the $|0\\rangle$ state. At this point there's no connection between them, and we can write them in the product state $|\\psi\\rangle=$\n",
        "$|0\\rangle \\otimes|0\\rangle$ which is the same as $|00\\rangle$.\n",
        "\n",
        "Comparing $|\\psi\\rangle$ to the Bell state, we see that at some point along the way, we'll need to get into a superposition. Using the set of gates we currently have at our disposal $(\\mathbf{X}, \\mathbf{Z}, \\mathbf{H})$, there doesn't appear to be a single gate that we can apply to take us from $|\\psi\\rangle$ to $\\left|\\psi_{\\text {Bell }}\\right\\rangle .$ Naively, it seems that we have two tasks ahead of\n",
        "us:\n",
        "\n",
        "1. Getting $|\\psi\\rangle$ into a superposition.\n",
        "\n",
        "2. Adjusting the individual kets so that we're in the Bell state.\n",
        "\n",
        "At the moment we have the Hadamard, which can move one of our qubits into superposition. For argument's sake, let's apply it to the first qubit:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\mathbf{H}_{1}|\\psi\\rangle &=(\\mathbf{H}|0\\rangle) \\otimes|0\\rangle \\\\\n",
        "&=\\frac{|0\\rangle+|1\\rangle}{\\sqrt{2}} \\otimes|0\\rangle \\\\\n",
        "&=\\frac{|00\\rangle+|10\\rangle}{\\sqrt{2}} .\n",
        "\\end{aligned}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cfRfbdXUylr"
      },
      "source": [
        "Now we need to find gates that allow us to coordinate action on two qubits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wLmVt2GVInj"
      },
      "source": [
        "While single qubit gates like $\\mathbf{X}$ and $\\mathbf{H}$ can't get us all the way to the Bell state, we'd still like to keep our gate set as simple as possible. In this spirit, let's stick with the Hadamard gate to perform our superposition, and look for a multiqubit gate $\\mathrm{M}$ that can get us the rest of the way:\n",
        "\n",
        "> $\n",
        "\\frac{|00\\rangle+|10\\rangle}{\\sqrt{2}} \\stackrel{\\mathrm{M}}{\\longrightarrow} \\frac{|00\\rangle+|11\\rangle}{\\sqrt{2}}\n",
        "$\n",
        "\n",
        "**Die erste Spalte mit 0 und 1 (links jeweils) zeigt, dass dieses Qubit in einer Superposition ist mit 50% Probability von 0 und 1, während das zweite Qubit (jeweils rechts) 0 und 0 ist, weil es sich nich im initialen Zustand befindet, der immer 100% 0 ist!**\n",
        "\n",
        "Following behaviors would make for a suitable multi-qubit gate M:\n",
        "\n",
        "* Flip qubit 2 whenever qubit 1 and qubit 2 are opposite\n",
        "\n",
        "* Flip qubit 2 if qubit 1 is in state ∣1⟩\n",
        "\n",
        "* we need to keep the core principle of quantum mechanics — reversibility!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-hyI4Y8WH5A"
      },
      "source": [
        "Consider the action of $\\mathbf{M}$ on the two-qubit basis states: if a $|11\\rangle$ term appears in the quantum state after we apply $\\mathrm{M}$, we can't tell if it's because we started with a $|11\\rangle$ term, or if it's because we started with a $|10\\rangle$ term.\n",
        "\n",
        "The preferred entangling gate, called CNOT (controlled NOT), gets us into the Bell state while respecting the reversibility condition:\n",
        "$$\n",
        "\\begin{array}{l}\n",
        "|00\\rangle \\stackrel{\\text { CNOT }}{\\longrightarrow}|00\\rangle \\\\\n",
        "|01\\rangle \\stackrel{\\text { CNOT }}{\\longrightarrow}|01\\rangle \\\\\n",
        "|10\\rangle \\stackrel{\\text { CNOT }}{\\longrightarrow}|11\\rangle \\\\\n",
        "|11\\rangle \\stackrel{\\text { CNOT }}{\\longrightarrow}|10\\rangle .\n",
        "\\end{array}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsYSv3aWW02A"
      },
      "source": [
        "> CNOT, acting on a two-qubit term $\\left|q_{1} q_{2}\\right\\rangle$, applies the $\\mathbf{N O T}(\\mathbf{X})$ gate to the second qubit only if the first qubit is in state $|1\\rangle$. The first qubit controls the action on the second."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnpFAHpAX3CO"
      },
      "source": [
        "This enables us to prepare the entangled Bell state and is a subroutine\n",
        "\n",
        "> $\\frac{|10\\rangle+|00\\rangle}{\\sqrt{2}} \\stackrel{\\text { CNOT }}{\\longrightarrow} \\frac{|11\\rangle+|00\\rangle}{\\sqrt{2}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exg3Vtx79vEF"
      },
      "source": [
        "**For Quantum Cryptography**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JG9DW7T9yVu"
      },
      "source": [
        "* But Alice and Bob aren't stuck with the computational basis: **the Bell state is entangled no matter what basis we use to analyze it**. This is particularly easy to see by switching to the Hadamard basis.\n",
        "\n",
        "* As we showed before, the Bell state has the same form in the computational basis as it does in the Hadamard basis:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJJVI3nJ95Sd"
      },
      "source": [
        "> $\\left|\\psi_{\\text {Bell }}\\right\\rangle=\\frac{|00\\rangle+|11\\rangle}{\\sqrt{2}}=\\frac{|--\\rangle+|++\\rangle}{\\sqrt{2}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku7YIhNG99wX"
      },
      "source": [
        "* So, Alice and Bob are free to use either basis to coordinate their bits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy2g1dN5CzEk"
      },
      "source": [
        "*If Alice measures her qubit using the Hadamard basis, what are the possibilities for Bob's measurement in the computational basis?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBI_xr4hDMDh"
      },
      "source": [
        "![gg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_037.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op9AlkI4DSIz"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_038.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dba0LoLwGlRc"
      },
      "source": [
        "**CNOT Gate and Entanglement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPNGjNBmG7Fi"
      },
      "source": [
        "Quantum states $|\\psi\\rangle$ aren't always one of the computational basis states.\n",
        "\n",
        "In general, they can also be (ignoring normalization factors)\n",
        "\n",
        ">$\n",
        "|+\\rangle=|0\\rangle+|1\\rangle\n",
        "$\n",
        "\n",
        "or\n",
        "\n",
        ">$\n",
        "|-\\rangle=|0\\rangle-|1\\rangle \\text {. }\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUslZaxCGow1"
      },
      "source": [
        "*What does the CNOT gate do with these input states?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB5YrBr6GeKQ"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_039.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZO0odc6qWrf"
      },
      "source": [
        "###### *Superdense Coding (Bell State): 2 Qubits - H, CNOT & X-Gate: Superdense Coding for Quantum Communication*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t1z-q7TYSAb"
      },
      "source": [
        "Superdense Coding is a method to transmit two classical bits of information by sending only one qubit of information. This is accomplished by pre-sharing an entangled state between the sender and the receiver. This entangled state allows the receiver of the one qubit of information to decode the two classical bits that were originally encoded by the sender."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk5lRZUzYycF"
      },
      "source": [
        "*Complete example from Cirq*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "QjgzsbSpYlMx",
        "outputId": "901dcfab-6cb6-4340-8dd4-16ed82086f9a"
      },
      "source": [
        "def make_superdense_circuit():\n",
        "    circuit = cirq.Circuit()\n",
        "    q0, q1, q2, q3, q4 = cirq.LineQubit.range(5)\n",
        "\n",
        "    # Randomly sets q0 and q1 to either 0 or 1\n",
        "    circuit.append([cirq.H(q0), cirq.H(q1)])\n",
        "    circuit.append(cirq.measure(q0, q1, key=\"input \"))\n",
        "\n",
        "    # Creates Bell State to be shared on q2 and q4\n",
        "    circuit.append([cirq.H(q2), cirq.CNOT(q2, q4)])\n",
        "    # Step 1 of encoding (controlled NOT gate on q1 / q2)\n",
        "    circuit.append(cirq.CNOT(q1, q2))\n",
        "    # Step 2 of encoding (controlled Z gate on q0 / q2)\n",
        "    circuit.append(cirq.CZ(q0, q2))\n",
        "    # Sends encoded information to receiver\n",
        "    circuit.append(cirq.SWAP(q2, q3))\n",
        "    # Step 1 of decoding (controlled NOT gate on q3 and q4)\n",
        "    circuit.append(cirq.CNOT(q3, q4))\n",
        "    # Step 2 of decoding (Hadamard gate on q3)\n",
        "    circuit.append(cirq.H(q3))\n",
        "    # Measurement by receiver to decode bits\n",
        "    circuit.append(cirq.measure(q3, q4, key=\"output\"))\n",
        "\n",
        "    return circuit\n",
        "\n",
        "\n",
        "def main():\n",
        "    circuit = make_superdense_circuit()\n",
        "    print(\"Circuit:\")\n",
        "    print(circuit)\n",
        "\n",
        "    sim = cirq.Simulator()\n",
        "    results = sim.run(circuit, repetitions=20)\n",
        "    print(\"\\nResults:\")\n",
        "    print(results)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b2894455c156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-b2894455c156>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mcircuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_superdense_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circuit:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-b2894455c156>\u001b[0m in \u001b[0;36mmake_superdense_circuit\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_superdense_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcircuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcirq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCircuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mq0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcirq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLineQubit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Randomly sets q0 and q1 to either 0 or 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cirq' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPQWnRvwYoTQ"
      },
      "source": [
        "*Step by Step Walkthrough*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20Va63288FK9"
      },
      "source": [
        "# Create Vanilla Qubits\n",
        "# Named Qubit\n",
        "a = cirq.NamedQubit(\"a\")\n",
        "b = cirq.NamedQubit(\"b\")\n",
        "\n",
        "#Line-Qubit\n",
        "qubits = cirq.LineQubit.range(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbSod7koqiXk"
      },
      "source": [
        "https://medium.com/qiskit/demystifying-superdense-coding-41d46401910e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZYteiqUsRV9"
      },
      "source": [
        "*Now adding Pauli X gate to alter outcome*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FZm_6jgsHAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f021a2a1-6f14-4715-bcf6-0047ffbf5722"
      },
      "source": [
        "# Define operations\n",
        "ops=[cirq.H(a), # Superposition\n",
        "     cirq.CNOT(a,b), # Entanglement\n",
        "     cirq.X(a), # Pauli X gate -> changes outcome from 00 to 01\n",
        "     cirq.CNOT(a,b),\n",
        "     cirq.H(a),\n",
        "     cirq.measure(a,b)] # Measurement\n",
        "\n",
        "# Build circuit\n",
        "circuit=cirq.Circuit(ops)\n",
        "\n",
        "print(circuit)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: ───H───@───X───@───H───M───\n",
            "          │       │       │\n",
            "b: ───────X───────X───────M───\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1-1MAVyuUtB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b9c3370-790a-49ee-afa7-1336de90ea3c"
      },
      "source": [
        "simulator = cirq.Simulator()\n",
        "result = simulator.run(circuit,repetitions=100)\n",
        "print('Measurement results')\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Measurement results\n",
            "a,b=0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000, 1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kXujiebsaoS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0f0fdb95-7290-45bc-85d5-54a3ba1c59f1"
      },
      "source": [
        "# Visualization\n",
        "# After doing that, you should see the quantum state become ∣00⟩+∣11⟩\n",
        "_ = cirq.vis.plot_state_histogram(result) #, plt.subplot())\n",
        "# https://quantumai.google/cirq/tutorials/state_histograms"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYnYC_jRsdau"
      },
      "source": [
        "result.histogram(key=\"a,b\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Challenges*"
      ],
      "metadata": {
        "id": "Bs0vbHxkhFvU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [T1 and T2 Error](https://youtu.be/b7XSD2Eqb0s?si=CX3myisYAi0ReJQF)\n",
        "\n",
        "Video: [Quantum Algorithms for Hamiltonian Simulation | Quantum\n",
        "Colloquium ](https://youtu.be/X4gegxIuh1o?si=tMX01yfnfvv2-kLn)\n",
        "\n",
        "Video: [Classical shadows - Richard Küng | TQC 2023](https://youtu.be/1n9O0biAUWk?si=8o3HhLx75e89bZtL)"
      ],
      "metadata": {
        "id": "zAx2WQ8qKksn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *T-Gate Depth*"
      ],
      "metadata": {
        "id": "vysHiG6QtWbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is t-count in quantum computing and why is it relevant?**\n",
        "\n",
        "In quantum computing, T-count is a critical metric that influences the feasibility and efficiency of quantum algorithms. Here's a breakdown of what it means and its significance:\n",
        "\n",
        "**What is T-Count?**\n",
        "\n",
        "* **Definition:** The T-count refers to the number of T-gates present within a quantum circuit. T-gates are fundamental quantum gates, but they are among the most difficult to implement reliably in fault-tolerant quantum computers.\n",
        "* **Universal Gate Sets:** Quantum circuits are built from sets of basic gates. A common universal gate set includes the Clifford group gates (H, S, CNOT) and the T-gate. While Clifford gates are relatively easier to implement, any quantum algorithm, in theory, can be constructed using a combination of Clifford gates and T-gates.\n",
        "\n",
        "**Why is T-Count Relevant?**\n",
        "\n",
        "1. **Fault Tolerance:**  Current quantum computers are susceptible to noise and errors.  Fault-tolerant quantum computation techniques are needed for reliable, large-scale quantum algorithms.  T-gates are a major source of error in fault-tolerant systems due to their complexity.  Minimizing T-count reduces the places where errors can occur, improving the chances of successful computation.\n",
        "\n",
        "2. **Hardware Constraints:** Implementing T-gates in real quantum hardware is more resource-intensive than other gates. Excessive T-gates in a circuit design can place high demands on the underlying quantum hardware architecture.\n",
        "\n",
        "3. **Algorithm Efficiency:**  Often, the T-count of a quantum circuit is directly correlated to its execution time and the overall computational cost. Reducing the T-count generally leads to faster and more efficient quantum algorithms.\n",
        "\n",
        "4. **Quantum Supremacy Comparison:** T-count can be a useful metric for comparing the efficiency of different quantum algorithms and benchmarking the progress of quantum computers. A lower T-count might suggest one algorithm is more practical to implement than another.\n",
        "\n",
        "**Optimization Efforts**\n",
        "\n",
        "Due to the importance of T-count, a significant amount of research in quantum computing is dedicated to developing techniques to reduce the T-count of quantum circuits. This includes:\n",
        "\n",
        "* **Algorithm Design:** Designing new quantum algorithms that inherently require fewer T-gates.\n",
        "* **Circuit Optimization:** Developing tools and methods to automatically optimize existing quantum circuits to reduce their T-count while maintaining functional correctness.\n",
        "* **Hardware Improvements:**  Research into physical implementations of quantum computers that can implement the T-gate with higher fidelity and lower resource cost.\n",
        "\n",
        "**Let me know if you'd like a specific example of how T-count optimization is applied in a quantum algorithm!**\n"
      ],
      "metadata": {
        "id": "WbZI6nPYtaXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ok, and what means \"T-depth of 46 million\"?**\n",
        "\n",
        "The phrase \"T-depth of 46 million\" refers to a quantum circuit's complexity and its impact on hardware requirements. Here's what it means:\n",
        "\n",
        "* **T-depth:** T-depth, in quantum computing,  indicates the number of sequential layers of T-gates in a quantum circuit.  If a circuit needs multiple T-gates to be executed simultaneously, that only counts as a single layer in the T-depth.\n",
        "\n",
        "* **Significance of \"T-depth of 46 million\":**\n",
        "   * **Error Potential:** A circuit with a T-depth of 46 million implies that it requires 46 million execution cycles where T-gates must be applied faultlessly in succession. Considering the high error rates of current T-gate implementations, this highlights extreme challenges in running such a circuit reliably.\n",
        "   * **Resource Demands:**  T-depth directly influences the number of qubits and overall resources needed for execution. A  large T-depth may require holding quantum states (qubits) in a coherent and error-free state for an extended period while waiting for sequential T-gate applications, adding significantly to hardware complexity.   \n",
        "\n",
        "**Why it Matters:**\n",
        "\n",
        "A T-depth of 46 million reveals:\n",
        "\n",
        "1. **Impracticality with Present Hardware:**  The circuit is likely beyond the capabilities of currently available fault-tolerant quantum computers.\n",
        "2. **Need for Optimization:**  Significant algorithm and quantum circuit optimization would be necessary to reduce T-depth before the algorithm becomes feasible to run\n",
        "3. **Benchmarking:** This value could be a benchmark to track advancements in quantum hardware. As fidelity and the ability to perform sequential T-gates with fewer errors improve, circuits with large T-depths become more viable.\n",
        "\n",
        "**Let me know if you'd like to explore the connection between T-depth and specific quantum algorithms!**\n"
      ],
      "metadata": {
        "id": "wgmWgucftdGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Error Correction*"
      ],
      "metadata": {
        "id": "Apl61SPnakw3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [Transmon Qubit](https://youtu.be/kbeSTcmeXCs?si=JwzvgDvBdbqWjN_r)"
      ],
      "metadata": {
        "id": "gxb4K7Dh9xXp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.quantamagazine.org/never-repeating-tiles-can-safeguard-quantum-information-20240223/"
      ],
      "metadata": {
        "id": "zYUg4WOs3re6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.spektrum.de/news/kosmische-strahlung-verursacht-ein-sechstel-der-quantenfehler/2208778"
      ],
      "metadata": {
        "id": "D4_hc7cp99jH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resisting high-energy impact events through gap engineering in superconducting qubit arrays: https://arxiv.org/abs/2402.15644 (T1 error)"
      ],
      "metadata": {
        "id": "n5Rug5t6I12f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resisting high-energy impact events through gap engineering in superconducting qubit arrays**\n",
        "\n",
        "In a beautiful experiment, my colleagues at Google show that gap-engineered superconducting qubits are resilient to high energy (cosmic rays, gammas) impacts, and even IR irradiation. This experiment largely puts to rest the worry that you would need to build the quantum computer in a tunnel under a mountain.\n",
        "\n",
        "https://arxiv.org/abs/2402.15644"
      ],
      "metadata": {
        "id": "bK9WjmvOTPWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Dave Aasen - Quantum computation from dynamic automorphism codes - IPAM at UCLA ](https://youtu.be/Wrn9ewZaR9U?si=rUydxzOFMw03zXIH)\n",
        "\n",
        "Recorded 27 November 2023. Dave Aasen of Microsoft Station Q presents \"Quantum computation from dynamic automorphism codes\" at IPAM's Topology, Quantum Error Correction and Quantum Gravity Workshop.\n",
        "Abstract: We propose a new model of quantum computation comprised of low-weight measurement sequences that simultaneously encode logical information, enable error correction, and apply logical gates. These measurement sequences constitute a new class of quantum error-correcting codes generalizing Floquet codes, which we call dynamic automorphism codes. We construct an explicit example, the dynamic automorphism color code, which is assembled from short measurement sequences that can realize all 72 automorphisms of the 2D color code. On a stack of N triangular patches, the dynamic automorphism color code encodes N logical qubits and can implement the full logical Clifford group by a sequence of two- and, more rarely, three-qubit Pauli measurements. We also make the first step towards universal quantum computation with dynamic automorphism codes by introducing a 3D dynamic automorphism color code and showing that a non-Clifford logical gate can be realized by adaptive two-qubit measurements.\n",
        "\n"
      ],
      "metadata": {
        "id": "LN3GkaTPy2Zb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "video: [Calibrating large quantum processors](https://www.youtube.com/watch?v=fk2HH9M4FqA&list=WL&index=8&t=224s)"
      ],
      "metadata": {
        "id": "ixbZSt8G76I4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "video: [Estimating overheads for quantum fault-tolerance in the honeycomb code](https://youtu.be/ND9OoqJ0NMw?si=y2jnMCryfqdOc4wn)\n",
        "\n",
        "video: [Pulse sequence design for crosstalk mitigation](https://youtu.be/suO1_7rZAW0?si=XSNiKQX8t23yZOe6)\n",
        "\n",
        "honeycomb: [Craig gidney: [Talk] Software and the Honeycomb Code](https://youtu.be/O3NaTGmY0Rw?si=3fp6f9ApE8Gu5sF2)\n",
        "\n",
        "honeycomb: [A short history of the honeycomb code](https://youtu.be/frnym8S5qM4?si=wrnIJ6A6_a188Xug)"
      ],
      "metadata": {
        "id": "UcLw3fA4zCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "video: [QIP 2022 | Floquet Codes (Matthew Hastings)](https://www.youtube.com/watch?v=JTvByDNy8zE&list=WL&index=6&t=68s)\n",
        "\n",
        "video: [QIP2023 | Floquet codes without parent subsystem codes (Margarita Davydova)](https://www.youtube.com/watch?v=nq021Pw7orc&list=WL&index=7&t=40s)"
      ],
      "metadata": {
        "id": "bMmznOFT7sSp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://quantumpoet.com/superconducting-quantum-computing/"
      ],
      "metadata": {
        "id": "dSMojPGuvt7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.quantamagazine.org/how-quantum-computers-will-correct-their-errors-20211116/"
      ],
      "metadata": {
        "id": "4h_aGy2Kf4UJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.quantamagazine.org/new-codes-could-make-quantum-computing-10-times-more-efficient-20230825/\n",
        "\n",
        "https://www.quantamagazine.org/physicists-create-elusive-particles-that-remember-their-pasts-20230509/"
      ],
      "metadata": {
        "id": "oqNWZS_EPXdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*difference between \"code space\", \"code word\" and \"stabilizer code\"?*\n",
        "\n",
        "https://quantumcomputing.stackexchange.com/questions/1822/what-is-the-difference-between-code-space-code-word-and-stabilizer-code"
      ],
      "metadata": {
        "id": "yRaDer6BKAp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classical Error Correction Codes**\n",
        "\n",
        "https://www.quantamagazine.org/the-basic-algebra-behind-secret-codes-and-space-communication-20230123/"
      ],
      "metadata": {
        "id": "pvAtUauVDPN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Error Correction Zoo**\n",
        "\n",
        "https://errorcorrectionzoo.org/c/honeycomb\n",
        "\n",
        "https://errorcorrectionzoo.org/list/ag\n",
        "\n",
        "https://errorcorrectionzoo.org/list/homological\n",
        "\n",
        "https://arxiv.org/abs/quant-ph/0110143"
      ],
      "metadata": {
        "id": "N8zOwuitr9nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/1603.02286\n",
        "\n",
        "Sometimes transversal means specifically \"the logical operation has constant depth, regardless of code distance\". For example, the transversal S gate in the folded surface code uses physical gates that aren't the S gate. It uses two qubit gates across the folded halves.\n",
        "\n",
        "https://quantumcomputing.stackexchange.com/questions/24269/what-is-formally-a-transversal-operator"
      ],
      "metadata": {
        "id": "8PeCMq-UIJ5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How does quantum error correction work?**\n",
        "\n",
        "Quantum error correction is a set of techniques for protecting quantum information from errors due to decoherence and other quantum noise. Here's a high-level summary:\n",
        "\n",
        "1. **Encoding**: The first step in quantum error correction is to encode the quantum information. Rather than storing a quantum bit of information (a \"qubit\") in a single physical qubit, we store it in multiple physical qubits. This is done in such a way that, even if some of the physical qubits are corrupted by noise, the original quantum information can still be recovered. This encoding is done using a quantum error-correcting code. There are many different types of quantum error-correcting codes, each with its strengths and weaknesses.\n",
        "\n",
        "2. **Syndrome measurement**: Once the quantum information has been encoded, the next step is to periodically check for errors. This is done by performing a syndrome measurement, which is a special kind of quantum measurement that can detect whether an error has occurred, and if so, what kind of error it was. Importantly, this measurement does not disturb the encoded quantum information.\n",
        "\n",
        "3. **Error correction**: If the syndrome measurement indicates that an error has occurred, the next step is to perform an error correction. This involves applying a series of quantum gates to the physical qubits to correct the error, based on the result of the syndrome measurement.\n",
        "\n",
        "4. **Repeat**: Because quantum systems are always subject to noise, this process of syndrome measurement and error correction needs to be repeated periodically to keep the errors in check.\n",
        "\n",
        "Challenges:\n",
        "\n",
        "* It's worth noting that the whole process of quantum error correction requires a significant overhead in terms of additional physical qubits and quantum operations. This is a major challenge in the development of large-scale, fault-tolerant quantum computers.\n",
        "\n",
        "* It's also worth noting that, although quantum error correction can protect against many types of errors, it cannot protect against all possible errors. In particular, **it's assumed that the errors are relatively rare and do not all occur at once, and that they are independent and identically distributed across the physical qubits**. **If these assumptions are violated, then quantum error correction may not be able to correct the errors**. This is another major challenge in the field of quantum error correction."
      ],
      "metadata": {
        "id": "JjYa1KwBkNRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [Introduction to Toric Code](https://youtu.be/ZRqgAbBGg40) very good\n",
        "Video: [The superconducting transmon qubit](https://youtu.be/dKTNBN99xLw)\n",
        "Video: [The transmon qubit](https://youtu.be/cb_f9KpYipk)\n",
        "Video: [Making quantum error correction practical](https://youtu.be/YPFpll1NFQc)\n",
        "Video: [Steven Girvin](https://youtu.be/nhUKHf-GN_Y)\n",
        "Video: [Quantum Industry Talks](https://youtu.be/eyICn3KCUPI)\n",
        "Video: [Qiskit QEC](https://youtu.be/ZY8PddknCos), [Qiskit](https://youtu.be/SHr3uSv9Bts), [qiskit](https://youtu.be/96a0G4G5ZH8)"
      ],
      "metadata": {
        "id": "68dkfSxfVj8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Concepts:*** *Ancilla qubits, surface code, distance code, X (bit flip) and Z (phase flip) error, threshold theory, required fault-tolerance, logical vs physical qubit*\n",
        "\n",
        "*Tasks: Error detection, error mitigation, error correction, error suppression*\n",
        "\n",
        "Video [Progress Towards Quantum Error Correction with the Surface Code | Qiskit Seminar Series](https://www.youtube.com/watch?v=si5a9RJP01A)"
      ],
      "metadata": {
        "id": "uRkoUVMsuEg4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use more than one qubit to represent a state, use neighboring qubit check (so you don't measure the exact state which would collapse the quantum state). You can decode with it and see that the error was on the last qubit. Then you can correct the physical qubit to get back the correct logical qubit state:\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1278.png)"
      ],
      "metadata": {
        "id": "l3Ja_nTmmvIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[An Introduction to Quantum Error Correction and Fault-Tolerant Quantum Computation](https://arxiv.org/pdf/0904.2557.pdf)"
      ],
      "metadata": {
        "id": "2OdDTy_mW_Ic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For what do you need abelian groups in quantum computing?\n",
        "\n",
        "In quantum computing, Abelian groups are used to describe the symmetry of a quantum system. Symmetry is a fundamental concept in quantum mechanics, and it refers to the idea that a physical system will remain unchanged under certain transformations. For example, the symmetry of a quantum system may be described by a group of rotations, translations, or reflections. Abelian groups are used to describe the symmetry of a quantum system because they have the useful property of being commutative, meaning that the order in which the transformations are applied does not affect the outcome. This property makes it possible to use Abelian groups to describe the symmetries of a quantum system in a way that is mathematically tractable and easy to work with."
      ],
      "metadata": {
        "id": "4KQRd-aYkmU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classical Error detection and correction**\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Error_detection_and_correction\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Repetition_code"
      ],
      "metadata": {
        "id": "mGJ-sWNFvF47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Faut-Tolerant QC (Quantum Error Correction)**\n",
        "\n",
        "* Bit flip (from 0 to 1) or dephasing (from superposition to exact state)\n",
        "\n",
        "* Challenge: we need to keep that states correct without looking at them (because then WE dephase them)\n",
        "\n",
        "* We need a method to **build relatively noiseless qubits (logical qubits)out of many noisy ones (physical qubits)**. This is quantum error correction.\n",
        "\n",
        "* Solution: one way (repetition encoding), sit our qubits on a line. We then go along and ask every pair of next-door-neighbours whether they agree or disagree with each other. This tells us nothing about whether they are 0 or 1. But repetition encoding, which protects against bit flip errors so well, actually makes dephasing more likely!\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Quantum_error_correction\n",
        "\n",
        "\n",
        "* Examples of QEC: **repetition code** (simplest QEC) and **surface code** (and color codes?)\n",
        "\n",
        "* techniques: syndrome measurements, decoding, logical operations\n",
        "\n",
        "* https://www.quantamagazine.org/how-space-and-time-could-be-a-quantum-error-correcting-code-20190103/\n",
        "\n",
        "\n",
        "* [An introduction to Fault-tolerant Quantum Computing](https://arxiv.org/abs/1508.03695)\n",
        "\n",
        "http://decodoku.blogspot.com/2016/02/5-story-so-far_57.html\n",
        "\n",
        "* [INTRODUCTION TO\n",
        "QUANTUM ERROR\n",
        "CORRECTION](https://cpb-us-w2.wpmucdn.com/voices.uchicago.edu/dist/0/2327/files/2019/11/QECIntro.pdf)"
      ],
      "metadata": {
        "id": "B-hRX5qBqHdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exkurs: Error Mitigation**\n",
        "\n",
        "* quantum error correction is long term goal, meanwhile we try to mitigate it\n",
        "\n",
        "* Error mitigation techniques: statistical corrections (on histogram for example)\n",
        "\n",
        "\t* https://qiskit.org/textbook/ch-quantum-hardware/measurement-error-mitigation.html\n",
        "\n",
        "\t* https://arxiv.org/abs/2005.10189"
      ],
      "metadata": {
        "id": "jX7JYnTLqNo9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DiVincenzo's criteria**\n",
        "\n",
        "Video: [Introduction to Toric Code](https://youtu.be/ZRqgAbBGg40) (very good!)\n",
        "\n",
        "Video: [Gottesman 1](https://youtu.be/ltJ1jXQeDl8) and [Gottesman 2](https://youtu.be/cUqys29d0YA)\n",
        "\n",
        "[DiVincenzo's criteria](https://en.m.wikipedia.org/wiki/DiVincenzo%27s_criteria) are conditions necessary for constructing a quantum computer, conditions proposed in 2000 by the theoretical physicist David P. DiVincenzo.\n",
        "\n",
        "**1. A scalable physical system with well-characterized qubits.**\n",
        "\n",
        "**2. The ability to initialize the state of the qubits to a simple fiducial state, such as 000...).**\n",
        "\n",
        "**3. Long relevant decoherence times, much longer than the gate operation time.**\n",
        "\n",
        "**4. A \"universal\" set of quantum gates** (that approximate any unitary operation - a unitary transformation preserves the inner product, which is a property of the Hilbert space)\n",
        "\n",
        "**5. A qubit-specific measurement capability** (ability to measure individual qubits)\n",
        "\n",
        "* Trapped Ion and superconducting qubits do really well on all five criteria\n",
        "\n",
        "6. *The ability to interconvert stationary and flying qubits.*\n",
        "\n",
        "7. *The ability to faithfully transmit flying qubits between specified locations.*\n",
        "\n",
        "* The DiVincenzo criteria consist of seven conditions an experimental setup must satisfy to successfully implement quantum algorithms such as Grover's search algorithm or Shor factorization.\n",
        "\n",
        "* The first five conditions regard quantum computation itself. Two additional conditions regard implementing quantum communication, such as that used in quantum key distribution. One can demonstrate that DiVincenzo's criteria are satisfied by a classical computer.\n",
        "\n",
        "* Comparing the ability of classical and quantum regimes to satisfy the criteria highlights both the complications that arise in dealing with quantum systems and the source of the quantum speed up.\n",
        "\n",
        "*Universal quantum computing and quantum annealer: not all criteria match the quantum annealers*\n",
        "\n",
        "**Definition of Quantum Computing**\n",
        "\n",
        "[Quantum computing](https://en.m.wikipedia.org/wiki/Quantum_computing) is a type of computation whose operations can harness the phenomena of quantum mechanics, such as superposition, interference, and entanglement to perform computation. Devices that perform quantum computations are known as quantum computers.\n",
        "\n",
        "*Harnessing effects of quantum mechanics: by this definition also quantum annealers are quyantum computers.*"
      ],
      "metadata": {
        "id": "9b6pMJ8JVL_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stabilizer Code and Parity Check Measurement**"
      ],
      "metadata": {
        "id": "v41iaGUgY8hR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exkurs: Stabilizer Code**\n",
        "\n",
        "*Exkurs: Stabilizer Code & Ancilla qubits*\n",
        "\n",
        "* A [stabilizer](https://en.m.wikipedia.org/wiki/Stabilizer_code) quantum error-correcting code appends [ancilla qubits](https://en.m.wikipedia.org/wiki/Ancilla_bit) to qubits that we want to protect.\n",
        "\n",
        "**A stabilizer quantum error-correcting code appends ancilla qubits to qubits that we want to protect**. A unitary encoding circuit rotates the global state into a subspace of a larger Hilbert space. This highly entangled, encoded state corrects for local noisy errors.\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Stabilizer_code\n",
        "\n",
        "In quantum computing, **a stabilizer code is a type of error-correcting cod**e that is used to protect quantum information from the effects of noise and decoherence. These codes are based on the concept of stabilizer operators, which are a special type of operator that can be used to detect and correct errors in a quantum system. The basic idea behind stabilizer codes is to encode the quantum information using a set of stabilizer operators, such that any errors that occur in the system can be detected and corrected by measuring the values of these operators. GPT\n",
        "\n",
        "\n",
        "Many quantum error correction schemes can be classified as stabilizer codes, where a single bit of **quantum information is encoded in the joint state of many physical qubits**, which we refer to as data qubits. Interspersed among the data qubits are **measure qubits**, which periodically measure the parity of chosen combinations of data qubits. https://arxiv.org/pdf/2102.06132.pdf\n",
        "\n",
        "\n",
        "https://www.youtube.com/watch?v=Rs2NMe4Lsbw&t=456s\n",
        "\n",
        "https://leftasexercise.com/2019/01/28/basics-of-quantum-error-correction/\n",
        "\n",
        "https://leftasexercise.com/2019/02/04/q-fault-tolerant-quantum-computing/\n",
        "\n",
        "https://leftasexercise.com/2019/03/25/qec-an-introduction-to-toric-codes/\n",
        "\n",
        "https://leftasexercise.com/2019/04/08/quantum-error-correction-the-surface-code/\n",
        "\n",
        "https://leftasexercise.com/2019/02/11/quantum-error-correction-with-stabilizer-codes/\n",
        "\n",
        "https://leftasexercise.com/2018/09/10/quantum-computing-an-overview/"
      ],
      "metadata": {
        "id": "2ns0241plUDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stabilizer code with parity check circuits (for Z and X errors)"
      ],
      "metadata": {
        "id": "4c1Ooe-Odl3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parity measurement**: is it even (correct) or odd (error)? You will have a square with one dimension for X error and another dimension for Z error measurement. You have an **ancilla qubit** to make the measurements with C-Z-gate and C-X gate (but you first put it into an equal superposition).\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1283.png)"
      ],
      "metadata": {
        "id": "iCtG8eoVtaGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You put both X and Z together and get a 2D lattice of surface code with a determined code distance. We have now data qubits, X ancilla qubits and Z ancilla qubits.\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1284.png)"
      ],
      "metadata": {
        "id": "ujX9f7Wevt2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exkurs: Repetition Codes**\n",
        "\n",
        "* look at majority of bits\n",
        "\n",
        "* https://qiskit.org/textbook/ch-quantum-hardware/error-correction-repetition-code.html\n",
        "\n",
        "* repetition code: redundancy (repetition) is a way to make sure the message gets delivered (i.e. with majority voting, for d repetition: $P=\\sum_{n=0}^{[ a / 2]}\\left(\\begin{array}{l}d \\\\ n\\end{array}\\right) p^{n}(1-p)^{d-n} \\sim\\left(\\frac{p}{(1-p)}\\right)^{[ d / 2]}$\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_100.png)"
      ],
      "metadata": {
        "id": "zEwG8U1SwWhd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ZX-calculus**"
      ],
      "metadata": {
        "id": "cZPcI0kqrh4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/1307.7025\n",
        "\n",
        "The ZX-calculus is complete for stabilizer quantum mechanics"
      ],
      "metadata": {
        "id": "0fudQnLJODY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ZX Calculus: Hopf rule\n",
        "\n",
        "Reasoning with connectivity using diagrammatic reasoning\n",
        "\n",
        "ZX Calculus: Hadamard rule\n",
        "\n",
        "Evaluating quantum circuits using diagrammatic reasoning."
      ],
      "metadata": {
        "id": "5gLhGntqCW37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://en.wikipedia.org/wiki/ZX-calculus\n",
        "\n",
        "https://en.wikipedia.org/wiki/Penrose_graphical_notation\n",
        "\n",
        "https://en.wikipedia.org/wiki/Tensor_network_theory?wprov=sfti1\n",
        "\n",
        "https://en.wikipedia.org/wiki/Unified_field_theory\n",
        "\n",
        "\n",
        "\n",
        "https://en.wikipedia.org/wiki/Matrix_product_state?wprov=sfti1\n",
        "\n",
        "\n",
        "https://en.wikipedia.org/wiki/Density_matrix_renormalization_group?wprov=sfti1\n",
        "\n",
        "https://en.wikipedia.org/wiki/Categorical_quantum_mechanics?wprov=sfti1\n",
        "\n",
        "And finally I'll learn about fault-tolerance cause now it's in a language that I can understand, cause I co-invented it with Ross Duncan!\n",
        "\n",
        "https://lnkd.in/dX2YDzfF\n",
        "\n",
        "But the “newly introduced ZX-instruments” want to be the bastard spiders of the dodo-book. They go back a long time, even before ZX calculus itself, and published here:\n",
        "\n",
        "https://lnkd.in/e4VvrGHA\n",
        "\n",
        "Quantum In Pictures also has that stuff, and so does this paper:\n",
        "\n",
        "https://lnkd.in/eSwFWkHZ"
      ],
      "metadata": {
        "id": "KbDcHaTjrqmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fidelity (Error Probability)**"
      ],
      "metadata": {
        "id": "f0O6pdoUYhec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Physical and Logical Qubits\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Physical_and_logical_qubits"
      ],
      "metadata": {
        "id": "j7puSMXHeUxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fidelity**: For Shor's algorithm with estimated 10^9 physical gates required, the error should be less than 10^-9, ideally 10^-10. We are still several orders of magnitude away from that accuracy / faut-tolerance.\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1279.png)"
      ],
      "metadata": {
        "id": "EM0u6HMroENg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Many applications call for error rates in the 10−15 regime [2–9], but state-of-the-art quantum platforms typically have physical error rates near 10−3\n",
        "https://arxiv.org/pdf/2102.06132.pdf"
      ],
      "metadata": {
        "id": "FcbSD88fkhOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run quantum algorithms perfectly we need error probability of 1 in a billion or 1 in a trillion - but we are at 1 in a thousand\n",
        "\n",
        "Video: [Suppressing quantum errors by scaling a surface code logical qubit](https://www.youtube.com/watch?v=dVkLNwSTBU0)"
      ],
      "metadata": {
        "id": "pQbRXxY779rs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exkurs: Fidelity of quantum states**\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Fidelity_of_quantum_states\n",
        "\n",
        "* Noise transforms pure states into mixed states.\n",
        "\n",
        "  * There are also simpler ones: Fidelity between two pure states\n",
        "\n",
        "  * And there are also more complex ones: Fidelity between two mixed states\n",
        "\n",
        "* fidelity is generally defined as the quantity:\n",
        "\n",
        "> ${\\displaystyle F(\\rho ,\\sigma )=\\left(\\operatorname {tr} {\\sqrt {{\\sqrt {\\rho }}\\sigma {\\sqrt {\\rho }}}}\\right)^{2}}$\n",
        "\n",
        "* most useless state is fidelity 0,5. because fidelity = 0 means orthogonal, and =1 means exactly the same.\n",
        "\n",
        "* Video: [Fidelity](https://www.youtube.com/watch?v=GWi_HIVz2B4)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1275.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1276.png)"
      ],
      "metadata": {
        "id": "GV4K-Cl0qIIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two types of errors that you want to detect: **Bit-flip** (represented with Pauli X gate) and **Phase-flip** (represented with Pauli-Z gate). But 1D string physical qubits cannot protect from bit and phase flip at the same time. You need a 2D string.\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1281.png)"
      ],
      "metadata": {
        "id": "In3mQfhOp0Ff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota bene: Qubits können auch ganz verloren gehen**\n",
        "\n",
        "* Inzwischen können Quantencomputer mit einer gewissen Anzahl von Rechenfehlern, wie zum Beispiel Bitflip- oder Phasenflip-Fehlern, umgehen. Zusätzlich zu diesen Fehlern können jedoch auch Qubits ganz aus dem Quantenregister verloren gehen.\n",
        "\n",
        "* Je nach Art des Quantencomputers kann dies auf den tatsächlichen Verlust von Teilchen wie Atomen oder Ionen zurückzuführen sein, oder darauf, dass Quantenteilchen beispielsweise in unerwünschte Energiezustände übergehen, welche nicht mehr als Qubit erkannt werden. Wenn ein Qubit verloren geht, wird die Information in den verbleibenden Qubits unlesbar und ungeschützt. Für das Ergebnis der Berechnung kann dieser Prozess zu einem potentiell verheerenden Fehler werden.\n",
        "\n",
        "https://www.cosmos-indirekt.de/News/Neue_Methode_schützt_Quantencomputer_vor_Ausfällen.html\n",
        "\n",
        "Resolving catastrophic error bursts from cosmic rays in large arrays of superconducting qubits.\n",
        "\n",
        "https://arxiv.org/abs/2104.05219\n",
        "\n",
        "https://physicsworld.com/a/cosmic-ray-threat-to-quantum-computing-greater-than-previously-thought/"
      ],
      "metadata": {
        "id": "0N8AlBcAz4Uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Error Syndrome Measurement**\n",
        "\n",
        "**|1> measured in instead of a |0> : The permutations of outputted |1〉’s is called the “error syndrome”.**\n",
        "\n",
        "Syndrome: what qubit the error is on\n",
        "\n",
        "Error syndrome measurement:\n",
        "\n",
        "https://www.quora.com/Error-Correcting-Codes-What-is-a-syndrome:\n",
        "\n",
        "* The syndrome measurement provides information about the error that has happened, but not about the information that is stored in the logical qubit—as otherwise the measurement would destroy any quantum superposition of this logical qubit with other qubits in the quantum computer, which would prevent it from being used to convey quantum information. (https://en.m.wikipedia.org/wiki/Quantum_error_correction)\n",
        "\n",
        "* It is the result of multiplying a parity check matrix times a vector. By convention, codewords of a code have syndrome zero, so that by linearity of the code, the syndrome of a word is the syndrome of the \"error\" vector. Typically from the syndrome you would either try to determine whether there was an error (is the syndrome nonzero?) and recover the error from it, so that in turn you can recover the data from the received word.\n",
        "\n",
        "syndrome. = error?\n",
        "\n",
        "here slide 4: https://people.engr.tamu.edu/andreas-klappenecker/689/stabilizer.pdf"
      ],
      "metadata": {
        "id": "fYAPsGZXAPsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code Distance and Surface Code**"
      ],
      "metadata": {
        "id": "dpys_ybfYkxU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://en.m.wikipedia.org/wiki/Five-qubit_error_correcting_code"
      ],
      "metadata": {
        "id": "KVjhpug-hkYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantum **Threshold theory** ensure that there is a limit that helps to get error under control even with larger numbers of physical qubits. The **code distance** is then a result of the max error rate and represents the number of physical qubits for one state:\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1280.png)"
      ],
      "metadata": {
        "id": "RuL0PiU_okd_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exkurs: Quantum Threshold Theorem**\n",
        "\n",
        "* Challenge: quantum computer will not be able to perform gate operations perfectly, some small constant error is inevitable\n",
        "\n",
        "* [quantum threshold theorem](https://en.m.wikipedia.org/wiki/Quantum_threshold_theorem) (or quantum fault-tolerance theorem) states that a quantum computer\n",
        "  * **with a physical error rate below a certain threshold** can,\n",
        "  * **through application of quantum error correction schemes**,\n",
        "  * suppress the logical error rate to arbitrarily low levels.\n",
        "\n",
        "* This shows that quantum computers can be made fault-tolerant, as an analogue to von Neumann's threshold theorem for classical computation\n",
        "\n",
        "* The formal statement of the threshold theorem depends on the types of error correction codes and error model being considered.\n",
        "\n",
        "* for any particular error model (such as having each gate fail with independent probability p), use **error correcting codes** to build better gates out of existing gates.\n",
        "\n",
        "  * Though these \"better gates\" are larger, and so are more prone to errors within them, their error-correction properties mean that they have a lower chance of failing than the original gate (provided p is a small-enough constant).\n",
        "\n",
        "  * Then, one can use these better gates to recursively create even better gates, until one has gates with the desired failure probability, which can be used for the desired quantum circuit.\n",
        "\n",
        "* Current estimates put the threshold for the [surface code](https://en.m.wikipedia.org/wiki/Toric_code) (here: Toric code) on the order of 1%, though estimates range widely and are difficult to calculate due to the exponential difficulty of simulating large quantum systems.\n",
        "\n",
        "* At a 0.1% probability of a [depolarizing](https://en.m.wikipedia.org/wiki/Depolarization) error, the surface code would require approximately 1,000-10,000 physical qubits per logical data qubit, though more pathological error types could change this figure drastically.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M1xEbTDdNwar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exkurs: Distance Code / Code Distance**\n",
        "\n",
        "* https://physics.stackexchange.com/questions/29397/what-is-the-code-distance-in-quantum-information-theory\n",
        "\n",
        "\n",
        "* Over all 25 cycles of error correction, the distance-5 code realises lower logi- cal error probabilities pL than the average of the subset distance-3 codes - [Paper](https://arxiv.org/pdf/2207.06431.pdf)\n",
        "\n",
        "* the distance is the shortest path in a certain \"space of errors\" which maps between two orthogonal quantum states that are in the code.\n",
        "\n",
        "* The natural space of errors is that of single qubit errors of the form 𝜎𝑋, 𝜎𝑌 or 𝜎𝑧, in the case where the Hilbert space is that of 𝑛 qubits.\n",
        "\n",
        "* So you can think of distance as the shortest path to get from one state to another by operations on single qubits, applied one at a time sequentially.\n",
        "\n",
        "* [Source](https://physics.stackexchange.com/questions/29397/what-is-the-code-distance-in-quantum-information-theory)"
      ],
      "metadata": {
        "id": "ieotWtPN7sz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Surface Code*"
      ],
      "metadata": {
        "id": "KSaDCK89Y3_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, code distance and surface code are not the same in quantum error correction.\n",
        "\n",
        "* **Code distance** is a measure of the ability of a quantum error-correcting code to correct errors. A code with a higher code distance can correct more errors than a code with a lower code distance.\n",
        "* **Surface code** is a specific type of quantum error-correcting code that has a high code distance. Surface codes are often used in quantum computers because they are relatively easy to implement and can correct a large number of errors.\n",
        "\n",
        "In other words, code distance is a property of all quantum error-correcting codes, while surface code is a specific type of quantum error-correcting code that has a high code distance.\n",
        "\n",
        "Here is an analogy to help you understand the difference between code distance and surface code:\n",
        "\n",
        "* Code distance is like the number of lanes on a highway. A highway with more lanes can handle more traffic than a highway with fewer lanes.\n",
        "* Surface code is like a specific type of highway that is designed to handle a lot of traffic. Surface highways have more lanes than other types of highways, so they can handle more traffic.\n",
        "\n",
        "I hope this helps! Let me know if you have any other questions."
      ],
      "metadata": {
        "id": "XJl73OAdfcoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2D Surface code** protects from X error and Z error (X and Z - that's why 2 D). Errors typically arise only locally. The gate structure needs to fit the physical geometry of the quantum processor. Error per gate should be 0,5%, but overall threshold depends on case.\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1282.png)"
      ],
      "metadata": {
        "id": "jQZePon1slGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exkurs: Stabilizer Code $\\rightarrow$ Surface Code $\\rightarrow$ Toric Code**\n",
        "\n",
        "* https://quantumcomputing.stackexchange.com/questions/2106/what-is-the-surface-code-in-the-context-of-quantum-error-correction\n",
        "\n",
        "* **Surface codes**: family of quantum error correcting codes defined on a 2D lattice of qubits.\n",
        "\n",
        "* Each code has [stabilizers](https://en.m.wikipedia.org/wiki/Stabilizer_code) that are defined equivalently in the bulk, but differ from one another in their boundary conditions.\n",
        "\n",
        "* The members of the surface code family are sometimes also described by more specific names:\n",
        "\n",
        "  * The [toric code](https://en.m.wikipedia.org/wiki/Toric_code) is a surface code with periodic boundary conditions,\n",
        "\n",
        "  * the planar code is one defined on a plane, etc.\n",
        "\n",
        "* How many qubits are in a surface code? - While the surface code requires four-qubit measurements to encode a single logical qubit, we introduce families of quantum error correcting codes that use only three-qubit measurements. [Paper](https://www.ucl.ac.uk/quantum/news/2021/aug/subsystem-codes-outperform-surface-code)\n",
        "\n",
        "* [Surface codes: Towards practical large-scale quantum computation](https://arxiv.org/abs/1208.0928)\n",
        "\n",
        "* [Topological quantum memory (paper)](https://arxiv.org/abs/quant-ph/0110143)\n",
        "\n",
        "* [Surface codes: Towards practical large-scale quantum computation (paper)](https://arxiv.org/abs/1208.0928)\n",
        "\n",
        "* [My blog series introducing surface codes](http://decodoku.blogspot.com/2016/02/5-story-so-far_57.html)\n",
        "\n",
        "* The surface codes can also be generalized to qudits. For more on that, [see here (Fault-tolerant quantum computation by anyons)](https://arxiv.org/abs/quant-ph/9707021)"
      ],
      "metadata": {
        "id": "Ur4bkT3KooVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exkurs: Toric Code**\n",
        "\n",
        "* For the toric code we don’t put our qubits in a line, we put them in a grid pattern.\n",
        "\n",
        "* Video: [INTRODUCTION TO TOPOLOGICAL ORDER, DEMONSTRATION VIA THE TORIC CODE](https://www.youtube.com/watch?v=Rs2NMe4Lsbw&t=456s)\n",
        "\n",
        "* https://leftasexercise.com/2019/03/25/qec-an-introduction-to-toric-codes/\n",
        "\n",
        "* http://decodoku.blogspot.com/2016/03/6-toric-code.html\n",
        "\n",
        "* http://decodoku.blogspot.com/2016/03/6-toric-code-part-2.html\n",
        "\n",
        "* http://decodoku.blogspot.com/2016/03/8-toric-code-part-3.html\n",
        "\n",
        "* http://decodoku.blogspot.com/2016/04/9-toric-code-part-4.html\n",
        "\n",
        "* http://decodoku.blogspot.com/2016/04/10-toric-code-part-5.html"
      ],
      "metadata": {
        "id": "zpXlgK2jyNPu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exkurs: Color Code**\n",
        "\n",
        "* [Fault-tolerant quantum computing with color codes](https://arxiv.org/abs/1108.5738)\n",
        "\n",
        "* https://physics.stackexchange.com/questions/169176/quantum-error-correction-surface-code-vs-color-code\n",
        "\n",
        "The color code and surface code are very similar. They are stabilizer codes composed of qubits arranged in two dimensions, requiring only geometrically local stabilizer measurements.\n",
        "\n",
        "From the theory point of view, the codes are very similar. In fact, with collaborators we have proven that the color code is equivalent to a surface code (paper) up to a geometrically local unitary (one which only makes nearby qubits interact). One can think by analogy of the surface code* as a napkin with two rough and two smooth sides and the color code as folding this napkin along its diagonal. Because in the folded napkin, there are new things that are now close, it is possible to do more logical gates \"transversally\". This is good because it keeps errors from propagating and is relatively easy. However, the color code needs more qubits to interact in each stabilizer so ends up leading to a lower noise threshold. So one can say that although very similar, each code has its advantages and disadvantages.\n",
        "\n",
        "At this point, only very small versions of either of these codes are being demonstrated. The Rainer Blatt group demonstrated the smallest possible color-code which also uses 7 qubits (this instance is also referred to as the Steane code). However, the underlying geometry in which the qubits are laid out in the Blatt setup is a linear chain of ions, so I would say that this is not the natural setting to extend to larger and larger system sizes.\n",
        "\n",
        "**The superconducting qubit people (Martinis, IBM, DiCarlo, ...) on the other hand, are concentrating more on surface codes**. While in principle, their architecture should allow them to go full fledge 2D, for now, they are having the classical logic come in from the sides, which is something that needs to change.\n",
        "\n",
        "*There is actually an ambiguity as to what to call surface codes, but I will refer to the quantum double of Z2 with rough and smooth boundaries defined by Bravyi and Kitaev (paper)."
      ],
      "metadata": {
        "id": "9tWyVLKvxLE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Distance 2 Qubit Surface Code (Gate Circuit)*"
      ],
      "metadata": {
        "id": "cNo9Qsp7ZTQe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's go down from a seven qubit surface code to a simpler two qubit surface code. Smallest meaningful is a 2x2 lattice. But it's just an error detection code, because it's too small to do error correction.\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1286.png)"
      ],
      "metadata": {
        "id": "d503fihiwLGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Green line is a flux line**. We put a magnetic flux through the script loop of each qubit to put a a specific frequency where we want it to be. **Pink line is a charge line** that is used for single qubit gates. All the rest (red, blue, purple box) are part of the readout. It's very important to have a good readout - we need to measure the ancilla qubits during the operation to see if there wasn't an error. You see that sort of resonator over each Qubit (die dinger die aussehen wir alte Heizungskoerper) - this is very standard, there is a harmonic oscillator.\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1287.png)"
      ],
      "metadata": {
        "id": "ugRZQcwN0eoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1288.png)"
      ],
      "metadata": {
        "id": "Mbmct0-22-2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1289.png)"
      ],
      "metadata": {
        "id": "sddTSG2S7J3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*7 Qubit Surface Code (Gate Circuit)*"
      ],
      "metadata": {
        "id": "QHclLheAYhtq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a 7 qubit gate circuit. You can't correct the error, but you can detect it. At the end we verify by measuring the actual state of each qubit.\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1290.png)\n"
      ],
      "metadata": {
        "id": "eqXaY73s5YSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can run multiple measurements in (20) microseconds for Z and X operator:\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1291.png)"
      ],
      "metadata": {
        "id": "ywM2-Zqb6dQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**D = 3 Surface Code Stabilizer Gate Sequence**\n",
        "\n",
        "* Red: data qubits\n",
        "* Blue: X-type ancilla qubit\n",
        "* Green Z-type ancilla qubit\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1300.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1301.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1302.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1303.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1304.png)\n"
      ],
      "metadata": {
        "id": "5sejATAN9-FL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1305.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1306.png)\n",
        "\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1307.png)\n",
        "\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1308.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "1L2hW2GU_SsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Future of Quantum Error Correction*"
      ],
      "metadata": {
        "id": "0PltPkkfZ1Uw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Future of quantum error correction**\n",
        "* we still have problems like leakage etc\n",
        "  * When they ask about thresholds, they are also derived from ideal models. Things like circular ZZ coupling can make it much harder.\n",
        "  * If you add leakage to your CZ gates, you could take a surface code that would sort of there was zero leakage below the physical error rate. But if you add leakage to that 0.1 percent degrees (the red line), which is a second. When you do the decoding (the green line), suddenly you are not below the threshold anymore\n",
        "* Also, if we want distance n=17 (mentioned in the beginning) you have an insane amount of data coming out of the device:\n",
        "  * we need ($n^2 -1$) physical qubits for error correction. So if one readout is 1 bit, we need 288 bits per microsecond ($\\mu$s) per qubit).\n",
        "  * This amounts to 288 Gbits per s for 1000 logical qubits\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1292.png)"
      ],
      "metadata": {
        "id": "yps3FbFbuHOl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Anyons, Transmon and Fluxonium**"
      ],
      "metadata": {
        "id": "oQZJ3rU97I-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Anyon (Quasi Particles)**\n",
        "\n",
        "* https://de.m.wikipedia.org/wiki/Anyon\n",
        "\n",
        "* PBS Video on Quasiparticles: https://youtu.be/le_ORQZzkmE"
      ],
      "metadata": {
        "id": "gy8QFKOMICxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transmon and Fluxonium Qubit**\n",
        "\n",
        "* Better hardware to protect against noise orders of magnitude better (to get down to 10^-5 instead of 10^-9\n",
        "* they can show cherence times above 1 millisecond, they had single qubit errors of 0.9999 (only 4x) with Fluxonium\n",
        "\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1293.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1299.png)\n",
        "\n",
        "*Source: https://theorie.physik.uni-konstanz.de/burkard/sites/default/files/images/Seminar_3_TrFl.pdf*\n",
        "\n",
        "\n",
        "Video: [Google Keynote: Superconducting qubits for quantum computation: transmon vs fluxonium](https://www.youtube.com/watch?v=qsizrKrUZDg)"
      ],
      "metadata": {
        "id": "We68Qy_9vgEl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Anyons, Qubit Braiding and Topological Quantum Computing**\n",
        "\n",
        "https://dom-kufel.github.io/blog/2023-05-13-toric_code-intro/#loop-excitations-and-error-correction\n",
        "\n",
        "https://www.quantamagazine.org/physicists-create-elusive-particles-that-remember-their-pasts-20230509/\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1568.png)\n",
        "\n",
        "\n",
        "\n",
        "https://arthurpesah.me/blog/2023-05-13-surface-code/\n",
        "\n",
        "https://dom-kufel.github.io/blog/2023-05-13-toric_code-intro/\n",
        "\n",
        "https://arthurpesah.me/blog/2023-01-31-stabilizer-formalism-1/\n",
        "\n",
        "https://arthurpesah.me/blog/2022-01-25-intro-qec-1/\n",
        "\n",
        "https://blog.google/technology/research/an-important-step-towards-improved-quantum-computers/\n",
        "\n",
        "https://phys.org/news/2023-05-google-quantum-ai-braids-non-abelian.html\n",
        "\n",
        "https://www.spektrum.de/news/nichtabelsche-anyonen-auf-quantenprozessor-simuliert/2138241\n",
        "\n",
        "\n",
        "\n",
        " I am also frustrated by us and the media representing these anyon simulations as a \"step towards fault-tolerance\". Certainly topological codes are inspired by the physics of anyons and there are direct analogies between how those codes work and are realized and these simulations. I also have no doubt that certain aspects of these simulations have some degree of error robustness. But my understanding is that once you get serious about turning such simulations into a form of fault-tolerance appropriate for our devices and then try to optimize its realization you end up with the surface code. So while thinking about the physics of error-correction from this perspective might be useful and there are myriad mathematical similarities between what is going on in these simulations and topological codes, I think it is misleading/wrong to claim that performing these simulations is taking us any closer to fault-tolerance (whether the surface code or a different form of it). People keep telling me that I am misunderstanding this (and maybe I am!) but I have not been convinced of that yet.\n",
        "\n",
        "my objection, which might be different from Cody's, is that the title of this blog post suggests that this experiment is getting us closer to realizing universal fault-tolerant quantum computers. In particular, when we say it is a step closer to improved quantum computers, it makes it sound like this approach is somehow a step on our roadmap for realizing fault-tolerant quantum computers, or that it is going to make our ultimate goal easier or something like that. That is reading between the lines a little bit, but it is how it sounds to me. Is that actually true? Or is this in the category of \"nice demonstration, but not something we're going to follow up on, and thus not a step towards us improving quantum computers other than in the very broad sense that it helps test hardware capabilities like most physics team experiments do\"? My understanding is that nothing about this experiment is likely to change anything about how we are planning to realize fault-tolerance. Maybe that is incorrect, or it is correct and I am just reading too much into the implications of statements like the title. It would be nice to understand this better.\n",
        "\n",
        "The main sense in which the non-abelian anyons are useful for fault tolerance is that they are isomorphic to twists in the surface code, and you can use twists to store logical qubits. But we already knew about twists independent of this work e.g. from https://arxiv.org/abs/1609.04673 so I don't know what it adds on the fault tolerance side.\n",
        "\n",
        "I did give a presentation to the authors of our abelian paper on how to do it fault tolerantly (they were technically \"using\" a surface code, but they were preparing it entirely unitarily which is not fault tolerant; you have to use measurements for everything). They weren't so interested I think, because the measurement version is harder and maybe also because they didn't consider it \"really doing it\" in the same way. I actually did run some quick shots of my versions of the circuits on the device back when pink was in M2 shape, and it worked, in that I got non-zero signal (the error rate was close to max but not max). I wasn't doing adept or etc or etc; if an experimentalist did it it would have been better. Also I now have much better versions of the circuit, which are described in https://arxiv.org/abs/2302.07395 .\n",
        "\n",
        "My point was that if you interpret TQC as broadly (\"you have things that act like anyons\") then this is demonstrating something interesting (multiparticle entangled EC state, FT gates on that state).  But I also agree with Ryan in that I think the blog post does not convey this well.\n",
        "\n",
        "Fair enough, I'm just trying to put forth a perspective on why it is fine to say this is an interesting experiment in topological quantum computation.  And if you want some idea of how it might lead to noise protection, yes  https://arxiv.org/abs/quant-ph/9912040 which was expanded upon in https://arxiv.org/abs/0907.3988\n",
        "\n",
        "And indeed our own team's work investigating how simulations of many body systems are related does or does not give protection of topologically protected information is in this direction.\n",
        "\n",
        "I think I agree with everything you've said Dave. But I don't think any of that really justifies the framing of the blog post title, which to me suggests that this is moving us closer to building a fault-tolerant quantum computer as opposed to exploring the error robustness of anyon simulation."
      ],
      "metadata": {
        "id": "yvGciNEzWO-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, anyons and transmons are related in quantum computing. Anyons are theoretical particles that have unique properties that make them well-suited for quantum computing. Transmons are physical implementations of qubits that can be used to build quantum computers.\n",
        "\n",
        "One of the key properties of anyons is that they can be braided together to perform quantum operations. This is because the braiding of anyons is a topological operation, meaning that it is not affected by the environment. This makes anyons very resistant to noise, which is a major challenge in quantum computing.\n",
        "\n",
        "Transmons, on the other hand, are physical particles that can be used to build qubits. Qubits are the basic unit of information in quantum computing. Transmons are made of superconducting circuits and can be manipulated using microwaves.\n",
        "\n",
        "Transmons are not as topologically protected as anyons, but they are much easier to implement in a practical quantum computer. This is because transmons can be manufactured using existing semiconductor technology.\n",
        "\n",
        "So, anyons and transmons are both promising candidates for quantum computing. Anyons are more topologically protected, but transmons are easier to implement. It is still not clear which approach will ultimately be more successful, but both anyons and transmons are active areas of research.\n",
        "\n",
        "Here is a table that summarizes the key differences between anyons and transmons:\n",
        "\n",
        "| Property | Anyons | Transmons |\n",
        "|---|---|---|\n",
        "| Topological protection | Yes | No |\n",
        "| Ease of implementation | No | Yes |\n",
        "| Current research status | Active | Active |\n",
        "\n",
        "I hope this helps! Let me know if you have any other questions."
      ],
      "metadata": {
        "id": "CaNGqKxZgJy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://en.m.wikipedia.org/wiki/Jellium\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Cooper-Paar\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Bose–Einstein_condensate\n",
        "\n",
        "https://opg.optica.org/oe/fulltext.cfm?uri=oe-2-8-299&id=63264\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Phonon\n",
        "\n",
        "\n",
        "Part of this correlation is the formation of pairs of electrons called Cooper pairs. According to Josephson, under certain circumstances these Cooper pairs move from one superconductor to the other across the thin insulating layer. Such motion of pairs of electrons constitutes the Josephson current, and the process by which the pairs cross the insulating layer is called Josephson tunneling.\n",
        "\n",
        "https://www.britannica.com/science/Josephson-effect\n",
        "\n",
        "\n",
        "Meissner effect\n",
        "\n",
        "Meissner effect, the expulsion of a magnetic field from the interior of a material that is in the process of becoming a superconductor, that is, losing its resistance to the flow of electrical currents when cooled below a certain temperature, called the transition temperature, usually close to absolute zero. The Meissner effect, a property of all superconductors, was discovered by the German physicists W. Meissner and R. Ochsenfeld in 1933.\n",
        "\n",
        "https://slideplayer.com/slide/5010186/\n",
        "\n",
        "Squid"
      ],
      "metadata": {
        "id": "I2GgHQvDATOJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Josephson Junction*"
      ],
      "metadata": {
        "id": "siEtU4-r3-Hu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Superconducting integrated circuits**\n",
        "\n",
        "- Conductance is not constant but varies with how much current is flowing, making it an unharmonic oscillator\n",
        "- Potential of the conductor is a cosine\n",
        "- Low energy excitations are pairs of electrons slashing back and forth between the two antenna pads\n",
        "- From ground state to first excited state: 5 gigahertz\n",
        "- From first excited state to second excited state transition: 4.9 Ghz (due to flattened curve of cosine)\n",
        "\n",
        "More details: https://www.youtube.com/watch?v=uD69GCYF9Zg&t=2023s\n"
      ],
      "metadata": {
        "id": "yx8LP-FXATe4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Übergangsdipolmoment (Transition dipole moment)\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Übergangsdipolmoment"
      ],
      "metadata": {
        "id": "MTADPYzI5eaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ZZ: Residual ZZ coupling, circular ZZ coupling, ZZ crosstalk**\n",
        "\n",
        "*  Noise is a significant obstacle to quantum computing, and 𝑍 𝑍 cross- talk is one of the most destructive types of noise affecting supercon- ducting qubits. Previous approaches to suppressing 𝑍𝑍 crosstalk have mainly relied on specific chip design that can complicate chip fabrication and aggravate decoherence. To some extent, special chip design can be avoided by relying on pulse optimization to sup- press 𝑍𝑍 crosstalk. However, existing approaches are non-scalable, as their required time and memory grow exponentially with the number of qubits involved. https://arxiv.org/pdf/2202.07628.pdf\n",
        "\n",
        "* In superconductors a destructive type of noise known as 𝑍𝑍 crosstalk. This refers to an always-on 𝜎𝑧 ⊗ 𝜎𝑧 inter- action between qubits connected by couplings, which originates from the interaction between the computational and non-computational energy levels of qubits.\n",
        "\n",
        "* different types of crosstalks:\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1295.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1296.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1297.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1298.png)\n",
        "\n",
        "\n",
        "*Source: https://www.youtube.com/watch?v=si5a9RJP01A&t=3645s*\n",
        "\n",
        "* second graph: top red is perfect readout, and black light is for max 10% readout\n",
        "* We need very good readout and very small ZZ error\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1294.png)"
      ],
      "metadata": {
        "id": "y9wvhg9DyWQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Barren Plateaus*"
      ],
      "metadata": {
        "id": "bIfbMtM1Y-7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sss"
      ],
      "metadata": {
        "id": "zetQy67PY8x2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Symmetries*"
      ],
      "metadata": {
        "id": "ZVxXcD-mYYhA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hamiltonian Symmetries\n",
        "\n",
        "With this new knowledge we are now able to understand what is meant when some Hamiltonian models are said to be symmetric under some symmetry group.\n",
        "\n",
        "https://pennylane.ai/qml/demos/tutorial_liealgebra/"
      ],
      "metadata": {
        "id": "t4ojzBkXZRYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pennylane.ai/qml/demos/tutorial_geometric_qml/"
      ],
      "metadata": {
        "id": "_CgA0vF-Zu2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Incorporating Symmetries:\n",
        "\n",
        "This is a nice article published by Smik Patel and Artur F. Izmaylov. They basically represent the Hamiltonian as a direct sum of Lie algebras that are solvable by Lie group rotations. Hence, by expressing a given Hamiltonian in this particular sum, one would obtain part of the solution for each term and then sum over all terms.\n",
        "\n",
        "In this work, we applied algebraic methods to develop new decompositions of the electronic Hamiltonian for VQE. The exact solvability of the fragments is based on combining commutativity and anti-commutativity conditions for Pauli products in a way consistent with Lie algebraic structures.\n",
        "These algebraic structures are re-\n",
        "vealed once the Pauli symmetries are measured.\n",
        "The re-\n",
        "sulting effective Hamiltonian is an element of a compact Lie algebra, and can therefore be measured by applying a unitary in the corresponding Lie group.\n",
        "\n",
        "https://arxiv.org/abs/2402.09376"
      ],
      "metadata": {
        "id": "NMOxh06aYWi3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Encoding*"
      ],
      "metadata": {
        "id": "91Gi3EMaYlBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fourier is all you need**: positional and number encoding using periodic signals\n",
        "\n",
        "I just realized during a conversation with Vanio Markov the similarity between the sinusoidal position encoding in the transformer architecture and what we’ve been calling “value encoding” in quantum computing. This concept was the main idea in encoding a (polynomial) function in a quantum state (inspired by phase estimation), used for optimization purposes (and contributed to Qiskit): https://lnkd.in/ea7QU77\n",
        "\n",
        "The “Attention is all you neeed” paper (https://lnkd.in/gP-y4xUE ) explains the positional encoding, but other references, like the one below, may be more accessible.\n",
        "\n",
        "https://sair.synerise.com/fourier-feature-encoding/\n",
        "\n",
        "This is a video showing frequency/value encoding for various frequencies: https://github.com/QuState/cqc_code/blob/master/videos/three_qubit_frequency_encoding.mp4 . The interactive tool also shows both the complex sinusoid (geometric sequence)  for a frequency and its  Fourier transform."
      ],
      "metadata": {
        "id": "PB2uSkU6JIZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Encoding (Embedding)\n",
        "\n",
        "**Quantum computers are Kernel methods** of a very specific kind: https://www.youtube.com/watch?v=pe1d0RyCNxY&t=2655s\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1406.png)\n",
        "\n",
        "https://arxiv.org/abs/2001.03622 - Quantum embeddings for machine learning\n",
        "\n",
        "\n",
        "**Data Encoding is the most important!**\n",
        "\n",
        "https://youtu.be/pe1d0RyCNxY?t=3008\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1407.png)\n",
        "\n",
        "The Helstrom measurement is the measurement that has the minimum error probability when trying to distinguish between two states.05.09.2018\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Quantum_state_discrimination\n",
        "\n",
        "After we embedded / encoded our data, and if we encode it in a way that it separates one data type from another in the hilbert space, we already know which measurement is the best one to do. We know quite a bit about the measurements to distinguish data. **Maybe after encoding the data, we are already done**. We could even train the encoding!\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1410.png)\n",
        "\n",
        "\n",
        "https://arxiv.org/abs/2001.03622 - Quantum embeddings for machine learning\n",
        "\n"
      ],
      "metadata": {
        "id": "reC2GT6fUkEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **The easiest way for a parameter to enter a circuit is through a rotation of a single qubit, in proportion to the value of a single datapoint, so a single scalar value:**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_190.png)\n",
        "\n",
        "> **You can also use a sequence of rotations to embedd data (reuploding).** And maybe there is free parameters in between as well. Can make a more complex function available than if you upload only once in a single rotation.\n",
        "\n",
        "> **Learnable embeddings**: The other idea is to actually have a trainable embedding layer. Not to worry about training the unitary of the circuit, but worry about training the embedding and then use standard quantum information metrics to classify the data.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_191.png)"
      ],
      "metadata": {
        "id": "xYRmG4v9vwCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basis (State) Encoding**\n",
        "\n",
        "* We gave data points x12 and x2\n",
        "\n",
        "* We first need to represent data in binary form, like 00 and 10\n",
        "\n",
        "* Then we encode it into a QC in a way, such that we have basis states that represents them like |00> and |10>\n",
        "\n",
        "* with all other basis states having probability zero - represented in the amplitude vector\n",
        "\n",
        "* So we encode data in quantum state that is aligned with basis states\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_856.png)"
      ],
      "metadata": {
        "id": "Fxjw-h8ox4Kx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Amplitude Encoding**\n",
        "\n",
        "* we want to encode our classical information into an amplitude vector\n",
        "\n",
        "* you have a classical data vector with 4 entries (features) x1\n",
        "\n",
        "* now construct a circuit, so that we have an amplitude vector that corresponds to the values in the classical data vector:\n",
        "\n",
        "\t* we have 2 qubits initialized in the ground state\n",
        "\n",
        "\t* then we apply some operations U (x1) on these qubits\n",
        "\n",
        "\t* and then we get a quantum state that corresponds to an amplitude vector that exactly represents our classical data points\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_857.png)"
      ],
      "metadata": {
        "id": "F2UqpWiN0Dv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Angle Encoding**\n",
        "\n",
        "* we have 2 dimension data that we can write in a two dimensional vector\n",
        "\n",
        "* then I take the number of qubits equal to the number of features (rows / entries in a classical vector)\n",
        "\n",
        "* then I apply rotations to each of these qubits that are equal to the value of the features\n",
        "\n",
        "\t* for example I rotate the first qubit about some axis Z. The rotation value / rotation angle is equal to the first classical feature value\n",
        "\n",
        "\t* the I take my second qubit and rotate it, for example again by the Z axis, and the angle of the rotation is equal to the second feature value of my data point\n",
        "\n",
        "* for higher dimensional data, for example a third dimension classical vector, then I simply add more qubits to my system to encode this information\n",
        "\n",
        "* For example:  [z feature map (Qiskit)](https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZFeatureMap.html#qiskit.circuit.library.ZFeatureMap):\n",
        "\t* apply Hadamard operator first to each of the qubits, and then encode data values in rotations\n",
        "\t* and then repeat this as many times as you want (stacking operations sequentially like in the image) to encode data multpiple times in a row\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_858.png)"
      ],
      "metadata": {
        "id": "GbtZMigG2mij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Higher Order Encoding**\n",
        "\n",
        "* there is no theoretical reason why doing this or if it's better or not\n",
        "\n",
        "* the idea comes from the paper [Supervised learning with quantum enhanced feature spaces](https://arxiv.org/abs/1804.11326)\n",
        "\n",
        "* Basic idea: let's do an encoding that is hard to reproduce classically and simulate, and then maybe we get some quantum advantage in doing this\n",
        "\n",
        "* we have some two dimensional data with a vector with 2 entries\n",
        "\n",
        "\t* choose number of qubits = number of feature values\n",
        "\n",
        "\t* then apply an hadarmard on each qubit\n",
        "\n",
        "\t* and then do rotations about some axis Z, and the first angle is the first feature value, and the same with the second qubit\n",
        "\n",
        "\t* and then we apply some entanglement gates between these qubits\n",
        "\n",
        "\t* then we do another rotation (for example again Z axis), but this rotation angle depends on some function of the product of the feature values R(x^1 * x^2)\n",
        "\n",
        "\t* this is where the name comes from: we encode in a higher order product space\n",
        "\n",
        "\t* and this whole block of this encoding can be repeated, which is called the depth of the feature maps\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_860.png)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_861.png)"
      ],
      "metadata": {
        "id": "T8NOeUKI5dOf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Other Encodings**\n",
        "\n",
        "* Hamiltonian evolution ansatz encoding\n",
        "\n",
        "* Displacement Encoding\n",
        "\n",
        "* IQP Encoding (Instantaneous quantum polynomial)\n",
        "\n",
        "* Squeezing Encoding\n",
        "\n",
        "* QAOA Encoding"
      ],
      "metadata": {
        "id": "BtmFtmBU6JFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Quantum Mechanics*"
      ],
      "metadata": {
        "id": "GL1iMe8igraR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Gates and Circuits*"
      ],
      "metadata": {
        "id": "UQgau4E3u8MF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum Gates and Gradients (Weyl chamber of canonical non-local 2-qubit gates)**\n",
        "\n",
        "* Video: [Quantum Gates and Gradients](https://www.youtube.com/watch?v=cobp2Sf5f3o&t=880s)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1691.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1692.png)\n",
        "\n",
        "In quantum computing, the Weyl chamber of canonical non-local 2-qubit gates is a geometric representation of the space of all non-local two-qubit gates. It is a three-dimensional tetrahedron, with each vertex representing a particular type of gate. The Weyl chamber is useful for understanding the relationships between different gates, and for identifying important classes of gates.\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1694.png)\n",
        "\n",
        "The Weyl chamber is constructed from the canonical decomposition of non-local two-qubit gates. This decomposition involves representing each gate as a linear combination of three Pauli matrices (X, Y, and Z) acting on the two qubits. The coefficients of these matrices are called the canonical coordinates of the gate. The Weyl chamber is then defined as the set of all vectors in three-dimensional space whose canonical coordinates satisfy certain constraints.\n",
        "\n",
        "The vertices of the Weyl chamber correspond to the following four types of gates:\n",
        "\n",
        "* **Identity:** The identity gate, which does not change the state of the two qubits.\n",
        "\n",
        "* **CNOT:** The controlled-NOT gate, which flips the state of the target qubit if and only if the control qubit is in the state 1.\n",
        "\n",
        "* **Swap:** The swap gate, which exchanges the states of the two qubits.\n",
        "\n",
        "* **√Swap:** The square root of the swap gate, which is a gate that is halfway between the identity and the swap gate.\n",
        "\n",
        "The interior of the Weyl chamber consists of a much larger number of gates, including all of the other possible two-qubit gates that can be constructed from the Pauli matrices. These gates can be classified by their entanglement properties, their ability to generate certain types of states, and their performance in quantum algorithms.\n",
        "\n",
        "The Weyl chamber is a useful tool for understanding the structure of two-qubit quantum gates. It allows us to visualize the relationships between different gates, and to identify important classes of gates. The Weyl chamber can also be used to design new gates and algorithms.\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1693.png)"
      ],
      "metadata": {
        "id": "o0J_Y6zgSRNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stabilizer Circuits (Clifford Group & Pauli Gate)**"
      ],
      "metadata": {
        "id": "2wucAxpmEbW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://en.m.wikipedia.org/wiki/Stabilizer_code\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Five-qubit_error_correcting_code"
      ],
      "metadata": {
        "id": "67c8czs0O86E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [Linear Growth of Quantum Circuit Complexity](https://www.youtube.com/watch?v=McfxzoMw1Ig)\n",
        "\n",
        "Video: [Estimating the Fault Tolerant Cost of Classically Intractable Quantum Computations](https://www.youtube.com/watch?v=H1UdcAdw5kg)\n",
        "\n",
        "Video: [Crypto and Privacy Village 2021 Day 1](https://www.youtube.com/watch?v=8dcl9GTPebU)"
      ],
      "metadata": {
        "id": "Dq_P0-YlMDkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why is the Pauli z operator a stabilizer for state |0>?**\n",
        "\n",
        "The Pauli-Z operator \\( Z \\) is given by:\n",
        "\n",
        "$\n",
        "Z = \\begin{pmatrix}\n",
        "1 & 0 \\\\\n",
        "0 & -1 \\\\\n",
        "\\end{pmatrix}\n",
        "$\n",
        "\n",
        "A stabilizer for a quantum state \\( $|\\psi\\rangle$ \\) is an operator \\( S \\) such that:\n",
        "\n",
        "$\n",
        "S |\\psi\\rangle = |\\psi\\rangle\n",
        "$\n",
        "\n",
        "That is, applying the stabilizer leaves the state unchanged.\n",
        "\n",
        "Now, let's see if the Pauli-Z operator is a stabilizer for the state \\( |0\\rangle \\). The state \\( |0\\rangle \\) is represented as:\n",
        "\n",
        "$\n",
        "|0\\rangle = \\begin{pmatrix}\n",
        "1 \\\\\n",
        "0 \\\\\n",
        "\\end{pmatrix}\n",
        "$\n",
        "\n",
        "Applying the Pauli-Z operator to this state:\n",
        "\n",
        "$\n",
        "Z |0\\rangle = \\begin{pmatrix}\n",
        "1 & 0 \\\\\n",
        "0 & -1 \\\\\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "1 \\\\\n",
        "0 \\\\\n",
        "\\end{pmatrix}\n",
        "= \\begin{pmatrix}\n",
        "1 \\\\\n",
        "0 \\\\\n",
        "\\end{pmatrix}\n",
        "= |0\\rangle\n",
        "$\n",
        "\n",
        "Indeed, $Z |0\\rangle = |0\\rangle$, so the Pauli-Z operator is a stabilizer for the state $|0\\rangle$.\n",
        "\n",
        "The identity operator $I$ is also a stabilizer!"
      ],
      "metadata": {
        "id": "CKvI_-fHHlhG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stabilizer Circuits:**  *Generate stabilizer states (don't change eigenvalues of Pauli matrices), but can be efficienly simulated classically + are not universal. Sometimes are transversal (=automatically fault-tolerant).*\n",
        "\n",
        "  * **Group Generators and Stabilizer States**:\n",
        "\n",
        "    * [Clifford group](https://en.m.wikipedia.org/wiki/Clifford_gates) consists of a set of n-qubit operations generated by three gates: CNOT, H and S. [Construct a single qubit gate Pauli gates X, Y, Z from S, H and Pauli gates](https://quantumcomputing.stackexchange.com/questions/29035/constructing-a-single-qubit-gate-from-s-h-and-pauli-gates)\n",
        "\n",
        "    * **The Clifford Group is the group of operators which maps the Pauli Group {I, X, Y, Z} onto itself**\n",
        "\n",
        "      * The Pauli matrices are [involutory](https://en.m.wikipedia.org/wiki/Involutory_matrix) (a square matrix that is its own inverse): I^2 = X^2 = Y^2 = Z^2 = -i X Y Z = I\n",
        "\n",
        "      * The Pauli matrices also [anti-commute](https://en.m.wikipedia.org/wiki/Anticommutative_property), for example Z X = i Y = -X Z\n",
        "\n",
        "      * The [rotation operators](https://en.m.wikipedia.org/wiki/List_of_quantum_logic_gates#Rotation_operator_gates) Rx(θ), Ry(θ), Rz(θ), the [phase shift gate](https://en.m.wikipedia.org/wiki/Quantum_logic_gate#Phase_shift_gates) P(φ) and [CNOT](https://en.m.wikipedia.org/wiki/Quantum_logic_gate#CNOT) form a universal set of quantum gates [Source](https://en.m.wikipedia.org/wiki/Quantum_logic_gate) (due to phase shift it is universal)\n",
        "\n",
        "    * **Stabilizer states: Clifford gates \"preserve\" Pauli group: when you apply a Clifford gate to a Pauli operator, the result is another Pauli operator. Clifford group generates [stabilizer states](https://en.m.wikipedia.org/wiki/Stabilizer_code)** or stabilizer circuits = circuits that only consist of gates from the normalizer of the qubit Pauli group = CNOT, Hadamard, and phase gate.\n",
        "\n",
        "    * Clifford gates can be efficiently implemented in many physical systems = they are NOT expensive (like T gate) = based on surface code\n",
        "\n",
        "    * Clifford-group elements take stabilizer groups to stabilizer groups and thus stabilizer states to stabilizer states. A Clifford unitary can be multiplied by a phase without changing how it conjugates operators. http://info.phys.unm.edu/~caves/reports/stabilizer.pdf. https://arxiv.org/pdf/1603.03999.pdf. Paper: [On Clifford groups in quantum computing](https://arxiv.org/abs/1810.10259)\n",
        "  \n",
        "  * **Bad thing**: Stabilizer circuits can be efficiently and perfectly simulated classically according to the [Gottesman–Knill theorem](https://en.m.wikipedia.org/wiki/Gottesman%E2%80%93Knill_theorem) (in polynomial time on a probabilistic classical computer).\n",
        "\n",
        "    1. Preparation of qubits in computational basis states,\n",
        "    2. Clifford gates (Hadamard gates, controlled NOT gates, phase gate S ), and\n",
        "    3. Measurements in the computational basis.\n",
        "\n",
        "  * **Solution**: Because there are quantum operations that don't preserve the Pauli group, we need non-Clifford gates to achieve universal quantum computing like tha T-gate). [Magic States](https://en.m.wikipedia.org/wiki/Magic_state_distillation) can help to implement them efficiently. <font color=\"red\"> Note: why can't you simulate a T-gate in polynomial time?\n",
        "\n",
        "    * Universal Quantum Gates = Any quantum operation can be constructed to any desired level of precision.\n",
        "\n",
        "    * You need: Clifford gate (H, S, CNOT) +  Non Clifford gate (T). Alternatively: Toffoli gate + H. Alternatively: Single-qubit rotation gates (Pauli gates) + CNOT gate + Phase shift (incl. Z, S, T gate).\n",
        "\n",
        "    * Classically: One can show that the AND, NOT and OR gates form a universal set which means that any logical operation on a arbitrary number of qubits can be expressed in terms of these gates. Thus, classically, we only need 1-bit and 2-bit gates to perform any operation. https://young.physics.ucsc.edu/150/gates.pdf"
      ],
      "metadata": {
        "id": "KXLuIdIBcD7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Synthesizing**\n",
        "* a rotation (with a T gate): find interatively a sequence of T gates that can be used to implement a desired rotation with minimum number of T gates for a given rotation.\n",
        "* With T-count algorithm in polynomial-time to optimize circuit and make it mofe efficient + fault-tolerant. Example, the rotation that takes the state |0⟩ to the state |+⟩ can be synthesized with a single T gate.\n",
        "* https://www.nature.com/articles/s41534-022-00651-y\n"
      ],
      "metadata": {
        "id": "zm-zEdmqu2oo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Pauli Gates*"
      ],
      "metadata": {
        "id": "0LWkHsu1_r51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/quantum-untangled/visualizing-quantum-logic-gates-part-1-515bb7b58916\n",
        "\n",
        "Nice visualisations: https://medium.com/analytics-vidhya/quantum-gates-7fe83817b684\n",
        "\n",
        "https://pme.uchicago.edu/awschalom-group/all-optical-holonomic-single-qubit-gates\n"
      ],
      "metadata": {
        "id": "PGcrDhdstYmq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pauli-X Gate (Flip Computational States)**\n",
        "\n",
        "> $X=\\left[\\begin{array}{ll}0 & 1 \\\\ 1 & 0\\end{array}\\right]=\\sigma_{x}=\\mathrm{NOT}$\n",
        "\n",
        "* The Pauli- $X$ gate is the quantum equivalent of the [NOT gate](https://en.m.wikipedia.org/wiki/Inverter_(logic_gate)) for classical computers (its main function is to invert the input signal applied) with respect to the standard basis $|0\\rangle,|1\\rangle$, which distinguishes the $z$ axis on the Bloch sphere. It is sometimes called a bit-flip as it maps $|0\\rangle$ to $|1\\rangle$ and $|1\\rangle$ to $|0\\rangle .$\n",
        "\n",
        "* The Pauli gates $(X, Y, Z)$ are the three Pauli matrices $\\left(\\sigma_{x}, \\sigma_{y}, \\sigma_{z}\\right)$ and act on a single qubit. The Pauli $X_{1} Y$ and $Z$ equate, respectively, to a rotation around the $x, y$ and $z$ axes of the Bloch sphere by $\\pi$ radians.\n",
        "\n",
        "* Nice visualisations: https://medium.com/analytics-vidhya/quantum-gates-7fe83817b684\n",
        "\n"
      ],
      "metadata": {
        "id": "zDXxSuLakwyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Square Root of Pauli-X Gate**\n",
        "\n",
        "The square root of NOT gate (or square root of Pauli- $X, \\sqrt{X}$ ) acts on a single qubit. It maps the basis state $|0\\rangle$ to $\\frac{(1+i)|0\\rangle+(1-i)|1\\rangle}{2}$ and $|1\\rangle$ to $\\frac{(1-i)|0\\rangle+(1+i)|1\\rangle}{2} .$\n",
        "\n",
        "In matrix form it is given by\n",
        "\n",
        ">$\n",
        "\\sqrt{X}=\\sqrt{\\mathrm{NOT}}=\\frac{1}{2}\\left[\\begin{array}{cc}\n",
        "1+i & 1-i \\\\\n",
        "1-i & 1+i\n",
        "\\end{array}\\right]=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{cc}\n",
        "e^{i \\pi / 4} & e^{-i \\pi / 4} \\\\\n",
        "e^{-i \\pi / 4} & e^{i \\pi / 4}\n",
        "\\end{array}\\right]$\n",
        "\n",
        "such that\n",
        "\n",
        ">$\n",
        "(\\sqrt{X})^{2}=(\\sqrt{\\mathrm{NOT}})^{2}=\\left[\\begin{array}{ll}\n",
        "0 & 1 \\\\\n",
        "1 & 0\n",
        "\\end{array}\\right]=X\n",
        "$\n",
        "\n",
        "> *This operation represents a rotation of $\\pi / 2$ about $x$ -axis at the Bloch sphere*."
      ],
      "metadata": {
        "id": "PeMSkgSzlzsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pauli-Y Gate (Phase Flip between i and -i)**\n",
        "\n",
        "> $Y=\\sigma_{y}=\\left[\\begin{array}{cc}0 & -i \\\\ i & 0\\end{array}\\right]$\n",
        "\n",
        "* Similarly, the Pauli- $Y$ maps $|0\\rangle$ to $i|1\\rangle$ and $|1\\rangle$ to $-i|0\\rangle$ (NOT gate with i-multiple):\n"
      ],
      "metadata": {
        "id": "htDSfNdzJulw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pauli-Z Gate ($\\pi$ Flip Phase between +1 and -1)**\n",
        "\n",
        "> $Z=\\left[\\begin{array}{cc}1 & 0 \\\\ 0 & -1\\end{array}\\right]=\\sigma_{z}\\quad Z=|0\\rangle\\langle 0|-| 1\\rangle\\langle 1|$\n",
        "\n",
        "* Pauli Z gate is a phase flip gate that causes rotation around the z-axis by π radians. Z flippt zwischen den Polen der X Achse (+ und -).\n",
        "\n",
        "* *Z Gate flippt zwischen den Hadamard gegenüberliegenden Richtungen auf der X-Achse. We change the phase (or sign) on a Qubit*:\n",
        "\n",
        "> $\\mathbf{Z}|0\\rangle=|0\\rangle$\n",
        "\n",
        "> $\\mathbf{Z}|1\\rangle=-|1\\rangle$\n",
        "\n",
        "* Since |0⟩ and |1⟩ lie on the z-axis, the Z-gate will not affect these states. To put it in other terms *|0⟩ and |1⟩ are the two eigenstates of the Z-gate*. On the other hand, it flips |+⟩ to |-⟩ and |-⟩ to |+⟩.\n",
        "\n",
        "* Pauli $Z$ leaves the basis state $|0\\rangle$ unchanged and maps $|1\\rangle$ to $-|1\\rangle$. Due to this nature, it is sometimes called *phase-flip* (flips sign of second entangled state)\n",
        "\n",
        "* *The Z gate is like the X gate but in the hadamard basis, flipping states*"
      ],
      "metadata": {
        "id": "qj2bMNDwLoDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pauli-S Gate: $\\frac{\\pi}{2}$ Flip Phase between Z and Y (with $\\mu$=i and $\\nu$=-i)**\n",
        "\n",
        "> ${S}=\\left[\\begin{array}{cc}1 & 0 \\\\ 0 & i\\end{array}\\right]=\\left[\\begin{array}{cc}1 & 0 \\\\ 0 & \\sqrt{-1}\\end{array}\\right]=\\sqrt{\\mathbf{Z}}$\n",
        "\n",
        "* The phase gate $\\mathbf{Z}$ transforms $|+\\rangle$ to $|-\\rangle$, and we can find the gate that does \"half of\" this transformation by finding the square root of the matrix $\\mathbf{Z}$\n",
        "\n",
        "* fintuning Z gate in der Hadamard basis: S-gate is die Hälfte vom Z-Gate, und R-Gate ein viertel vom Z-Gate\n",
        "\n",
        "* Use the matrix $\\mathbf{S}$ to find the state $|\\mu\\rangle$ which is \"halfway\" between $|+\\rangle$ and $|-\\rangle$ :\n",
        "\n",
        "> $\\mathbf{S}|+\\rangle=|\\mu\\rangle =\\frac{1}{\\sqrt{2}}(|0\\rangle+i|1\\rangle)$\n",
        "\n",
        "If you begin with $|+\\rangle$ and apply the $\\mathbf{S}$ gate three times in a row, you find a new state, $|\\nu\\rangle$ which appears to mirror the complex state $|\\mu\\rangle$ :\n",
        "\n",
        "> $|\\mu\\rangle=\\frac{1}{\\sqrt{2}}(|0\\rangle+i|1\\rangle)$\n",
        "\n",
        "> $|\\nu\\rangle=\\frac{1}{\\sqrt{2}}(|0\\rangle-i|1\\rangle) .$"
      ],
      "metadata": {
        "id": "Frcfbnlgr6d-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've already uncovered the gates we need to perform any rotations around the $x$ - and $z$-axes, which can bring us from an initialized qubit to any other quantum state.\n",
        "\n",
        "Unfortunately, this result comes with a pretty serious caveat: all of the gates we have used so far are discrete. They perform rotations around the Bloch sphere, but since they rotate in discrete hops (of $\\pi / 2$ or $\\pi$ ), they are unable to reach most of the intermediate states on the surface of the sphere.\n",
        "\n",
        "One solution to this problem is to define smaller and smaller rotations around these axes. The gate $\\mathbf{S}$ is equal to $\\sqrt{\\mathbf{Z}}$ and halves its rotation angle from $\\pi$ to $\\pi / 2$. Even greater division of these gates is possible, and some of them have\n",
        "common names:\n",
        "\n",
        "$\\mathbf{Z}=\\mathbf{Z}=\\left[\\begin{array}{cc}1 & 0 \\\\ 0 & -1\\end{array}\\right]$ Rotation: $\\pi$\n",
        "\n",
        "$\\mathbf{S}=\\sqrt[2]{\\mathbf{Z}}=\\left[\\begin{array}{cc}1 & 0 \\\\ 0 & i\\end{array}\\right]$ Rotation: $\\pi / 2$\n",
        "\n",
        "\n",
        "$\\mathbf{T}=\\sqrt[4]{\\mathbf{Z}}=\\left[\\begin{array}{cc}1 & 0 \\\\ 0 & e^{i \\pi / 4}\\end{array}\\right] \\quad$ Rotation: $\\pi / 4$ not clifford\n",
        "\n",
        "$\\mathbf{R 8}=\\sqrt[8]{\\mathbf{Z}}=\\left[\\begin{array}{cc}1 & 0 \\\\ 0 & e^{i \\pi / 8}\\end{array}\\right] \\quad$ Rotation: $\\pi / 8 .$ not clifford"
      ],
      "metadata": {
        "id": "6jspQ2kndBZg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjqz8Hkol68T"
      },
      "source": [
        "**Swap Gate**\n",
        "\n",
        "*2 Qubits - Swap Gate (& Swap Square root): Swap two Qubits (like in Quantum Fourier Transform)*\n",
        "\n",
        "The swap gate **swaps two qubits**.\n",
        "\n",
        "With respect to the basis $|00\\rangle,|01\\rangle,|10\\rangle,|11\\rangle$, it is represented by the matrix:\n",
        "\n",
        ">$\n",
        "\\text { SWAP }=\\left[\\begin{array}{llll}\n",
        "1 & 0 & 0 & 0 \\\\\n",
        "0 & 0 & 1 & 0 \\\\\n",
        "0 & 1 & 0 & 0 \\\\\n",
        "0 & 0 & 0 & 1\n",
        "\\end{array}\\right]\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzlOABhWmMms"
      },
      "source": [
        "**Square root of swap gate**\n",
        "\n",
        "The $\\sqrt{\\text { SWAP }}$ gate performs half-way of a two-qubit swap.\n",
        "\n",
        "It is universal such that any many-qubit gate can be constructed from only $\\sqrt{\\text { SWAP }}$ and single qubit gates.\n",
        "\n",
        "The $\\sqrt{\\text { SWAP }}$ gate is not, however maximally entangling; more than one application of it is required to produce a Bell state from product states.\n",
        "\n",
        "With respect to the basis $|00\\rangle,|01\\rangle,|10\\rangle,|11\\rangle$, it is represented by the matrix:\n",
        "\n",
        ">$\n",
        "\\sqrt{\\mathrm{SWAP}}=\\left[\\begin{array}{cccc}\n",
        "1 & 0 & 0 & 0 \\\\\n",
        "0 & \\frac{1}{2}(1+i) & \\frac{1}{2}(1-i) & 0 \\\\\n",
        "0 & \\frac{1}{2}(1-i) & \\frac{1}{2}(1+i) & 0 \\\\\n",
        "0 & 0 & 0 & 1\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n",
        "This gate arises naturally in systems that exploit exchange interaction."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transversal Gate (Eastin–Knill theorem)**"
      ],
      "metadata": {
        "id": "Z5VmP1XnIHWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arthurpesah.me/blog/2023-12-25-transversal-gates/"
      ],
      "metadata": {
        "id": "vzCwuL1sZypU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transversality**\n",
        "\n",
        "* **Transversal gates**: transversal is \"the logical operation is achieved by broadcasting the same operation over the physical qubits\" [Source](https://quantumcomputing.stackexchange.com/questions/24269/what-is-formally-a-transversal-operator). Are automatically fault-tolerant.\n",
        "\n",
        "* Non-Clifford gates (like T-gate) can NOT be implemented transversally in a fault-tolerant manner in any quantum error-correcting code, see [Eastin-Knill theorem](https://en.m.wikipedia.org/wiki/Eastin%E2%80%93Knill_theorem). Because Set of transversal gates is finite group. **A finite group - unlike a finite set - cannot approximate an infinite set of all unitaries arbitrarily well**. [Source](https://quantumcomputing.stackexchange.com/questions/28057/how-to-intuitively-understand-why-t-gate-cant-be-implemented-transversally). So you need at least one non transversal / non-Clifford gate for universality.\n",
        "  \n",
        "* non-transversal gates have higher depth (dominant contributer to fault-tolerant threshold).  Goal: Simplify these implementations. [Source](https://quantumcomputing.stackexchange.com/questions/21580/why-do-we-care-about-the-number-of-t-gates-in-a-quantum-circuit) with magic state distillation.\n",
        "\n",
        "* [Transversal logical gate for Stabilizer (or at least Steane code)](https://quantumcomputing.stackexchange.com/questions/15301/transversal-logical-gate-for-stabilizer-or-at-least-steane-code) and [errorcorrectionzoo](https://errorcorrectionzoo.org/list/quantum_transversal)"
      ],
      "metadata": {
        "id": "IWKsUajQyA1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1639.png)"
      ],
      "metadata": {
        "id": "i6wGbXqJJ1aX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/0811.4262\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Eastin%E2%80%93Knill_theorem"
      ],
      "metadata": {
        "id": "OhGA2GT2IKkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Magic State Distillation**"
      ],
      "metadata": {
        "id": "gq1Pg2IZkUmQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distillation & Magic States** *Some non-Clifford gates are magic states, allow for universal quantum computing*\n",
        "  \n",
        "  * Magic states are specific quantum states that can be used to implement non-Clifford gates (like T-gate) in a fault-tolerant way. A non-Clifford gate, such as the T-gate. All magic states are non-Clifford gates, but not all non-Clifford gates are magic states.\n",
        "\n",
        "  * [Magic States](https://en.m.wikipedia.org/wiki/Magic_state_distillation) are non-Clifford gates that can be used to efficiently implement Clifford gates and perform any quantum algorithm. They are not stabilizer states (not invariant under the action of the Pauli matrices = resulting state will have different eigenvalues) and have very nice properties with respect to fault-tolerant quantum computation. <font color=\"red\"> Note: what are these properties?</font>  [what-are-magic-states](https://quantumcomputing.stackexchange.com/questions/13629/what-are-magic-states)\n",
        "  \n",
        "  * Magic States are a key component of the [\"magic state **distillation**\"](https://en.m.wikipedia.org/wiki/Magic_state_distillation) protocol, a technique used in quantum error correction. Then, using a procedure called **gate injection or state injection**, these magic states can be used to effectively implement non-Clifford gates in a fault-tolerant manner. This is done by preparing the magic state, performing some Clifford operations and measurements (which can be done fault-tolerantly), and using the outcomes to adaptively apply further Clifford operations.\n",
        "    \n",
        "  * **Distillation**: This protocol involves preparing many noisy copies of a magic state, then performing a series of operations to \"distill\" these into fewer, higher-fidelity magic states. Distillation: purifying a quantum state by combining multiple copies of the state. Goal is to produce a state with high fidelity (close to desired state, e.g. closer to ideal T gate than the input states). T gate can be distilled efficiently (relative to alternatives) because it is a **magic state** = there are a number of different distillation protocols that have high yields (high efficiency).\n",
        "      \n",
        "  * https://en.m.wikipedia.org/wiki/Five-qubit_error_correcting_code\n",
        "\n",
        "  * https://www.nature.com/articles/s41534-022-00666-5\n",
        "\n",
        "**quantum gate injection or magic state injection**\n",
        "\n",
        "https://quantumcomputing.stackexchange.com/questions/28481/is-this-kind-of-t-injection-correct\n",
        "\n",
        "**lattice surgery**: Lattice surgery is a method to perform quantum computation fault-tolerantly by using operations on boundary qubits between different patches of the planar code.\n"
      ],
      "metadata": {
        "id": "VnRYxkP9diSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**It's a kind of magic.**\n",
        "\n",
        "Quantum states can be much less magical than they computationally appear to be.\n",
        "\n",
        "*A little magic means a lot*\n",
        "\n",
        "https://arxiv.org/abs/2308.16228\n",
        "\n",
        "Notions of so-called #magic quantify how non-classical #quantumstates are in a precise sense: high values of magic are necessary to demonstrate a quantum advantage in #quantumcomputing; they also play a key role in #quantumerrorcorrection.\n",
        "\n",
        "In this work, we introduce the phenomenon of `#pseudomagic' - wherein certain ensembles of quantum states with low magic are computationally indistinguishable from quantum states with high magic. Previously, such computational indistinguishability has been studied with respect to entanglement, by introducing the notion of #pseudoentanglement. However, we show that pseudomagic neither follows from pseudoentanglement, nor implies it.\n",
        "\n",
        "In terms of applications, pseudomagic sheds new light on the theory of #quantumchaos: it reveals the existence of states that, although built from non-chaotic unitaries, cannot be distinguished from #randomchaoticstates by any physical observer. Further applications include new lower bounds on #statesynthesis problems, #propertytesting protocols, as well as implications for #quantumcryptography.\n",
        "\n",
        "Our results have the conceptual implication that magic is a `hide-able' property of quantum states: some states have a lot more magic than meets the (computationally-bounded) eye. From the physics perspective, it advocates the mindset that the only physical properties that can be measured in a laboratory are those that are efficiently computationally detectable."
      ],
      "metadata": {
        "id": "Q4RHws1hTcz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**can you give me an example of magic state distillation in quantum computing?**\n",
        "\n",
        "Certainly! Magic state distillation is a protocol used to produce fault-tolerant, high-fidelity \"magic states\" from noisy versions of those states. These magic states can be used to perform non-Clifford gates, which are essential for universal quantum computation but are generally not directly implementable in a fault-tolerant manner.\n",
        "\n",
        "The core idea is to take multiple copies of a noisy magic state, process them together using quantum operations, and produce a smaller number of less-noisy magic states.\n",
        "\n",
        "Here's a simplified outline of the process using the $|T\\rangle$ state, a commonly used magic state:\n",
        "\n",
        "1. **Preparation**: Prepare multiple copies of the noisy $|T\\rangle$ state:\n",
        "$|T\\rangle = \\cos(\\frac{\\pi}{8})|0\\rangle + e^{i \\frac{\\pi}{4}}\\sin(\\frac{\\pi}{8})|1\\rangle$ - (Stimmt das?)\n",
        "\n",
        "2. **Encoding**: Encode these states using a specially designed quantum error-correcting code. For our purposes, think of this as a way to \"spread out\" the errors.\n",
        "\n",
        "3. **Verification**: Perform a quantum error-detection procedure on the encoded states. If the procedure detects an error, the states are discarded, and the process starts over.\n",
        "\n",
        "4. **Decoding**: If no error is detected, decode the protected information to produce a fewer number of $|T\\rangle$ states that have a higher fidelity than the initial states.\n",
        "\n",
        "The process can be iteratively repeated, using the distilled states as the input for another round of distillation until the desired fidelity is achieved.\n",
        "\n",
        "While this is a conceptual overview, the real magic state distillation involves a deeper dive into the specifics of the error-correcting codes and quantum circuits used for encoding, verification, and decoding. Researchers have proposed various protocols to optimize the trade-offs in terms of the number of initial states needed, the final fidelity achieved, and the overhead of the quantum operations."
      ],
      "metadata": {
        "id": "Ns9hFthVJwa6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*(2004) Fault-Tolerant Postselected Quantum Computation: Schemes (**Magic State Distillation**)*"
      ],
      "metadata": {
        "id": "AGZAnbN8AI5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/quant-ph/0402171\n",
        "\n",
        "https://arxiv.org/abs/quant-ph/0403025\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Magic_state_distillation#:~:text=Magic%20state%20distillation%20is%20a,contribute%20to%20quantum%20computers'%20power."
      ],
      "metadata": {
        "id": "y4KmoFxr5d-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/1209.2426"
      ],
      "metadata": {
        "id": "zh2Dim8aNpBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Magic state distillation is a process in quantum computing which aims to produce high-quality, or \"magic\", quantum states from imperfect ones, thus helping to correct errors that arise due to the imperfections of physical qubits and quantum gates. This method is used to implement non-Clifford gates, which are a crucial building block for universal quantum computation, but are particularly prone to noise and errors.\n",
        "\n",
        "The term \"distillation\" is used to evoke the idea of refining or purifying a substance, just like in chemistry. In this context, multiple imperfect copies of a quantum state are combined and processed to produce fewer copies with higher fidelity.\n",
        "\n",
        "Magic state distillation is an important part of some quantum error correction schemes, such as the surface code. These schemes are key to creating reliable and scalable quantum computers. However, as of my knowledge cutoff in 2021, practical, large-scale implementations of magic state distillation were yet to be realized, as the process is quite resource-intensive.\n"
      ],
      "metadata": {
        "id": "pcd2jrpe5oWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Magic States**\n",
        "\n",
        "* if we have access to certain specific quantum states, known as magic states, then even with only Clifford gates, we can perform universal quantum computation. This is done by using these magic states as resources in a specific type of quantum protocol called magic state distillation.\n",
        "\n",
        "* These magic states are especially important in quantum error correction because they are resistant to certain types of quantum noise and can be \"distilled\" to produce high-fidelity magic states even when we start with imperfect copies. This makes them very useful in designing fault-tolerant quantum computers, as they can help us overcome the errors that inevitably occur in any real-world quantum system.\n",
        "\n",
        "Magic states are purified from n copies of a mixed state $\\rho$ . These states are typically provided via an ancilla to the circuit. A magic state for the $T$ gate is ${\\displaystyle |M\\rangle =\\cos(\\beta /2)|0\\rangle +e^{i{\\frac {\\pi }{4}}}\\sin(\\beta /2)|1\\rangle }$ where ${\\displaystyle \\beta =\\arccos \\left({\\frac {1}{\\sqrt {3}}}\\right)}$. By combining (copies of) magic states with Clifford gates, can be used to make a non-Clifford gate\n",
        "\n",
        "*The first magic state distillation algorithm, invented by Sergey Bravyi and Alexei Kitaev, is a follows.*\n",
        "\n",
        "* Input: Prepare 5 imperfect states.\n",
        "* Output: An almost pure state having a small error probability.\n",
        "* repeat\n",
        "  * Apply the decoding operation of the five-qubit error correcting code and measure the syndrome.\n",
        "  * If the measured syndrome is ${\\displaystyle |00000\\rangle }$, the distillation attempt is successful.\n",
        "  * else Get rid of the resulting state and restart the algorithm.\n",
        "* until The states have been distilled to the desired purity."
      ],
      "metadata": {
        "id": "9_FS5V9hlPyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Magic state distillation**](https://en.m.wikipedia.org/wiki/Magic_state_distillation) is a procedure in quantum computation that is used to create high-fidelity quantum states, starting from several copies of a \"noisy\" state. The name \"distillation\" is used because it's similar to the idea of distilling a liquid to increase its purity.\n",
        "\n",
        "The technique was first proposed by Emanuel Knill in 2004, and further analyzed by Sergey Bravyi and Alexei Kitaev the same year.\n",
        "\n",
        "Here's a high-level overview of how it works:\n",
        "\n",
        "1. **Preparation**: Prepare several copies of a quantum state. These states are typically \"noisy\" copies of a desired magic state, meaning they have some errors or deviations from the perfect magic state.\n",
        "\n",
        "2. **Error Detection**: Apply a quantum error-detecting code to these copies. This code is a series of quantum operations that can identify (but not correct) certain errors in the quantum states.\n",
        "\n",
        "3. **Measurement**: Measure the error-detecting code. This does not directly measure the quantum states themselves but measures whether an error has been detected.\n",
        "\n",
        "4. **Post-selection**: If the measurement indicates that no errors were detected, then (due to the properties of quantum mechanics) the quantum states are projected into a state that is closer to the perfect magic state than the original states were. If an error was detected, discard the states and start over.\n",
        "\n",
        "5. **Repeat**: Repeat this process several times. Each time, the states get closer to the perfect magic state.\n",
        "\n",
        "By repeating this process, one can \"distill\" a set of noisy magic states into a smaller number of higher-fidelity magic states. This is a crucial part of many fault-tolerant quantum computing schemes, as it allows one to perform universal quantum computation even in the presence of noise."
      ],
      "metadata": {
        "id": "iFeGkcT-lTDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**T-Gate and Toffoli Gate**"
      ],
      "metadata": {
        "id": "gLYqKHKB_yS7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [Jens Eisert | September 27, 2022 | A Single T-Gate Makes Quantum Distribution Learning Hard](https://www.youtube.com/watch?v=HAKPulM08hs)"
      ],
      "metadata": {
        "id": "K6ehfiAJL4v9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is so special about the T-gate?**\n",
        "\n",
        "* non-Clifford gate, majority of non-Clifford gates used, most expensive gate (based on surface code), for universal quantum gate, controls phase / rotation (phase shift) by $\\frac{i \\pi}{4}$ around Z-axis\n",
        "* [Craig Gidney of why T-gates are best option](https://quantumcomputing.stackexchange.com/questions/33357/universal-gate-set-magic-states-and-costliness-of-the-t-gate/33358#33358)\n",
        "* [Can someone explain to me what is T gate and tdg like im five?](https://quantumcomputing.stackexchange.com/questions/26666/can-someone-explain-to-me-what-is-t-gate-and-tdg-like-im-five)\n",
        "* [Why do we care about the number of 𝑇 gates in a quantum circuit?](https://quantumcomputing.stackexchange.com/questions/21580/why-do-we-care-about-the-number-of-t-gates-in-a-quantum-circuit)\n",
        "\n",
        "> $\\mathbf{T}=\\sqrt[4]{\\mathbf{Z}}=\\left[\\begin{array}{cc}1 & 0 \\\\ 0 & e^{\\frac{i \\pi}{4}}\\end{array}\\right]$\n",
        "\n",
        "> Applying it: $\n",
        "T|1\\rangle=\\left[\\begin{array}{ll}\n",
        "1 & 0 \\\\\n",
        "0 & e^{\\frac{i \\pi}{4}}\n",
        "\\end{array}\\right]\\left[\\begin{array}{l}\n",
        "0 \\\\\n",
        "1\n",
        "\\end{array}\\right]=e^{\\frac{i \\pi}{4}}|1\\rangle\n",
        "$ Since QPE will give us $\\theta$ where: $\n",
        "T|1\\rangle=e^{2 i \\pi \\theta}|1\\rangle\n",
        "$ we expect to find theta: $\n",
        "\\theta=\\frac{1}{8}\n",
        "$\n",
        "\n",
        "*Paper [Universal Quantum Computation with ideal Clifford gates and noisy  ancillas](https://arxiv.org/abs/quant-ph/0403025): check out figure 1 that provides a nice visualization of two types of magic states and also definition 1 on page 3. confusingly, T state is the \"H-type state\" and not the \"T-type state\" in their lingo (since the density matrix of the T state is (I+1/sqrt2(X+Y))/2) - Yes, it seems to me that in the old days folks named these states by the operators of which the states were the eigenvectors (rather than by the gate you could realize using the states as we do today). the caption of figure 1 undersells its significance. the octahedron consists of states which don't boost computational power of the Clifford gateset (see Theorem 1 on the same page). it's the high-purity states outside the octahedron that are useful. I mean isn't the eigenstate the more sensible naming scheme?  Old man shakes cane. T |T> = t |T>. +1 to naming things for what they are instead of for what you can do with them (as that is subject to change)*"
      ],
      "metadata": {
        "id": "lYtm8-hjDwuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is so special about the Toffoli-gate?**\n",
        "\n",
        "![ggg](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ef/Qcircuit_ToffolifromCNOT.svg/799px-Qcircuit_ToffolifromCNOT.svg.png)\n",
        "\n",
        "* construct a quantum mechanical Toffoli gate out of 1-qubit and 2-qubit gates.\n",
        "* [Toffoli gate](https://en.m.wikipedia.org/wiki/Toffoli_gate#), a reversible gate, and is universal in classical computing - can simulate classical computation (https://youtu.be/qs0D9sdbKPU?t=6520) - essential tool for building big classical operations like multipliers and [multiplexers](https://en.m.wikipedia.org/wiki/Multiplexer)\n",
        "* It is used in the Shor algorithm, quantum error correction, fault-tolerant computation and quantum arithmetic operations (https://www.nature.com/articles/npjqi201619)\n",
        "* In many of Google's papers talk about directly distilling Toffoli rather T = Toffoli has many clear connections to classical logic and is a more natural gate when your algorithm is bottlenecked by classical logic rather than single qubit rotations\n",
        "* [Are Toffoli gates actually used in designing quantum circuits?](https://quantumcomputing.stackexchange.com/questions/11915/are-toffoli-gates-actually-used-in-designing-quantum-circuits)\n",
        "* [A Simple Proof that Toffoli and Hadamard are Quantum Universal](https://arxiv.org/abs/quant-ph/0301040)"
      ],
      "metadata": {
        "id": "XPdY_aRRVpZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hadamard Gate**"
      ],
      "metadata": {
        "id": "Ca3fvYOc_oY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [Logic Gates Rotate Qubits](https://www.youtube.com/watch?v=ZBaXPY_0TNI)\n",
        "\n",
        "Video: [Qubits vs Bits: The Kickback Effect](https://www.youtube.com/watch?v=EjdngeGXWEg)"
      ],
      "metadata": {
        "id": "d6OTWQs8Lcu0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Hadamard Gate (Superposition)*\n",
        "\n",
        "> $H=\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right)$\n",
        "\n",
        "**The Hadamard states ∣+⟩ and ∣−⟩ are considered superposition states**\n",
        "\n",
        "because they are a combination of the two computational states:\n",
        "\n",
        "> $|\\pm\\rangle=\\frac{1}{\\sqrt{2}}|0\\rangle \\pm \\frac{1}{\\sqrt{2}}|1\\rangle$\n",
        "\n",
        "**Apply Hadamard gate on a qubit that is in the |0> state**:\n",
        "\n",
        "> <font color=\"blue\">$\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right)\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{l}1 \\\\ 1\\end{array}\\right]$\n",
        "\n",
        "The qubit enters a new state where the probability of measuring 0 is:\n",
        "\n",
        "* $\\left(\\frac{1}{\\sqrt{2}}\\right)^{2}=\\frac{1}{2}$\n",
        "\n",
        "And the probability of measuring 1 is also:\n",
        "\n",
        "* $\\left(\\frac{1}{\\sqrt{2}}\\right)^{2}=\\frac{1}{2}$\n",
        "\n",
        "**Now apply Hadamard gate on a qubit that is in the |1> state**:\n",
        "\n",
        "> <font color=\"blue\">$\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right)\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right]=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{l}1 \\\\ -1\\end{array}\\right]$\n",
        "\n",
        "The qubit enters a new state where the probability of measuring 0 is:\n",
        "\n",
        "* $\\left(\\frac{1}{\\sqrt{2}}\\right)^{2}=\\frac{1}{2}$\n",
        "\n",
        "And the probability of measuring 1 is also:\n",
        "\n",
        "* $\\left(\\frac{-1}{\\sqrt{2}}\\right)^{2}=\\frac{1}{2}$\n",
        "\n",
        "Hence, in both cases (qubit |0> or qubit |1>) applying a Hadamard Gate gives an equal chance for the qubit to be 0 or 1' when measured.\n",
        "\n",
        "Source: https://freecontent.manning.com/all-about-hadamard-gates/\n",
        "\n",
        "**Herleitung Hadamard (Wichtig!)**\n",
        "\n",
        "For an equal (or uniform) superposition of the two computational states, we can set the two coefficients equal to each other:\n",
        "\n",
        "$a_{1}=a_{2}=a$\n",
        "\n",
        "The normalization condition for a well-behaved quantum state requires that the sum of the squared magnitudes of the coefficients be equal to one; this is sufficient to find\n",
        "a\n",
        "a for a uniform superposition:\n",
        "\n",
        "$|a|^{2}+|a|^{2}=1$\n",
        "\n",
        "$2|a|^{2}=1$\n",
        "\n",
        "$|a|^{2}=\\frac{1}{2}$\n",
        "\n",
        "$a=\\frac{1}{\\sqrt{2}}$\n",
        "\n",
        "In vector form, this state can represented as\n",
        "\n",
        "> $\\left[\\begin{array}{l}\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}}\\end{array}\\right]$ = $\\frac{1}{\\sqrt{2}}$ $\\left[\\begin{array}{c} 1 \\\\ 0 \\end{array}\\right]$ + $\\frac{1}{\\sqrt{2}}$ $\\left[\\begin{array}{c} 0 \\\\ 1 \\end{array}\\right]$\n",
        "\n",
        "This is what we can use now to understand Hadamard, where you want \"halfway\" a 50/50 chance of basis states 0 and 1 (Bloch sphere representation of superposition state):\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_025.jpg)\n",
        "\n",
        "*Hadamard gate operations:*\n",
        "\n",
        "> $\\begin{aligned} H(|0\\rangle) &=\\frac{1}{\\sqrt{2}}|0\\rangle+\\frac{1}{\\sqrt{2}}|1\\rangle=:|+\\rangle \\\\ H(|1\\rangle) &=\\frac{1}{\\sqrt{2}}|0\\rangle-\\frac{1}{\\sqrt{2}}|1\\rangle=:|-\\rangle \\\\ H\\left(\\frac{1}{\\sqrt{2}}|0\\rangle+\\frac{1}{\\sqrt{2}}|1\\rangle\\right) &=\\frac{1}{2}(|0\\rangle+|1\\rangle)+\\frac{1}{2}(|0\\rangle-|1\\rangle)=|0\\rangle \\\\ H\\left(\\frac{1}{\\sqrt{2}}|0\\rangle-\\frac{1}{\\sqrt{2}}|1\\rangle\\right) &=\\frac{1}{2}(|0\\rangle+|1\\rangle)-\\frac{1}{2}(|0\\rangle-|1\\rangle)=|1\\rangle \\end{aligned}$\n",
        "\n",
        "One application of the Hadamard gate to either a 0 or 1 qubit will produce a quantum state that, if observed, **will be a 0 or 1 with equal probability** (as seen in the first two operations). This is exactly like flipping a fair coin in the standard probabilistic model of computation. However, if the Hadamard gate is applied twice in succession (as is effectively being done in the last two operations), then the final state is always the same as the initial state (because quantum operations are reversable, unlike operations on classical computers)."
      ],
      "metadata": {
        "id": "_T8yeOt7mKxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Circuit Noise**"
      ],
      "metadata": {
        "id": "xMyCxxxgo5T2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is Laplacian noise in the context of quantum computing and quantum machine learning?**\n",
        "\n",
        "Laplacian noise is a type of noise that is often used to model the effects of decoherence in quantum computing. Decoherence is the loss of quantum coherence due to interactions with the environment.\n",
        "\n",
        "Laplacian noise is a non-Gaussian noise, which means that it does not follow a normal distribution. Instead, it follows a Laplace distribution, which is a bell-shaped curve with heavier tails than a normal distribution.\n",
        "\n",
        "The Laplace noise is characterized by a parameter called the scale parameter, which controls the amount of noise. The larger the scale parameter, the more noise there is.\n",
        "\n",
        "Laplacian noise can be added to quantum states to simulate the effects of decoherence. This can be done by adding a random variable to each qubit in the state, where the random variable is drawn from a Laplace distribution.\n",
        "\n",
        "Laplacian noise can also be used to design quantum machine learning algorithms that are robust to noise. For example, Laplacian noise can be used to regularize quantum neural networks, which can help to improve their performance.\n",
        "\n",
        "Here are some of the key properties of Laplacian noise:\n",
        "\n",
        "* It is a non-Gaussian noise.\n",
        "* It follows a Laplace distribution.\n",
        "* It is characterized by a scale parameter.\n",
        "* It can be used to simulate the effects of decoherence in quantum computing.\n",
        "* It can be used to design quantum machine learning algorithms that are robust to noise.\n",
        "\n",
        "Laplacian noise is a versatile tool that can be used to study the effects of noise in quantum computing and quantum machine learning. It is a promising area of research with the potential to improve the performance of quantum computers and quantum machine learning algorithms."
      ],
      "metadata": {
        "id": "mgs7G5vRo-ph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What kinds of noise can you add to a quantum computing circuit?**\n",
        "\n",
        "There are many different kinds of noise that can be added to a quantum computing circuit. Some of the most common types of noise include:\n",
        "\n",
        "* **Bit flip noise:** This is the most common type of noise. It occurs when a qubit is flipped from the |0⟩ state to the |1⟩ state or vice versa.\n",
        "* **Phase flip noise:** This type of noise occurs when the phase of a qubit is flipped. This means that the probability of measuring the qubit in the |0⟩ state or the |1⟩ state is flipped.\n",
        "* **Amplitude damping:** This type of noise occurs when the amplitude of a qubit is reduced. This means that the probability of measuring the qubit in the |0⟩ state is decreased, and the probability of measuring it in the |1⟩ state is increased.\n",
        "* **Depolarizing noise:** This is the most general type of noise. It can cause any combination of bit flip, phase flip, and amplitude damping noise.\n",
        "\n",
        "These are just a few of the many different types of noise that can be added to a quantum computing circuit. The specific type of noise that is added depends on the source of the noise.\n",
        "\n",
        "Noise is a major obstacle to the development of practical quantum computers. It can cause errors in quantum computations, which can lead to incorrect results. There are a number of techniques that can be used to reduce the effects of noise, such as quantum error correction.\n",
        "\n",
        "I hope this helps! Let me know if you have any other questions.\n",
        "\n",
        "Here are some additional details about the different types of noise mentioned above:\n",
        "\n",
        "* **Bit flip noise:** Bit flip noise can be modeled by a Pauli X gate, which flips the state of the qubit. The probability of a bit flip error occurring is determined by the strength of the noise.\n",
        "* **Phase flip noise:** Phase flip noise can be modeled by a Pauli Z gate, which flips the phase of the qubit. The probability of a phase flip error occurring is determined by the strength of the noise.\n",
        "* **Amplitude damping:** Amplitude damping can be modeled by a beam splitter, which mixes the |0⟩ and |1⟩ states of the qubit. The probability of an amplitude damping error occurring is determined by the strength of the noise.\n",
        "* **Depolarizing noise:** Depolarizing noise can be modeled by a depolarizing channel, which randomly changes the state of the qubit. The probability of a depolarizing error occurring is determined by the strength of the noise.\n",
        "\n",
        "The effects of noise can be mitigated by using quantum error correction. Quantum error correction is a technique that can be used to detect and correct errors in quantum computations. Quantum error correction can be used to make quantum computers more resistant to noise.\n",
        "\n",
        "I hope this helps! Let me know if you have any other questions."
      ],
      "metadata": {
        "id": "-O53JXv_pEJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do you have more examples? Like Laplacian noise and more?**\n",
        "\n",
        "Sure. Here are some other examples of noise that can be added to a quantum computing circuit:\n",
        "\n",
        "* **Gaussian noise:** Gaussian noise is a type of noise that is characterized by a Gaussian distribution. This means that the probability of a certain error occurring is given by a Gaussian function. Gaussian noise can be caused by thermal fluctuations in the environment.\n",
        "* **Readout noise:** Readout noise is the noise that occurs when a qubit is measured. This noise can cause errors in the measurement results. Readout noise can be caused by a number of factors, including the environment and the measurement device.\n",
        "* **Crosstalk noise:** Crosstalk noise is the noise that occurs when one qubit affects the state of another qubit. This noise can be caused by the interaction between the qubits.\n",
        "* **Qubit loss:** Qubit loss is the loss of a qubit from the system. This can occur due to a number of factors, such as environmental noise or errors in the control system.\n",
        "\n",
        "These are just a few of the many different types of noise that can be added to a quantum computing circuit. The specific type of noise that is added depends on the source of the noise and the specific application.\n",
        "\n",
        "I hope this helps! Let me know if you have any other questions."
      ],
      "metadata": {
        "id": "603erkTepKMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**And laplacian noise?**\n",
        "\n",
        "Yes, Laplacian noise is another type of noise that can be added to a quantum computing circuit. It is a non-Gaussian noise, which means that it does not follow a Gaussian distribution. Instead, it follows a Laplace distribution, which is a bell-shaped curve with heavier tails than a Gaussian distribution.\n",
        "\n",
        "Laplacian noise can be added to a quantum state by adding a random variable to each qubit in the state, where the random variable is drawn from a Laplace distribution. The Laplace noise is characterized by a parameter called the scale parameter, which controls the amount of noise. The larger the scale parameter, the more noise there is.\n",
        "\n",
        "Laplacian noise is often used to model the effects of decoherence in quantum computing. Decoherence is the loss of quantum coherence due to interactions with the environment. Laplacian noise is more robust to noise than Gaussian noise, which makes it a good choice for applications where noise is a major concern.\n",
        "\n",
        "Laplacian noise can also be used to design quantum machine learning algorithms that are robust to noise. For example, Laplacian noise can be used to regularize quantum neural networks, which can help to improve their performance.\n",
        "\n",
        "Here are some of the key properties of Laplacian noise:\n",
        "\n",
        "* It is a non-Gaussian noise.\n",
        "* It follows a Laplace distribution.\n",
        "* It is characterized by a scale parameter.\n",
        "* It can be added to quantum states to simulate the effects of decoherence in quantum computing.\n",
        "* It can be used to design quantum machine learning algorithms that are robust to noise.\n",
        "\n",
        "Laplacian noise is a versatile tool that can be used to study the effects of noise in quantum computing and quantum machine learning. It is a promising area of research with the potential to improve the performance of quantum computers and quantum machine learning algorithms."
      ],
      "metadata": {
        "id": "qCnnUEPHpOQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is Laplacian noise in the context of quantum computing and quantum machine learning?**\n",
        "\n",
        "Laplacian noise is a type of noise that is often used to model the effects of decoherence in quantum computing. Decoherence is the loss of quantum coherence due to interactions with the environment.\n",
        "\n",
        "Laplacian noise is a non-Gaussian noise, which means that it does not follow a normal distribution. Instead, it follows a Laplace distribution, which is a bell-shaped curve with heavier tails than a normal distribution.\n",
        "\n",
        "The Laplace noise is characterized by a parameter called the scale parameter, which controls the amount of noise. The larger the scale parameter, the more noise there is.\n",
        "\n",
        "Laplacian noise can be added to quantum states to simulate the effects of decoherence. This can be done by adding a random variable to each qubit in the state, where the random variable is drawn from a Laplace distribution.\n",
        "\n",
        "Laplacian noise can also be used to design quantum machine learning algorithms that are robust to noise. For example, Laplacian noise can be used to regularize quantum neural networks, which can help to improve their performance.\n",
        "\n",
        "Here are some of the key properties of Laplacian noise:\n",
        "\n",
        "* It is a non-Gaussian noise.\n",
        "* It follows a Laplace distribution.\n",
        "* It is characterized by a scale parameter.\n",
        "* It can be used to simulate the effects of decoherence in quantum computing.\n",
        "* It can be used to design quantum machine learning algorithms that are robust to noise.\n",
        "\n",
        "Laplacian noise is a versatile tool that can be used to study the effects of noise in quantum computing and quantum machine learning. It is a promising area of research with the potential to improve the performance of quantum computers and quantum machine learning algorithms."
      ],
      "metadata": {
        "id": "C6pxre-a4HnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Jens Eisert: What do we do with Quantum Computers?](https://youtu.be/70MD0pe6HGs) and [(2023) Disentangling Hype from Practicality](https://www.researchgate.net/publication/372075046_Disentangling_Hype_from_Practicality_On_Realistically_Achieving_Quantum_Advantage)"
      ],
      "metadata": {
        "id": "Ntf_T5a8waQ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Where does a quantum computer has an (exponential) advantage over a classical computer in machine learning tasks?**\n",
        "\n",
        "* Classical Data (learn classical Boolean circuits):\n",
        "  * average error: no\n",
        "  * worse error: no\n",
        "\n",
        "* Quantum Data (learn unknown cptp maps over known observables):\n",
        "  * average error: no - classical ML can learn unknown state p or observable O very well\n",
        "  * worse error: yes (predicting ex-\n",
        "pectation values of Pauli operators in an unknown n-\n",
        "qubit quantum state ρ)"
      ],
      "metadata": {
        "id": "xdH07JFx1Szq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Pending questions*\n",
        "\n",
        "what is the chernoff bound\n",
        "\n",
        "how can you learn the phase of a heisenberg-weyl operator?\n",
        "\n",
        "what is the phase of a heisenberg-weyl operator?\n",
        "\n",
        "what is a simplectic inner product?\n"
      ],
      "metadata": {
        "id": "DH8extyZD-oU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is meant by the parity of the two qubits?**\n",
        "\n",
        "The \"parity\" of two qubits refers to whether the number of qubits in the state |1⟩ is even or odd.\n",
        "\n",
        "The parity operator for two qubits, which could be denoted as Z ⊗ Z in terms of Pauli matrices, acts on a two-qubit state |ψ⟩ = α|00⟩ + β|01⟩ + γ|10⟩ + δ|11⟩ as follows:\n",
        "\n",
        "(Z ⊗ Z)|ψ⟩ = α|00⟩ - β|01⟩ - γ|10⟩ + δ|11⟩\n",
        "\n",
        "In this case, the eigenvalues of the parity operator are +1 and -1. States |00⟩ and |11⟩ have even parity (0 and 2 qubits are in the state |1⟩, respectively, both of which are even numbers), so the parity operator gives them a factor of +1. States |01⟩ and |10⟩ have odd parity (1 qubit is in the state |1⟩), so the parity operator gives them a factor of -1.\n",
        "\n",
        "Measuring the expectation value of the parity operator tells you about the relative likelihood of being in an even parity state versus an odd parity state. For example, if a two-qubit system is in the state |ψ⟩ = 1/√2(|00⟩ + |11⟩), then the expectation value of the parity operator would be +1, indicating that measurements of both qubits will always yield the same result, either both 0 or both 1. On the other hand, if the system is in the state |ψ⟩ = 1/√2(|01⟩ + |10⟩), then the expectation value of the parity operator would be -1, indicating that measurements of both qubits will always yield opposite results."
      ],
      "metadata": {
        "id": "n-lA7hp1t_Gp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "John Preskyll - Quantum Computation\n",
        "\n",
        "https://youtu.be/w08pSFsAZvE"
      ],
      "metadata": {
        "id": "eG1F6mn_fsDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what means \"bounded fan-in (a general form of locality restriction)\" in the context of quantum computing?**\n",
        "\n",
        "In the context of quantum computing, the concept of \"fan-in\" relates to the number of input bits that a quantum gate or operation can accept.\n",
        "\n",
        "When we say a system or a circuit has \"bounded fan-in,\" it means that there's a limit to the number of input bits any single gate or operation can accept.\n",
        "\n",
        "\"Bounded fan-in\" is a kind of \"locality restriction.\" In a locality restriction, we limit how our quantum operations can act. In physical systems, this is often motivated by the fact that most physical interactions are local -- for instance, each qubit in a quantum computer might only interact directly with a small number of nearby qubits.\n",
        "\n",
        "A gate or operation with bounded fan-in can only act on a fixed number of qubits. For example, if we're working with a two-qubit bounded fan-in, our gates can only act on one or two qubits at a time -- we can't have a single gate that acts on three or more qubits simultaneously. This is a general form of locality restriction because it restricts how 'far' each operation can 'reach' in the space of qubits.\n",
        "\n",
        "This is important in quantum computing because it affects the kinds of circuits and algorithms we can use. It's also important when thinking about how to physically implement a quantum computer, as real-world quantum systems often have natural locality restrictions due to physical constraints."
      ],
      "metadata": {
        "id": "L3scapHoAYEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what means strings over n bits?**\n",
        "\n",
        "In the context of computer science and mathematics, a \"string over n bits\" usually refers to a sequence or set of binary digits (bits) of length n. Each bit can either be a 0 or a 1.\n",
        "\n",
        "For instance, if n = 3, then the possible strings over 3 bits are: 000, 001, 010, 011, 100, 101, 110, 111. These are all the possible combinations of 3 bits.\n",
        "\n",
        "The total number of possible strings over n bits is 2^n, because each bit has 2 possible states (0 or 1), and there are n such bits. This principle is widely used in areas such as digital computing, information theory, cryptography, etc."
      ],
      "metadata": {
        "id": "qRrlJTQgAfHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what means \"covering number bounds\" in quantum computing?**\n",
        "\n",
        "Covering number bounds in quantum computing (and more generally in the field of mathematics) refer to a metric related to how many of a certain-sized object are needed to \"cover\" or contain another object.\n",
        "\n",
        "The concept of a covering number is used in various mathematical contexts, but the general idea remains the same. The covering number of a set (in a metric space) is the smallest number of \"balls\" of a given radius that can cover the entire set.\n",
        "\n",
        "In quantum computing, this might be used in the context of quantum states or operations. For instance, if you're talking about quantum states in a Hilbert space, you might be asking: how many quantum states (treated as \"balls\" in the Hilbert space) of a certain \"size\" (or distance from each other) do you need to cover the entire space of possible quantum states?\n",
        "\n",
        "Covering numbers are important in quantum computing because they can help us understand the complexity of various tasks, including the complexity of approximating a given quantum state or operation.\n",
        "\n",
        "Bounding the covering number, or providing covering number bounds, is important because it gives us a measure of the \"size\" or complexity of the space we're dealing with. These bounds can help us understand the resources required for tasks such as quantum state preparation, quantum channel simulation, and so on."
      ],
      "metadata": {
        "id": "MOIwu35QAkuV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Qubitization**\n",
        "\n",
        "\"Qubitization\" is a term related to quantum computing. It is a procedure to convert a certain operation into a quantum operation that can be performed on a quantum computer. Qubitization offers an approach for performing certain computational tasks with a significant reduction in resource requirements compared to other quantum algorithms.\n",
        "\n",
        "A primary example of the use of qubitization is in simulating Hamiltonians, a fundamental problem in quantum physics, with an algorithm known as the \"qubitization of Hamiltonian.\" This algorithm allows the efficient estimation of quantities such as ground state energy, which are of significant interest in quantum chemistry and condensed matter physics.\n",
        "\n",
        "The key advantage of qubitization over other quantum simulation algorithms is that it allows a more efficient use of quantum resources. However, the technique typically requires a more complex set of quantum gates and, as of my knowledge cut-off in September 2021, is a subject of active research and development in the field of quantum computing.\n",
        "\n",
        "Please note that the understanding and implementation of qubitization may have evolved beyond my last update. For the most accurate information, it's recommended to refer to the latest literature in the field of quantum computing.\n",
        "\n",
        "https://arxiv.org/abs/1610.06546"
      ],
      "metadata": {
        "id": "Ph9a0fu1y9Es"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trotterization**\n",
        "\n",
        "https://vtomole.com/blog/2019/04/07/trotter\n",
        "\n",
        "**Trotterization** is a technique used in quantum computing to simulate the evolution of a quantum system under a Hamiltonian that is a sum of many terms. The idea is to break down the evolution into a sequence of smaller evolutions, each of which is under a single term of the Hamiltonian. This can be done because the exponential of a sum of matrices is approximately equal to the product of the exponentials of the individual matrices, up to a small error.\n",
        "\n",
        "The Trotterization formula is:\n",
        "\n",
        "> $e^{-iHt} \\approx \\left( e^{-iH_0t/r} \\cdot e^{-iH_1t/r} \\cdots e^{-iH_{d-1}t/r} \\right)^r$\n",
        "\n",
        "where $H$ is the Hamiltonian, $t$ is the time, $r$ is the number of Trotter steps, and $H_i$ are the individual terms of the Hamiltonian.\n",
        "\n",
        "The error in the Trotterization approximation can be controlled by increasing the number of Trotter steps. However, this also increases the complexity of the quantum circuit that is needed to implement the Trotterized evolution.\n",
        "\n",
        "Trotterization is a powerful technique that can be used to simulate a wide variety of quantum systems. However, it is important to note that the error in the Trotterization approximation can be significant, especially for long times or for Hamiltonians with terms that do not commute.\n",
        "\n",
        "Here are some additional details about Trotterization:\n",
        "\n",
        "* The Trotterization formula was first introduced by Harold Trotter in 1958.\n",
        "* The error in the Trotterization approximation is of the order of $O(t^2/r^2)$.\n",
        "* The number of Trotter steps needed to achieve a given accuracy depends on the Hamiltonian and the desired accuracy.\n",
        "* Trotterization can be used to simulate the evolution of both closed and open quantum systems.\n",
        "* Trotterization is a key technique in many quantum algorithms, such as quantum simulation, quantum chemistry, and quantum machine learning."
      ],
      "metadata": {
        "id": "5tnibSuZLcPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shadow Tomography**"
      ],
      "metadata": {
        "id": "i_mzlg6WUapR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.quantamagazine.org/machine-learning-aids-classical-modeling-of-quantum-systems-20230914/"
      ],
      "metadata": {
        "id": "0RlEe49PJsfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "State Tomography, Shadow Tomography and Process Tomography (Choi matrix)"
      ],
      "metadata": {
        "id": "edw279abUZ6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> State tomography is an alternative to boolean functions in quantum computational learning"
      ],
      "metadata": {
        "id": "6ZVr_tksjzSN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> To solve shadow tomography, the goal is to find a quantum state σ that satisfies Tr(σEi) ≈ Tr(ρEi) for all i (the trace distance is almost zero, the states are identical). Further, one would like to minimize the number of copies of ρ, suggesting that σ should be no more informative than matching the above expectations."
      ],
      "metadata": {
        "id": "I42TFae9nf2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is the difference between state tomography and shadow tomorgraphy?**\n",
        "\n",
        "The main difference between state tomography and shadow tomography is the number of copies of the quantum state that are needed to reconstruct the state.\n",
        "\n",
        "In state tomography, the complete state vector or density matrix of the quantum state is reconstructed. This requires measuring the state in a complete set of bases, which can be exponentially many bases for a large quantum state.\n",
        "\n",
        "In shadow tomography, only a subset of the bases is measured. This allows the state to be reconstructed with fewer copies of the state, but the reconstructed state may not be as accurate as the state reconstructed using state tomography.\n",
        "\n",
        "Shadow tomography can be useful when the number of copies of the state is limited, or when it is only necessary to reconstruct a specific aspect of the state.\n",
        "\n",
        "Here is a table summarizing the key differences between state tomography and shadow tomography:\n",
        "\n",
        "| Feature | State tomography | Shadow tomography |\n",
        "|---|---|---|\n",
        "| Number of copies of state needed | Exponentially many | Polynomially many |\n",
        "| Accuracy | High | Low |\n",
        "| Applications | Reconstructing the complete state vector or density matrix | Reconstructing a specific aspect of the state |\n",
        "\n",
        "Here are some examples of when shadow tomography can be used:\n",
        "\n",
        "* To reconstruct the behavior of a quantum state on a specific set of operations.\n",
        "* To reconstruct the entanglement of a quantum state.\n",
        "* To reconstruct the purity of a quantum state.\n",
        "\n",
        "***Shadow tomography is a promising new technique for reconstructing quantum states with fewer copies of the state. As quantum technologies develop, shadow tomography is likely to become an increasingly important tool for understanding and manipulating quantum states.***\n"
      ],
      "metadata": {
        "id": "5SNoHHqcj0-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is the difference of shadow tomography and state tomography to process tomography?**\n",
        "\n",
        "\n",
        "The main difference between shadow tomography, state tomography, and process tomography is the object that is being reconstructed.\n",
        "\n",
        "* **State tomography** reconstructs the state of a quantum system. This can be done by measuring the system in a complete set of bases and using the results to reconstruct the state vector or density matrix of the system.\n",
        "* **Shadow tomography** reconstructs a classical shadow of a quantum state. A classical shadow is a lower-dimensional representation of the quantum state that still retains some of its key properties.\n",
        "* **Process tomography** reconstructs the quantum process that transforms one quantum state into another. This can be done by preparing an ensemble of quantum states and sending them through the process, then using state tomography to identify the resultant states.\n",
        "\n",
        "In terms of the number of copies of the quantum system needed, shadow tomography and process tomography are both more efficient than state tomography. Shadow tomography can reconstruct a classical shadow of a quantum state with only polynomially many copies of the state, while process tomography can reconstruct a quantum process with only exponentially many copies of the state.\n",
        "\n",
        "However, shadow tomography and process tomography are less accurate than state tomography. The classical shadow of a quantum state may not be able to perfectly represent the quantum state, and the reconstructed quantum process may not be perfectly accurate.\n",
        "\n",
        "Here is a table summarizing the key differences between shadow tomography, state tomography, and process tomography:\n",
        "\n",
        "| Feature | Shadow tomography | State tomography | Process tomography |\n",
        "|---|---|---|---|\n",
        "| Object being reconstructed | Classical shadow of a quantum state | State vector or density matrix of a quantum state | Quantum process that transforms one quantum state into another |\n",
        "| Number of copies of quantum system needed | Polynomially many | Exponentially many | Exponentially many |\n",
        "| Accuracy | Low | High | Low |\n",
        "| Applications | Reconstructing specific aspects of a quantum state | Reconstructing the complete state of a quantum state | Reconstructing the behavior of a quantum process |\n",
        "\n",
        "I hope this helps! Let me know if you have any other questions."
      ],
      "metadata": {
        "id": "752lwZmzkuel"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*What is shadow tomography and how is it used in this context?*\n",
        "\n",
        "* Shadow tomography is a technique that assumes access to multiple copies of a quantum state and uses a hypothesis state model, often stored classically, to require a minimal number of destructive measurements.\n",
        "\n",
        "* In the context of quantum neural network training, recent developments in shadow tomography have challenged the notion that quantum measurement collapse entirely rules out the reuse of quantum information as in backpropagation.\n",
        "\n",
        "* By assuming access to multiple copies of a quantum state, a modification of existing shadow tomography routines enables backpropagation scaling if one restricts costs to the quantum overhead and ignores the classical cost incurred to implement known shadow tomography schemes.\n",
        "\n",
        "*What is shadow tomography and how is it used in the context of quantum computing?*\n",
        "\n",
        "* Shadow tomography, in the context of quantum computing, is a technique used to characterize an unknown quantum state by gathering statistical information about its measurement outcomes. It is an approach that aims to reconstruct the quantum state without directly accessing it.\n",
        "\n",
        "* In quantum computing, qubits represent the fundamental units of information and are typically manipulated in superposition states. However, obtaining complete knowledge about the quantum state of a qubit is challenging due to limitations such as noise, decoherence, and the no-cloning theorem. Shadow tomography offers a way to infer information about the state without requiring full access to it.\n",
        "\n",
        "* The technique involves performing a series of measurements on a large number of identically prepared quantum systems in the same unknown state. Each measurement provides partial information about the state, revealing statistical probabilities for the different measurement outcomes. By gathering a sufficiently large set of measurement statistics, it becomes possible to infer the likely quantum state.\n",
        "\n",
        "* The reconstruction of the quantum state from the collected statistics is achieved through mathematical techniques, such as maximum likelihood estimation or compressed sensing algorithms. These methods leverage the statistical patterns observed in the measurement outcomes to estimate the underlying quantum state that generated them.\n",
        "\n",
        "* Shadow tomography provides a means to characterize unknown quantum states in a non-invasive manner, making it particularly useful for quantum systems that are difficult or impossible to access directly. It plays a crucial role in quantum information processing tasks such as quantum error correction, state verification, and characterizing the performance of quantum devices.\n",
        "\n",
        "\n",
        "*What is gentle measurement in the context of quantum computing?*\n",
        "\n",
        "* Gentle measurement techniques often employ strategies such as weak measurements, quantum non-demolition measurements, or adaptive measurements.\n",
        "\n",
        "* Weak measurements involve extracting partial information about the system while causing minimal disturbance.\n",
        "\n",
        "* Quantum non-demolition measurements are designed to measure one property of the system without affecting other compatible observables.\n",
        "\n",
        "* Adaptive measurements dynamically adjust the measurement strategy based on the intermediate measurement results to minimize disturbance.\n",
        "\n",
        "* By using gentle measurement techniques, researchers can gather information about quantum states while preserving their fragile nature. This is particularly important in quantum computing, where maintaining the coherence of quantum bits (qubits) is crucial for performing reliable computations and preventing errors."
      ],
      "metadata": {
        "id": "BkjNfD00kURa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**quantum state tomography**, and it is already an important task in experimental physics. To give some examples, tomography has been used to obtain a detailed picture of a chemical reaction (namely, the dissociation of I2 molecules) [29]; to confirm the preparation of three-photon [28] and eight-ion [20] entangled states; to test controlled-NOT gates [26]; and to characterize optical devices [15].\n",
        "Physicists would like to scale up tomography to larger systems, in order to study the many-particle entangled states that arise (for example) in chemistry, condensed-matter physics, and quantum information. But there is a fundamental obstacle in doing so. This is that, to reconstruct an n-qubit state, one needs to measure a number of observables that grows exponentially in n: in particular like 4^n, the number of parameters in a 2^n × 2^n density matrix. This exponentiality is certainly a practical problem—Ha ̈ffner et al. [20] report that, to reconstruct an entangled state of eight calcium ions, they needed to perform 656, 100 experiments! But to us it is a theoretical problem as well. For it suggests that learning an arbitrary state of (say) a thousand particles would take longer than the age of the universe, even for a being with unlimited computational power.\n",
        "Source: The Learnability of Quantum States"
      ],
      "metadata": {
        "id": "XfBOiHzuNSrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "quantum shadow tomography, which gives a way of predicting the values of most quantum observables using a small number of samples from a quantum system.\n",
        "\n",
        "Aaronson S 2018 Shadow tomography of quantum states Proc. of the 50th Annual ACM SIGACT Symp. on Theory of Computing\n",
        "pp 325–38"
      ],
      "metadata": {
        "id": "Aq23Xx1H2aaj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/1711.01053"
      ],
      "metadata": {
        "id": "-AzCvKg-59TN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ***Sample complexity of quantum state tomography (e.g. shadow tomography) important for difference between coherent and incoherent measurements***\n"
      ],
      "metadata": {
        "id": "2tcJVkBR9ZB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is the shadow tomography problem in quantum information theory?**\n",
        "\n",
        "In quantum information theory, the shadow tomography problem refers to the task of characterizing an unknown quantum state by gathering statistical information about its measurement outcomes. It addresses the challenge of reconstructing a quantum state without directly accessing it.\n",
        "\n",
        "The shadow tomography problem arises due to the limitations of directly measuring quantum states. In quantum systems, the act of measurement can disturb the system and potentially cause the collapse of its quantum state. Additionally, some quantum states may be inaccessible or difficult to measure directly due to experimental constraints or limitations.\n",
        "\n",
        "To overcome these challenges, shadow tomography offers a non-invasive approach to infer information about the unknown quantum state. Instead of directly measuring the state, it focuses on collecting statistical data by repeatedly measuring identically prepared copies of the state and recording the outcomes.\n",
        "\n",
        "The goal of the shadow tomography problem is to use the collected statistical data to reconstruct an estimate of the quantum state that is consistent with the observed measurement outcomes. This estimation process involves mathematical techniques such as maximum likelihood estimation, compressed sensing, or machine learning algorithms.\n",
        "\n",
        "Solving the shadow tomography problem is important in various quantum information tasks, including quantum state verification, characterization of quantum devices, and quantum error correction. By obtaining accurate reconstructions of unknown quantum states, researchers can gain insights into the properties of quantum systems and develop techniques to mitigate errors and improve quantum information processing tasks.\n",
        "\n",
        "**what is the exponential classical cost within the shadow tomography problem?**\n",
        "\n",
        "The term \"exponential classical cost\" in the context of the shadow tomography problem refers to the computational complexity associated with classical methods of characterizing or reconstructing an unknown quantum state. It signifies that the amount of computational resources required grows exponentially with the size of the quantum system.\n",
        "\n",
        "In shadow tomography, the goal is to estimate the quantum state by collecting measurement statistics. The challenge lies in finding an efficient algorithm to reconstruct the state from this statistical data. Classical methods typically involve searching through a large space of possible quantum states and optimizing a likelihood function or another measure of agreement with the observed statistics.\n",
        "\n",
        "However, for large quantum systems, the number of possible quantum states grows exponentially with the number of qubits. As a result, exhaustive classical methods that explore the entire state space become computationally infeasible as the system size increases. This exponential growth in the number of possible states leads to an exponential increase in the computational cost required for reconstruction.\n",
        "\n",
        "The exponential classical cost in shadow tomography highlights the need for alternative approaches, such as leveraging quantum computers or developing more efficient reconstruction algorithms. Quantum computers can potentially provide speedup by harnessing the principles of quantum mechanics, allowing for more efficient exploration of the state space or utilizing specialized quantum algorithms tailored for state reconstruction.\n",
        "\n",
        "Reducing the classical cost of shadow tomography is an active area of research, and various techniques, including compressed sensing, machine learning, and adaptive measurement strategies, have been explored to mitigate the computational challenges associated with large-scale quantum systems."
      ],
      "metadata": {
        "id": "8QKE7d8OvYR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is meant by incoherent and coherent measurements in sample complexity (for shadow tomography)?**\n",
        "\n",
        "In the context of quantum computing and quantum information theory, coherent and incoherent measurements refer to two different types of quantum measurements.\n",
        "\n",
        "1. **Coherent measurements**: These are the idealized measurements usually described in basic quantum mechanics where measuring a quantum state immediately collapses it into one of the eigenstates of the measured observable. Coherent measurements are unitary and reversible.\n",
        "\n",
        "2. **Incoherent measurements**: These measurements, on the other hand, correspond to a more generalized form of measurement, described by a set of positive-operator valued measures (POVMs). POVMs need not be unitary or reversible, and they can model a broader range of real-world measurement processes, including those where the quantum system interacts with an environment and decoheres.\n",
        "\n",
        "> The difference between coherent and incoherent measurements can become ***important when we consider the sample complexity of quantum state tomography, or in your specific case, shadow tomography.***\n",
        "\n",
        "Quantum state tomography is the process of determining the unknown state of a quantum system from the outcomes of measurements made on the system. The sample complexity of this process refers to the number of measurements needed to accurately reconstruct the quantum state.\n",
        "\n",
        "When performing quantum state tomography, incoherent measurements can sometimes offer advantages in terms of reduced sample complexity, since they can provide more information per measurement about the state of the system. However, they may also be more technically challenging to implement than coherent measurements, and they may introduce additional sources of error.\n",
        "\n",
        "The concept of \"shadow tomography\" you're referring to might involve using a small number of random measurements (or \"shadows\") to estimate properties of the quantum state, and it might have different sample complexity depending on whether coherent or incoherent measurements are used. The detailed analysis of this would depend on the specific shadow tomography protocol and the properties of the quantum state and the measurement process.\n"
      ],
      "metadata": {
        "id": "5923WPqg8sS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://en.wikipedia.org/wiki/Quantum_tomography\n",
        "\n",
        "https://en.wikipedia.org/wiki/Classical_shadow\n",
        "\n",
        "Scott Aaronson: Shadow Tomography https://arxiv.org/abs/1711.01053\n",
        "\n",
        "https://www.spektrum.de/news/quantennetzwerke-zeigen-schwarmintelligenz/2116689"
      ],
      "metadata": {
        "id": "ZstkVSpb2UOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shadow tomography, also known as X-ray phase-contrast imaging or phase tomography, is a technique used to create detailed three-dimensional images of an object's internal structure. It is primarily employed in the field of medical imaging but also finds applications in materials science and other areas.\n",
        "\n",
        "Traditional X-ray imaging relies on the attenuation of X-rays as they pass through different tissues or materials, resulting in a two-dimensional projection image that shows variations in X-ray absorption. However, some tissues or materials have similar absorption properties, making it challenging to distinguish between them based solely on their attenuation.\n",
        "\n",
        "Shadow tomography overcomes this limitation by exploiting the phase shift of X-rays as they pass through an object. When X-rays encounter a boundary between two materials with different refractive indices, they undergo a phase shift. This phase shift contains valuable information about the object's internal structure.\n",
        "\n",
        "To perform shadow tomography, a coherent X-ray source, such as a synchrotron or an X-ray tube, is used. The X-rays pass through the object and are collected by a detector placed behind it. The collected X-rays contain both intensity and phase information.\n",
        "\n",
        "The key to shadow tomography lies in extracting the phase information from the intensity measurements. This is typically achieved by using specialized techniques such as interferometry or grating-based methods. These methods create interference patterns that encode the phase information, which can then be computationally reconstructed into a three-dimensional image.\n",
        "\n",
        "The resulting shadow tomography image provides not only information about the X-ray absorption but also about the object's refractive index distribution and other structural features. This enables visualization of fine details, such as boundaries between tissues or subtle density variations, which may not be easily distinguishable in traditional X-ray images.\n",
        "\n",
        "Shadow tomography has the potential to improve diagnostic accuracy and enhance our understanding of complex biological and materials systems. However, it currently requires advanced X-ray sources and specialized techniques, limiting its widespread availability in clinical settings. Nevertheless, ongoing research and technological advancements aim to make shadow tomography more accessible and applicable in various fields."
      ],
      "metadata": {
        "id": "iMNjAZqA5-s_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apologies for the confusion in my previous response. Shadow tomography can indeed be related to the characterization of quantum states, often referred to as \"quantum state tomography.\"\n",
        "\n",
        "In quantum mechanics, the state of a quantum system is described by a mathematical object known as a quantum state. Quantum state tomography aims to reconstruct or characterize the complete quantum state of a system by performing measurements on the system in different bases or using various observables.\n",
        "\n",
        "Shadow tomography of quantum states is a specific technique used for quantum state reconstruction. It involves measuring the shadows or projections of the quantum state onto a set of measurement operators or observables. These measurements provide partial information about the quantum state, similar to the way shadows reveal information about the object casting them.\n",
        "\n",
        "The procedure for shadow tomography of quantum states typically involves preparing the system in different known initial states, applying a set of measurements or observables to the system, and then collecting the measurement outcomes. By repeating this process for a sufficiently large number of initial states and measurements, it becomes possible to reconstruct the complete quantum state of the system through computational methods.\n",
        "\n",
        "The reconstructed quantum state provides valuable information about the system's properties, such as its purity, entanglement, coherence, and other relevant characteristics. This information is crucial for understanding and characterizing quantum systems, as well as for verifying the performance of quantum devices and protocols.\n",
        "\n",
        "Quantum state tomography, including shadow tomography, plays a vital role in the development, verification, and optimization of quantum algorithms, quantum error correction, quantum communication, and other applications of quantum information science.\n",
        "\n",
        "It's important to note that quantum state tomography can be a challenging task due to various factors, such as noise, imperfections in measurements, and the exponential growth of the state space with the number of quantum bits (qubits). Researchers continually work on improving the efficiency and accuracy of quantum state tomography techniques to overcome these challenges."
      ],
      "metadata": {
        "id": "bI5xQd9s6Atw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Quantum Process Tomography*"
      ],
      "metadata": {
        "id": "dgxniphi11W3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/quant-ph/0702131"
      ],
      "metadata": {
        "id": "vrfRDNCp18Bt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum Tomography?**\n",
        "\n",
        "Quantum tomography is an experimental procedure to reconstruct a description of part of quantum system from the measurement outcomes of a specific set of experiments. In Qiskit we implement the following types of tomography:\n",
        "\n",
        "**Quantum state tomography**: Given a state-preparation circuit that prepares a system in a state, reconstruct a description of the density matrix 𝜌\n",
        " of the actual state obtained in the system.\n",
        "\n",
        "**Quantum process tomography**: Given a circuit, reconstruct a description of the quantum channel \n",
        " that describes the circuit’s operator when running on the system.\n",
        "\n",
        "**Quantum gate set tomography**: Performs process tomography on a set of gates in a self-consistent manner, meaning quantum noises on gates used by the tomography process itself is also taken into account.\n",
        "\n",
        "This notebook gives examples for how to use the ignis.verification.tomography modules.\n",
        "\n",
        "Quantum tomography refers to a suite of techniques used in quantum computing and quantum information theory to reconstruct a description of a part of a quantum system based on measurement data. The word \"tomography\" comes from medical imaging, where it's used to denote techniques that build a 3D image of an object from 2D slices.\n",
        "\n",
        "In quantum mechanics, there are two main types of tomography: state tomography and process tomography.\n",
        "\n",
        "1. **Quantum State Tomography**: This is a method used to determine the quantum state of a system. The goal is to construct the density matrix that represents the state of the system. This is done by making a series of measurements on identically prepared quantum systems and using the statistical results of these measurements to reconstruct the state. State tomography is a challenging problem in general, as the number of parameters to be estimated grows exponentially with the number of qubits.\n",
        "\n",
        "2. **Quantum Process Tomography**: This extends the concept of state tomography to quantum operations or processes. The goal here is to determine the quantum operation that a particular quantum system implements. In other words, given access to a quantum process (which could be a quantum gate, a sequence of quantum gates, or a quantum channel), the task is to identify the corresponding quantum map. This is done by preparing a set of input states, applying the process, and performing state tomography on the outputs. The data are then used to reconstruct the process matrix or Choi matrix, which fully describes the quantum operation. Again, process tomography is also a challenging problem, as the number of parameters to be estimated grows rapidly with the number of qubits.\n",
        "\n",
        "Quantum tomography is a fundamental tool for quantum characterization, verification, and validation, which are crucial tasks in quantum computing and quantum information processing. However, due to the complexity of these tasks, research is being conducted into more efficient methods, such as compressed sensing and other methods based on assumptions about the structure of the states or processes being measured.\n",
        "\n",
        "Qiskit:\n",
        "\n",
        "https://qiskit.org/documentation/stable/0.26/tutorials/noise/8_tomography.html\n",
        "\n",
        "https://qiskit.org/documentation/tutorials/simulators/2_device_noise_simulation.html\n",
        "\n",
        "[How do I change the fitter algorithm in a state tomography experiment? - 1 Minute Qiskit](https://www.youtube.com/watch?v=MsENB0n4Ac8)"
      ],
      "metadata": {
        "id": "OaOjrY5x5Cfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Choi matrix = Process Matrix, which fully describes the quantum operation**\n",
        "\n",
        "The data are then used to reconstruct the process matrix or Choi matrix, which fully describes the quantum operation\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Choi%27s_theorem_on_completely_positive_maps\n",
        "\n",
        "Quantum tomography refers to a suite of techniques used in quantum computing and quantum information theory to reconstruct a description of a part of a quantum system based on measurement data. The word \"tomography\" comes from medical imaging, where it's used to denote techniques that build a 3D image of an object from 2D slices.\n",
        "\n",
        "In quantum mechanics, there are two main types of tomography: state tomography and process tomography.\n",
        "\n",
        "1. **Quantum State Tomography**: This is a method used to determine the quantum state of a system. The goal is to construct the density matrix that represents the state of the system. This is done by making a series of measurements on identically prepared quantum systems and using the statistical results of these measurements to reconstruct the state. State tomography is a challenging problem in general, as the number of parameters to be estimated grows exponentially with the number of qubits.\n",
        "\n",
        "2. **Quantum Process Tomography**: This extends the concept of state tomography to quantum operations or processes. The goal here is to determine the quantum operation that a particular quantum system implements. In other words, given access to a quantum process (which could be a quantum gate, a sequence of quantum gates, or a quantum channel), the task is to identify the corresponding quantum map. This is done by preparing a set of input states, applying the process, and performing state tomography on the outputs. The data are then used to reconstruct the process matrix or Choi matrix, which fully describes the quantum operation. Again, process tomography is also a challenging problem, as the number of parameters to be estimated grows rapidly with the number of qubits.\n",
        "\n",
        "Quantum tomography is a fundamental tool for quantum characterization, verification, and validation, which are crucial tasks in quantum computing and quantum information processing. However, due to the complexity of these tasks, research is being conducted into more efficient methods, such as compressed sensing and other methods based on assumptions about the structure of the states or processes being measured."
      ],
      "metadata": {
        "id": "fVcxQqimzDiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is a quantum state tomography?**\n",
        "\n",
        "Quantum state tomography is the process of determining the state of a quantum system based on the results of measurements. In essence, it's a method used to figure out the unknown quantum state of a system. It's called \"tomography\" because, like a CT scan in medicine, it combines many different measurements to construct a full picture of something you can't directly observe in one shot.\n",
        "\n",
        "For a quantum system, the state is typically represented by a density matrix. In the simplest case, for a single qubit, the density matrix is a 2x2 Hermitian matrix that is positive semi-definite and has trace 1. The generalization to multiple qubits is a matrix that is 2^n x 2^n (where n is the number of qubits), but with the same properties.\n",
        "\n",
        "Quantum state tomography involves making various measurements on many identically-prepared copies of the quantum system and then using the results to reconstruct the density matrix. The measurements you make are usually in different bases. For a single qubit, measurements are often made in the X, Y, and Z bases, which correspond to the Pauli matrices.\n",
        "\n",
        "However, as the number of qubits increases, the number of measurements you need to make grows exponentially, which makes full quantum state tomography unfeasible for large systems. For a system of n qubits, the density matrix contains 4^n - 1 independent real parameters, which is why the number of measurements needed increases so rapidly.\n",
        "\n",
        "Therefore, in practice, people use other methods to get partial information about the state or use assumptions to reduce the number of necessary measurements. There are also methods that attempt to directly estimate quantities of interest, like the expectation value of an observable, without fully reconstructing the state."
      ],
      "metadata": {
        "id": "-Bv3caiQuGsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what are these alternative methods to quantum state tomography?**\n",
        "\n",
        "Indeed, full quantum state tomography is often impractical due to the exponential number of measurements required as the number of qubits increases. Here are some alternative methods that are commonly used in practice:\n",
        "\n",
        "1. **Quantum Process Tomography**: Instead of trying to determine the state of a quantum system, quantum process tomography aims to determine the quantum operation or quantum channel that describes a quantum process. This can be more practical in many experimental scenarios where you're more interested in characterizing a quantum gate or a quantum circuit.\n",
        "\n",
        "2. **Direct Estimation of Expectation Values**: Rather than attempting to reconstruct the full quantum state, you can directly estimate the expectation value of a specific observable by making many measurements in the basis corresponding to that observable and averaging the results.\n",
        "\n",
        "3. **Quantum State Estimation**: Quantum state estimation techniques use a set of projective measurements to estimate the state of a quantum system. This is similar to quantum state tomography, but instead of trying to reconstruct the full state, it only attempts to estimate it based on the results of projective measurements.\n",
        "\n",
        "4. **Quantum Compressed Sensing**: Compressed sensing is a method that uses the sparsity of a state in a certain basis to reduce the number of measurements required. It has been applied in the context of quantum state tomography, especially for states that are known to be sparse in a certain basis.\n",
        "\n",
        "5. **Machine Learning Techniques**: Machine learning methods, including neural networks and other techniques, have been increasingly used for quantum state tomography and characterization. These methods can often handle higher-dimensional data and can help reduce the number of measurements required.\n",
        "\n",
        "6. **Randomized Benchmarking**: This is a method for characterizing the performance of quantum gates by applying sequences of random gates followed by their inverse and seeing how often the system returns to the initial state.\n",
        "\n",
        "Remember, the choice of method depends on the specific task, the number of qubits, and the resources available. Each method has its strengths and limitations and might be suited to different experimental setups or goals.\n",
        "\n"
      ],
      "metadata": {
        "id": "AcHLAsw4uvoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Block Encoding**\n",
        "\n",
        "Block encoding is the framework or tool for developing a variety of quantum algorithms by encoding a matrix as a block of a unitary.There are various ways to implement the same as per requirement,one of the ways is by decomposing the matrices into linear combinations of displacement matrices.\n",
        "\n",
        "\n",
        "block encodings (unitary, signal proicesing, transformation)\n",
        "\n",
        "https://quantumcomputing.stackexchange.com/questions/18236/block-encoding-technique-what-is-it-and-what-is-it-used-for"
      ],
      "metadata": {
        "id": "v1ou698c0kn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block Encoding (Gibbs-Sampling)"
      ],
      "metadata": {
        "id": "A5mYvARiUf-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/1806.01838\n",
        "\n",
        "Quantum singular value transformation and beyond"
      ],
      "metadata": {
        "id": "GYNleGbzLh_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "aaronson"
      ],
      "metadata": {
        "id": "Y86Jw3gfSQg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/2203.10236"
      ],
      "metadata": {
        "id": "fA9_AEsAIPhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://de.wikipedia.org/wiki/Gibbs-Sampling"
      ],
      "metadata": {
        "id": "Sd2SdVyZPSrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block encoding is the framework or tool for developing a variety of quantum algorithms by encoding a matrix as a block of a unitary.There are various ways to implement the same as per requirement,one of the ways is by decomposing the matrices into linear combinations of displacement matrices.\n",
        "\n",
        "Arxiv: [Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics](https://arxiv.org/abs/1806.01838)\n",
        "\n",
        "In HHL f(x) = 1/x. Use Singular Value Transformation to approximate it! https://www.youtube.com/watch?v=L40UUDxPEbE&list=WL&index=3&t=215s\n",
        "\n",
        "https://quantumcomputing.stackexchange.com/questions/18197/in-the-context-of-block-encoding-what-does-0-rangle-otimes-i-represent\n",
        "\n",
        "https://quantumcomputing.stackexchange.com/questions/18236/block-encoding-technique-what-is-it-and-what-is-it-used-for"
      ],
      "metadata": {
        "id": "7XFH8tKPLEJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*(2021) Quantum **Krylov subspace** algorithms for ground and excited state energy estimation*"
      ],
      "metadata": {
        "id": "Drnam8uix3L6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/2109.06868"
      ],
      "metadata": {
        "id": "AE6k5L9fRiXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://en.m.wikipedia.org/wiki/Krylov_subspace\n",
        "\n",
        "\n",
        "https://quantum-journal.org/papers/q-2023-05-23-1018/\n",
        "\n",
        "We present an algorithm that uses block encoding on a quantum computer to exactly construct a Krylov space, which can be used as the basis for the Lanczos method to estimate extremal eigenvalues of Hamiltonians. While the classical Lanczos method has exponential cost in the system size to represent the Krylov states for quantum systems, our efficient quantum algorithm achieves this in polynomial time and memory. The construction presented is exact in the sense that the resulting Krylov space is identical to that of the Lanczos method, so the only approximation with respect to the exact method is due to finite sample noise. This is possible because, unlike previous quantum Krylov methods, our algorithm does not require simulating real or imaginary time evolution. We provide an explicit error bound for the resulting ground state energy estimate in the presence of noise.\n",
        "\n",
        "https://medium.com/qiskit/a-mainstay-of-classical-ground-state-algorithms-gets-a-quantum-speedup-8003687dbb0d"
      ],
      "metadata": {
        "id": "z_W9d3IIx7NI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Resource Estimation for Quantum Algorithms*"
      ],
      "metadata": {
        "id": "y7r0yPBYKf60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [Roy J. Garcia | Nov. 15, 2022 | Resource theory of quantum scrambling](https://www.youtube.com/watch?v=pikuMFTDEbI&list=PLBn8lN0DcvpmcGQ1H_9YMFPew1ZsP_8Sj&index=11&t=25s)\n",
        "\n",
        "Video: [Quantum computing use cases for the pharma industry [QCT21/22, Seminar #5]](https://www.youtube.com/watch?v=CkzazWRCdWw&list=WL&index=37&t=2074s)"
      ],
      "metadata": {
        "id": "Q6eTdz4sX4Ul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "https://www.handelsblatt.com/audio/disrupt-podcast/drei-experten-drei-perspektiven-wann-werden-quantencomputer-endlich-realitaet/29571162.html\n",
        "\n",
        "https://spectrum.ieee.org/quantum-computing-skeptics\n",
        "\n",
        "https://ap-verlag.de/welchen-entwicklungsstand-hat-das-quantencomputing-erreicht/85623/\n",
        "\n",
        "https://www.riskcompliance.de/news/wie-veraendert-quantencomputing-das-banking/"
      ],
      "metadata": {
        "id": "ys8hKh3l2Va_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://quantumcomputing.stackexchange.com/questions/21518/review-paper-on-depth-qubits-and-t-gates-number-on-cliffordt-decomposition-f"
      ],
      "metadata": {
        "id": "2UOmCkkoKjJ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from Table 1 in arxiv.org/abs/2012.03819, pricing commonly used non-trivial options (autocallables and TARFs) using Monte Carlo simulations on a quantum computer takes ~10 billion gates\n",
        "\n",
        "https://arxiv.org/abs/2012.03819: A Threshold for Quantum Advantage in Derivative Pricing\n",
        "\n"
      ],
      "metadata": {
        "id": "M_o9NPECNoQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Classical Emulation of Quantum Algorithms*"
      ],
      "metadata": {
        "id": "5LYWuYGRUVyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Physicists 'entangle' individual molecules for the first time, hastening possibilities for quantum computing\n",
        "\n",
        "https://phys-org.cdn.ampproject.org/c/s/phys.org/news/2023-12-physicists-entangle-individual-molecules-hastening.amp"
      ],
      "metadata": {
        "id": "9c4M19VFLhKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What if quantum computers were not about getting faster results, but better results?\n",
        "\n",
        "This could be the case in optimization problems.\n",
        "\n",
        "Because when optimization problems become big enough, finding THE best answer is usually not practically achievable.\n",
        "\n",
        "The goal of optimization algorithms is therefore to get as close as possible to the best answer, but they usually only output a \"local optimum\", not the \"global optimum\".\n",
        "\n",
        "👉 So, if a quantum computer takes longer but finds a better optimum, this is a new form of quantum advantage, right?\n",
        "\n",
        "Well... yes and no.\n",
        "\n",
        "The thing is that you can emulate the behavior of a quantum computer with a classical computer. Even better, unlike real quantum computers, emulators running on classical computers aren't bothered by noise, so they tend to produce better results.\n",
        "\n",
        "This means that if you have a quantum algorithm whose main benefit is \"it finds better solutions\", then you also have a classical algorithm which does that.\n",
        "\n",
        "Just use your classical computer to run your quantum algorithm on an emulator and you're good!\n",
        "\n",
        "👉 So, why bother with real quantum computers?\n",
        "\n",
        "The problem of emulation is that the memory requirements grow exponentially with the number of qubits you want to emulate.\n",
        "\n",
        "Emulating a handful of qubits can be done on a sheet of paper.\n",
        "\n",
        "Emulating 40 qubits requires terabytes of memory.\n",
        "\n",
        "Emulating 100 qubits requires more than the combined storage capacity of all devices on Earth.\n",
        "\n",
        "This memory problem can be easily converted into a computing time problem. Need the coefficient of a given state? Don't get it from the memory, just recompute it.\n",
        "\n",
        "But then your computing time is the one that grows exponentially out of hand.\n",
        "\n",
        "At the end of the day, a classical computer is theoretically able to find results just as good as those found by a quantum computer. Possibly even better, if you consider that classical computers are not bothered by noise.\n",
        "\n",
        "But it would just take too much time.\n",
        "\n",
        "So, is it \"better results\" or \"faster results\"? To me, this really looks like two faces of the same coin!"
      ],
      "metadata": {
        "id": "HhE6VY_TUde-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fourier is all you need**: positional and number encoding using periodic signals\n",
        "\n",
        "I just realized during a conversation with Vanio Markov the similarity between the sinusoidal position encoding in the transformer architecture and what we’ve been calling “value encoding” in quantum computing. This concept was the main idea in encoding a (polynomial) function in a quantum state (inspired by phase estimation), used for optimization purposes (and contributed to Qiskit): https://lnkd.in/ea7QU77\n",
        "\n",
        "The “Attention is all you neeed” paper (https://lnkd.in/gP-y4xUE ) explains the positional encoding, but other references, like the one below, may be more accessible.\n",
        "\n",
        "https://sair.synerise.com/fourier-feature-encoding/\n",
        "\n",
        "This is a video showing frequency/value encoding for various frequencies: https://github.com/QuState/cqc_code/blob/master/videos/three_qubit_frequency_encoding.mp4 . The interactive tool also shows both the complex sinusoid (geometric sequence)  for a frequency and its  Fourier transform."
      ],
      "metadata": {
        "id": "vCRgH1q0bWlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Encoding (Embedding)\n",
        "\n",
        "**Quantum computers are Kernel methods** of a very specific kind: https://www.youtube.com/watch?v=pe1d0RyCNxY&t=2655s\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1406.png)\n",
        "\n",
        "https://arxiv.org/abs/2001.03622 - Quantum embeddings for machine learning\n",
        "\n",
        "\n",
        "**Data Encoding is the most important!**\n",
        "\n",
        "https://youtu.be/pe1d0RyCNxY?t=3008\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1407.png)\n",
        "\n",
        "The Helstrom measurement is the measurement that has the minimum error probability when trying to distinguish between two states.05.09.2018\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Quantum_state_discrimination\n",
        "\n",
        "After we embedded / encoded our data, and if we encode it in a way that it separates one data type from another in the hilbert space, we already know which measurement is the best one to do. We know quite a bit about the measurements to distinguish data. **Maybe after encoding the data, we are already done**. We could even train the encoding!\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1410.png)\n",
        "\n",
        "\n",
        "https://arxiv.org/abs/2001.03622 - Quantum embeddings for machine learning\n",
        "\n"
      ],
      "metadata": {
        "id": "zkMaiR5lbWlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **The easiest way for a parameter to enter a circuit is through a rotation of a single qubit, in proportion to the value of a single datapoint, so a single scalar value:**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_190.png)\n",
        "\n",
        "> **You can also use a sequence of rotations to embedd data (reuploding).** And maybe there is free parameters in between as well. Can make a more complex function available than if you upload only once in a single rotation.\n",
        "\n",
        "> **Learnable embeddings**: The other idea is to actually have a trainable embedding layer. Not to worry about training the unitary of the circuit, but worry about training the embedding and then use standard quantum information metrics to classify the data.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_191.png)"
      ],
      "metadata": {
        "id": "Ihzo1PqRbWlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basis (State) Encoding**\n",
        "\n",
        "* We gave data points x12 and x2\n",
        "\n",
        "* We first need to represent data in binary form, like 00 and 10\n",
        "\n",
        "* Then we encode it into a QC in a way, such that we have basis states that represents them like |00> and |10>\n",
        "\n",
        "* with all other basis states having probability zero - represented in the amplitude vector\n",
        "\n",
        "* So we encode data in quantum state that is aligned with basis states\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_856.png)"
      ],
      "metadata": {
        "id": "b3wxbJoKbWlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Amplitude Encoding**\n",
        "\n",
        "* we want to encode our classical information into an amplitude vector\n",
        "\n",
        "* you have a classical data vector with 4 entries (features) x1\n",
        "\n",
        "* now construct a circuit, so that we have an amplitude vector that corresponds to the values in the classical data vector:\n",
        "\n",
        "\t* we have 2 qubits initialized in the ground state\n",
        "\n",
        "\t* then we apply some operations U (x1) on these qubits\n",
        "\n",
        "\t* and then we get a quantum state that corresponds to an amplitude vector that exactly represents our classical data points\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_857.png)"
      ],
      "metadata": {
        "id": "-DivshtbbWlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Angle Encoding**\n",
        "\n",
        "* we have 2 dimension data that we can write in a two dimensional vector\n",
        "\n",
        "* then I take the number of qubits equal to the number of features (rows / entries in a classical vector)\n",
        "\n",
        "* then I apply rotations to each of these qubits that are equal to the value of the features\n",
        "\n",
        "\t* for example I rotate the first qubit about some axis Z. The rotation value / rotation angle is equal to the first classical feature value\n",
        "\n",
        "\t* the I take my second qubit and rotate it, for example again by the Z axis, and the angle of the rotation is equal to the second feature value of my data point\n",
        "\n",
        "* for higher dimensional data, for example a third dimension classical vector, then I simply add more qubits to my system to encode this information\n",
        "\n",
        "* For example:  [z feature map (Qiskit)](https://qiskit.org/documentation/stubs/qiskit.circuit.library.ZFeatureMap.html#qiskit.circuit.library.ZFeatureMap):\n",
        "\t* apply Hadamard operator first to each of the qubits, and then encode data values in rotations\n",
        "\t* and then repeat this as many times as you want (stacking operations sequentially like in the image) to encode data multpiple times in a row\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_858.png)"
      ],
      "metadata": {
        "id": "qQF73onwbWlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Higher Order Encoding**\n",
        "\n",
        "* there is no theoretical reason why doing this or if it's better or not\n",
        "\n",
        "* the idea comes from the paper [Supervised learning with quantum enhanced feature spaces](https://arxiv.org/abs/1804.11326)\n",
        "\n",
        "* Basic idea: let's do an encoding that is hard to reproduce classically and simulate, and then maybe we get some quantum advantage in doing this\n",
        "\n",
        "* we have some two dimensional data with a vector with 2 entries\n",
        "\n",
        "\t* choose number of qubits = number of feature values\n",
        "\n",
        "\t* then apply an hadarmard on each qubit\n",
        "\n",
        "\t* and then do rotations about some axis Z, and the first angle is the first feature value, and the same with the second qubit\n",
        "\n",
        "\t* and then we apply some entanglement gates between these qubits\n",
        "\n",
        "\t* then we do another rotation (for example again Z axis), but this rotation angle depends on some function of the product of the feature values R(x^1 * x^2)\n",
        "\n",
        "\t* this is where the name comes from: we encode in a higher order product space\n",
        "\n",
        "\t* and this whole block of this encoding can be repeated, which is called the depth of the feature maps\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_860.png)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_861.png)"
      ],
      "metadata": {
        "id": "y02BnicBbWlJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Other Encodings**\n",
        "\n",
        "* Hamiltonian evolution ansatz encoding\n",
        "\n",
        "* Displacement Encoding\n",
        "\n",
        "* IQP Encoding (Instantaneous quantum polynomial)\n",
        "\n",
        "* Squeezing Encoding\n",
        "\n",
        "* QAOA Encoding"
      ],
      "metadata": {
        "id": "5pjrMx1KbWlJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ***Mathematical Formulation & Postulates of Quantum Mechanics***"
      ],
      "metadata": {
        "id": "iptu2LVks6If"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1698.jpg)"
      ],
      "metadata": {
        "id": "Hbmeml_TU5Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://en.m.wikipedia.org/wiki/Bra–ket_notation\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Quantum_state\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Measurement_in_quantum_mechanics\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Wave_function"
      ],
      "metadata": {
        "id": "g5_S-_U6lMXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.linkedin.com/pulse/math-quantum-computing-hard-concept-simple-terms-teddy-porfiris/"
      ],
      "metadata": {
        "id": "VyXbQKw2Ktpw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"There are (at least) two possible ways to formulate precisely (i.e. mathematically) elementary\n",
        "QM. The eldest one, historically speaking, is due to von Neumann in essence, and is formulated using the language of Hilbert spaces and the spectral theory of unbounded operators. A more recent and mature formulation was developed by several authors in the attempt to solve quantum field theory problems in mathematical physics. It relies on the theory of abstract algebras (*-algebras and C* -algebras) that are built mimicking the operator algebras defined and studied, again, by von Neumann (nowadays known as W* -algebras or von Neumann algebras), but freed from the Hilbert-space structure. The core result is the celebrated GNS theorem (after Gelfand, Najmark and Segal), that we will prove in Chap. 14. The newer formulation can be considered an extension of the former one, in a very precise sense that we shall not go into here, also by virtue of the novel physical context it introduces and by the possibility of treating physical systems with infinitely many degrees of freedom, i.e. quantum fields. In particular, this second formulation makes precise sense of the demand for locality and covariance of relativistic quantum field theories, and allows to extend quantum field theories to a curved spacetime.\"\n",
        "-Valter Moretti"
      ],
      "metadata": {
        "id": "VNk-lacMqzQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.cs.cmu.edu/~odonnell/quantum15/lecture17.pdf\n",
        "\n",
        "https://quantum.phys.cmu.edu/QCQI/qitd463.pdf\n",
        "\n",
        "https://quantum.phys.cmu.edu/QCQI/qitd412.pdf"
      ],
      "metadata": {
        "id": "oQDonJmr5Q6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Ehrenfest and the Liouville correspondence*\n",
        "\n",
        "* The Ehrenfest theorem and the Liouville's theorem provide important connections between the microscopic (quantum) and the macroscopic (classical) descriptions of physical systems.\n",
        "\n",
        "* **Ehrenfest Theorem**: In quantum mechanics, the Ehrenfest theorem provides a link between the quantum mechanical description of the motion of particles and the classical motion as described by Newton's laws. Named after Paul Ehrenfest, who proved it in 1927, it demonstrates how the expectation values (average values) of quantum observables (like position and momentum) evolve with time. **Under some circumstances, when quantum effects are small, these expectation values follow trajectories similar to classical mechanics.**\n",
        "\n",
        "* Mathematically, the Ehrenfest theorem states that the time derivative of the expectation value of an operator equals the expectation value of the time derivative of the operator. For position (x) and momentum (p), it can be written as:\n",
        "\n",
        "* d〈x〉/dt = 〈p〉/m  (Ehrenfest's first theorem, analogous to velocity = momentum/mass)\n",
        "d〈p〉/dt = -〈dV/dx〉  (Ehrenfest's second theorem, analogous to Newton's second law)\n",
        "\n",
        "* where V is the potential energy and m is the mass of the particle.\n",
        "\n",
        "* **Liouville's Theorem**: In classical statistical mechanics, Liouville's theorem describes the time evolution of phase space distribution function (a function that gives the probability of the system to be in a certain state with given position and momentum) in a Hamiltonian system (a system governed by Hamilton's equations). The theorem states that the distribution function is constant along the trajectories of the system. That is, the total phase space volume is conserved.\n",
        "\n",
        "* This provides a bridge between microscopic (individual particle trajectories) and macroscopic (bulk or average behavior) properties of the system. The Liouville's theorem is a cornerstone in the development of statistical mechanics and the concept of entropy.\n",
        "\n",
        "* Both of these theorems provide important links between classical and quantum descriptions of physics. They show that in certain limits, classical and quantum mechanical descriptions become similar, providing a physical intuition for the correspondence principle, which states that quantum mechanics must reproduce classical physics in the limit of large quantum numbers."
      ],
      "metadata": {
        "id": "PN6ALFTxu9-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://phys.org/news/2023-01-scientists-quantum-harmonic-oscillator-room.html"
      ],
      "metadata": {
        "id": "6VMJ5J0fVOgM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Video: [Map of Quantum Physics](https://youtu.be/gAFAj3pzvAA)"
      ],
      "metadata": {
        "id": "OEoP77S6dgsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://phys.org/news/2022-11-common-misconceptions-quantum-physics.html\n",
        "\n",
        "https://www.derstandard.de/story/2000140294674/wie-die-quantenphysik-mit-unserer-vorstellung-von-realitaet-aufraeumt\n",
        "\n",
        "https://physicsworld.com/a/how-the-stern-gerlach-experiment-made-physicists-believe-in-quantum-mechanics/"
      ],
      "metadata": {
        "id": "eT_D-OhRlWtg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Korrespondenzprinzip](https://de.m.wikipedia.org/wiki/Korrespondenzprinzip): Klassische Größen werden durch Operatoren ersetzt. Die quantenmechanische Aufenthaltswahrscheinlichkeitsdichte eines Teilchens ist proportional zum Quadrat der Wellenfunktion der Materiewelle an jener Stelle. Für große Quantenzahlen geht die quantenmechanische Wahrscheinlichkeitsdichte asymptotisch in die klassische über.\n",
        "\n",
        "![ggg](https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Korrespondenzprinzip.svg/640px-Korrespondenzprinzip.svg.png)\n"
      ],
      "metadata": {
        "id": "MSQgI9GjQAv7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKKG0DSv8FhZ"
      },
      "source": [
        "*Postulate der Quantenmechanik (Kopenhagener Interpretation)*\n",
        "\n",
        "1. **Zustand**: Der Zustand eines physikalischen Systems zu einem Zeitpunkt $t_{0}$ wird durch die Angabe eines zum Zustandsraum $\\mathcal{H}$ gehörenden komplexen Zustandsvektors $\\left|\\psi\\left(t_{0}\\right)\\right\\rangle$ definiert. Vektoren, die sich nur um einen von 0 verschiedenen Faktor $c \\in \\mathbb{C}$ unterscheiden, beschreiben denselben Zustand. Der Zustandsraum des Systems ist ein Hilbertraum.\n",
        "\n",
        "2. **Observable**: Jede Größe $A$, die physikalisch , gemessen\" werden kann, ist durch einen im Zustandsraum wirkenden hermiteschen Operator $\\hat{A}$ beschrieben. Dieser Operator wird als Observable bezeichnet und hat ein reelles Spektrum mit einer vollständigen sogenannten Spektralschar, bestehend aus einem , diskreten\" Anteil mit Eigenvektoren und Eigenwerten (Punktspektrum) und aus einem Kontinuum.\n",
        "\n",
        "3. **Messresultat**: Resultat der Messung einer physikalischen Größe $A$ kann nur einer der Eigenwerte der entsprechenden Observablen $\\hat{A}$ sein oder bei kontinuierlichem Spektrum des Operators eine messbare Menge aus dem Kontinuum.\n",
        "\n",
        "4. **Messwahrscheinlichkeit im Fall eines diskreten nichtentarteten Spektrums**: Wenn die physikalische Größe $A$ an einem System im Zustand $|\\psi\\rangle$ gemessen wird, ist die Wahrscheinlichkeit $P\\left(a_{n}\\right)$, den nichtentarteten Eigenwert $a_{n}$ der entsprechenden Observable $\\hat{A}$ zu erhalten (mit dem zugehörigen Eigenvektor $\\left|u_{n}\\right\\rangle$ ) $P\\left(a_{n}\\right)=\\left|\\left\\langle u_{n} \\mid \\psi\\right\\rangle\\right|^{2}$. Dabei seien $\\psi$ und $u_{n}$ normiert.\n",
        "\n",
        "5. **Die Zeitentwicklung des Zustandsvektors** $|\\psi(t)\\rangle$ ist gegeben durch die folgende Schrödingergleichung, wobei $\\hat{H}(t)$ die der totalen Energie des Systems zugeordnete Observable ist:\n",
        "\n",
        ">$\\mathrm{i} \\hbar \\frac{\\partial}{\\partial t}|\\psi(t)\\rangle=\\hat{H}(t)|\\psi(t)\\rangle$\n",
        "\n",
        "http://vergil.chemistry.gatech.edu/notes/quantrev/node20.html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [Mathematical_formulation_of_quantum_mechanics](https://en.m.wikipedia.org/wiki/Mathematical_formulation_of_quantum_mechanics)\n",
        "* [C*-algebra](https://en.m.wikipedia.org/wiki/C*-algebra)\n",
        "* [Quantum_geometry](https://en.m.wikipedia.org/wiki/Quantum_geometry)\n",
        "* [Noncommutative_geometry](https://en.m.wikipedia.org/wiki/Noncommutative_geometry)\n",
        "* [Geometric_quantization](https://en.m.wikipedia.org/wiki/Geometric_quantization)"
      ],
      "metadata": {
        "id": "wGmG22vunC0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_209.png)\n"
      ],
      "metadata": {
        "id": "q8MuXUSiqRrJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE--P8idzoP-"
      },
      "source": [
        "**Video: [Crash course in density matrices](https://www.youtube.com/watch?v=1tserF6VGqI)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWlXYxSBzPS3"
      },
      "source": [
        "**Single spin one half particle, focus on spin degrees of freedom & Pauli-matrices**\n",
        "\n",
        "* when the spin degrees of freedom interact with an electromagnetic field, the Pauli matrices come into play:\n",
        "\n",
        "> $\\sigma^{Z}=\\left(\\begin{array}{cc}1 & 0 \\\\ 0 & -1\\end{array}\\right) \\quad \\sigma^{X}=\\left(\\begin{array}{ll}0 & 1 \\\\ 1 & 0\\end{array}\\right) \\quad \\sigma^{Y}=\\left(\\begin{array}{cc}0 & -i \\\\ i & 0\\end{array}\\right)$\n",
        "\n",
        "* we have chosen a basis in such a way that the Pauli Z matrix is diagonal. Here are its basis vectors, the spin up in the z direction and the spin down direction, written as column vectors:\n",
        "\n",
        "> $|\\uparrow\\rangle=\\left(\\begin{array}{l}1 \\\\ 0\\end{array}\\right) \\quad |\\downarrow\\rangle=\\left(\\begin{array}{l}0 \\\\ 1\\end{array}\\right)$\n",
        "\n",
        "* we can re-express the basis vectors for the Pauli X matrix in either direction in terms of these vectors, but in the positive direction we can write it in the following way:\n",
        "\n",
        "> $|\\rightarrow\\rangle=\\frac{1}{\\sqrt{2}}(|\\uparrow\\rangle+|\\downarrow\\rangle)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvOyiyJtzRtd"
      },
      "source": [
        "**States we are used to use in quantum mechanics are called 'pure states'.**\n",
        "\n",
        "* Any state can be written as the linear combination of the up and down vectors in the z-direction\n",
        "\n",
        "> $|\\psi\\rangle=a|\\uparrow\\rangle+b|\\downarrow\\rangle$\n",
        "\n",
        "* a and b are complex numbers whose modulus squared sum to 1\n",
        "\n",
        "> $\\langle\\psi \\mid \\psi\\rangle=|a|^{2}+|b|^{2}$\n",
        "\n",
        "* a and b can be referred to as the probability amplitudes, where their modulus squared are the probabilities that the system is in a particular configuration.\n",
        "\n",
        "* If we perform an ensemble of measurements on the system, we will find that the mean or expected value, for example of the Pauli-Z matrix, will be given by:\n",
        "\n",
        "> $\\left\\langle\\sigma^{Z}\\right\\rangle=\\left\\langle\\psi\\left|\\sigma^{Z}\\right| \\psi\\right\\rangle$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZoOoevVzUPa"
      },
      "source": [
        "**Dynamics: if we want to study how a quantum system changes in time, we usually refer to the Schroedinger equation.**\n",
        "\n",
        "> $i \\frac{d}{d t}|\\psi(t)\\rangle=\\hat{H}|\\psi\\rangle$\n",
        "\n",
        "* the operator $\\hat{H}$ is called the Hamiltonian and it tells us about the total energy in a system, and how things in a system interact with each other.\n",
        "\n",
        "* the easiest way to solve this problem is to first solve the Eigenvalue problem, which involves finding the Eigenvectors and the Eigenvalues of the hamiltonian. We are able the different values of the Eigenvalues and Eigenvectors with the label k:\n",
        "\n",
        "> $\\hat{H}\\left|E_{k}\\right\\rangle=E_{k}\\left|E_{k}\\right\\rangle$\n",
        "\n",
        "* This allows us to know that the Eigenvectors, when plugged into the Schroedinger equation ...\n",
        "\n",
        "> $i \\frac{d}{d t}\\left|E_{k}\\right\\rangle=\\hat{H}\\left|E_{k}\\right\\rangle=E_{k}\\left|E_{k}\\right\\rangle$\n",
        "\n",
        "* ... just pick up a phase in time depending on the energy they correspond to:\n",
        "\n",
        "> $\\left|E_{k}(t)\\right\\rangle=e^{-i E_{k} t}\\left|E_{k}\\right\\rangle$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jitINkMkzWk-"
      },
      "source": [
        "**Now to sum more general situation with some generic state $\\psi$**\n",
        "\n",
        "* we can decompose $\\psi$ in terms of energy Eigenbasis:\n",
        "\n",
        "> $|\\psi\\rangle=\\sum_{m} c_{m}\\left|E_{m}\\right\\rangle$\n",
        "\n",
        "* where $c_{m}$ is given by the inner product of the energy Eigenvector labelled by m and $\\psi$ itself:\n",
        "\n",
        "> $c_{m}=\\left\\langle E_{m} \\mid \\psi\\right\\rangle$\n",
        "\n",
        "* We can then time-evolve the state by simply time-evolving the energy Eigen-Kets:\n",
        "\n",
        "> $|\\psi(t)\\rangle=\\sum_{m} c_{m} e^{-i E_{m} t}\\left|E_{m}\\right\\rangle$\n",
        "\n",
        "* Tracking the expectation value of an observable is quite easy: Simply applying the state vector in time to both sides of the matrix gives the following equation:\n",
        "\n",
        "> $\\langle A(t)\\rangle=\\sum_{m, n} \\bar{c}_{n} c_{m} A_{n, m} e^{i\\left(E_{n}-E_{m}\\right) t}$\n",
        "\n",
        "* Where we have labelled the matrix entries of a by the energy Eigenbasis in the following way:\n",
        "\n",
        "> $A_{n, m}=\\left\\langle E_{n}|A| E_{m}\\right\\rangle$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utZdbq6QzZD9"
      },
      "source": [
        "**Propeties of the trace of a matrix**\n",
        "\n",
        "* We have a basis of states labeled by j $|j\\rangle, j=1,2$.. N that form a complete orthonormal basis. Then I write the trace of a matrix in the following way:\n",
        "\n",
        "> $\\operatorname{Tr}(A)=\\sum_{j}\\langle j|A| j\\rangle$\n",
        "\n",
        "* the trace is a linear mapping which tells us that we can separate the trace of the sum of two matrices apart like this, and we can also pull scalar multiples outside of the trace:\n",
        "\n",
        "> $\\operatorname{Tr}(A+B)=\\operatorname{Tr} A+\\operatorname{Tr} B$ with $\\operatorname{Tr}(c A)=c \\operatorname{Tr} A$\n",
        "\n",
        "* When we take the trace of two matrices multiplied by each other, the trace is invariant under swapping the two matrices inside of the trace.\n",
        "\n",
        "> $\\operatorname{Tr}(A B)=\\operatorname{Tr}(B A)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Om09eqlza4O"
      },
      "source": [
        "**Density Matrices**\n",
        "\n",
        "* Going from a pure state represented by a Ket we can introduce the density matrix which is a completely equivalent way to represent the state of a quantum system\n",
        "\n",
        "* the density matrix in this context is just the outer product of the state with itself:\n",
        "\n",
        "> $\\rho=|\\psi\\rangle\\langle\\psi|$\n",
        "\n",
        "* the expectation value is rewritten in terms of a trace, but it is mathematically equivalent to the earlier expression:\n",
        "\n",
        "> $\\left\\langle\\sigma^{Z}\\right\\rangle=\\operatorname{Tr}\\left(\\rho \\sigma^{2}\\right)=\\left\\langle\\psi\\left|\\sigma^{Z}\\right| \\psi\\right\\rangle$\n",
        "\n",
        "* the density matrix has two fundamental properties: it's trace is 1 in the context of a pure state:\n",
        "\n",
        "> $\\operatorname{Tr} \\rho=1$\n",
        "\n",
        "> $\\operatorname{Tr}|\\psi\\rangle\\left\\langle\\left.\\psi|=|\\langle\\psi \\mid \\psi\\rangle\\right|^{2}=1\\right.$\n",
        "\n",
        "* and it's a positive operator:\n",
        "\n",
        "> $\\rho \\geq 0$\n",
        "\n",
        "* If I take any state vector our state space and perform the following operation, then the result is always greater than or equal to zero:\n",
        "\n",
        "> $\\langle\\phi|\\rho| \\phi\\rangle=|\\langle\\phi \\mid \\psi\\rangle|^{2} \\geq 0$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuLO_P1u6FBJ"
      },
      "source": [
        "**Dynamics: von Neumann equation of time evolution**\n",
        "\n",
        "* show from the Schroedinger equation we can derive the von Neumann equation of time evolution:\n",
        "\n",
        "> $i \\frac{\\partial \\rho}{\\partial t}=[\\hat{H}, \\rho]$\n",
        "\n",
        "* It features the commutation relationship between the Hamiltonian and the density matrix itself\n",
        "\n",
        "* then the expectation value for an observable in time can be rewritten in the following way:\n",
        "\n",
        "> $\\langle A(t)\\rangle=\\operatorname{Tr}(\\rho(t) A)$\n",
        "\n",
        "* where the density matrix $\\rho$ evolves with the Hamiltonian being applied to it in time:\n",
        "\n",
        "> $\\rho(t)=e^{-i \\hat{H} t} \\rho e^{i \\hat{H} t}$\n",
        "\n",
        "*  similarly re-expressed in the basis of the energy Eigenvalues\n",
        "\n",
        "> $\\rho(t)=\\sum_{m, n} \\rho_{m, n} e^{-i\\left(E_{m}-E_{n}\\right) t}\\left|E_{m}\\right\\rangle\\left\\langle E_{n}\\right|$\n",
        "\n",
        "* where $\\rho_{m,n}$ can be written in the following way, where we have re-expressed its entries in terms of the energy Eigenbasis:\n",
        "\n",
        "> $\\rho_{m, n}=\\left\\langle E_{m}|\\rho| E_{n}\\right\\rangle$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmo42wRj8v6C"
      },
      "source": [
        "**Mixed States**\n",
        "\n",
        "* what if we are unsure of what pure state our system is in? (We are somehow ignorant / unwissend to what pure state we are in)\n",
        "\n",
        "* then we can describe a statistical ensemble of pure states which we call a mixed states\n",
        "\n",
        "> $\\rho=\\sum_{j} p_{j}\\left|\\psi_{j}\\right\\rangle\\left\\langle\\psi_{j}\\right|$\n",
        "\n",
        "* the ensemble is written as a sum of pure states with probabilities $p_j$ and the probabilities are greater than zero and sum up to one:\n",
        "\n",
        "> $p_{j} \\geq 0 \\quad \\sum_{j} p_{j}=1$\n",
        "\n",
        "* Mixed states are also trace 1 and are positive operators:\n",
        "\n",
        "> $\\operatorname{Tr} \\rho=1, \\quad \\rho \\geq 0$\n",
        "\n",
        "* Dynamics and the expectation values work in an identical way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUFROLA7BPGU"
      },
      "source": [
        "**Non-uniqueness of mixed states decomposition**\n",
        "\n",
        "* Interestingly it's not completely correct to interpret $p_j$ as the probability of being in a particular state labeled by j.\n",
        "\n",
        "* To see this consider the following example let $\\rho$ be a mixed state written in the following way:\n",
        "\n",
        "> $\\rho=\\frac{4}{5}|\\downarrow\\rangle\\left\\langle\\downarrow\\left|+\\frac{1}{5}\\right| \\uparrow\\right\\rangle\\langle\\uparrow|$\n",
        "\n",
        "* we say the system is in state down with probability 4/5 and in state up with 1/5.\n",
        "\n",
        "* What if I prepared two other states with the following new state vectors a and b with the following probability amplitudes of being in down or up state:\n",
        "\n",
        "> $|a\\rangle=\\sqrt{\\frac{4}{5}}|\\downarrow\\rangle+\\frac{1}{\\sqrt{5}}|\\uparrow\\rangle$\n",
        "\n",
        "> $|b\\rangle=\\sqrt{\\frac{4}{5}}|\\downarrow\\rangle-\\frac{1}{\\sqrt{5}}|\\uparrow\\rangle$\n",
        "\n",
        "* Then if we prepare these states with probability one-half:\n",
        "\n",
        "> $\\rho=\\frac{1}{2}|a\\rangle\\left\\langle a\\left|+\\frac{1}{2}\\right| b\\right\\rangle\\langle b|$\n",
        "\n",
        "* We see that we get the same density matrix as before working this out expanding the definitions of a and b allows us to arrive at our original density matrix:\n",
        "\n",
        "> $\\rho=\\frac{4}{5}|\\downarrow\\rangle\\left\\langle\\downarrow\\left|+\\frac{1}{5}\\right| \\uparrow\\right\\rangle\\langle\\uparrow|$\n",
        "\n",
        "* Therefore two different ensembles of pure states can give rise to the same mixed state and we must be careful when we interpret $p_j$ as strictly probabilities of a particular system being strictly in its associated pure state in the sum.\n",
        "\n",
        "* Finally, if you get a matrix how could you tell if it's pure or mixed? Mathematically quite simple way to check: square the matrix and take its trace. If the trace is still 1, we say that the density matrix is pure if it is less than one then we say it's mixed. This is actually independent of the time evolution.\n",
        "\n",
        "> $\\operatorname{Tr}\\left(\\rho^{2}\\right) \\leq 1$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ***Ket $|\\psi\\rangle$ - State Space $V$(Vector)*** *- also: Wave Function (Pure State, Postulate I)*"
      ],
      "metadata": {
        "id": "jBh1Tr-vn_4f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtcIVsSgCSld"
      },
      "source": [
        "> <font color=\"blue\">**<u>Postulate I of Quantum Mechanics</u>: The state of a physical system is characterized by a state vector that belongs to a complex vector space $\\mathcal{V}$, called the state space of the system**\n",
        "\n",
        "* State Space Formalism: unification of Schrodinger wave mechanics and matrix mechanics (Heisenberg, Born, Jordan), both are equivalent.\n",
        "\n",
        "* **Matrix mechanics ('matrix formulation'): Most useful when we deal with finite, discrete bases (like spin). Then it reduces to the rules of simple matrix multiplication**. Kronecker delta\n",
        "\n",
        "* **Schrodinger wave mechanics: for continuous basis (like position)** Dirac delta function\n",
        "\n",
        "* State Space: the vector space in which quantum systems live\n",
        "\n",
        "  * Euclidean space: classical physics, 3D, real, inner product (Hilbert Space)\n",
        "\n",
        "  * State space: quantum physics, infinite dimensions, complex numbers, inner product (Hilbert Space)\n",
        "\n",
        "Video: [Dirac notation: state space and dual space](https://www.youtube.com/watch?v=hJoWM9jf0gU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlC5y6Hpsj_E"
      },
      "source": [
        "<font color=\"blue\">*Ket Algebra - Quantum State Vector*\n",
        "\n",
        "**A Ket $|\\psi\\rangle$ $\\doteq$ $\\left[\\begin{array}{l}a_{0} \\\\ a_{1}\\end{array}\\right]$, also called 'quantum state', <u>represents</u> the wave function of a quantum system (\"Psi\")**, consisting of **probability amplitudes**. This Quantum state is a **stochastic vector**, written as a column vector.\n",
        "\n",
        "> **A Ket is technically a pure quantum state**.\n",
        "\n",
        "* Wave function notation to describe superposition of Pure States.\n",
        "\n",
        "So, you have an (orthonormal) basis with 3 vectors and coefficients, to describe a vector in space (in Hilbert space):\n",
        "\n",
        "> $\\vec{v}=$<font color='blue'>$2$</font>$\\left(\\begin{array}{l}1 \\\\ 0 \\\\ 0\\end{array}\\right)$<font color='blue'>$+3$</font>$\\left(\\begin{array}{l}0 \\\\ 1 \\\\ 0\\end{array}\\right)$<font color='blue'>$+0$</font>$\\left(\\begin{array}{l}0 \\\\ 0 \\\\ 1\\end{array}\\right)$\n",
        "\n",
        "The basis vectors will all entries in 0 and only one with 1 correspond to possibe measurement outcomes (spin up or down).\n",
        "\n",
        "The coefficients can be collected in one vector and are complex numbers:\n",
        "\n",
        "> $\\vec{v}=$<font color='blue'>$\\left(\\begin{array}{l}2 \\\\ 3 \\\\ 0\\end{array}\\right)$</font>\n",
        "\n",
        "An arbitrary state for a qubit can be written as a linear combination of the Pauli matrices, which provide a basis for $2 \\times 2$ self-adjoint matrices:\n",
        "\n",
        "> $\n",
        "\\rho=\\frac{1}{2}\\left(I+r_{x} \\sigma_{x}+r_{y} \\sigma_{y}+r_{z} \\sigma_{z}\\right)\n",
        "$\n",
        "\n",
        "* where the real numbers $\\left(r_{x}, r_{y}, r_{z}\\right)$ are the coordinates of a point within the unit ball and\n",
        "\n",
        "> $\n",
        "\\sigma_{x}=\\left(\\begin{array}{ll}\n",
        "0 & 1 \\\\\n",
        "1 & 0\n",
        "\\end{array}\\right), \\quad \\sigma_{y}=\\left(\\begin{array}{cc}\n",
        "0 & -i \\\\\n",
        "i & 0\n",
        "\\end{array}\\right), \\quad \\sigma_{z}=\\left(\\begin{array}{cc}\n",
        "1 & 0 \\\\\n",
        "0 & -1\n",
        "\\end{array}\\right)\n",
        "$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Siehe auch: [Projective Hilbert Space](https://en.m.wikipedia.org/wiki/Projective_Hilbert_space) with rays or projective rays"
      ],
      "metadata": {
        "id": "_sFD45vxEg5a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgSzA4IwURCu"
      },
      "source": [
        "<font color=\"blue\">*Multiply Ket with a Scalar: Vector-Scalar-Multiplication*\n",
        "\n",
        "Vector-Scalar:\n",
        "\n",
        "$\\left[\\begin{array}{l}x_{0} \\\\ x_{1}\\end{array}\\right] \\otimes\\left[y_{0}\\right]=\\left[\\begin{array}{l}x_{0}\\left[y_{0}\\right] \\\\ x_{1}\\left[y_{0}\\right]\\end{array}\\right]=\\left[\\begin{array}{l}x_{0} y_{0} \\\\ x_{1} y_{0}\\end{array}\\right]$\n",
        "\n",
        "\n",
        "<font color=\"blue\">*Multiply Ket with another Ket: Ket - Tensor Product (Vector-Vector-Multiplication, Kronecker Product)*\n",
        "\n",
        "> $\\mathbf{uv}$ = $\\left[\\begin{array}{c}u_{1} \\\\ u_{2}\\end{array}\\right]$ $\\otimes$ $\\left[\\begin{array}{c}v_{1} \\\\ v_{2} \\end{array}\\right]$ = $\\left[\\begin{array}{l}u_{1}\\left[\\begin{array}{l}v_{1} \\\\ v_{2}\\end{array}\\right] \\\\ u_{2}\\left[\\begin{array}{l}v_{1} \\\\ v_{2}\\end{array}\\right]\\end{array}\\right]$=  $\\left[\\begin{array}{c}u_{1} v_{1} \\\\ u_{1} v_{2}\\\\ u_{2} v_{1} \\\\ u_{2} v_{2}\\end{array}\\right]$\n",
        "\n",
        "*Zur Kombination von Quantum States:*\n",
        "\n",
        "> $\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]=|0\\rangle, \\quad\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right]=|1\\rangle$.\n",
        "\n",
        "We choose two qubits in state $|0\\rangle$:\n",
        "\n",
        "> $|0\\rangle \\otimes|0\\rangle = \\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right] \\otimes\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]=$</font> $\\left[\\begin{array}{l}1\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right] \\\\ 0\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]\\end{array}\\right]=$ $\\left [\\begin{array}{l}11 \\\\ 10 \\\\ 01 \\\\ 00\\end{array}\\right]$ = <font color=\"gray\">$\\left [\\begin{array}{l}3 \\\\ 2 \\\\ 1 \\\\ 0\\end{array}\\right]$</font> = <font color=\"blue\">$\\left [\\begin{array}{l}1 \\\\ 0 \\\\ 0 \\\\ 0\\end{array}\\right]$\n",
        "\n",
        "Quits in two different states:\n",
        "\n",
        "> $|0\\rangle \\otimes|1\\rangle = \\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right] \\otimes\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right]=\\left[\\begin{array}{l}1\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right] \\\\ 0\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right]\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\ 1 \\\\ 0 \\\\ 0\\end{array}\\right]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH8JeO4mW4q6"
      },
      "source": [
        "**How do we represent Ket's in a particular basis?**\n",
        "\n",
        "> <font color=\"blue\">$|\\psi\\rangle=\\sum_{i} c_{i}\\left|u_{i}\\right\\rangle \\quad$ where: $c_{i}=\\left\\langle u_{i} \\mid \\psi\\right\\rangle$\n",
        "\n",
        "Video: [Representations in quantum mechanics](https://www.youtube.com/watch?v=rp2k2oR5ZQ8)\n",
        "\n",
        "\n",
        "> $\\left\\{c_{i}\\right\\}$ are the representation of $|\\psi\\rangle$ in the $\\left\\{\\left|u_{i}\\right\\rangle\\right\\}$ basis\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_210.png)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_211.png)\n",
        "\n",
        "* a und b coefficients in euclidean space sind wie $u_i$ coefficients in quantum state space. (difference is bra-ket, wo bra das conjugate complex ist als dot product mit ket: es ist im erstem argument antilinear!).\n",
        "\n",
        "* expansion coefficients c are given by projection of the Ket onto the basis states u:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_212.png)\n",
        "\n",
        "* Here we can take out $|\\Psi\\rangle$ because it doesnt explicitely depend on $_i$:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_213.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0xfgmufRt0W"
      },
      "source": [
        "**Additional Ket-Algebra**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_202.png)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_203.png)\n",
        "\n",
        "For euclidean space: the scalar product is linear both in first and second argument:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_204.png)\n",
        "\n",
        "For state space: the scalar product is only linear in the second argument (and antilinear in the first argument):\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_205.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ***Bra $\\langle \\psi |$ - Dual Space $V^{*}$ (Covector)***"
      ],
      "metadata": {
        "id": "cqdowsM5oHEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **$|\\psi\\rangle$**: This is a quantum state, often called a 'ket' in the Dirac notation. It represents the state of a quantum system, which could be a single qubit or a system of multiple qubits.\n",
        "* **|ψ⟩:** This is the quantum state of the system. The state represents the configuration of the system's components, and it can be represented by a complex vector in a Hilbert space.\n",
        "\n",
        "2. **$\\langle\\psi|$**: This is the bra corresponding to the ket $|\\psi\\rangle $. In Dirac notation, $\\langle\\psi|$) represents the conjugate transpose of $|\\psi\\rangle$.\n",
        "\n",
        "* **⟨ψ|:** This denotes the inner product of the quantum state |ψ⟩ with itself. This inner product represents the overlap between the two states |ψ⟩ and |ψ⟩, which is a measure of their similarity.\n"
      ],
      "metadata": {
        "id": "_g5-XOuYVQ1X"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NOxv3yFtjD1"
      },
      "source": [
        "**How do we represent Bra's in a particular basis?**\n",
        "\n",
        "* Bra $\\langle \\Psi|$ is an element of the dual vector space $V^*$\n",
        "\n",
        "* Bra Psi times the identity operator ($\\langle \\Psi| * \\mathbb{I}$), and then write the identity operator out (its resolution in the u basis)\n",
        "\n",
        "* psi doesnt explicitylt depend on i, so we can write it into the summation, which brings us to this expression\n",
        "\n",
        "> $\\sum_{i}\\left\\langle\\psi \\mid u_{i}\\right\\rangle\\left\\langle u_{i}\\right|$\n",
        "\n",
        "* This is an expression for the bra psi in terms of the basis bra's u, and then the expansion coefficients are the brackets between psi and u $\\left\\langle\\psi \\mid u_{i}\\right\\rangle$\n",
        "\n",
        "\n",
        "If we look at these expansion coefficients $\\left\\langle\\psi \\mid u_{i}\\right\\rangle$, we can use the conjugation property of the scalar product to rewrite them like this:\n",
        "\n",
        "> $\\left\\langle\\psi \\mid u_{i}\\right\\rangle$ = $\\left\\langle u_{i} \\mid \\psi \\right\\rangle^*$ = $c_i^*$\n",
        "\n",
        "**The expansion coefficients are the complex conjugates of the expansion coefficients of the Ket**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_214.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ***Bra-Ket $\\langle \\psi |\\psi\\rangle = c$ - Linear Form (Covector-Vector)*** *- also: Projective Measurement*"
      ],
      "metadata": {
        "id": "1fAAZcgWoiJB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A6siRC6YyVY"
      },
      "source": [
        "> **Bra-Ket - Projective Measurement (Kovector-Vector-Multiplication, Born Rule)**\n",
        "\n",
        "* Dirac delta function (a distribution!) = quantum measurement\n",
        "\n",
        "* See also [wiki: Bra–ket notation](https://en.m.wikipedia.org/wiki/Bra–ket_notation)\n",
        "\n",
        "* From 'Exterior algebra' $\\rightarrow$ 'Multilinear Forms':\n",
        "\n",
        "  * **A row vector can be thought of as a function (as a form), rather than a row vector, that acts on another vector.**\n",
        "\n",
        "  * In Quantum mechanics: Linear functionals are particularly important in quantum mechanics. Quantum mechanical systems are represented by Hilbert spaces, which are [anti–isomorphic](https://en.m.wikipedia.org/wiki/Antiisomorphism) to their own dual spaces. A state of a quantum mechanical system can be identified with a linear functional. For more information see bra–ket notation.\n",
        "\n",
        "  * Bra-Ket $\\langle\\psi \\mid \\psi\\rangle$: **Kovector-Vector-Multiplication**, Born Rule (Projective Measurement)\n",
        "\n",
        "  * ⟨0∣1⟩ und ⟨1∣0⟩ ergeben inner product 0 (orthogonal zueinander), zB $\\langle 0 \\mid 1\\rangle=[1,0]\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right] = 0$. Und ⟨0∣0⟩ und ⟨1∣1⟩ = 1.\n",
        "\n",
        "*See also: [dot product between a covector and a vector is a scalar, after all!](https://cafephysics35698708.wordpress.com/2017/12/23/moving-away-from-ortho-land-vectors-covectors-and-all-that/) but read also why [There are a couple ways to view a dot product as a linear map by changing your view slightly](https://math.stackexchange.com/questions/2856198/is-dot-product-a-kind-of-linear-transformation)*\n",
        "\n",
        "* Inner Product / Bra-Ket, conjugate transpose of Ket.\n",
        "You get a scalar as output.\n",
        "\n",
        "* The Bra-Ket $\\langle\\psi \\mid \\psi\\rangle$  represents the inner product in the Hilbert space\n",
        "\n",
        "* Zur Messung von Zustaenden in einer Basis (zB ich will die Probability wissen, mit der man den State=1 erhält)\n",
        "\n",
        "* Quantum mechanical systems are represented by Hilbert spaces, which are anti–isomorphic to their own dual spaces.\n",
        "\n",
        "* **A state of a quantum mechanical system can be identified with a linear functional**.\n",
        "\n",
        "> $\\mathbf{u}^{\\top} \\mathbf{v}=\\left[\\begin{array}{llll}u_{1} & u_{2} & \\cdots & u_{n}\\end{array}\\right]\\left[\\begin{array}{c}v_{1} \\\\ v_{2} \\\\ \\vdots \\\\ v_{n}\\end{array}\\right]=\\left[u_{1} v_{1}+u_{2} v_{2}+\\cdots+u_{n} v_{n}\\right]$ = scalar\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_248.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Case 1: Inner product of two basis vectors**:\n",
        "\n",
        "\n",
        "* ⟨0∣1⟩ und ⟨1∣0⟩ ergeben inner product 0 (orthogonal zueinander), im Detail fur $\\langle 0 \\mid 1\\rangle=[1,0]\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right] = 0$\n",
        "\n",
        "* ⟨0∣0⟩ und ⟨1∣1⟩ ergeben inner product 1 (mit sich selbst multipliziert / die beiden Berechnungsbasisvektoren sind orthonormal)\n",
        "\n",
        "**Case 2: Berechne Wahrscheinlichkeit fur Messung eines Eigenstates (Born's Rule)**\n",
        "\n",
        "* Die orthonormalen Eigenschaften sind im folgenden Beispiel nützlich\n",
        "\n",
        "* Es gibt einen Zustand mit der Wave Function / Wahrscheinlichkeit fur beide Zustaende $|\\psi\\rangle=\\frac{3}{5}|1\\rangle+\\frac{4}{5}|0\\rangle$\n",
        "\n",
        "* die Wahrscheinlichkeit des Messens 1 ist dann (1 ist hierbei die basis, weil ich es messen will) [Source](https://docs.microsoft.com/de-de/azure/quantum/concepts-dirac-notation):\n",
        "\n",
        ">$\n",
        "|\\langle 1 \\mid \\psi\\rangle|^{2}=\\left|\\frac{3}{5}\\langle 1 \\mid 1\\rangle+\\frac{4}{5}\\langle 1 \\mid 0\\rangle\\right|^{2}=\\frac{9}{25}\n",
        "$\n",
        "\n",
        "* weil $\\langle 1 \\mid 0\\rangle=0$ faellt der zweite Term weg: $\\frac{4}{5}\\langle 1 \\mid 0\\rangle$ = $\\frac{4}{5} * 0$\n",
        "\n",
        "* Another example: $\\left[\\begin{array}{ll}2 & 1\\end{array}\\right]\\left(\\left[\\begin{array}{l}x \\\\ y\\end{array}\\right]\\right)=2 x+1 y$. **The covector [2, 1] can be thought of as a function, rather than a row vector, that acts on another vector.**\n",
        "\n",
        "> <font color=\"red\">*The probability of a particular measurement is then the absolute square of the scalar product with the basis vector that corresponds to the outcome (probability of measuring $X$ is). This is <u>Born's Rule</u>. This scalar product of the wave function with a basis vector is also sometimes called a <u>projection</u> on that basis vector:*\n",
        "\n",
        "> $|\\langle X \\mid \\Psi\\rangle|^{2}=a_{1} a_{1}^{*}$\n",
        "\n",
        "* where $\\mid \\Psi\\rangle$ is the wavefunction of the probability superposition and $\\langle X \\mid$ is the basis vector of one outcome.\n",
        "\n",
        "**Case 3: Sum over all basis vectors**\n",
        "\n",
        "> $\\langle\\Psi^* |\\Psi\\rangle$ = $ (a{_1}^*, a{_2}^*, a{_3}^*) \\left(\\begin{array}{l}a_{1} \\\\ a_{2} \\\\ a_{3}\\end{array}\\right)$ = $(a{_1}^*a_1 + a{_2}^*a_2 + a{_2}^*a_2)$\n",
        "\n",
        "**The probability to get ANY measurement outcome is equal to one, which means that the sum over the squared scalar products with all basis vectors has to be one. Which is just the length of the vector (all wave functions have length 1)**:\n",
        "\n",
        "> $1=a_{1} a_{1}^{*}+a_{2} a_{2}^{*}+a_{3} a_{3}^{*}=|\\langle \\Psi \\mid \\Psi\\rangle|^{2}$\n",
        "\n",
        "* With this bra-ket notation it's now very easy to write dot products = the **inner product between Bra and Ket which is $\\langle\\psi \\mid \\psi\\rangle$ = 1**, and it is normalized the result is 1(it's a particular way of writing the 2-norm when using complex inputs).\n",
        "\n",
        "* With the dot product of bra and ket you will get a **scalar as a result**, like total probability is 1, here for the coefficients (probability amplitudes):\n",
        "\n",
        "> $\\langle\\psi^* \\mid \\psi\\rangle = \\left|a_{0}\\right|^{2}+\\left|a_{1}\\right|^{2}= 1$\n",
        "\n",
        "* **We expand the Ket $\\psi$ in the basis u**, where the expansion coefficients c are given by the Braket between u and psi:\n",
        "\n",
        "> $|\\psi\\rangle=\\sum_{i} c_{i}\\left|u_{i}\\right\\rangle = c_{1} * u_{1} + c_{2} * u_{2} .. + c_{i}* u_{i} = c_{1}\\left(\\begin{array}{l}1 \\\\ 0 \\\\ 0\\end{array}\\right)+{c_{2}}\\left(\\begin{array}{l}0 \\\\ 1 \\\\ 0\\end{array}\\right)+.. c_{i}\\left(\\begin{array}{l}0 \\\\ 0 \\\\ i\\end{array}\\right) \\quad =\\left\\langle u_{i} \\mid \\psi\\right\\rangle$\n",
        "\n",
        "* <font color=\"red\">This c cofficients are what we call **representation of the Ket psi in the u basis**.\n",
        "\n",
        "> $\\left(\\begin{array}{c}\\langle u_{1} \\mid \\psi\\rangle \\\\ \\left\\langle u_{2} \\mid \\psi\\right\\rangle \\\\ \\vdots \\\\ \\left\\langle u_{i} \\mid \\psi\\right\\rangle \\\\ \\vdots\\end{array}\\right)=\\left(\\begin{array}{c}c_{1} \\\\ c_{2} \\\\ \\vdots \\\\ c_{i} \\\\ \\vdots \\\\ \\end{array}\\right)$"
      ],
      "metadata": {
        "id": "JhSZ3kxevCQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Quantum Measurements from an Observable (via its Operator) - Use Case: What is the most likely Eigenvalue of an Observable like Momentum or Position?**\n",
        "\n",
        "Video: [Measurements in quantum mechanics || Concepts](https://www.youtube.com/watch?v=u1R3kRWh1ek)\n",
        "\n",
        "> **$\\hat{A}\\left|u_{n}\\right\\rangle=\\lambda_{n}\\left|u_{n}\\right\\rangle \\longrightarrow P\\left(\\lambda_{n}\\right)=\\left|\\left\\langle u_{n} \\mid \\psi\\right\\rangle\\right|^{2}=\\left|c_{n}\\right|^{2}$**\n",
        "\n",
        "> <font color=\"blue\">**<u>Postulate II of quantum mechanics</u>: a physical quantity $\\mathcal{A}$ is associated with a hermitian operator $\\hat{A}$, that is called an observable.**\n",
        "\n",
        "* Physical quantity $\\mathcal{A} \\longrightarrow$ Observable $\\hat{A}$\n",
        "\n",
        "* To understand what it means to measure $\\hat{A}$ in quantum mechanics, the key equation to consider is the Eigenvalue equation of the operator $\\hat{A}$ here:\n",
        "\n",
        "> $\n",
        "\\hat{A}\\left|u_{n}\\right\\rangle=\\lambda_{n}\\left|u_{n}\\right\\rangle\n",
        "$\n",
        "\n",
        "<font color =\"blue\">*$\\rightarrow$ When you apply a measurement operator in an Eigenstate, you will measure /get the Eigenvalue of this Eigenstate (postulate III of quantum mechanics). Challenge: we just dont know in which Eigenstate our system $|\\Psi\\rangle$ is.*</font>\n",
        "\n",
        "* with $\\lambda_{n}$ Eigenvalues and $u_{n}$ Eigenstates\n",
        "\n",
        "> <font color=\"blue\">**<u>Postulate III of quantum mechanics</u>: The result of a measurement of a physical quantity is one of the Eigenvalues of the associated observable.**\n",
        "\n",
        "\n",
        "* This means: when we want to measure property $\\hat{A}$ we first need to solve the corresponding Eigenvalue equation, which allows us to find all Eigenvalues $\\lambda_{1}$, $\\lambda_{2}$, .. $\\lambda_{n}$\n",
        "\n",
        "* So the operator $\\hat{A}$ encodes all the possible outcomes of the measurement, irrespective of what the state of the system is.\n",
        "\n",
        "* **So the question is: if we measure $\\hat{A}$ in state $|\\Psi\\rangle$: which Eigenvalue will we get?** (Postulate III will tell us we will get one of the Eigenvalues $\\lambda_{n}$, but not which one)\n",
        "\n",
        "> <font color=\"blue\">**<u>Postulate VI of quantum mechanics</u>: The measurement of $\\mathcal{A}$ in a system in normalized state $|\\psi\\rangle$ gives eigenvalue $\\lambda_{n}$ with probability:**\n",
        "\n",
        "\n",
        "> $\n",
        "P\\left(\\lambda_{n}\\right)=\\left|\\left\\langle u_{n} \\mid \\psi\\right\\rangle\\right|^{2}\n",
        "$ $\\quad (= \\left|c_{n}\\right|^{2})$\n",
        "\n",
        "<font color =\"blue\">*$\\rightarrow$ $u_n$ are the possible Eigenstates to which we project our actual system state $|\\Psi\\rangle$. We square its norm and then see which one has the highest value = highest probability that the state is in this Eigenstate (with a givne Eigenvalue $\\lambda_{n}$). For example we will get $\\lambda_{1}$ with probability $\\left|\\left\\langle u_{1} \\mid \\psi\\right\\rangle\\right|^{2}$*</font>\n",
        "\n",
        "\n",
        "* This means: for an operator $\\hat{A}$ we have a list of Eigenvalues, where each of them corresponds to an Eigenstate:\n",
        "\n",
        "  * $\\lambda_{1}$ for $|u_1\\rangle$,\n",
        "\n",
        "  * $\\lambda_{2}$ for $|u_2\\rangle$,\n",
        "\n",
        "  * ...\n",
        "\n",
        "  * $\\lambda_{n}$ for $|u_n\\rangle$\n",
        "\n",
        "* these relations and values come from the Eigenvalue equation of the specific operator $\\mathcal{A}$ and are independent of the state of our system.\n",
        "\n",
        "* **But when we measure $\\mathcal{A}$, we measure it in a specific state $|\\Psi\\rangle$**. We will get $\\lambda_{1}$ with $\\left|\\left\\langle u_{1} \\mid \\psi\\right\\rangle\\right|^{2}$\n",
        "\n",
        "* So what we get as result depends (1) on the intrinsic properties $\\mathcal{A}$ with its Eigenvalues and Eigenstates,  and (b) on the specific state $|\\Psi\\rangle$ in which our system is.\n",
        "\n",
        "* So with postulate 4: rather then telling us the precise outcome of a measurement it tells us the probability associated with any given outcome\n",
        "\n",
        "> $\\begin{array}{cccccc} \\hat{A}: \\quad  & \\lambda_{1} & \\lambda_2 & \\lambda_3 & \\lambda_{n} \\\\ & \\left|u_{1}\\right\\rangle & \\left|u_{2}\\right\\rangle & \\left|u_{3}\\right\\rangle & \\left|u_{n}\\right\\rangle \\\\ |\\psi\\rangle: & \\left|\\left\\langle u_{1} \\mid \\psi\\right\\rangle\\right|^{2} & \\left|\\left\\langle u_{2} \\mid \\psi\\right\\rangle\\right|^{2} & \\left|\\left\\langle u_{3} \\mid \\psi\\right\\rangle\\right|^{2} & \\left|\\left\\langle u_{n} \\mid \\psi\\right\\rangle\\right|^{2}\\end{array}$\n",
        "\n",
        "\n",
        "**How does the state $|\\Psi\\rangle$ of a system encodes the possible outcomes of a measurement?**\n",
        "\n",
        "> <font color =\"blue\">$\\hat{A}\\left|u_{n}\\right\\rangle=\\lambda_{n}\\left|u_{n}\\right\\rangle \\longrightarrow P\\left(\\lambda_{n}\\right)=\\left|\\left\\langle u_{n} \\mid \\psi\\right\\rangle\\right|^{2}$</font>\n",
        "\n",
        "* We can write the state $|\\Psi\\rangle$ in a complete basis of our state space and the Eigenstates $u_n$ over Hermitian operator like $\\hat{A}$ provide such a basis\n",
        "\n",
        "* this means we can write $|\\Psi\\rangle$ in the u-Basis (Eigenstates) like this:\n",
        "\n",
        "> $|\\psi\\rangle=\\sum_{n} c_{n}\\left|u_{n}\\right\\rangle$\n",
        "\n",
        "<font color =\"blue\">$\\rightarrow$ $\\left|c_{m}\\right|^{2}$ is the probability and hence $c_n$ the squared root of the probability of a given Eigenvalue for each Eigenstate $\\left|u_{n}\\right\\rangle$ from this part here above:\n",
        "\n",
        "> $\\begin{array}{cccccc} \\hat{A}: \\quad  & \\lambda_{1} & \\lambda_2 & \\lambda_3 & \\lambda_{n} \\\\ & \\left|u_{1}\\right\\rangle & \\left|u_{2}\\right\\rangle & \\left|u_{3}\\right\\rangle & \\left|u_{n}\\right\\rangle \\\\ |\\psi\\rangle: & \\left|\\left\\langle u_{1} \\mid \\psi\\right\\rangle\\right|^{2} & \\left|\\left\\langle u_{2} \\mid \\psi\\right\\rangle\\right|^{2} & \\left|\\left\\langle u_{3} \\mid \\psi\\right\\rangle\\right|^{2} & \\left|\\left\\langle u_{n} \\mid \\psi\\right\\rangle\\right|^{2}\\end{array}$\n",
        "\n",
        "* and these expansion coefficients c which we call **the representation of $|\\Psi\\rangle$ in the u-Basis**, are given by the projection of $|\\Psi\\rangle$ onto the u-Basis states:\n",
        "\n",
        "> $c_{n}=\\left\\langle u_{n} \\mid \\psi\\right\\rangle$\n",
        "\n",
        "* This means we can rewrite the probability p of measuring Eigenvalue $\\lambda_n$ as also equal to absolute value of $c_n$ squared:\n",
        "\n",
        "> $P\\left(\\lambda_{m}\\right)=\\left|\\left\\langle u_{m} \\mid \\psi\\right\\rangle\\right|^{2}=\\left|c_{m}\\right|^{2}$\n",
        "\n",
        "<font color =\"blue\">$\\rightarrow$ For example we will get $\\lambda_{1}$ with probability $\\left|\\left\\langle u_{1} \\mid \\psi\\right\\rangle\\right|^{2}$\n",
        "\n",
        "**What does this mean?**\n",
        "\n",
        "* imagine our system is in state $\\Psi\\rangle$ and we want to measure a property $|\\Psi\\rangle$\n",
        "\n",
        "> $|\\psi\\rangle \\longrightarrow \\hat{A} \\longrightarrow ?$\n",
        "\n",
        "* Then what we do is to write the state $|\\Psi\\rangle$ in the basis of Eigenstates of $\\hat{A}$, and <font color =\"blue\">the expansion coefficient $c_n$ tell us the relative contribution of Eigenstate $|u_n\\rangle$ to state $|\\Psi\\rangle$, which in turn tell us how likely it is to measure the associated Eigenvalue $\\lambda_n$</font>\n",
        "\n",
        "> $|\\psi\\rangle=\\sum_{m} c_{m}\\left|u_{m}\\right\\rangle$\n",
        "\n",
        "* mit $c_{m}=\\left\\langle u_{m} \\mid \\psi\\right\\rangle$\n",
        "\n",
        "> $|\\psi\\rangle=\\sum_{m} \\left\\langle u_{m} \\mid \\psi\\right\\rangle\\left|u_{m}\\right\\rangle$\n",
        "\n",
        "* <font color=\"red\">here you can re-arrange and get an outer product (is this true???)\n",
        "\n",
        "> $|\\psi\\rangle=\\sum_{m} |u_{m}\\rangle \\langle u_{m}| \\psi\\rangle$\n",
        "\n",
        "= create outer product of a certain eigenvector to take a measurement of it\n",
        "\n",
        "Passt zu weiter unten (video prof m mit projection operators):\n",
        "\n",
        "> $(|\\varphi\\rangle\\langle\\psi|)|x\\rangle=|\\varphi\\rangle(\\langle\\psi \\mid x\\rangle)=a|\\varphi\\rangle$\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_199.png)\n",
        "\n",
        "Imagine we have n copies of the state $|\\Psi\\rangle$ and measure each. We get an Eigenvalue from the Eigenvalue equation, but with different probabilities. As p approaches $\\infty$ with N copies (= $p_n$), we will reach the most probable Eigenvalue P($\\lambda_m$) (postulates 4):\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_200.png)\n",
        "\n",
        "**A special case if our system with state $|\\Psi\\rangle$ is in an Eigenstate of the property that we are measuring (the operator $\\hat{A}$, for example momentum, positon etc), say $|u_m\\rangle$**:\n",
        "\n",
        "> $|\\psi\\rangle=\\left|u_{m}\\right\\rangle$\n",
        "\n",
        "* This corresponds to the expansion coefficient $c_m$ = 1, while all other coefficients vanish.\n",
        "\n",
        "* In this particular case we do know with absolute certainty what the outcome of the measurement will be. Probability = 1:\n",
        "\n",
        "> $P\\left(\\lambda_{m}\\right)=\\left|c_{m}\\right|^{2}=1$\n",
        "\n",
        "**This means: If the system is in an Eigenstate of the property that we are measuring (=momentum, position etc, measured by an operator), then the outcome of the measurement is the associated Eigenvalue with probability 1.**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_287.png)"
      ],
      "metadata": {
        "id": "nKVQn725YOeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ***Ket-Bra $|\\psi\\rangle \\langle \\psi | = P$ - Linear Map (Vector-Covector) - Projection Operator***"
      ],
      "metadata": {
        "id": "cyrUknMLo8bl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use Case 1: Projection Operator (Outer Product)**"
      ],
      "metadata": {
        "id": "vmUk0nAHzPCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A measurement outcome is actually a projection (to the first basis vector)**\n",
        "\n",
        "* So if we want to model that we get the outcome 0, then we take the corresponding projection | 0 X 0 | and we apply it on the quantum state: | 0 X 0 | $\\Phi$> bzw. | 0 > < 0 | $\\Phi$ >\n",
        "\n",
        "* this is how you pull out samples from a quantum state and how you apply measurement to this particular probability distribution\n",
        "\n",
        "> The probability of measuring a value with probability amplitude $\\phi$ is $1 \\geq|\\phi|^{2} \\geq 0$, where $|\\cdot|$ is the [modulus](https://en.m.wikipedia.org/wiki/Absolute_value#Complex_numbers).\n",
        "\n",
        "**Ket-Bra (also: Projection Operator, Outer Product or Density Matrix)**\n",
        "\n",
        "* Use Case 1: used for mixed states\n",
        "\n",
        "* Use Case 2: used when I want to measure a specific Eigenstate / Eigenvector to get its probability.\n",
        "\n",
        "* Is a pair: Vector-Covector\n",
        "\n",
        "> $\\mathbf{u v}^{T}=\\left[\\begin{array}{c}u_{1} \\\\ u_{2} \\\\ \\vdots \\\\ u_{n}\\end{array}\\right]\\left[\\begin{array}{llll}v_{1} & v_{2} & \\cdots & v_{n}\\end{array}\\right]$= $\\left[\\left[\\begin{array}{c}u_{1} \\\\ u_{2} \\\\ \\vdots \\\\ u_{n}\\end{array}\\right] v_{1}\\left[\\begin{array}{c}u_{1} \\\\ u_{2} \\\\ \\vdots \\\\ u_{n}\\end{array}\\right] v_{2} \\ldots \\left[\\begin{array}{c}u_{1} \\\\ u_{2} \\\\ \\vdots \\\\ u_{n}\\end{array}\\right] v_{2} \\right]$ = $\\left[\\begin{array}{cccc}u_{1} v_{1} & u_{1} v_{2} & \\cdots & u_{1} v_{n} \\\\ u_{2} v_{1} & u_{2} v_{2} & \\cdots & u_{2} v_{n} \\\\ \\vdots & \\vdots & & \\vdots \\\\ u_{n} v_{1} & u_{n} v_{2} & \\cdots & u_{n} v_{n}\\end{array}\\right]$\n",
        "\n",
        "> $|0\\rangle\\langle 0| =$ $\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]\\left[\\begin{array}{ll}1 & 0\\end{array}\\right]=\\left[\\begin{array}{ll}1 & 0 \\\\ 0 & 0\\end{array}\\right]$\n",
        "\n",
        "* A measurement outcome is actually a projection (to the first basis vector)\n",
        "\n",
        "* If we want to model that we get the outcome 0, then we take the corresponding projection | 0 X 0 | and we apply it on the quantum state: | 0 X 0 | $\\Phi$>. This is how you pull out samples from a quantum state and how you apply measurement to this particular probability distribution\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_307.jpg)\n",
        "\n",
        "From this video: https://youtu.be/U6fn5LvevEE\n",
        "\n",
        "**Example: if you want to measure with which probability the quantum system is in state 0, you apply $|0\\rangle \\langle0|$ operator which is $\\hat{P}=\\left(\\begin{array}{ll}1 & 0 \\\\ 0 & 0\\end{array}\\right)$, because: $|0\\rangle\\langle 0|=\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]\\left[\\begin{array}{ll}1 & 0\\end{array}\\right]=\\left[\\begin{array}{ll}1 & 0 \\\\ 0 & 0\\end{array}\\right]$**\n",
        "\n",
        "* \"Projector\", \"projection\" and \"projection operator\" are the same thing. In quantum mechanics, one usually defines a projection operator as\n",
        "\n",
        "> $\n",
        "\\hat{P}=|\\psi\\rangle\\langle\\psi|\n",
        "$\n",
        "\n",
        "This operator then acts on quantum states (vectors) $|\\Psi\\rangle$ as\n",
        "\n",
        "> $\n",
        "\\hat{P}|\\Psi\\rangle=|\\psi\\rangle\\langle\\psi \\mid \\Psi\\rangle=\\langle\\psi \\mid \\Psi\\rangle|\\psi\\rangle\n",
        "$\n",
        "\n",
        "This is exactly the same as the projector you defined in matrix form, since we can think of $|\\psi\\rangle\\langle\\psi|$ as the diagonal components of a matrix. For example, if $|\\Psi\\rangle=\\alpha|0\\rangle+\\beta|1\\rangle$ and $|\\psi\\rangle=|0\\rangle$, we would find that the projector projects out a particular state\n",
        "\n",
        "> $\n",
        "\\hat{P}|\\Psi\\rangle=\\alpha|0\\rangle\n",
        "$\n",
        "\n",
        "In matrix form this would be exactly the same as what you defined, since now\n",
        "\n",
        "> $\n",
        "\\hat{P}=\\left(\\begin{array}{ll}\n",
        "1 & 0 \\\\\n",
        "0 & 0\n",
        "\\end{array}\\right), \\quad|\\Psi\\rangle=\\left(\\begin{array}{l}\n",
        "\\alpha \\\\\n",
        "\\beta\n",
        "\\end{array}\\right)\n",
        "$\n",
        "\n",
        "And now\n",
        "\n",
        "> $\n",
        "\\hat{P}|\\Psi\\rangle=\\left(\\begin{array}{ll}\n",
        "1 & 0 \\\\\n",
        "0 & 0\n",
        "\\end{array}\\right)\\left(\\begin{array}{l}\n",
        "\\alpha \\\\\n",
        "\\beta\n",
        "\\end{array}\\right)=\\left(\\begin{array}{l}\n",
        "\\alpha \\\\\n",
        "0\n",
        "\\end{array}\\right)\n",
        "$\n",
        "\n",
        "\"Projector\", \"projection\" and \"projection operator\" are the same thing. In quantum mechanics, one usually defines a projection operator as\n",
        "\n",
        "> $\n",
        "\\hat{P}=|\\psi\\rangle\\langle\\psi|\n",
        "$\n",
        "\n",
        "This operator then acts on quantum states (vectors) $|\\Psi\\rangle$ as\n",
        "\n",
        "> $\n",
        "\\hat{P}|\\Psi\\rangle=|\\psi\\rangle\\langle\\psi \\mid \\Psi\\rangle=\\langle\\psi \\mid \\Psi\\rangle|\\psi\\rangle\n",
        "$\n",
        "\n",
        "This is exactly the same as the projector you defined in matrix form, since **we can think of $|\\psi\\rangle\\langle\\psi|$ as the diagonal components of a matrix**. For example, if $|\\Psi\\rangle=\\alpha|0\\rangle+\\beta|1\\rangle$ and $|\\psi\\rangle=|0\\rangle$, we would find that the projector projects out a particular state\n",
        "\n",
        "> $\n",
        "\\hat{P}|\\Psi\\rangle=\\alpha|0\\rangle\n",
        "$\n",
        "\n",
        "In matrix form this would be exactly the same as what you defined, since now\n",
        "\n",
        "> $\n",
        "\\hat{P}=\\left(\\begin{array}{ll}\n",
        "1 & 0 \\\\\n",
        "0 & 0\n",
        "\\end{array}\\right), \\quad|\\Psi\\rangle=\\left(\\begin{array}{l}\n",
        "\\alpha \\\\\n",
        "\\beta\n",
        "\\end{array}\\right)\n",
        "$\n",
        "\n",
        "And now\n",
        "\n",
        "> $\n",
        "\\hat{P}|\\Psi\\rangle=\\left(\\begin{array}{ll}\n",
        "1 & 0 \\\\\n",
        "0 & 0\n",
        "\\end{array}\\right)\\left(\\begin{array}{l}\n",
        "\\alpha \\\\\n",
        "\\beta\n",
        "\\end{array}\\right)=\\left(\\begin{array}{l}\n",
        "\\alpha \\\\\n",
        "0\n",
        "\\end{array}\\right)\n",
        "$\n",
        "\n",
        "https://physics.stackexchange.com/questions/394258/what-is-the-standard-definition-of-projector-projection-and-projection-ope\n",
        "\n",
        "The density matrix is a representation of a linear operator called the density operator. The density matrix is obtained from the density operator by choice of basis in the underlying space. In practice, the terms density matrix and density operator are often used interchangeably.\n",
        "\n",
        "In operator language, a density operator for a system is a positive semidefinite, Hermitian operator of trace one acting on the Hilbert space of the system. This definition can be motivated by considering a situation where a pure state $\\left|\\psi_{j}\\right\\rangle$ is prepared with probability $p_{j}$, known as an ensemble. The probability of obtaining projective measurement result $m$ when using projectors $\\Pi_{m}$ is given by\n",
        "\n",
        "> $\n",
        "p(m)=\\sum_{j} p_{j}\\left\\langle\\psi_{j}\\left|\\Pi_{m}\\right| \\psi_{j}\\right\\rangle=\\operatorname{tr}\\left[\\Pi_{m}\\left(\\sum_{j} p_{j}\\left|\\psi_{j}\\right\\rangle\\left\\langle\\psi_{j}\\right|\\right)\\right]\n",
        "$\n",
        "\n",
        "which makes the density operator, defined as\n",
        "\n",
        "> <font color=\"red\">$\n",
        "\\rho=\\sum_{j} p_{j}\\left|\\psi_{j}\\right\\rangle\\left\\langle\\psi_{j}\\right|\n",
        "$\n",
        "\n",
        "= probability of getting a state |0> for example with outer product / density matrix $\\hat{P}=\\left(\\begin{array}{ll}1 & 0 \\\\ 0 & 0\\end{array}\\right)$ PLUS probability of getting state |1> etc."
      ],
      "metadata": {
        "id": "5bWbx2kRFnsl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\">*Projection Operator (Outer Product) & Eigenvalues in Systems of Linear Equations (HHL)*\n",
        "\n",
        "Problem Statement:\n",
        "\n",
        "> $A|x\\rangle=|b\\rangle \\quad$ (System of linear equations in a quantum state)\n",
        "\n",
        "And we want to find this:\n",
        "\n",
        ">$\n",
        "|x\\rangle=A^{-1}|b\\rangle \\quad \\text { (the solution is: }|x\\rangle=\\sum_{j=0}^{N-1} \\lambda_{j}^{-1} b_{j}\\left|u_{j}\\right\\rangle \\text { ) }\n",
        "$\n",
        "\n",
        "We need to find the inverse matrix $A^{-1}$. We can get the matrix inverse via eigendecomposition. Since $A$ is Hermitian (normal!), it has a spectral decomposition:\n",
        "\n",
        "> <font color=\"blue\">$\n",
        "A=\\sum_{j=0}^{N-1} \\lambda_{j}\\left|u_{j}\\right\\rangle\\left\\langle u_{j}\\right|, \\quad \\lambda_{j} \\in \\mathbb{R}\n",
        "$\n",
        "\n",
        "(if I want to know get the Eigenvector from a measurement, I create the outer product / density matrix of the Eigenvector like above. this is like a measurement)\n",
        "\n",
        "where $\\left|u_{j}\\right\\rangle$ is the $j^{t h}$ eigenvector of $A$ with respective eigenvalue $\\lambda_{j}$. Then,\n",
        "\n",
        "> $\n",
        "A^{-1}=\\sum_{j=0}^{N-1} \\lambda_{j}^{-1}\\left|u_{j}\\right\\rangle\\left\\langle u_{j}\\right|\n",
        "$"
      ],
      "metadata": {
        "id": "MXGA0EYlF9iP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\">**Case 1 - Bra-Ket (Inner Product)**: *I want to know the Eigenvalue of an observable (but I don't know which is the most probable Eigenvector)? Then I apply an operator to the quantum state (position operator, momentum operator etc). I will get the most probable Eigenvector / Eigenstate with an according Eigenvalue*\n",
        "\n",
        "> $\\hat{A}\\left|u_{n}\\right\\rangle=\\lambda_{n}\\left|u_{n}\\right\\rangle \\longrightarrow P\\left(\\lambda_{n}\\right)=\\left|\\left\\langle u_{n} \\mid \\psi\\right\\rangle\\right|^{2}=\\left|c_{n}\\right|^{2}$\n",
        "\n",
        "= apply a certain operator (=observable) on a quantum state and you get the Eigenvalue of this state (here u can also be considered the eigenstate / eigenvector)\n",
        "\n",
        "<font color=\"blue\">**Case 2 - Ket-Bra (Outer Product)**: *I want to measure a specific Eigenstate / Eigenvector to get its probability? Then I take the outer product / density matrix of the desired outcome and make a measurement on the quantum state / system (=project it onto the desired Eigenvector)*\n",
        "\n",
        "> $|\\psi\\rangle=\\sum_{m} c_{m}\\left|u_{m}\\right\\rangle$\n",
        "\n",
        "*  mit $c_{m}=\\left\\langle u_{m} \\mid \\psi\\right\\rangle$\n",
        "\n",
        "> $|\\psi\\rangle=\\sum_{m}\\left\\langle u_{m} \\mid \\psi\\right\\rangle\\left|u_{m}\\right\\rangle$\n",
        "\n",
        "* here you can re-arrange and get an outer product (true?):\n",
        "\n",
        "> $\n",
        "|\\psi\\rangle=\\sum_{m}\\left|u_{m}\\right\\rangle\\left\\langle u_{m} \\mid \\psi\\right\\rangle$\n",
        "\n",
        "= create outer product of a certain eigenvector to take a measurement of it\n",
        "\n",
        "\n",
        "* Passt zu weiter unten (video prof $m$ mit projection operators):\n",
        "\n",
        "> $\n",
        "(|\\varphi\\rangle\\langle\\psi|)|x\\rangle=|\\varphi\\rangle(\\langle\\psi \\mid x\\rangle)=a|\\varphi\\rangle\n",
        "$\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_250.png)\n",
        "\n",
        "Video: [Projection operators in quantum mechanics](https://www.youtube.com/watch?v=M9V4hhqyrKQ)\n",
        "\n",
        "> **Projection Operators project one quantum state on another or onto a subspace of the state space**\n",
        "\n",
        "* for example: when we measure a property of a quantum particle, then the state of the particle collapses onto a different state\n",
        "\n",
        "* the projection operator mathematically describes this collapse\n",
        "\n",
        "> **projection operator associated with a Ket Psi: $| \\Psi \\rangle$ is the outer product of psi with itself: $|\\Psi\\rangle \\langle \\Psi|$**\n",
        "\n",
        "* then we check what it does on an arbirary state phi\n",
        "\n",
        "* the projection operator projects an arbitrary state (here Phi) onto the reference state (here Psi).\n",
        "\n",
        "* the proportionality constant C is given by the overlap between the initial state phi and the state psi that defines the projection operator\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_264.png)\n",
        "\n",
        "Properties of the projection operator:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_265.png)\n",
        "\n",
        "Eigenvalues and Eigenstates of Projection operator:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_266.png)\n",
        "\n",
        "The Projection operator allows us to write any Ket as a sum of two other Kets:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_267.png)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_268.png)\n",
        "\n",
        "One common way in which the projection operator is used in quantum mechanics is to project onto a subspace of the whole state space.\n",
        "\n",
        "* Most convenient way to write this down is in terms of basis states of our state space.\n",
        "\n",
        "* For a basis u we consider a subset of basis states u1, to un which soon an n-dimensional subspace of the full state space.\n",
        "\n",
        "* We then write the projection operator onto this n-dimensional subspace as pn\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_269.png)\n",
        "\n",
        "Summary:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_270.png)\n",
        "\n",
        "**Projective measurement (PVM - Projection-valued measure)**\n",
        "\n",
        "* See [this article](https://en.m.wikipedia.org/wiki/Measurement_in_quantum_mechanics#Projective_measurement) and longer article on [PVM](https://en.m.wikipedia.org/wiki/Projection-valued_measure)\n",
        "\n",
        "* The eigenvectors of a von Neumann observable form an orthonormal basis for the Hilbert space, and each possible outcome of that measurement corresponds to one of the vectors comprising the basis. A density operator is a positive-semidefinite operator on the Hilbert space whose trace is equal to 1.\n",
        "\n",
        "> <font color =\"red\">**For each measurement that can be defined, the probability distribution over the outcomes of that measurement can be computed from the density operator. The procedure for doing so is the Born rule, which states that**</font>\n",
        "\n",
        "> $\n",
        "P\\left(x_{i}\\right)=\\operatorname{tr}\\left(\\Pi_{i} \\rho\\right)\n",
        "$\n",
        "\n",
        "* where $\\rho$ is the density operator, and $\\Pi_{i}$ is the [projection operator](https://en.m.wikipedia.org/wiki/Projection_(linear_algebra)) onto the basis vector corresponding to the measurement outcome $x_{i}$.\n",
        "\n",
        "* The average of the eigenvalues of a von Neumann observable, weighted by the Born-rule probabilities, is the [expectation value](https://en.m.wikipedia.org/wiki/Expectation_value_(quantum_mechanics)) of that observable. For an observable $A$, the expectation value given a quantum state $\\rho$ is\n",
        "\n",
        ">$\n",
        "\\langle A\\rangle=\\operatorname{tr}(A \\rho)\n",
        "$\n",
        "\n",
        "* A density operator that is a rank-1 projection is known as a pure quantum state, and all quantum states that are not pure are designated mixed. Pure states are also known as wavefunctions."
      ],
      "metadata": {
        "id": "qy0sjtMGU9XY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0kD-s4t82ez"
      },
      "source": [
        "###### ***Ket-Bra $|\\psi\\rangle \\langle \\psi |$ - Mixed States (Density Matrix)***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Use Case 2: Mixed States (Density Matrix)***\n",
        "\n",
        "Die [Quantenstatistik](https://de.m.wikipedia.org/wiki/Quantenstatistik) wendet zur Untersuchung makroskopischer Systeme die Methoden und Begriffe der klassischen statistischen Physik an und berücksichtigt zusätzlich die quantenmechanischen Besonderheiten im Verhalten der Teilchen.\n",
        "\n",
        "Wie die Quantenmechanik berücksichtigt auch die Quantenstatistik die folgende doppelte Unkenntnis:\n",
        "\n",
        "> 1. Kennt man den Zustand eines Systems genau – liegt also ein **reiner Zustand (pure state)** vor – und ist dieser kein Eigenzustand der Observablen, so kann man den Messwert einer Einzelmessung dennoch nicht exakt vorhersagen.\n",
        "\n",
        "* A pure state can be written in terms of a Ket state $|\\psi\\rangle$ $\\doteq$ $\\left[\\begin{array}{l}a_{0} \\\\ a_{1}\\end{array}\\right]$\n",
        "\n",
        "  * <font color =\"blue\">$|\\psi\\rangle$</font> $=\\sum_{i} c_{i}\\left|\\varphi_{i}\\right\\rangle$\n",
        "\n",
        "  * Spin up or spin down = **pure states**, can be written as a single wave function $\\mid \\psi\\rangle$.\n",
        "\n",
        "> 2. Kennt man den Zustand des Systems nicht genau, so muss von einem **gemischten Zustand (mixed state)** ausgegangen werden. Ebenso: when one wants to describe a physical system which is entangled with another, as its state can not be described by a pure state. For mixed states with noise in qubits.\n",
        "\n",
        "* A mixed state can be described with a density matrix:\n",
        "\n",
        "  * <font color =\"blue\">$\\rho$ </font>$=\\sum_{i} p_{i}\\left|\\varphi_{i} \\times \\varphi_{i}\\right|$\n",
        "  * Sum over probabilities times the corresponding projection operators onto certain basis states $\\varphi_{i}$\n",
        "\n",
        "  * It allows for the calculation of the probabilities of the outcomes of any measurement performed upon this system, using the Born rule.\n",
        "\n",
        "**There are two more ways to distinguish a pure state from a mixed state:**\n",
        "\n",
        "1. Take the trace of the square of the density matrix:\n",
        "\n",
        "  * $\\operatorname{Tr}\\left[\\rho^{2}\\right]=1 \\rightarrow$ Pure state (like Summe der Eigenwerte entlang der Spur: 1-0-0-0..)\n",
        "\n",
        "  * $\\operatorname{Tr}\\left[\\rho^{2}\\right]< 1 \\rightarrow$ Mixed state. <font color=\"red\">But in the examples below the trace is always = 1? (and some off-diagonal elements)</font>\n",
        "\n",
        "2. Geometricaly, pure states lie on the surface of the Blochsphere. Mixed states are confined within the Bloch sphere.\n",
        "\n",
        "> $\n",
        "\\begin{array}{c|c|c}\n",
        "& \\begin{array}{c}\n",
        "\\text { Pure } \\\\\n",
        "\\text { State }\n",
        "\\end{array} & \\begin{array}{c}\n",
        "\\text { Mixed } \\\\\n",
        "\\text { State }\n",
        "\\end{array} \\\\\n",
        "\\hline \\begin{array}{c}\n",
        "\\text { Density } \\\\\n",
        "\\text { Matrix } \\\\\n",
        "|\\psi\\rangle\\langle\\psi|\n",
        "\\end{array} & \\color{green} ✔ & \\color{green}✔ \\\\\n",
        "\\hline \\begin{array}{c}\n",
        "\\text { Wave } \\\\\n",
        "\\text { Function } \\\\\n",
        "|\\Psi\\rangle\n",
        "\\end{array} & \\color{green}✔ & \\color{red} ❌\n",
        "\\end{array}\n",
        "$\n",
        "\n",
        "**Why do we need this alternative formalism, these density matrices?**\n",
        "\n",
        "* To illustrate the difference, think about this Ket $|\\psi\\rangle$, which is the equal superposition of 0 and 1. We can write out the vector form $\\left[\\begin{array}{l}1 / \\sqrt{2} \\\\ 1 / \\sqrt{2}\\end{array}\\right]$. And if we write the corresponding $\\rho$, it will have 0.5 for every element in the matrix.\n",
        "\n",
        "> $|\\psi\\rangle=\\frac{1}{\\sqrt{2}}(|0\\rangle+(1\\rangle)=\\left[\\begin{array}{l}1 / \\sqrt{2} \\\\ 1 / \\sqrt{2}\\end{array}\\right] \\rightarrow $$\\rho=\\left[\\begin{array}{ll}0.5 & 0.5 \\\\ 0.5 & 0.5\\end{array}\\right]$\n",
        "\n",
        "* On the other hand if we create the uniform distribution over the density matrix corresponding to the 0-Ket and the density matrix corresponding to the 1-Ket, then this density matrix will be different:\n",
        "\n",
        "> $\\rho^{\\prime}=\\frac{1}{2}(|0 \\times 0|+|1 \\times 1|)=\\left[\\begin{array}{ll}0.5 & 0 \\\\ 0 & 0.5\\end{array}\\right]$\n",
        "\n",
        "* It doesn't have off-diagonal elements. These off-diagonal elements are critical for many quantum operations, sometimes also called 'coherences'. This is then called a maximally mixed state = equivalent of a uniform distribution in classical probability theory. This means we have absolutely no predictive power of what's going to happen next. Entropy of the state is maximal.\n",
        "\n",
        "* Ideally we want quantum states with a high coherence, but in reality noise affects, and these coherences disappear.\n",
        "\n",
        "https://www.youtube.com/watch?v=BE8RxAESx5I&list=PLBn8lN0Dcvpla6a6omBni1rjyQJ4CssTP&index=47\n"
      ],
      "metadata": {
        "id": "XKh8o95dlsKS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiVIYzwp82e1"
      },
      "source": [
        "**Explanation 1: Density Matrix for Mixed States**\n",
        "\n",
        "*Source here point 2.1: https://qiskit.org/textbook/ch-quantum-hardware/density-matrix.html*\n",
        "\n",
        "* Let's consider the case where we initialize a qubit in the |0⟩ state, and then apply a Hadamard gate.\n",
        "\n",
        "* **Now, unlike the scenario we described for pure states, this Hadamard gate is not ideal: Due to errors in the quantum-computer hardware, only 80% of the times the state is prepared**, this Hadamard gate produces the desired state:\n",
        "\n",
        "> $\\left|\\psi_{1}\\right\\rangle=\\frac{1}{\\sqrt{2}}(|0\\rangle+|1\\rangle)$\n",
        "\n",
        "* The remaining $20 \\%$ of the times, the pulse applied to rotate the state is either too short or too long by $\\frac{\\pi}{6}$ radians about the $x$-axis. This means that when we use this Hadamard gate, we could end up with following two undesired outcome states:\n",
        "\n",
        ">$\n",
        "\\left|\\psi_{2}\\right\\rangle=\\frac{\\sqrt{3}}{2}|0\\rangle+\\frac{1}{2}|1\\rangle, \\quad\\left|\\psi_{3}\\right\\rangle=\\frac{1}{2}|0\\rangle+\\frac{\\sqrt{3}}{2}|1\\rangle\n",
        "$\n",
        "\n",
        "* The figure below shows the Bloch representation for the three possible states our qubit could take if the short pulse happens 10% of the time, and the long pulse the remaining 10% of the time:\n",
        "\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_198.png)\n",
        "\n",
        "* Since we do not know the outcome of our qubit everytime we prepare it, we can represent it as a mixed state of the form:\n",
        "\n",
        "**Step 1: how do we get the density matrix? - Take the column vector, turn it into a row vector, and then multiply them both:**\n",
        "\n",
        "> $(\\hat{\\rho})$ $=\\left(\\begin{array}{l}1 \\\\ 0\\end{array}\\right) \\times\\left(\\begin{array}{ll}1 & 0\\end{array}\\right)$ = $\\left(\\begin{array}{ll}1 & 0 \\\\ 0 & 0\\end{array}\\right)$\n",
        "\n",
        "in this case:\n",
        "\n",
        "> $\n",
        "\\rho_{H}=\\frac{4}{5}\\left|\\psi_{1}\\right\\rangle\\left\\langle\\psi_{1}\\left|+\\frac{1}{10}\\right| \\psi_{2}\\right\\rangle\\left\\langle\\psi_{2}\\left|+\\frac{1}{10}\\right| \\psi_{3}\\right\\rangle\\left\\langle\\psi_{3}\\right|$\n",
        "\n",
        "* Here, the factors $\\frac{4}{5}, \\frac{1}{10}$ and $\\frac{1}{10}$ correspond to the classical probabilities of obtaining the states $\\left|\\psi_{1}\\right\\rangle,\\left|\\psi_{2}\\right\\rangle$ and $\\left|\\psi_{3}\\right\\rangle$, respectively.\n",
        "\n",
        "**Step 2: Add the matrices together**: By replacing each of these three possible state vectors into  $\\rho$ , we can find the density matrix that represents this mixture:\n",
        "\n",
        "> $\\rho_{H}=\\frac{4}{5}\\left[\\begin{array}{ll}\\frac{1}{2} & \\frac{1}{2} \\\\ \\frac{1}{2} & \\frac{1}{2}\\end{array}\\right]+\\frac{1}{10}\\left[\\begin{array}{cc}\\frac{3}{4} & \\frac{\\sqrt{3}}{4} \\\\ \\frac{\\sqrt{3}}{4} & \\frac{1}{4}\\end{array}\\right]+\\frac{1}{10}\\left[\\begin{array}{cc}\\frac{1}{4} & \\frac{\\sqrt{3}}{4} \\\\ \\frac{\\sqrt{3}}{4} & \\frac{3}{4}\\end{array}\\right]$\n",
        "$\\rho_{H}=\\left[\\begin{array}{cc}\\frac{1}{2} & \\frac{\\sqrt{3}}{20}+\\frac{2}{5} \\\\ \\frac{\\sqrt{3}}{20}+\\frac{2}{5} & \\frac{1}{2}\\end{array}\\right]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wWPEnYF82e2"
      },
      "source": [
        "**Explanation 2: Density Matrix for Mixed States**\n",
        "\n",
        "*Source: Parth G: https://www.youtube.com/watch?v=ZAOc4eMTQiw*\n",
        "\n",
        "* **Pain Point**:  when we see this notation for two states spin up and spin down: $|\\psi\\rangle=\\frac{1}{\\sqrt{2}}|\\uparrow\\rangle+\\frac{1}{\\sqrt{2}}|\\downarrow\\rangle$ we think of it as being in a superposition of both states. But sometimes we don't know if the system is actually in this superposition, or not already collapsed to one.\n",
        "\n",
        "* So, in practice before we measure a system, it can be in following three states, because we lack information about it. This is a mixed state:\n",
        "\n",
        "  * 33% probability: $|\\psi\\rangle=\\mid \\uparrow>$\n",
        "\n",
        "  * 33% probability: $|\\psi\\rangle=\\mid \\downarrow>$\n",
        "\n",
        "  * 33% probability: $|\\psi\\rangle=\\frac{1}{\\sqrt{2}}|\\uparrow\\rangle+\\frac{1}{\\sqrt{2}}|\\downarrow\\rangle$\n",
        "\n",
        "* **Mixed state**: lack of information about the system, hence for example giving equal probability to each possible outcome.\n",
        "\n",
        "* **When dealing with a mixed state we need to represent it with what's known as a density operator or density matrix**.\n",
        "\n",
        "* Wave function notation $|\\psi\\rangle$ can only be used to describe pure states. But density matrices $|\\psi\\rangle\\langle\\psi|$ can be used to describe mixed and pure states.\n",
        "\n",
        "* and how do we get the density matrix? - Take the column vector, turn it into a row vector, and then multiply them both:\n",
        "\n",
        "> $(\\hat{\\rho})$ $=\\left(\\begin{array}{l}1 \\\\ 0\\end{array}\\right) \\times\\left(\\begin{array}{ll}1 & 0\\end{array}\\right)$ = $\\left(\\begin{array}{ll}1 & 0 \\\\ 0 & 0\\end{array}\\right)$\n",
        "\n",
        "On top of that you can even add several mixed states to get one final mixed states. Mixed state: our knowledge of the system is limited. It could be either one of multiple psi states.\n",
        "\n",
        "* Image 1: We have to add up the density matrices of each possible spin state whilst making sure that we weight it with the probability of it being in that psi state\n",
        "\n",
        "* Image 2: That would give us the final density matrix, which is the mixture in the mixed state.\n",
        "\n",
        "* Image 3: it is for this reason that there is no way to write a mixed state as a single wave function or a single vector. We have to deal with matrices that represent the different pure states in which our system could be. And each of these density matrices has to be weighted by how likely it is that our system is on that pure that.\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_006a.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GXuS8c94Iay"
      },
      "source": [
        "###### ***Ket-Bra $|\\psi\\rangle \\langle \\psi |$ - Expectation Values***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An observable in quantum mechanics is represented by a Hermitian operator. The spectral norm (or operator norm) of a Hermitian operator is equal to its largest eigenvalue in absolute value."
      ],
      "metadata": {
        "id": "5cVUHgYvHoiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\">**<u>Density matrix formalism</u> to calculate Expectation Values**\n",
        "\n",
        "\n",
        "* [Expectation value](https://en.m.wikipedia.org/wiki/Expectation_value_(quantum_mechanics)): The average of the eigenvalues of a von Neumann observable, weighted by the Born-rule probabilities, is the expectation value of that observable. What is the average value of quantum measurement outcomes?\n",
        "\n",
        "* Large number of particle interactions when we are trying to measure a total effect from an aggregation of subatomic particles: run an experiment involving the observation of energy levels in a type of atom N times under fixed conditions. The expectation value e of the experiment turns out to be an illegitimate energy level for that atom, but E = Ne will give the correct total energy assuming N is large enough.\n",
        "\n",
        "* Expectation value of an observable $Q$ (like the momentum of a particle) in a (normalized) state $|\\Psi\\rangle$ gives the average of all possible values (weighted by their corresponding probabilities) that one may expect to observe in an experiment designed to measure $Q$ in state $|\\Psi\\rangle$ over many experiments where the average of all values of $Q$ will approach the expectation value $\\langle\\Psi|Q| \\Psi\\rangle$ (one set of measurement perturbs the system)"
      ],
      "metadata": {
        "id": "NWbNfdo0aS0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\">**First: The expectation value of an operator $Q$ is given by $\\langle Q\\rangle=\\langle\\psi|Q| \\psi\\rangle$ = $\\sum_{n} \\lambda_{n}\\left|\\left\\langle u_{n} \\mid \\psi\\right\\rangle\\right|^{2}$(spectral decomposition)**</font>\n",
        "\n",
        "* Given a state vector for a pure state $|s\\rangle$, with its complex-conjugate transpose is $\\langle s|$, the operator whose expectation value you are evaluating could be written $|A|$ and $|s\\rangle$ has a component which is a $\\lambda$-eigenstate for $A$.\n",
        "\n",
        "\n",
        "* A mixture of states is a weighted average of such operators, and its expectation value is the weighted average of the expectation values of the pure states.\n",
        "\n",
        "* Suppose, $\\left|\\psi_{1}\\right\\rangle,\\left|\\psi_{2}\\right\\rangle, \\ldots$ be the orthonormal basis of eigenstates of observable $Q$ with corresponding eigenvalues $\\lambda_{1}, \\lambda_{2}, \\ldots$ respectively. One can expand the given (normalized) state $|\\Psi\\rangle$ in the above basis as\n",
        "\n",
        "> $\n",
        "|\\Psi\\rangle=\\alpha_{1}\\left|\\psi_{1}\\right\\rangle+\\alpha_{2}\\left|\\psi_{2}\\right\\rangle+\\cdots+\\alpha_{n}\\left|\\psi_{n}\\right\\rangle+\\ldots\n",
        "$\n",
        "\n",
        "* According to a basic postulate of Quantum mechanics the above expansion implies that upon measuring $Q$ in state $|\\Psi\\rangle$ the outcome of the experiment will be eigenvalue $\\lambda_{1}$ with probability $\\left|\\alpha_{1}\\right|^{2}$, eigenvalue $\\lambda_{2}$ with probability $\\left|\\alpha_{2}\\right|^{2}$ and so on. The (weighted) average of all possible values of $Q$ that can be observed in state $|\\Psi\\rangle$ will be the expectation value of $Q$ in state $|\\Psi\\rangle$:\n",
        "\n",
        "> <font color=\"blue\">$\\sum_{n} \\lambda_{n}\\left|\\left\\langle u_{n} \\mid \\psi\\right\\rangle\\right|^{2}$ = $\\left|\\alpha_{1}\\right|^{2} \\lambda_{1}+\\left|\\alpha_{2}\\right|^{2} \\lambda_{2}+\\ldots =\\left\\langle\\alpha_{1} \\psi_{1}+\\alpha_{2} \\psi_{2}+\\ldots| \\, | \\lambda_{1} \\alpha_{1} \\psi_{1}+\\lambda_{2} \\alpha_{2} \\psi_{2}+\\ldots\\right\\rangle =\\left\\langle\\alpha_{1} \\psi_{1}+\\alpha_{2} \\psi_{2}+\\ldots|Q| \\alpha_{1} \\psi_{1}+\\alpha_{2} \\psi_{2}+\\ldots\\right\\rangle =\\langle\\Psi|Q| \\Psi\\rangle$\n",
        "\n",
        "* This is because operator $Q$ can be written as a sum over its Eigenvalues $a_i$ times projection operators onto its Eigenstates.\n",
        "\n",
        "> $Q=\\sum_{i} \\lambda_{n} \\left| u_{n} \\rangle \\langle \\ u_{n}\\right|$ $\\quad$ with $Q\\left| u_{n}\\right\\rangle= \\lambda_{n}\\left| u_{n}\\right\\rangle$\n",
        "\n",
        "* By using decomposition in the definition of the expectation value, we get this result:\n",
        "\n",
        "> $\\langle Q\\rangle_{\\psi}=\\langle\\psi|Q| \\psi\\rangle=$ $\\sum_{i} \\lambda_{n}\\langle\\psi| u_{n} \\rangle $ <font color =\"orange\">$\\langle u_{u}| \\psi \\rangle$</font> $=\\sum_{i} \\lambda_{n}$ <font color =\"blue\">$\\left|\\left\\langle u_{n} \\mid \\psi\\right\\rangle\\right|^{2}$</font>\n",
        "\n",
        "* We sum over all Eigenvalues, which are the possible outcomes of a measurement, weighted by the probabilities that this particular Eigenvalue occurs if we start in the state $\\Psi$.\n",
        "\n",
        "  * <font color =\"orange\">$\\langle u_{n} | \\psi\\rangle$</font> - this is called the **transition amplitude**\n",
        "\n",
        "  * <font color =\"blue\">$|\\langle u_{n} | \\psi\\rangle|^{2}$</font> - this is called the **transition probability** (absolute square of the transition amplitude)\n",
        "\n",
        "> $\\langle\\hat{A}\\rangle$ $=\\sum_{n} \\lambda_{n} P\\left(\\lambda_{n}\\right)$ and since: $P\\left(\\lambda_{n}\\right)=\\left|\\left\\langle u_{n} \\mid \\psi\\right\\rangle\\right|^{2}=\\left|c_{n}\\right|^{2}$:\n",
        "\n",
        "> $\\langle\\hat{A}\\rangle$ $=\\sum_{n} \\lambda_{n} \\left|c_{n}\\right|^{2}$</font>\n",
        "\n",
        "> $\\langle\\hat{A}\\rangle$ $=\\sum_{n} \\lambda_{n} \\left|\\left\\langle u_{n} \\mid \\psi\\right\\rangle\\right|^{2}$</font>\n",
        "\n",
        "\n",
        "> $|\\psi\\rangle \\longrightarrow\\langle\\hat{A}\\rangle_{\\psi}=\\langle\\hat{A}\\rangle=\\sum_{n} \\lambda_{n} P\\left(\\lambda_{n}\\right)$ <font color =\"blue\">$=\\sum_{n} \\lambda_{n}\\left|\\left\\langle u_{n} \\mid \\psi\\right\\rangle\\right|^{2}$\n",
        "\n",
        "* <font color =\"blue\">$\\rightarrow$ die Summe der Eigenwerte $\\lambda_{n}$ jeweils multipliziert mit der Wahrscheinlichkeit $P\\left(\\lambda_{n}\\right) = \\left|\\left\\langle u_{n} \\mid \\psi\\right\\rangle\\right|^{2}$, den jeweiligen Eigenwert zu erhalten = Expectation Value</font>\n",
        "\n",
        "* Beispielrechnung mit interessantem Ergebnis: Eigenwert -1 mit Amplitude 0.25 und Eigenwert +1 mit Amplitude 0.25\n",
        "\n",
        "  * = $(-1) * (0.25)^2$ + $(+1) * (0.25)^2$\n",
        "\n",
        "  * = $(-1) * (0,5)$ + $(+1) * (0.5)$ = -0.5 + 0.5\n",
        "\n",
        "  * = 0 $\\rightarrow$ Expectation value, aber kein erlaubtes physikalisches Ergebnis.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Im0HXIwpZSfq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\">**Second: The expectation value $\\langle \\psi|A| \\psi\\rangle$ can be evaluated as the trace of $|\\psi\\rangle\\langle \\psi| A$.**</font>\n",
        "\n",
        "* The operator $|\\psi\\rangle\\langle \\psi|$ is an operator of trace 1, and the operator $|\\psi\\rangle\\langle \\psi|$ is an operator of trace 1.\n",
        "\n",
        "* $\\rho = |\\psi\\rangle \\langle \\psi|$ is an operator of trace=1. We can calculate the expectation value of $A$ by taking the trace over $\\rho$ times $A$:\n",
        "\n",
        "> **$\\langle A\\rangle_{\\rho}:= \\langle \\psi|A| \\psi\\rangle = \\operatorname{Tr}[\\rho A] =\\operatorname{Tr}[\\, |\\psi\\rangle \\langle \\psi| \\, A]$**</font>\n",
        "\n",
        "* Taking the trace over an operator means to sum over the matrix elements of that operator between states of a complete basis $\\operatorname{Tr}[B]=\\sum_{i}\\left\\langle\\eta_{i}|B| \\eta_{i}\\right\\rangle$. We are adding $\\rho = |\\psi\\rangle \\langle \\psi|$ and move the two complex numbers $\\eta$, since they are not operators:\n",
        "\n",
        "> $\\langle A\\rangle_{\\rho}:=\\operatorname{Tr}[\\rho A]$ = $\\sum_{i} {\\left\\langle\\eta_{i}\\right| \\psi \\rangle}{\\left\\langle\\psi|A| \\eta_{i}\\right\\rangle}$\n",
        "\n",
        "* We sum over the basis states. Since $| \\eta_{i} \\rangle \\langle \\eta_{i} |$ = 1, we get $\\langle\\psi|A| \\psi\\rangle$, which is the same result from working with density matrices:\n",
        "\n",
        "> $\\sum_{i}\\left\\langle\\psi|A| \\eta_{i} \\rangle \\langle \\eta_{i} | \\psi\\right\\rangle$ = $\\langle\\psi|A| \\psi\\rangle=\\langle A\\rangle_{\\psi}$\n"
      ],
      "metadata": {
        "id": "taewaWhtaMqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_195.png)"
      ],
      "metadata": {
        "id": "lX-bFe39aNwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_201.png)"
      ],
      "metadata": {
        "id": "RyU5akyieNvl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Eigenvalues, Observables & Operators*"
      ],
      "metadata": {
        "id": "gXZXzSSsrrUL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpO0HLIBkdmU"
      },
      "source": [
        "> <font color=\"blue\">**<u>Postulate II of quantum mechanics</u>: a physical quantity $\\mathcal{A}$ is associated with a hermitian operator $\\hat{A}$, that is called an observable.**\n",
        "\n",
        "> <font color=\"blue\">**<u>Postulate III of quantum mechanics</u>: The result of a measurement of a physical quantity is one of the Eigenvalues of the associated observable.**\n",
        "\n",
        "Video: [Eigenvalues and eigenstates in quantum mechanics](https://www.youtube.com/watch?v=p1zg-c1nvwQ)\n",
        "\n",
        "> We consider the action of $\\hat{A}$ on a special Ket $|\\Psi\\rangle$ such that the only way in which $\\hat{A}$ changes $|\\Psi\\rangle$ is by scaling it by a constant and we obtain $\\lambda |\\Psi\\rangle$\n",
        "\n",
        "The Eigenvector of an operator are those special directions in the vector space which the operator doesn't change.\n",
        "\n",
        "The probability of each eigenvalue is related to the projection of the physical state on the subspace related to that eigenvalue.\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Operator_(physics)#Operators_in_quantum_mechanics\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_257.png)\n",
        "\n",
        "> [C$*$-algebras](https://en.m.wikipedia.org/wiki/C*-algebra) were first considered primarily for their use in quantum mechanics **to model algebras of physical observables**. This line of research began with Werner Heisenberg's matrix mechanics and in a more mathematically developed form with Pascual Jordan around 1933. See also [Quantum Group](https://en.m.wikipedia.org/wiki/Quantum_group).\n",
        "\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_251.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Anti-)Commutators, Quantum Numbers und \"Vollständiger Satz kommutierender Observablen\"**\n",
        "\n",
        "Um einen quantenmechanischen Zustand eindeutig zu charakterisieren, sind oft mehrere Observablen notwendig. Beispielsweise ist es beim Wasserstoffatom nicht ausreichend, nur die Energie anzugeben (mittels der Hauptquantenzahl n), sondern es sind zwei weitere Observablen notwendig: der Betrag des Drehimpulses (Quantenzahl l) und die z-Komponente des Drehimpuls (Quantenzahl m). Diese drei Größen bilden dann einen vollständigen Satz kommutierender Observablen.\n",
        "Eine Menge von Observablen A, B, C,... bildet einen v.S.k.O., wenn eine orthonormale Basis des Zustandsraums aus gemeinsamen Eigenvektoren der Observablen existiert, und diese Basis (bis auf einen Phasenfaktor) eindeutig ist.\n",
        "\n",
        "Solch ein Verhalten ist in der Quantenmechanik allerdings eher die Ausnahme. Die meisten Paare von Observablen lassen sich nicht gleichzeitig beliebig genau messen, was eine Konsequenz aus der heisenbergschen Unschärferelation ist. Man spricht dann auch von komplementären Observablen.\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Vollständiger_Satz_kommutierender_Observablen"
      ],
      "metadata": {
        "id": "rRJWyBvzCSAs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc9HeAnZvFPv"
      },
      "source": [
        "**Solving: How to find Eigenvalues and Eigenvectors?**\n",
        "\n",
        "* For an arbitrary operator (except the identity operator) it is generally not possible to figure out the eigenvalues and eigenstates simply by inspection of how the operator acts\n",
        "\n",
        "* More general approach needed:\n",
        "\n",
        "\t* consider basis u that is orthonormal.\n",
        "\n",
        "\t* Then we write the Eigenvalue equation in the u basis (just project both sides of the equation onto the basis states u).\n",
        "\n",
        "\t* next we insert the identity operator after the A operator on left and side\n",
        "\n",
        "\t* then write the resolution of the identity in the u basis\n",
        "\n",
        "\t* then take sum on the beginning\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_260.png)\n",
        "\n",
        "* the equation $\\sum_{j}\\left(A_{i j}-\\lambda \\delta_{i j}\\right) c_{j}=0$ is equivalent to the original Eigenvalue equation $\\hat{A}|\\psi\\rangle=\\lambda|\\psi\\rangle$, but now written in the u representation\n",
        "\n",
        "* finding the eigenvalues and eigenvectors now becomes finding the lambda and c in the new equation = \"matrix diagonalization\"\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_261.png)\n",
        "\n",
        "> **All we really need to do quantum mechanics is to get enough practice in diagonalizing matrices**\n",
        "\n",
        "* we have following operator A and state Psi\n",
        "\n",
        "* we want to find the eigenvalues and eigenvectors of the operator A\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_263.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYnM169ZFHeZ"
      },
      "source": [
        "<font color=\"blue\">**Operators acting on Quantum State Vectors: Matrix-Vector-Multiplication (Single Qubit)**\n",
        "\n",
        "*Applying a Hadamard gate to a single qubit (matrix-vector multiplication) - Simple dot product! You get a vector out.*\n",
        "\n",
        "$H |0\\rangle = \\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right)\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]= \\frac{1}{\\sqrt{2}}\\left[\\begin{array}{ll}1 + 0 \\\\ 1 + 0\\end{array}\\right]=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{c}1 \\\\ 1\\end{array}\\right] = |+\\rangle$\n",
        "\n",
        "$H |1\\rangle = \\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right)\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right]= \\frac{1}{\\sqrt{2}}\\left[\\begin{array}{ll}0 + 1 \\\\ 0 -1\\end{array}\\right]=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{c}1 \\\\ -1\\end{array}\\right] = |-\\rangle$\n",
        "\n",
        "*Diese Zustände können auch mithilfe der Dirac-Notation als Summen von |0⟩ und |1⟩ erweitert werden:*\n",
        "\n",
        "$|+\\rangle=\\frac{1}{\\sqrt{2}}(|0\\rangle+|1\\rangle)$ weil <font color=\"gray\">wegen $|0\\rangle=\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]$ und $|1\\rangle=\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right]$ daher:</font> $\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{ll}1 + 0 \\\\ 0 + 1\\end{array}\\right]=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{c}1 \\\\ 1\\end{array}\\right]$\n",
        "\n",
        "$|-\\rangle=\\frac{1}{\\sqrt{2}}(|0\\rangle-|1\\rangle)$ weil: $\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{ll}1 - 0 \\\\ 0 - 1\\end{array}\\right]=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{c}1 \\\\ -1\\end{array}\\right]$\n",
        "\n",
        "*Zusammenfassend, das ist alles das gleiche, sieht aber komplett anders aus:*\n",
        "\n",
        "<font color=\"blue\">$H |0\\rangle$</font> $ = \\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right)\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right] =\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{c}1 \\\\ 1\\end{array}\\right]$ <font color=\"blue\">$ \\,\\,= |+\\rangle$ = $\\frac{1}{\\sqrt{2}}(|0\\rangle+|1\\rangle)$\n",
        "\n",
        "<font color=\"blue\">$H |1\\rangle$</font>$ = \\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right)\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right]=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{c}1 \\\\ -1\\end{array}\\right]$ <font color=\"blue\">$ = |-\\rangle$ = $\\frac{1}{\\sqrt{2}}(|0\\rangle-|1\\rangle)$\n",
        "\n",
        "*$|0\\rangle$ und $|1\\rangle$ stellen hier die Basis dar, in der die Quantenzustaende berechnet werden.* ***Man kann allerdings auch eine andere Basis waehlen, zB $|+\\rangle$ und $|-\\rangle$:***\n",
        "\n",
        "$|0\\rangle=\\frac{1}{\\sqrt{2}}(|+\\rangle+|-\\rangle)$ vergleiche: <font color=\"blue\">$|+\\rangle$ = $\\frac{1}{\\sqrt{2}}(|0\\rangle+|1\\rangle)$\n",
        "\n",
        "$|1\\rangle=\\frac{1}{\\sqrt{2}}(|+\\rangle-|-\\rangle)$ vergleiche: <font color=\"blue\">$|-\\rangle$ = $\\frac{1}{\\sqrt{2}}(|0\\rangle-|1\\rangle)$\n",
        "\n",
        "*Applying an Identity Operator:*\n",
        "\n",
        "$I |0\\rangle = \\left(\\begin{array}{cc}1 & 0 \\\\ 0 & 1\\end{array}\\right)\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]= \\left[\\begin{array}{ll}1 + 0 \\\\ 0 + 0\\end{array}\\right]=\\left[\\begin{array}{c}1 \\\\ 0\\end{array}\\right]$\n",
        "\n",
        "$I |1\\rangle = \\left(\\begin{array}{cc}1 & 0 \\\\ 0 & 1\\end{array}\\right)\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right]= \\left[\\begin{array}{ll}0 + 0 \\\\ 0 + 1\\end{array}\\right]=\\left[\\begin{array}{c}0 \\\\ 1\\end{array}\\right]$\n",
        "\n",
        "*Applying a Pauli-X Operator:*\n",
        "\n",
        "$X|0\\rangle=\\left[\\begin{array}{ll}0 & 1 \\\\ 1 & 0\\end{array}\\right]\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]=\\left[\\begin{array}{ll}0 + 0 \\\\ 1 + 0\\end{array}\\right]=\\left[\\begin{array}{l}0 \\\\ 1\\end{array}\\right]$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTK-u1Q4nrGv"
      },
      "source": [
        "<font color=\"blue\">**Matrix-Vector-Multiplication (Multi Qubit)**\n",
        "\n",
        "> $A \\mathbf{x}=\\left[\\begin{array}{cccc}a_{11} & a_{12} & \\ldots & a_{1 n} \\\\ a_{21} & a_{22} & \\ldots & a_{2 n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ a_{m 1} & a_{m 2} & \\ldots & a_{m n}\\end{array}\\right]\\left[\\begin{array}{c}x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_{n}\\end{array}\\right]=\\left[\\begin{array}{c}a_{11} x_{1}+a_{12} x_{2}+\\cdots+a_{1 n} x_{n} \\\\ a_{21} x_{1}+a_{22} x_{2}+\\cdots+a_{2 n} x_{n} \\\\ \\vdots \\\\ a_{m 1} x_{1}+a_{m 2} x_{2}+\\cdots+a_{m n} x_{n}\\end{array}\\right]$\n",
        "\n",
        "**First create the tensor product of two operators**: For construction of the desired two-qubit gate, you need the same tensor product operation as you used for the vectors. Here where $H_1$ is a one-qubit Hadamard gate in the two-qubit space $(\\hat{H} \\otimes \\mathbf{I})$, where Hadamard is applied only to one Qubit:\n",
        "\n",
        "> $H_{1} \\equiv H_{0} \\otimes I=\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{ll}1\\left(\\begin{array}{ll}1 & 0 \\\\ 0 & 1\\end{array}\\right) & 1\\left(\\begin{array}{ll}1 & 0 \\\\ 0 & 1\\end{array}\\right) \\\\ 1\\left(\\begin{array}{ll}1 & 0 \\\\ 0 & 1\\end{array}\\right) & -1\\left(\\begin{array}{ll}1 & 0 \\\\ 0 & 1\\end{array}\\right)\\end{array}\\right)=\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cccc}1 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & -1 & 0 \\\\ 0 & 1 & 0 & -1\\end{array}\\right)$\n",
        "\n",
        "**Second, apply the new 'tensored' operator on the tensor product of two state vectors**:\n",
        "\n",
        "See the tensor product of two vectors in state $|0\\rangle$:\n",
        "\n",
        "> $|0\\rangle \\otimes|0\\rangle = \\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right] \\otimes\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]=$</font> $\\left[\\begin{array}{l}1\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right] \\\\ 0\\left[\\begin{array}{l}1 \\\\ 0\\end{array}\\right]\\end{array}\\right]=$ <font color=\"blue\">$\\left [\\begin{array}{l}1 \\\\ 0 \\\\ 0 \\\\ 0\\end{array}\\right]$\n",
        "\n",
        "Now applying $H_1$ you mix up the first qubit states and keep the second qubit state unchanged:\n",
        "\n",
        "> $H_{1}(|0\\rangle \\otimes|0\\rangle)=H_{1}\\left(\\begin{array}{l}1 \\\\ 0 \\\\ 0 \\\\ 0\\end{array}\\right)$= <font color=\"blue\">$\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cccc}1 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & -1 & 0 \\\\ 0 & 1 & 0 & -1\\end{array}\\right) \\left(\\begin{array}{l}1 \\\\ 0 \\\\ 0 \\\\ 0\\end{array}\\right)$ = $\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{l}1 \\\\ 0 \\\\ 1 \\\\ 0\\end{array}\\right)$</font>= $\\frac{1}{\\sqrt{2}}(|0\\rangle \\otimes|0\\rangle+|1\\rangle \\otimes|0\\rangle)$\n",
        "\n",
        "**Another way of writing this (=apply H to one qubit only in a 1 qubit in a 2 qubit system) for a joint state of two initialized qubits $\n",
        "|0\\rangle \\otimes|0\\rangle\n",
        "$ is:**\n",
        "\n",
        "> <font color=\"orange\">$\\hat{H}\\left|q_{0}\\right\\rangle \\otimes\\left|q_{1}\\right\\rangle$</font> = $\n",
        "\\mathbf{H}|0\\rangle \\otimes|0\\rangle=\\left(\\frac{1}{\\sqrt{2}}|0\\rangle+\\frac{1}{\\sqrt{2}}|1\\rangle\\right) \\otimes|0\\rangle\n",
        "$\n",
        "\n",
        "The tensor product is distributive, which in this case means it acts much like multiplication:\n",
        "\n",
        ">$\n",
        "\\mathbf{H}|0\\rangle \\otimes|0\\rangle=\\frac{1}{\\sqrt{2}}|0\\rangle \\otimes|0\\rangle+\\frac{1}{\\sqrt{2}}|1\\rangle \\otimes|0\\rangle\n",
        "$\n",
        "\n",
        "See [Tensor_product](https://en.wikipedia.org/wiki/Tensor_product)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z7cDFlh_eL1"
      },
      "source": [
        "<font color=\"blue\">**Matrix-Matrix-Multiplication (Kronecker / Tensor)**\n",
        "\n",
        "Zur Kombination von Operators in einem Timestep (zB H bei qubit 1 und I bei Qubit 2). Two systems being described as a joint system.\n",
        "\n",
        "> $\\left[\\begin{array}{ll}a & b \\\\ c & d\\end{array}\\right] \\otimes\\left[\\begin{array}{ll}e & f \\\\ g & h\\end{array}\\right]=\\left[\\begin{array}{lll}a\\left[\\begin{array}{ll}e & f \\\\ g & h\\end{array}\\right] & b\\left[\\begin{array}{ll}e & f \\\\ g & h\\end{array}\\right] \\\\ c\\left[\\begin{array}{ll}e & f \\\\ g & h\\end{array}\\right] & d\\left[\\begin{array}{llll}e & f \\\\ g & h\\end{array}\\right]\\end{array}\\right]=\\left[\\begin{array}{llll}a e & a f & \\text { be } & b f \\\\ a g & a h & b g & b h \\\\ c e & c f & d e & d f \\\\ c g & c h & d g & d h\\end{array}\\right]$\n",
        "\n",
        "$H \\otimes I=\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right) \\otimes\\left(\\begin{array}{ll}1 & 0 \\\\ 0 & 1\\end{array}\\right)=\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{ll}1\\left(\\begin{array}{ll}1 & 0 \\\\ 0 & 1\\end{array}\\right) & 1\\left(\\begin{array}{ll}1 & 0 \\\\ 0 & 1\\end{array}\\right) \\\\ 1\\left(\\begin{array}{ll}1 & 0 \\\\ 0 & 1\\end{array}\\right) & -1\\left(\\begin{array}{ll}1 & 0 \\\\ 0 & 1\\end{array}\\right)\\end{array}\\right)=\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{rrrr}1 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & -1 & 0 \\\\ 0 & 1 & 0 & -1\\end{array}\\right)$\n",
        "\n",
        "$I \\otimes H=\\left(\\begin{array}{ll}1 & 0 \\\\ 0 & 1\\end{array}\\right) \\otimes \\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right) = \\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cc}1\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right) & 0\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right) \\\\ 0\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right) & 1\\left(\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right)\\end{array}\\right)=\\frac{1}{\\sqrt{2}}\\left(\\begin{array}{cccc}1 & 1 & 0 & 0 \\\\ 1 & -1 & 0 & 0 \\\\ 0 & 0 & 1 & 1 \\\\ 0 & 0 & 1 & -1\\end{array}\\right)$\n",
        "\n",
        "$Y \\otimes X=\\left[\\begin{array}{cc}0 & -i \\\\ i & 0\\end{array}\\right] \\otimes\\left[\\begin{array}{ll}0 & 1 \\\\ 1 & 0\\end{array}\\right]=\\left[\\begin{array}{ll}0\\left[\\begin{array}{ll}0 & 1 \\\\ 1 & 0\\end{array}\\right] & -i\\left[\\begin{array}{ll}0 & 1 \\\\ 1 & 0\\end{array}\\right] \\\\ i\\left[\\begin{array}{ll}0 & 1 \\\\ 1 & 0\\end{array}\\right] & 0\\left[\\begin{array}{ll}0 & 1 \\\\ 1 & 0\\end{array}\\right]\\end{array}\\right]=\\left[\\begin{array}{cccc}0 & 0 & 0 & -i \\\\ 0 & 0 & -i & 0 \\\\ 0 & i & 0 & 0 \\\\ i & 0 & 0 & 0\\end{array}\\right]$\n",
        "\n",
        "$X \\otimes H=\\left[\\begin{array}{ll}0 & 1 \\\\ 1 & 0\\end{array}\\right] \\otimes \\frac{1}{\\sqrt{2}}\\left[\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right]=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{cc}0 \\times\\left[\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right] & 1 \\times\\left[\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right] \\\\ 1 \\times\\left[\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right] & 0 \\times\\left[\\begin{array}{cc}1 & 1 \\\\ 1 & -1\\end{array}\\right]\\end{array}\\right]=\\frac{1}{\\sqrt{2}}\\left[\\begin{array}{cccc}0 & 0 & 1 & 1 \\\\ 0 & 0 & 1 & -1 \\\\ 1 & 1 & 0 & 0 \\\\ 1 & -1 & 0 & 0\\end{array}\\right] =\\left[\\begin{array}{cc}\n",
        "0 & H \\\\\n",
        "H & 0\n",
        "\\end{array}\\right]$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnohitquaGyf"
      },
      "source": [
        "**<font color=\"blue\">Matrix-Matrix-Multiplication (Usual)**\n",
        "\n",
        "> Used in serially wired gates (so NOT gates in one time step - here we use tensor product to combine them, but serial gates!)\n",
        "\n",
        "A line in the circuit is considered as a quantum wire and basically represents a single qubit. The product of operators keeps the same dimension.\n",
        "\n",
        "\n",
        "![ggg](https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Serially_wired_quantum_logic_gates.png/500px-Serially_wired_quantum_logic_gates.png)\n",
        "\n",
        "For example, putting the Pauli X gate after the Pauli Y gate, both of which act on a single qubit, can be described as a single combined gate C:\n",
        "\n",
        ">$\n",
        "C=X \\cdot Y=\\left[\\begin{array}{ll}\n",
        "0 & 1 \\\\\n",
        "1 & 0\n",
        "\\end{array}\\right] \\cdot\\left[\\begin{array}{cc}\n",
        "0 & -i \\\\\n",
        "i & 0\n",
        "\\end{array}\\right]=\\left[\\begin{array}{cc}\n",
        "i & 0 \\\\\n",
        "0 & -i\n",
        "\\end{array}\\right]\n",
        "$\n",
        "\n",
        ">$\n",
        "X \\cdot X=\\left(\\begin{array}{ll}\n",
        "0 & 1 \\\\\n",
        "1 & 0\n",
        "\\end{array}\\right)\\left(\\begin{array}{ll}\n",
        "0 & 1 \\\\\n",
        "1 & 0\n",
        "\\end{array}\\right)=\\left(\\begin{array}{ll}\n",
        "1 & 0 \\\\\n",
        "0 & 1\n",
        "\\end{array}\\right)=I\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M89sYf-N0_6u"
      },
      "source": [
        "<font color=\"blue\">**Hamiltonian Operator $\\mathcal{H}$**\n",
        "\n",
        "> <font color=\"red\">**The sum of the possible outcomes of kinetic and potential energy of this entire system in quantum mechanics is referred to the Hamiltonian $\\mathcal{H}$ (to calculate the lowest total energy of a two atom system)**\n",
        "\n",
        "* der [Hamiltonoperator](https://de.m.wikipedia.org/wiki/Hamiltonoperator) (Energieoperator) ist in der Quantenmechanik ein Operator, **der (mögliche) Energiemesswerte und die Zeitentwicklung angibt = describes the total energy of a system or particle**. <font color=\"red\">Er liefert beispielsweise die Energieniveaus des Elektrons im Wasserstoffatom.</font>\n",
        "\n",
        "* In der Quantenmechanik wird jeder Zustand des betrachteten physikalischen Systems durch einen zugehörigen Vektor $\\psi$ im Hilbertraum angegeben. Seine Zeitentwicklung wird nach der Schrödingergleichung durch den Hamiltonoperator $\\hat{H}$ bestimmt:\n",
        "\n",
        ">$\n",
        "\\mathrm{i} \\hbar \\frac{\\partial}{\\partial t} \\psi(t)=\\hat{H} \\psi(t)\n",
        "$\n",
        "\n",
        "* **For every problem there is a different Hamiltonian and a different corresponding Eigenspectrum**. Spektrum: Bereich der möglichen Messwerte. Eigenvalues = stabile Energielevel = Zustande, die die Elektronen in den Orbitalen beschreiben. Siehe auch [Hamilton-Funktion](https://de.m.wikipedia.org/wiki/Hamilton-Funktion).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MwSGedvzNov"
      },
      "source": [
        "<font color=\"blue\">**Time Evolution Operator $\\mathcal{U}$ bzw. $\\mathcal{T}$**\n",
        "\n",
        "* Der [Zeitentwicklungsoperator](https://de.m.wikipedia.org/wiki/Zeitentwicklungsoperator) $\\mathcal{U}$ bzw. $\\mathcal{T}$ ist ein quantenmechanischer Operator, mit dem sich die zeitliche Entwicklung eines physikalischen Systems berechnen lässt. Siehe auch [Time evolution](https://en.m.wikipedia.org/wiki/Time_evolution)\n",
        "\n",
        "* Der quantenmechanische Operator ist eng verwandt mit dem [Propagator](https://de.m.wikipedia.org/wiki/Propagator) in der Quantenfeld- oder Vielteilchentheorie. Üblicherweise wird er als $U\\left(t, t_{0}\\right)$ geschrieben und bezeichnet die Entwicklung des Systems vom Zeitpunkt $t_{0}$ zum Zeitpunkt $t$.\n",
        "\n",
        "Der Zeitentwicklungsoperator $U\\left(t, t_{0}\\right)$ wird definiert über die Zeitentwicklung eines beliebigen Zustandes $|\\psi\\rangle$ zu einem Zeitpunkt $t_{0}$ bis zum Zeitpunkt $t$ :\n",
        "\n",
        ">$\n",
        "|\\psi(t)\\rangle=U\\left(t, t_{0}\\right)\\left|\\psi\\left(t_{0}\\right)\\right\\rangle \\quad \\forall|\\psi\\rangle\n",
        "$\n",
        "\n",
        "Einsetzen in die Schrödingergleichung liefert einen Satz gewöhnlicher Differentialgleichungen 1. Ordnung:\n",
        "\n",
        ">$\\mathrm{i} \\hbar \\frac{\\partial}{\\partial t} U\\left(t, t_{0}\\right)=H(t) U\\left(t, t_{0}\\right)$\n",
        "\n",
        "Diese Gleichungen sind zur Schrödingergleichung insofern äquivalent, als sie die Erweiterung des Zeitentwicklungsoperators um einen infinitesimalen Zeitschritt $\\delta t$ beschreiben:\n",
        "\n",
        ">$\n",
        "U\\left(t+\\delta t, t_{0}\\right)=\\left(1-\\frac{i}{\\hbar} H(t) \\delta t\\right) U\\left(t, t_{0}\\right)+O\\left(\\delta t^{2}\\right)\n",
        "$\n",
        "\n",
        "mit dem Hamiltonoperator $H$, der den Erzeuger der Zeitentwicklungen darstellt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOBWmyGiyVUq"
      },
      "source": [
        "<font color=\"blue\">**Position Operator $\\hat{x}$**\n",
        "\n",
        "Der [Ortsoperator](https://de.m.wikipedia.org/wiki/Ortsoperator) gehört in der Quantenmechanik zur Ortsmessung von Teilchen.\n",
        "\n",
        "* Der physikalische Zustand $\\Psi$ eines Teilchens ist in der Quantenmechanik mathematisch gegeben durch den zugehörigen Vektor eines Hilbertraumes $\\mathrm{H}$.\n",
        "\n",
        "* Dieser Zustand wird folglich in der Bra-Ket-Notation durch den Vektor $|\\Psi\\rangle$ beschrieben.\n",
        "\n",
        "* Die Observablen werden durch selbstadjungierte Operatoren auf $\\mathrm{H}$ dargestellt.\n",
        "\n",
        "Speziell ist der Ortsoperator die Zusammenfassung der drei Observablen $\\hat{\\mathbf{x}}=\\left(\\hat{x}_{1}, \\hat{x}_{2}, \\hat{x}_{3}\\right)$, so dass\n",
        "\n",
        ">$\n",
        "E\\left(\\hat{x}_{j}\\right)=\\left\\langle\\hat{x}_{j} \\Psi, \\Psi\\right\\rangle_{\\mathrm{H}}, \\quad j=1,2,3\n",
        "$\n",
        "\n",
        "der Mittelwert (Erwartungswert) der Messergebnisse der j-ten Ortskoordinate des Teilchens im Zustand $\\Psi$ ist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_j3K_Pef4GA"
      },
      "source": [
        "<font color=\"blue\">**Momentum Operator $\\hat{p}$**\n",
        "\n",
        "Video: [Why Momentum in Quantum Physics is Complex](https://www.youtube.com/watch?v=kG-iihrYCG4&list=WL&index=22)\n",
        "\n",
        "Classical Momentum\n",
        "\n",
        "> p = m * v\n",
        "\n",
        "Quantum Mechanics: apply a measurement operator on wave function (eigenvalue equation:)\n",
        "\n",
        "> $\\hat{p}|\\Psi\\rangle=\\lambda|\\Psi\\rangle$\n",
        "\n",
        "Momentum measurement operator\n",
        "\n",
        "> $\\hat{p}=-i \\hbar \\frac{\\partial}{\\partial x}$ $\\quad$ with: $\\, i=\\sqrt{-1}$\n",
        "\n",
        "Der [Impulsoperator](https://de.m.wikipedia.org/wiki/Impulsoperator) $\\hat{p}$ ist in der Quantenmechanik der Operator zur Impulsmessung von Teilchen. In der Ortsdarstellung ist der Impulsoperator in einer Dimension gegeben durch (mit $\\frac{\\partial}{\\partial x}$ die partielle Ableitung in Richtung der Ortskoordinate $x$):\n",
        "\n",
        ">$\n",
        "\\hat{p}_{x}=-\\mathrm{i} \\hbar \\frac{\\partial}{\\partial x}=\\frac{\\hbar}{i} \\frac{\\partial}{\\partial x}\n",
        "$\n",
        "\n",
        "Mit dem Nabla-Operator $\\nabla$ erhält man in drei Dimensionen den Vektor:\n",
        "\n",
        ">$\n",
        "\\hat{\\mathbf{p}}=-\\mathrm{i} \\hbar \\nabla\n",
        "$\n",
        "\n",
        "* Der physikalische Zustand $\\Psi$ eines Teilchens ist in der Quantenmechanik mathematisch durch einen zugehörigen Vektor eines Hilbertraumes $\\mathcal{H}$ gegeben. Dieser Zustand wird folglich in der Bra-Ket-Notation durch den Vektor $|\\Psi\\rangle$ beschrieben.\n",
        "\n",
        "* Die Observablen werden durch selbstadjungierte Operatoren auf $\\mathcal{H}$ dargestellt. Speziell ist der Impuls-Operator die Zusammenfassung der drei Observablen $\\hat{\\mathbf{p}}=\\left(\\hat{p}_{1}, \\hat{p}_{2}, \\hat{p}_{3}\\right)$, so dass\n",
        "\n",
        ">$\n",
        "E\\left(\\hat{p}_{j}\\right)=\\left\\langle\\Psi\\left|\\hat{p}_{j}\\right| \\Psi\\right\\rangle \\quad j=1,2,3\n",
        "$\n",
        "\n",
        "der Mittelwert (Erwartungswert) der Messergebnisse der $j$ -ten Komponente des Impulses des Teilchens im Zustand $\\Psi$ ist."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\">**Translation Operator $\\hat{T}$**\n",
        "\n",
        "* the translation operator is the operator that allows us to move quantum states from one point to another\n",
        "\n",
        "* it allows us to understand many properties of wave functions:\n",
        "\n",
        "> **the wave function in real space is related to the wave function in momentum space by a Fourier transform**\n",
        "\n",
        "> $[\\hat{x}, \\hat{p}]=i \\hbar$\n",
        "\n",
        "* position $\\hat{x}$ and momentum $\\hat{p}$ operators. Their most important property is their commutator which is equal to $i \\hbar$\n",
        "\n",
        "* **Translation operator**:\n",
        "\n",
        "> $\\hat{T}(\\alpha)=e^{-i \\alpha \\hat{p} / \\hbar} \\quad \\alpha \\in \\mathbb{R}$\n",
        "\n",
        "* this is an operator that translates by an amount $\\alpha$\n",
        "\n",
        "* What does it mean to have a **function of an operator**, like the exponential function here: the function of an operator is defined by its Taylor expansion\n",
        "\n",
        "* adjoint of an operator: tells us about what the operator looks like in the dual space (NOT hermitian as you can see):\n",
        "\n",
        "> $\\begin{aligned} \\hat{T}^{t}(\\alpha)=& e^{i \\alpha \\hat{r}^{\\dagger} / \\hbar}=e^{i \\alpha \\hat{p} / \\hbar}=e^{-i(-\\alpha) \\hat{p} / \\hbar}=\\hat{T}(-\\alpha) \\\\ & \\hat{p}^{+}=\\hat{p} \\end{aligned}$\n",
        "\n",
        "* Let's look at the action of T dagger alpha on T alpha:\n",
        "\n",
        "> $\\hat{T}^{\\dagger}(\\alpha) \\hat{T}(\\alpha)=e^{i \\alpha \\hat{p} / \\hbar} e^{-i \\alpha \\hat{p} / \\hbar}=\\mathbb{1}$\n",
        "\n",
        "> $[\\hat{p}, \\hat{p}]=0$\n",
        "\n",
        "* remember: in general we cannot combine exponents of operators like if they were numbers, but here we can because the two exponents commute because the P operator commutes with itself\n",
        "\n",
        "* An operator whose adjoint is equal to its inverse is called a unitary operator\n",
        "\n",
        "> $\\left.\\begin{array}{l}\\hat{T}^{\\dagger}(\\alpha) \\hat{T}(\\alpha)=e^{i \\alpha \\hat{p} / \\hbar} e^{-i \\alpha \\hat{p} / \\hbar}=I \\\\ {[\\hat{p}, \\hat{p}]=0} \\\\ \\hat{T}(\\alpha) \\hat{T}^{\\dagger}(\\alpha)=e^{-i \\alpha \\hat{p} / \\hbar} e^{i \\alpha \\hat{p} / \\hbar}=I\\end{array}\\right\\} \\hat{T}^{\\dagger}(\\alpha)=\\hat{T}^{-1}(\\alpha)$\n",
        "\n",
        "* Overall:\n",
        "\n",
        "> $\\hat{T}^{\\dagger}(\\alpha)=\\hat{T}^{-1}(\\alpha)=\\hat{T}(-\\alpha)$"
      ],
      "metadata": {
        "id": "kHsMw4tA4gRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *$\\hookrightarrow$ States*"
      ],
      "metadata": {
        "id": "VHiwFI7ovP7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* phase states\n",
        "* Gibbs quantum states\n",
        "* Matrix product states\n",
        "* pure state, mixed state\n",
        "* Dicke state\n",
        "* Set of non-orthogonal quantum states"
      ],
      "metadata": {
        "id": "0zax9nK6B4zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What are the eigenvalues of density matrix of quantum state?**\n",
        "\n",
        "The eigenvalues of the density matrix of a quantum state represent the probabilities of finding the system in the corresponding eigenstates. The sum of all the eigenvalues must be equal to 1, which reflects the fact that the system must be in one of the eigenstates.\n",
        "\n",
        "For a pure state, the density matrix is a projector onto the state vector, and therefore has only one eigenvalue of 1, with the rest being 0. This means that the system is certain to be in the corresponding eigenstate.\n",
        "\n",
        "For a mixed state, the density matrix has at least two non-zero eigenvalues, indicating that the system has a non-zero probability of being in either of the corresponding eigenstates.\n",
        "\n",
        "The eigenvalues of the density matrix can also be used to characterize the degree of mixedness of the state. A state with only one non-zero eigenvalue is a pure state, while a state with many non-zero eigenvalues is a highly mixed state.\n",
        "\n",
        "Here are some examples of the eigenvalues of the density matrix for different quantum states:\n",
        "\n",
        "* **Pure state:**\n",
        "    * Spin-up state of a qubit: $\\lambda_1 = 1, \\lambda_2 = 0$\n",
        "    * Ground state of a harmonic oscillator: $\\lambda_0 = 1, \\lambda_1 = 0, \\lambda_2 = 0, ...$\n",
        "* **Mixed state:**\n",
        "    * Equal mixture of spin-up and spin-down states of a qubit: $\\lambda_1 = \\lambda_2 = 1/2$\n",
        "    * Thermal state of a harmonic oscillator: $\\lambda_0 > \\lambda_1 > \\lambda_2 > ... > 0$\n",
        "\n",
        "The eigenvalues of the density matrix can be used to calculate the expectation values of observables, as well as the probabilities of different measurement outcomes. For example, the probability of measuring the outcome $a$ when measuring the observable $A$ is given by:\n",
        "\n",
        "> $P(a) = \\sum_i \\lambda_i |\\langle a | \\psi_i \\rangle|^2$\n",
        "\n",
        "where $\\lambda_i$ and $\\psi_i$ are the eigenvalues and eigenstates of the density matrix, respectively.\n",
        "\n",
        "The eigenvalues of the density matrix are an important tool for understanding and characterizing quantum states. They are used in a wide variety of quantum applications, including quantum information theory, quantum computation, and quantum statistical mechanics."
      ],
      "metadata": {
        "id": "xxcXDJqv7Ctb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An $n$-dimensional **pure state** is $|\\psi\\rangle=\\sum_{i=1}^n \\alpha_i|i\\rangle$, where $|i\\rangle$ is the $n$-dimensional unit vector that has a 1 only at position $i$, the $\\alpha_i$ 's are complex numbers called the amplitudes, and $\\sum_{i \\in \\mid n]}\\left|\\alpha_i\\right|^2=1$.\n",
        "\n",
        "An $n$-dimensional **mixed state** (or density matrix) $\\rho=\\sum_{i=1}^n p_i\\left|\\psi_i\\right\\rangle \\psi_i \\mid$ is a mixture of pure states $\\left|\\psi_1\\right\\rangle, \\ldots,\\left|\\psi_n\\right\\rangle$ prepared with probabilities $p_1, \\ldots, p_n$, respectively. The eigenvalues $\\lambda_1, \\ldots, \\lambda_n$ of $\\rho$ are non-negative reals and satisfy $\\sum_{i \\in[n]} \\lambda_i=1$.\n",
        "\n",
        "If $\\rho$ is pure (i.e., $\\rho=|\\psi\\rangle \\psi \\mid$ for some $|\\psi\\rangle)$, then one of the eigenvalues is 1 and the others are 0 .\n",
        "\n",
        "To obtain classical information from $\\rho$, one could apply a **POVM (positive-operator-valued measure)** to the state $\\rho$. An $m$-outcome POVM is specified by a set of positive semidefinite matrices $\\left\\{M_i\\right\\}_{i \\in[m]}$ with the property $\\sum_i M_i=I d$. When this POVM is applied to the mixed state $\\rho$, the probability of the $j$-th outcome is given by $\\operatorname{Tr}\\left(M_j \\rho\\right)$."
      ],
      "metadata": {
        "id": "ce-HCRxhCNZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set of non-orthogonal quantum states**\n",
        "\n",
        "Sure, here is an example of a set of non-orthogonal quantum states:\n",
        "\n",
        "```\n",
        "|ψ⟩ = |0⟩ + |1⟩\n",
        "|ϕ⟩ = |0⟩ - |1⟩\n",
        "```\n",
        "\n",
        "These two states are non-orthogonal because their inner product is not zero:\n",
        "\n",
        "```\n",
        "⟨ψ|ϕ⟩ = (|0⟩ + |1⟩) ⟨0| - |1⟩) = 0 + 0 = 0\n",
        "```\n",
        "\n",
        "In other words, it is not possible to distinguish between these two states with certainty.\n",
        "\n",
        "Another example of a set of non-orthogonal quantum states is the set of all qubit states that lie on the Bloch sphere. The Bloch sphere is a unit sphere in three dimensions, and each point on the sphere represents a possible state of a qubit. Any two points on the Bloch sphere that are not diametrically opposite are non-orthogonal.\n",
        "\n",
        "Non-orthogonal quantum states are a fundamental part of quantum mechanics. They play a role in many quantum phenomena, such as quantum entanglement and quantum computing.\n",
        "\n",
        "\n",
        "*When do they occur?*\n",
        "\n",
        "Non-orthogonal quantum states occur whenever two or more quantum states are not perfectly aligned. This can happen in a variety of ways, such as:\n",
        "\n",
        "* When a quantum state is prepared in a superposition of two or more states.\n",
        "* When a quantum state is subjected to a measurement that does not perfectly distinguish between the different states.\n",
        "* When a quantum state is passed through a noisy channel.\n",
        "\n",
        "Non-orthogonal quantum states can be difficult to distinguish, but there are a number of techniques that can be used to do so.\n",
        "\n",
        "* One common technique is to use a projective measurement, which is a measurement that projects the quantum state onto one of a set of mutually orthogonal states. Another technique is to use a quantum algorithm, such as the Shor algorithm, which can be used to distinguish between non-orthogonal states with a high degree of accuracy.\n",
        "\n",
        "* Non-orthogonal quantum states play an important role in many quantum phenomena, such as quantum entanglement and quantum computing. In quantum entanglement, two or more quantum systems are linked together in such a way that they cannot be described independently. This is possible because the quantum states of the entangled systems are non-orthogonal.\n",
        "\n",
        "* In quantum computing, non-orthogonal quantum states are used to store information and to perform calculations. For example, a quantum computer can use non-orthogonal quantum states to represent the solutions to a problem. By performing measurements on these states, the quantum computer can then find the solution to the problem.\n",
        "\n",
        "The study of non-orthogonal quantum states is a rapidly developing field. As our understanding of quantum mechanics grows, we are finding new and exciting ways to use non-orthogonal quantum states to solve problems and to create new technologies."
      ],
      "metadata": {
        "id": "qSrKoh9rBnHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is the difference between mixed state and product state?**\n",
        "\n",
        "A mixed state and a product state are two different types of quantum states that arise in quantum mechanics and quantum information theory, each with its own distinct properties and interpretations.\n",
        "\n",
        "1. **Mixed State**: A mixed state describes a statistical mixture of different quantum states, each with a certain probability. Mathematically, a mixed state is represented by a density matrix, which is a positive-semidefinite Hermitian operator with trace 1. If a system is in a mixed state, it means we have some classical uncertainty about which specific quantum state it's in. For example, a system might be in state |0⟩ with probability 1/2 and in state |1⟩ with probability 1/2. This would correspond to the mixed state represented by the density matrix ρ = 1/2|0⟩⟨0| + 1/2|1⟩⟨1|.\n",
        "\n",
        "2. **Product State**: A product state refers to a state of a composite system that can be written as the tensor product of states of its subsystems. For example, if you have a two-qubit system and the first qubit is in state |0⟩ and the second qubit is in state |1⟩, the overall state of the system is the product state |0⟩⊗|1⟩, often written as |01⟩. A product state implies that there are no correlations between the subsystems, i.e., the subsystems are not entangled. If a state of a composite system cannot be written as a tensor product of states of its subsystems, it's called an entangled state.\n",
        "\n",
        "So, in summary, the difference lies in what each state represents: a mixed state represents classical uncertainty about which pure state a system is in, while a product state represents a separable (i.e., non-entangled) state of a composite system. Notably, these are not mutually exclusive: you can have a mixed state of product states, for example."
      ],
      "metadata": {
        "id": "Yyjr8c5B6SuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is a product state in quantum mechanics and quantum computing?**\n",
        "\n",
        "A product state in quantum mechanics is a state of a multi-qubit system that can be written as a product of individual qubit states. In other words, the state of each qubit is independent of the state of the other qubits. For example, the following is a product state of a two-qubit system:\n",
        "\n",
        "```\n",
        "|Ψ⟩ = |0⟩ |1⟩\n",
        "```\n",
        "\n",
        "This state represents a system in which the first qubit is in the |0⟩ state and the second qubit is in the |1⟩ state.\n",
        "\n",
        "Product states are typically less entangled than other types of quantum states, such as entangled states. Entanglement is a phenomenon in which the states of two or more qubits are linked together in such a way that they cannot be described independently.\n",
        "\n",
        "Product states are important in quantum computing because they are relatively easy to simulate and manipulate. Many quantum algorithms are designed to operate on product states.\n",
        "\n",
        "Here are some examples of product states in quantum computing:\n",
        "\n",
        "* The state of a quantum register that has been initialized to all zeros:\n",
        "\n",
        "```\n",
        "|Ψ⟩ = |0⟩⊗n\n",
        "```\n",
        "\n",
        "where n is the number of qubits in the register.\n",
        "\n",
        "* The state of a quantum register that has been used to store a classical bitstring:\n",
        "\n",
        "```\n",
        "|Ψ⟩ = |b1⟩⊗|b2⟩⊗...⊗|bn⟩\n",
        "```\n",
        "\n",
        "where bi is either 0 or 1, depending on the ith bit in the classical bitstring.\n",
        "\n",
        "* The state of a two-qubit system that is used to represent a Bell state:\n",
        "\n",
        "```\n",
        "|Ψ⟩ = (|00⟩ + |11⟩)/√2\n",
        "```\n",
        "\n",
        "This state is a product state, but it is also entangled. This is because the two qubits are correlated in such a way that measuring one qubit will instantly reveal the state of the other qubit.\n",
        "\n",
        "Product states are an essential concept in quantum mechanics and quantum computing. They are used in a wide variety of quantum algorithms and applications."
      ],
      "metadata": {
        "id": "9I8HNzzl61pU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matrix product state (MPS)**\n",
        "\n",
        "No, a product state is not the same as a matrix product state (MPS). A product state is a state of a multi-qubit system in which the state of each qubit is independent of the state of the other qubits. An MPS is a more general type of quantum state that can be used to represent a wide variety of entangled and non-entangled states.\n",
        "\n",
        "An MPS is represented by a tensor network, which is a graph of tensors that are connected to each other. The tensors in the network represent the local states of the qubits, and the connections between the tensors represent the interactions between the qubits.\n",
        "\n",
        "MPSs are useful for representing quantum states because they are efficient to simulate and manipulate. This is because the tensor network representation of an MPS can be truncated to a finite size without losing too much accuracy.\n",
        "\n",
        "Here is an example of an MPS for a two-qubit system:\n",
        "\n",
        "```\n",
        "|Ψ⟩ = T_1⊗T_2\n",
        "```\n",
        "\n",
        "where T_1 and T_2 are tensors of dimension d. This MPS represents a state in which the two qubits are entangled.\n",
        "\n",
        "MPSs are used in a variety of quantum algorithms and applications, including:\n",
        "\n",
        "* Quantum simulation\n",
        "* Quantum machine learning\n",
        "* Quantum error correction\n",
        "* Quantum cryptography\n",
        "\n",
        "MPSs are a powerful tool for representing and manipulating quantum states. They are particularly useful for simulating and manipulating large quantum systems, such as those used in quantum computing.\n",
        "\n",
        "To summarize, the key difference between a product state and an MPS is that a product state is a state in which the qubits are independent, while an MPS is a state in which the qubits can be entangled. MPSs are more general than product states, and they are used in a variety of quantum algorithms and applications."
      ],
      "metadata": {
        "id": "bxiVJbIb7KN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**quantum k-uniform state**\n",
        "  * multipartite quantum state whose reduced state on any k parties is maximally mixed = the state is completely uncorrelated between the k parties, and each party has equal probability of being in any of its possible states.\n",
        "  * Quantum k-uniform states are a special class of entangled states that are particularly useful for certain quantum information processing tasks. For example, they can be used to create quantum secret sharing schemes, which allow a group of parties to share a secret without revealing it to any individual party.\n",
        "  * One way to construct quantum k-uniform states is from quantum orthogonal arrays (QOAs). A QOA is a collection of quantum states that are orthogonal to each other when any k of them are considered together. Quantum k-uniform states can be obtained by taking the partial trace of a QOA over any k parties.\n",
        "  * have a number of interesting properties. For example, they are known to be distillable, which means that they can be used to create more entangled states. They are also known to be useful for quantum communication tasks such as teleportation and superdense coding.\n",
        "  Here are some additional things to know about quantum k-uniform states:\n",
        "    * They are a generalization of the well-known Bell states, which are 2-qubit quantum states that are maximally entangled.\n",
        "    * They can be used to create quantum error-correcting codes, which can be used to protect quantum information from errors.\n",
        "    * They can be used to create quantum cryptography protocols, which can be used to securely transmit information over long distances.\n",
        "    * They are still a relatively new area of research, and there is much that is still unknown about them. However, they have the potential to revolutionize the field of quantum information processing."
      ],
      "metadata": {
        "id": "LJQauktmIZFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is a Gibbs state?**\n",
        "\n",
        "Learning an unknown Hamiltonian from its Gibbs state has been studied in statistical physics and machine learning [CL68, HS+86, Tan98, AS14] for many decades, known as the “**inverse Ising problem**”.\n",
        "\n",
        "A survey on the complexity of learning quantum states, page 8\n",
        "\n",
        "A Gibbs state is a probability distribution over the states of a system that is consistent with the system's energy and the constraints that are imposed on it. It is named after Josiah Willard Gibbs, who introduced it in his work on statistical mechanics.\n",
        "\n",
        "A Gibbs state can be defined as follows:\n",
        "\n",
        "```\n",
        "P(x) = \\frac{e^{-H(x)/kT}}{\\sum_y e^{-H(y)/kT}}\n",
        "```\n",
        "\n",
        "where $x$ is a state of the system, $H(x)$ is the energy of the system in state $x$, $T$ is the temperature of the system, and $k$ is Boltzmann's constant.\n",
        "\n",
        "The Gibbs state is the equilibrium distribution of the system if the system is allowed to evolve over time according to the laws of statistical mechanics. This means that if the system is initially in any state, it will eventually converge to the Gibbs state as time goes on.\n",
        "\n",
        "Gibbs states are used in many different areas of physics, chemistry, and biology. They are used to describe the equilibrium distribution of molecules in a gas, the distribution of atoms in a crystal, and the distribution of genes in a population.\n",
        "\n",
        "Here are some of the applications of Gibbs states:\n",
        "\n",
        "* In statistical mechanics, Gibbs states are used to calculate the equilibrium properties of systems such as the pressure, temperature, and entropy.\n",
        "* In chemistry, Gibbs states are used to calculate the equilibrium constant for a chemical reaction.\n",
        "* In biology, Gibbs states are used to calculate the equilibrium distribution of genes in a population.\n",
        "* In machine learning, Gibbs states are used to train probabilistic models such as hidden Markov models and Bayesian networks.\n",
        "\n",
        "**can quantum systems also be in states that are not Gibbs states?**\n",
        "\n",
        "\n",
        "Yes, quantum systems can also be in states that are not Gibbs states. This is because quantum systems can exist in superpositions of states, which means that they can be in more than one state at the same time. A Gibbs state is a state where all the possible states of the system are equally likely, but a quantum system can be in a superposition of states where some states are more likely than others.\n",
        "\n",
        "For example, a quantum system with two possible states, $A$ and $B$, can be in a superposition of the two states, such that the system is equally likely to be in state $A$ or state $B$. This is called a coherent state. A Gibbs state for this system would be a state where the system is equally likely to be in state $A$ or state $B$, but a coherent state is not a Gibbs state because it is more likely to be in one state than the other.\n",
        "\n",
        "Another example is a quantum system with three possible states, $A$, $B$, and $C$. The Gibbs state for this system would be a state where the system is equally likely to be in state $A$, state $B$, or state $C$. However, a quantum system can be in a superposition of the three states, such that the system is more likely to be in state $A$ than state $B$ or state $C$. This is called an entangled state. An entangled state is not a Gibbs state because it is not possible to describe the state of the system in terms of the probabilities of the individual states.\n",
        "\n",
        "In general, quantum systems can be in any state that is consistent with the laws of quantum mechanics. This means that they can be in states that are not Gibbs states. Gibbs states are a special type of state that is often used in statistical mechanics, but they are not the only possible state for a quantum system."
      ],
      "metadata": {
        "id": "JcYlKISGf_ki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is a Gibbs state?**\n",
        "\n",
        "A Gibbs state is a probability distribution over the states of a system that is consistent with the system's energy and the constraints that are imposed on it. It is named after Josiah Willard Gibbs, who introduced it in his work on statistical mechanics.\n",
        "\n",
        "A Gibbs state can be defined as follows:\n",
        "\n",
        "```\n",
        "P(x) = \\frac{e^{-H(x)/kT}}{\\sum_y e^{-H(y)/kT}}\n",
        "```\n",
        "\n",
        "where $x$ is a state of the system, $H(x)$ is the energy of the system in state $x$, $T$ is the temperature of the system, and $k$ is Boltzmann's constant.\n",
        "\n",
        "The Gibbs state is the equilibrium distribution of the system if the system is allowed to evolve over time according to the laws of statistical mechanics. This means that if the system is initially in any state, it will eventually converge to the Gibbs state as time goes on.\n",
        "\n",
        "Gibbs states are used in many different areas of physics, chemistry, and biology. They are used to describe the equilibrium distribution of molecules in a gas, the distribution of atoms in a crystal, and the distribution of genes in a population.\n",
        "\n",
        "Here are some of the applications of Gibbs states:\n",
        "\n",
        "* In statistical mechanics, Gibbs states are used to calculate the equilibrium properties of systems such as the pressure, temperature, and entropy.\n",
        "* In chemistry, Gibbs states are used to calculate the equilibrium constant for a chemical reaction.\n",
        "* In biology, Gibbs states are used to calculate the equilibrium distribution of genes in a population.\n",
        "* In machine learning, Gibbs states are used to train probabilistic models such as hidden Markov models and Bayesian networks.\n"
      ],
      "metadata": {
        "id": "EbBba3xBtVPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**can quantum systems also be in states that are not Gibbs states?**\n",
        "\n",
        "Yes, quantum systems can also be in states that are not Gibbs states. This is because quantum systems can exist in superpositions of states, which means that they can be in more than one state at the same time. A Gibbs state is a state where all the possible states of the system are equally likely, but a quantum system can be in a superposition of states where some states are more likely than others.\n",
        "\n",
        "For example, a quantum system with two possible states, $A$ and $B$, can be in a superposition of the two states, such that the system is equally likely to be in state $A$ or state $B$. This is called a coherent state. A Gibbs state for this system would be a state where the system is equally likely to be in state $A$ or state $B$, but a coherent state is not a Gibbs state because it is more likely to be in one state than the other.\n",
        "\n",
        "Another example is a quantum system with three possible states, $A$, $B$, and $C$. The Gibbs state for this system would be a state where the system is equally likely to be in state $A$, state $B$, or state $C$. However, a quantum system can be in a superposition of the three states, such that the system is more likely to be in state $A$ than state $B$ or state $C$. This is called an entangled state. An entangled state is not a Gibbs state because it is not possible to describe the state of the system in terms of the probabilities of the individual states.\n",
        "\n",
        "In general, quantum systems can be in any state that is consistent with the laws of quantum mechanics. This means that they can be in states that are not Gibbs states. Gibbs states are a special type of state that is often used in statistical mechanics, but they are not the only possible state for a quantum system."
      ],
      "metadata": {
        "id": "TIdqE2X1tZgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Dicke States (with Garbage)*\n",
        "\n",
        "Dicke states are a class of quantum states that are defined as the equal-amplitude superposition of all n-qubit computational basis states with Hamming weight k. In other words, a Dicke state |D_n^k⟩ is a quantum state of n qubits where exactly k of the qubits are in the |1⟩ state and the remaining (n-k) qubits are in the |0⟩ state.\n",
        "\n",
        "Dicke states are important for quantum computing for a number of reasons. First, they are a type of entangled state, which means that the qubits in a Dicke state are correlated with each other in a way that cannot be explained by classical physics. This entanglement can be exploited to perform quantum algorithms that are much faster than any possible classical algorithm.\n",
        "\n",
        "Second, Dicke states are relatively easy to prepare on a quantum computer. This is because there are a number of efficient quantum circuits that can be used to create Dicke states. This makes them a good candidate for use in practical quantum computing applications.\n",
        "\n",
        "Third, Dicke states have a number of other applications in quantum information science. For example, they can be used to create quantum memories, quantum communication channels, and quantum simulators.\n",
        "\n",
        "Here are some specific examples of the applications of Dicke states in quantum computing:\n",
        "\n",
        "* **Quantum algorithms:** Dicke states can be used to speed up a variety of quantum algorithms, such as the Shor's algorithm for factoring large numbers and the Grover's algorithm for searching an unsorted database.\n",
        "* **Quantum communication:** Dicke states can be used to create quantum communication channels that are more secure than classical communication channels.\n",
        "* **Quantum simulation:** Dicke states can be used to simulate the behavior of physical systems, such as molecules and materials.\n",
        "\n",
        "Overall, Dicke states are an important class of quantum states with a wide range of applications in quantum computing. They are relatively easy to prepare on a quantum computer and can be used to speed up a variety of quantum algorithms and create secure quantum communication channels."
      ],
      "metadata": {
        "id": "SgkG11YTdwAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dicke states with garbage are a type of quantum state that is used in quantum computing to protect against noise and errors. They are created by adding a number of \"garbage\" qubits to a Dicke state. The garbage qubits are initialized in a random state, and they do not contribute to the computation. However, they help to protect the useful qubits from noise and errors.\n",
        "\n",
        "Here is an example of how Dicke states with garbage can be used to protect against noise and errors. Suppose we want to create a Dicke state of n qubits with k qubits in the |1⟩ state. We can do this by first initializing n qubits in the |0⟩ state. Then, we can add m garbage qubits to the system, where m is much larger than k. We can then initialize the garbage qubits in a random state. Finally, we can apply a Hadamard gate to each of the qubits.\n",
        "\n",
        "The resulting state will be a Dicke state with garbage. The useful qubits will be in the |1⟩ state with high probability, even if the noise and errors are very high. This is because the garbage qubits will absorb the noise and errors, and they will not affect the useful qubits.\n",
        "\n",
        "Dicke states with garbage are a powerful tool for protecting against noise and errors in quantum computing. They are relatively easy to implement, and they can be used to protect a wide range of quantum algorithms."
      ],
      "metadata": {
        "id": "ZLxTRNxIdy3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *$\\hookrightarrow$ Measurements*"
      ],
      "metadata": {
        "id": "dcFMdt_xthGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Square root measurement\n",
        "* Separable measurement\n",
        "* Random Clifford measurement (classical shadows based on random Clifford measurements)\n",
        "* POVM measurement\n",
        "* projective measurements\n",
        "* two-copy Bell basis measurement"
      ],
      "metadata": {
        "id": "i-e0Kydw0ZCS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Square root measurement (pretty good measurement)**\n",
        "\n",
        "The square root measurement (SRM), also known as the pretty good measurement (PGM), is a measurement introduced by Paul Hausladen and William Wootters in 1994. It is a quantum measurement that can be **used to distinguish between a set of non-orthogonal quantum states**.\n",
        "\n",
        "* The SRM is constructed by first finding the square roots of the inner products between the different states. These square roots are then normalized to form the measurement operators.\n",
        "\n",
        "* The SRM has several desirable properties. It is simple to construct, and it is asymptotically optimal for distinguishing between a large number of non-orthogonal states. It is also \"pretty good\" in the sense that it can distinguish between almost orthogonal states with a low probability of error.\n",
        "\n",
        "* The SRM has been used in a variety of applications in quantum computing, including quantum cryptography, quantum communication, and quantum machine learning.\n",
        "\n",
        "Here are some of the key properties of the square root measurement:\n",
        "\n",
        "* It is a projective measurement, which means that it always gives a definite result.\n",
        "* It is unbiased, which means that the probability of each outcome is equal.\n",
        "* It minimizes the probability of error for distinguishing between a set of non-orthogonal states.\n",
        "* It is asymptotically optimal, which means that its performance approaches the optimal as the number of states increases.\n",
        "\n",
        "The square root measurement is a powerful tool that can be used to perform a variety of tasks in quantum computing. It is simple to construct and efficient to implement, and it has been shown to be effective in a variety of applications.\n",
        "\n",
        "**Yes, there is a difference between the square root measurement and the positive-operator-valued measure (POVM).**\n",
        "\n",
        "A square root measurement is a special type of POVM. It is a projective measurement, which means that it always gives a definite result. The square root measurement is constructed by first finding the square roots of the inner products between the different states. These square roots are then normalized to form the measurement operators.\n",
        "\n",
        "A POVM is a more general type of measurement. It is not required to be projective, and it can give a range of possible results. The POVM is defined by a set of operators, called effect operators, that satisfy certain conditions.\n",
        "\n",
        "The main difference between the square root measurement and the POVM is that the square root measurement is always projective, while the POVM is not. This means that the square root measurement always gives a definite result, while the POVM can give a range of possible results.\n",
        "\n",
        "The square root measurement is a more powerful tool than the POVM, but it is also more restrictive. The square root measurement can only be used to distinguish between non-orthogonal states, while the POVM can be used to distinguish between any set of states.\n",
        "\n",
        "In general, the POVM is a more versatile tool than the square root measurement. However, the square root measurement is often a better choice when it is important to obtain a definite result.\n",
        "\n",
        "Here is a table summarizing the key differences between the square root measurement and the POVM:\n",
        "\n",
        "| Feature | Square root measurement | POVM |\n",
        "|---|---|---|\n",
        "| Projective | Yes | No |\n",
        "| Definite result | Always | Not always |\n",
        "| Generality | Less | More |\n",
        "| Versatility | Less | More |\n",
        "| Usefulness | When it is important to obtain a definite result | When it is not important to obtain a definite result or when the states to be distinguished are not non-orthogonal |"
      ],
      "metadata": {
        "id": "c0aVdWf8BlYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://en.m.wikipedia.org/wiki/Weyl%27s_inequality"
      ],
      "metadata": {
        "id": "Z2gY8WGxdr3S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is a separable measurement?**\n",
        "\n",
        "In quantum mechanics, a separable measurement is a measurement that can be performed on a multipartite quantum state without affecting the entanglement of the state.\n",
        "\n",
        "A multipartite quantum state is a state that describes the joint state of two or more quantum systems. Entanglement is a property of quantum states that allows them to be correlated in ways that are not possible in classical physics.\n",
        "\n",
        "A separable measurement is a measurement that can be performed on each subsystem of a multipartite quantum state independently of the other subsystems. This means that the measurement does not affect the entanglement between the subsystems.\n",
        "\n",
        "For example, consider a system of two qubits, which are quantum systems with two possible states. The state of the system can be described by a density matrix, which is a matrix that contains all the information about the state.\n",
        "\n",
        "A separable measurement on this system would be a measurement that could be performed on each qubit independently. This would mean that the measurement would not affect the entanglement between the qubits.\n",
        "\n",
        "Separable measurements are important in quantum information theory. They can be used to create protocols for quantum communication and computation that are robust to noise and decoherence.\n",
        "\n",
        "Here are some of the key properties of separable measurements:\n",
        "\n",
        "* They can be performed on each subsystem of a multipartite quantum state independently of the other subsystems.\n",
        "* They do not affect the entanglement between the subsystems.\n",
        "* They can be used to create protocols for quantum communication and computation that are robust to noise and decoherence.\n",
        "\n",
        "Separable measurements are a fundamental concept in quantum mechanics. They play an important role in quantum information theory and quantum computing."
      ],
      "metadata": {
        "id": "sr4dD1xctKnL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is a random Clifford measurement?**\n",
        "\n",
        "In the field of quantum computing, a Clifford measurement involves measuring a quantum state in a basis given by a Clifford operation.\n",
        "\n",
        "The Clifford group is a specific set of operations in quantum mechanics that map Pauli operators to other Pauli operators under conjugation. It includes operations like the Hadamard gate, phase gate, CNOT gate, and others. The Clifford group has important applications in quantum error correction and quantum cryptography.\n",
        "\n",
        "A random Clifford measurement is a measurement process where the measurement basis is chosen randomly from the set of all possible Clifford operations. Random Clifford operations can be used to create a form of \"scrambling\" that can be used to probe the properties of quantum systems, and they also find use in protocols for testing quantum computers, like the so-called randomized benchmarking procedure.\n",
        "\n",
        "When applied to quantum state tomography, random Clifford measurements can be used to extract information about the quantum state in a way that can be more efficient or robust against certain types of errors. For example, they might be used in a protocol for \"shadow tomography\", where a small number of random measurements are used to estimate properties of the quantum state. The specifics of how these measurements are used and their performance characteristics can depend on the details of the quantum system and the tomography protocol."
      ],
      "metadata": {
        "id": "EM6MX6sk-qUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is a POVM measurement? (vs projective measurements)**\n",
        "\n",
        "A Positive Operator-Valued Measure (POVM) is a mathematical formalism used in quantum mechanics to describe the process of making a measurement on a quantum system. **Unlike projective measurements (also called von Neumann measurements), which are limited to a specific set of states (the eigenstates of an observable), POVMs can represent more general kinds of measurements.**\n",
        "\n",
        "A POVM is a collection of positive semi-definite operators {E_i} acting on the state space of a quantum system, which sum up to the identity operator, that is, ∑i E_i = I. These operators E_i are also called \"effects\".\n",
        "\n",
        "When you perform a measurement described by a POVM on a quantum system in a state represented by a density matrix ρ, the probability of obtaining outcome i (associated with operator E_i) is given by tr(E_i ρ), where tr() denotes the trace operation.\n",
        "\n",
        "The ***key aspect of POVMs is that they allow for the description of measurements that do not have a complete set of orthogonal eigenstates, which are typical in situations like indirect or incomplete measurements***, measurements involving ancillary systems, and measurements involving quantum entanglement. This makes POVMs an essential tool in quantum information theory and quantum computing.\n",
        "\n",
        "* <font color=\"red\">mathematical examples?\n",
        "\n",
        "* <font color=\"red\">code examples?"
      ],
      "metadata": {
        "id": "E8ZcEaFmtmWX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is a POVM measurement on the state E(|xi⟩⟨xi|)?**\n",
        "\n",
        "*Von Neumann Measurement vs POVM*\n",
        "\n",
        "A Positive Operator-Valued Measure (POVM) is a type of generalized measurement used in quantum mechanics. When we want to make a measurement in quantum mechanics, we typically talk about observables, which are represented by Hermitian operators, and the associated eigenstates and eigenvalues. The eigenvalues are the possible outcomes of the measurement, and the state collapses into the corresponding eigenstate upon measurement.\n",
        "\n",
        "However, there are situations where a standard von Neumann measurement (which directly associates observables with Hermitian operators) is not sufficient. For example, if we want to consider more general types of measurements or if we're working with a subset of a larger system, we might need to use a POVM.\n",
        "\n",
        "A POVM is a set of positive semi-definite operators {E_i} that sum to the identity operator. Each E_i corresponds to a potential outcome of the measurement. The probability of each outcome i when measuring a state ρ is given by tr(E_i ρ).\n",
        "\n",
        "So if you have a state represented by E(|xi⟩⟨xi|) and a POVM {E_i}, the probability of getting the outcome corresponding to E_i would be tr(E_i E(|xi⟩⟨xi|)).\n",
        "\n",
        "The states E_i themselves don't necessarily need to be orthogonal or even pure states, which makes POVMs a very powerful and general measurement framework in quantum mechanics. They are often used in quantum information theory and quantum computation where complex measurement schemes are more common.\n"
      ],
      "metadata": {
        "id": "f70p5CAjtsMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is a two-copy Bell basis measurement?**\n",
        "\n",
        "A two-copy Bell basis measurement is a measurement in the Bell basis on two copies of a quantum state. This is an important concept in quantum information theory and quantum computing, especially in the context of entanglement and quantum teleportation.\n",
        "\n",
        "The Bell basis consists of four maximally entangled two-qubit states, known as Bell states. These states are:\n",
        "\n",
        "1. |Φ+⟩ = 1/√2 (|00⟩ + |11⟩)\n",
        "2. |Φ-⟩ = 1/√2 (|00⟩ - |11⟩)\n",
        "3. |Ψ+⟩ = 1/√2 (|01⟩ + |10⟩)\n",
        "4. |Ψ-⟩ = 1/√2 (|01⟩ - |10⟩)\n",
        "\n",
        "When we talk about a \"two-copy Bell basis measurement\", we are referring to performing a Bell basis measurement on two copies of a quantum state. Let's consider a state ρ. We have two copies of ρ, let's say ρ1 and ρ2. The two-copy Bell basis measurement would involve performing a Bell basis measurement on the combined system of ρ1 and ρ2.\n",
        "\n",
        "This kind of measurement could be used to assess properties such as the fidelity of the state ρ, or in protocols like entanglement distillation. It is also a key part of certain quantum error correction codes, where it's used to detect and correct errors without destroying the quantum information."
      ],
      "metadata": {
        "id": "LPat9lHG-_HI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what are quantum states using the fixed POVM?**\n",
        "\n",
        "In quantum mechanics, a Positive Operator-Valued Measure (POVM) is a set of measurement operators that act on quantum states. These operators are designed such that they satisfy certain mathematical properties that make them correspond to physical measurements. Specifically, each operator in the set is positive (its eigenvalues are nonnegative), and the sum of all the operators is the identity operator.\n",
        "\n",
        "A POVM provides a generalization of the concept of a quantum measurement. In the simplest case, quantum measurements are described by a set of projection operators that project onto different states in a quantum system. However, in more complex situations, such as when dealing with noise or imperfect detection, a more general type of measurement is needed, which is where POVMs come in.\n",
        "\n",
        "A \"fixed\" POVM would refer to a specific, predetermined set of measurement operators. For instance, in a quantum computing experiment, a researcher might choose a fixed POVM to measure the output states of a quantum circuit.\n",
        "\n",
        "As for \"quantum states using the fixed POVM,\" it is a bit unclear without more context. However, it could mean the process of applying this predetermined set of measurement operators to certain quantum states. The result of such a measurement would be a set of probabilities (one for each operator in the POVM), indicating the likelihood of each possible measurement outcome. These probabilities would then be used to infer properties of the quantum state or the quantum system.\n"
      ],
      "metadata": {
        "id": "ZPd_qh2D3AeV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RYVZpfsfPmTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *$\\hookrightarrow$ Eigenvalues*"
      ],
      "metadata": {
        "id": "cPAo7HRV06Ol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is meant by an observable with constant spectral norm?**\n",
        "\n",
        "An observable in quantum mechanics is represented by a Hermitian operator. **The spectral norm (or operator norm) of a Hermitian operator is equal to its largest eigenvalue in absolute value**.\n",
        "\n",
        "So, if an observable is described as having a \"constant spectral norm,\" it means that the maximum absolute value of its possible measurement outcomes (eigenvalues) is a constant.\n",
        "\n",
        "For example, the Pauli matrices that represent observables in a two-level quantum system (like a qubit) have a spectral norm of 1, because their eigenvalues are +1 and -1. So, these could be described as observables with constant spectral norm.\n",
        "\n",
        "In practice, this property could be useful because it gives a bound on the possible outcomes of measurements, which can simplify calculations or analyses. It also ensures that the observable is a bounded operator, which is an important property in functional analysis and quantum mechanics."
      ],
      "metadata": {
        "id": "_l8OqycaFhln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is meant by trace distance of the state prior to any measurements?**\n",
        "\n",
        "In the context of quantum mechanics and quantum information theory, the trace distance is a measure of the distinguishability of two quantum states. In a practical sense, it gives you the maximum probability over all possible measurements that you can correctly tell the two states apart.\n",
        "\n",
        "The trace distance between two quantum states ρ and σ is defined as:\n",
        "\n",
        "D(ρ, σ) = 1/2 * Tr[|ρ - σ|]\n",
        "\n",
        "where Tr denotes the trace, and |A| refers to the absolute value of the matrix A (which is defined as the square root of the product of A with its adjoint, or A*A†).\n",
        "\n",
        "The trace distance has a value between 0 and 1, where 0 indicates that the two states are identical, and 1 means the states are completely distinguishable.\n",
        "\n",
        "When the trace distance is mentioned in relation to \"the state prior to any measurements\", it generally refers to assessing how different two quantum states are before any action is taken to measure or otherwise alter these states. This can be important when considering the evolution of quantum systems, or assessing the impact of quantum noise or errors on a quantum state."
      ],
      "metadata": {
        "id": "2g56bk2w8b_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Page 9: \"**the final states of our algorithm on inputs v and w are Ω(1) apart in trace norm**\"\n",
        "  * The statement means that the trace distance between the final states of the algorithm on inputs v and w **is at least a constant**. **The trace distance is a measure of how different two quantum states are**.\n",
        "  * In other words, the **statement is saying that the final states of the algorithm on inputs v and w are not the same, and they are not even close to being the same**. The constant Ω(1) is a lower bound on the trace distance, and it means that the trace distance is at least some constant value, no matter how small that value is.\n",
        "  * **This statement is important in quantum learning theory because it shows that quantum algorithms can be used to distinguish between different inputs**. If the final states of the algorithm on different inputs were always the same, then quantum algorithms would not be able to learn anything about the inputs.\n",
        "  * The statement \"the final states of our algorithm on inputs v and w are Ω(1) apart in trace norm\" is a more formal way of saying that the final states of the algorithm on different inputs are distinguishable."
      ],
      "metadata": {
        "id": "5O2i38FthBHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def trace_distance(state1, state2):\n",
        "  \"\"\"Calculates the trace distance between two quantum states.\n",
        "\n",
        "  Args:\n",
        "    state1: A numpy array representing the first quantum state.\n",
        "    state2: A numpy array representing the second quantum state.\n",
        "\n",
        "  Returns:\n",
        "    The trace distance between the two quantum states.\n",
        "  \"\"\"\n",
        "\n",
        "  # Calculate the difference between the two quantum states.\n",
        "  difference = state1 - state2\n",
        "\n",
        "  # Calculate the trace of the absolute value of the difference.\n",
        "  trace = np.trace(np.abs(difference))\n",
        "\n",
        "  # Return the square root of the trace.\n",
        "  return 0.5 * np.sqrt(trace)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # Create two quantum states.\n",
        "  state1 = np.array([[1, 0], [0, 0]])\n",
        "  state2 = np.array([[0, 0], [0, 1]])\n",
        "\n",
        "  # Calculate the trace distance between the two quantum states.\n",
        "  trace_distance = trace_distance(state1, state2)\n",
        "\n",
        "  # Print the trace distance.\n",
        "  print(\"The trace distance is:\", trace_distance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNBVKC-xlyKE",
        "outputId": "7a3f9505-360e-4db2-e20e-de9fc30315d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The trace distance is: 0.7071067811865476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trace_distance = 0.5 * np.sqrt(np.trace(np.abs(state1 - state2)))"
      ],
      "metadata": {
        "id": "jsMwtjDjmYyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Measuring a quantum state in the computational basis is a Clifford measurement. A Clifford measurement is a measurement that can be performed by a circuit consisting only of Clifford gates. The computational basis measurements are the Pauli Z and Pauli X measurements, which are both Clifford gates. Therefore, measuring a quantum state in the computational basis is a Clifford measurement. The computational basis measurements are equivalent to the Pauli Z and Pauli X measurements"
      ],
      "metadata": {
        "id": "-KUhgNi_tMGt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expectation Value and Backpropagation**\n",
        "\n",
        "The average value (expectation value) of the measurement result is given by the\n",
        "Born rule: **bold text**\n",
        "\n",
        "> $\\langle B\\rangle=\\left\\langle\\psi\\left|U^{\\dagger}(\\theta) B U(\\theta)\\right| \\psi\\right\\rangle$\n",
        "\n",
        "Just linear algebra! Every step is a matrix-vector or matrix-matrix multiplication\n",
        "\n",
        "Expectation values depend continuously on the gate parameters\n",
        "\n",
        "**Backpropagating Through Quantum Circuits**\n",
        "\n",
        "However, as long as we don't \"zoom in\" to what is happening in the quantum circuit, backpropagation can treat the quantum circuit as a single indivisible function\n",
        "\n",
        "The expectation value of a quantum circuit is a differentiable function\n",
        "\n",
        "> $\n",
        "f(\\theta)=\\left\\langle\\psi\\left|U^{\\dagger}(\\theta) B U(\\theta)\\right| \\psi\\right\\rangle=\\langle B\\rangle$\n",
        "\n",
        "Running on hardware and using the parameter-shift rule, we can provide both ingredients needed by backpropagation\n",
        "\n",
        "> $\n",
        "\\left(\\langle B\\rangle, \\frac{\\partial}{\\partial \\theta}\\langle B\\rangle\\right)\n",
        "$"
      ],
      "metadata": {
        "id": "NOFPaQ7LDw1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spectral Gap**\n",
        "\n",
        "Minimum eigenvalue gap of my hamiltonian (spectral gap decrease polynomial or exponentially as a function of the number of particles?). Eigenvalue gap can become exponentially small.\n",
        "\n",
        "The spectral gap, in the context of quantum mechanics or graph theory, is the difference between the lowest two eigenvalues of a system’s Hamiltonian or the adjacency matrix of a graph. It provides crucial information about the system’s dynamics or the graph’s connectivity.\n",
        "\n",
        "In the context of Hamiltonian mechanics, the eigenvalues represent the possible energy levels of the system. The \"minimum eigenvalue gap\" of a Hamiltonian refers to the smallest difference between any two of these energy levels.\n",
        "\n",
        "The importance of this spectral gap is deeply connected to the behavior of quantum systems. If there is a non-zero gap between the lowest energy state (the ground state) and the rest of the spectrum, the system is said to be gapped. If the gap is zero, the system is gapless.\n",
        "\n",
        "In a gapped system, at low temperatures, thermal fluctuations aren't typically strong enough to push the system out of its ground state. This makes the system's behavior at low temperatures easier to predict.\n",
        "\n",
        "On the other hand, in a gapless system, even small fluctuations can cause the system to change its state, resulting in complex behavior.\n",
        "\n",
        "In the field of quantum computation, the spectral gap plays a crucial role in the speed and feasibility of quantum algorithms. For example, in adiabatic quantum computing, the algorithm's running time is inversely proportional to the square of the spectral gap. A smaller spectral gap implies a slower-running algorithm, which is not desirable."
      ],
      "metadata": {
        "id": "ZLCKV2c6c6b0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting back to 𝑓(𝜌,𝑂) = tr(𝑂E(𝜌)) : why do I need to calculate the eigenvalues (trace)?**\n",
        "\n",
        "*From paper: Information-theoretic bounds on quantum advantage in machine learning*\n",
        "\n",
        "* Trace = sum of Eigenvalues (in this context the trace gives a weighted sum of all outcomes – in other words, the average or expected value.)\n",
        "* Eigenvalues = each eigenvalue of an observable represents a possible outcome of a measurement\n",
        "\n",
        "In the expression 𝑓(𝜌,𝑂) = tr(𝑂E(𝜌)), the function tr denotes the trace of a matrix, not its eigenvalues. The trace of a matrix is defined as the sum of the elements on its main diagonal (from the top left to the bottom right). This is true for any square matrix, not just for those representing quantum states or operations.\n",
        "\n",
        "Now, **for the specific case of this expression, the trace is used to calculate the expected value of an observable for a quantum state that has undergone some operation E.** Here's why:\n",
        "\n",
        "In quantum mechanics, the expected (or average) value of an observable O for a state ρ is given by the formula tr(𝑂𝜌). This comes from the Born rule, one of the key postulates of quantum mechanics, which relates the probabilities of measurement outcomes to the state of the system. <font color=\"red\">The observable O is represented by a Hermitian operator, and the state ρ is represented by a density operator.</font>\n",
        "\n",
        "In your expression, E(𝜌) represents the state after some operation E has been applied. So tr(𝑂E(𝜌)) is the expected value of the observable O for the state resulting from E(𝜌).\n",
        "\n",
        "The trace is crucial here because it ensures that we're summing up the probabilities of all possible outcomes. In a physical sense, it is analogous to summing over all possible states that the system might be in. **Because each eigenvalue of an observable represents a possible outcome of a measurement, and the corresponding element of the density matrix gives the probability of that outcome**, taking the trace in this context gives a weighted sum of all outcomes – in other words, the average or expected value."
      ],
      "metadata": {
        "id": "bwYUoViG5BQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How can you accurately predict expectation values of Pauli observables in an unknown n-qubit quantum state ρ?**\n",
        "\n",
        "In quantum mechanics, the expectation value of an observable represented by an operator A on a state ρ can be calculated using the formula tr(Aρ), where \"tr\" denotes the trace operation.\n",
        "\n",
        "The Pauli matrices (or Pauli operators), named after Wolfgang Pauli, are a set of 2 × 2 matrices which are fundamental in quantum mechanics. They are defined as:\n",
        "\n",
        "- Pauli-X: σ_x = [[0, 1], [1, 0]]\n",
        "- Pauli-Y: σ_y = [[0, -i], [i, 0]]\n",
        "- Pauli-Z: σ_z = [[1, 0], [0, -1]]\n",
        "\n",
        "These operators can be extended to n-qubit systems to form a complete basis for Hermitian operators on that system. A Pauli observable on an n-qubit system is a tensor product of Pauli matrices, one for each qubit. For example, Z ⊗ Z is a Pauli observable for a 2-qubit system that measures the parity of the two qubits.\n",
        "\n",
        "***In order to predict the expectation value of a Pauli observable in an unknown state ρ, you would generally need to perform quantum state tomography***, which involves making many measurements on many identically-prepared quantum systems, and using the results to reconstruct the state ρ. Once you have ρ, you can use the formula tr(Aρ) to calculate the expectation value of any observable A.\n",
        "\n",
        "However, ***full quantum state tomography is not always practical, especially for large systems, due to the number of measurements required***. There are other techniques like direct estimation of the expectation value via sampling, adaptive methods, or compressed sensing techniques which can estimate the expectation value with fewer measurements.\n",
        "\n",
        "In a practical quantum computing scenario, the expectation value of a Pauli observable would often be estimated by preparing many copies of the state, measuring each in the basis corresponding to the observable, and taking the average of the results. These measurements can be implemented with the appropriate rotations and then a computational basis measurement.\n",
        "\n",
        "Remember, this is all assuming you have physical access to the quantum state or quantum system. If you only have classical access to information about the system, you can't accurately predict the expectation values without additional assumptions or information. Quantum mechanics fundamentally limits what you can know about a quantum system without direct quantum access to the system."
      ],
      "metadata": {
        "id": "q345WRdUtkcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what are 𝑘-body reduced density matrices?**\n",
        "\n",
        "In quantum mechanics, the state of a system of particles can be represented by a density matrix, which is a complex, positive semi-definite matrix with a trace equal to 1.\n",
        "\n",
        "For a system of N particles, the full density matrix lives in a high-dimensional Hilbert space (the tensor product of the individual particle's Hilbert spaces), and contains complete information about the state of the system. However, it can often be difficult to work with such high-dimensional objects.\n",
        "\n",
        "A k-body reduced density matrix is a lower-dimensional object that contains information about only a subset of the particles in the system.\n",
        "\n",
        "Formally, the k-body reduced density matrix is obtained by taking the partial trace over N-k of the particles in the system. This process \"averages out\" the information about these N-k particles, leaving behind a density matrix that describes the remaining k particles.\n",
        "\n",
        "The k-body reduced density matrix is a useful tool in many areas of quantum physics, including quantum chemistry and quantum information theory. It allows us to study the behavior of small subsystems within a larger quantum system, even when we can't (or don't want to) keep track of the full state of all the particles. For example, the 1-body reduced density matrix (also known as the one-particle density matrix) is often used in quantum chemistry to describe electron behavior in molecular systems."
      ],
      "metadata": {
        "id": "780q8PXoJZja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *$\\hookrightarrow$ Maps*"
      ],
      "metadata": {
        "id": "3hazOulegQat"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB17Qq-GLGBT"
      },
      "source": [
        "**Changing Basis (Map: Overlap Matrix)**\n",
        "\n",
        "* <font color=\"blue\">**For example: A particles position can be expressed as the superposition of momentum states**</font>\n",
        "\n",
        "* Goal: choose a 'good' basis that makes the maths as simple as possible\n",
        "\n",
        "Video: [Changing basis in quantum mechanics](https://www.youtube.com/watch?v=CDmXvPDMIFs)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_252.png)\n",
        "\n",
        "If we go from one representation to another: we need to calculate the overlaps between the corresponding basis states, with the [overlap matrix](https://www.chemeurope.com/en/encyclopedia/Overlap_matrix.html):\n",
        "\n",
        "* The Overlap matrix is used to calculate the overlap integral, which is a measure of the similarity between two basis functions. The overlap integral is important in quantum chemistry because it is used to construct the Hamiltonian matrix, which is used to solve the Schrödinger equation.\n",
        "* The overlap matrix is a square matrix, used in quantum chemistry to describe the inter-relationship of a set of basis vectors of a quantum system.\n",
        "* **If the vectors are orthogonal to one another, the overlap matrix will be diagonal.**\n",
        "* In addition, if the basis vectors form an orthonormal set, the overlap matrix will be the identity matrix.\n",
        "* The overlap matrix is always n×n, where n is the number of basis functions used. It is a kind of Gramian matrix.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_253.png)\n",
        "\n",
        "How do we get back from the new to the old basis?\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_254.png)\n",
        "\n",
        "How we do transform the representation of operators between basis? (resolve identities in the u basis)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_255.png)\n",
        "\n",
        "Summary:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_256.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CPTP Maps in Quantum Machine Learning**\n",
        "\n",
        "*A quantum channel is a completely positive, trace-preserving (CPTP) map. A CPTP map is mapping one density matrix (input) to another (Output)*\n",
        "\n",
        "*Source: Information-theoretic bounds on quantum advantage in machine learning*\n",
        "\n",
        "*tldr: in ML experiments for an on average error quantum ML  (which operates on quantum data) cannot outperform classical ML (which operaties on classical data. qQuantum ML can outperform only for worst-case prediction error (rather than a small average prediction error), where an exponential separation becomes possible.*\n",
        "\n",
        "We are interested in predicting functions of the form\n",
        "\n",
        "$f(x)=\\operatorname{tr}(O \\mathcal{E}(|x\\rangle\\langle x|))$\n",
        "\n",
        "* where $x$ is a classical input, e.g., chemicals involved in the reaction, a description of the molecule, or the intensity of lasers that con- trol the neutral atoms\n",
        "* $\\mathcal{E}$ is an arbitrary (possibly unknown) completely positive and trace preserving (CPTP) map - it characterizes a quantum evolution happening in the lab. Depending on the parameter x, it produces the quantum state $\\mathcal{E}$(|x⟩⟨x|)\n",
        "* $O$ is a ceratin known observable (what the experimentalist measures at the end of the experiment.)\n",
        "\n",
        "This equation  encompasses any physical process that takes a classical input and produces a real number as output. The goal is to construct a function h(x) that accurately approximates f(x) after accessing the physical process $\\mathcal{E}$ as few times as possible.\n",
        "\n",
        "The goal is to predict the measurement outcome for new physical experiments, with new values of x that have not been encountered during the training process.\n",
        "\n",
        "1. all problems that are approximately learnable by a quantum ML model are also approximately learnable by some restricted clas- sical ML model which executes the quantum process $\\mathcal{E}$ a comparable number of times. This applies in particular, to predicting outputs of quantum- mechanical processes.\n",
        "\n",
        "  * For the task of learning classical Boolean circuits, fundamental limits on quantum advantage have been established in previous work [11–13, 31, 80, 94]. Theorem 1 generalizes these existing results to the task of learning outcomes of quantum processes.\n",
        "\n",
        "  * Therefore finding that classical and quantum ML have comparable power (for average-case prediction) boosts our hopes that the combination of classical ML and near-term quan- tum algorithms [47, 52, 53, 76, 79] may fruitfully ad- dress challenging quantum problems in physics, chem- istry, and materials science.\n",
        "\n",
        "2. quantum ML can have an exponential ad- vantage over classical ML for certain problems where the objective is achieving a specified worst-case prediction error.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OgKDwE8CoMNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is the cptp map 𝑓(𝜌,𝑂) = tr(𝑂E(𝜌))?**\n",
        "\n",
        "*Source: Learning to predict arbitrary quantum processes*\n",
        "\n",
        "The expression you've given, 𝑓(𝜌,𝑂) = tr(𝑂E(𝜌)), doesn't directly represent a completely positive trace-preserving (CPTP) map. Rather, it looks like the representation of an expectation value in the context of quantum mechanics or quantum information theory.\n",
        "\n",
        "In the given equation:\n",
        "- 𝜌 is a density operator representing the state of a quantum system.\n",
        "- 𝑂 is an observable, which is a Hermitian operator corresponding to a physical quantity that can be measured.\n",
        "- E(𝜌) is some operation being performed on the state 𝜌; this could potentially represent a quantum channel or some other operation. The nature of this operation isn't specified by your question.\n",
        "- tr( ) denotes the trace, which for an operator is the sum of its eigenvalues.\n",
        "\n",
        "So, tr(𝑂E(𝜌)) is the expected value (or mean value) of the measurement of the observable 𝑂 in the state resulting from the operation E(𝜌).\n",
        "\n",
        "A CPTP map, on the other hand, describes the evolution of quantum states when they interact with an environment. It is a map that takes a density operator to another density operator, and it has two properties:\n",
        "1. It's completely positive, meaning that it preserves the positive semi-definiteness of the quantum state (ensuring that the state remains a valid physical state).\n",
        "2. It's trace-preserving, which ensures that the total probability of all possible outcomes remains equal to 1.\n",
        "\n",
        "Given this, if E were to represent a CPTP map, then tr(𝑂E(𝜌)) still wouldn't itself be a CPTP map, but instead the expectation value of an observable given a quantum state evolved by a CPTP map."
      ],
      "metadata": {
        "id": "bxF65qHK441R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**calculate the density matrices and quantum channels of those classical operations that are represented as a quantum operation?**\n",
        "\n",
        "Yes, you can. A classical operation represented as a quantum operation can indeed have a density matrix and a quantum channel that describes it. Let's take the classical NOT operation as an example, which can be represented as a quantum operation using the Pauli-X (or NOT) gate.\n",
        "\n",
        "1. **Density Matrix**: The density matrix represents the state of a quantum system. If we start with a single qubit in the state |0⟩ (which can represent a classical bit in the state 0), the density matrix is given by |0⟩⟨0|, which is:\n",
        "\n",
        "    ```\n",
        "    ρ_0 = |0⟩⟨0| = [1, 0]\n",
        "                      [0, 0]\n",
        "    ```\n",
        "\n",
        "    If we apply the X gate (the quantum equivalent of the classical NOT operation), the qubit goes to the state |1⟩, and its density matrix is given by |1⟩⟨1|:\n",
        "\n",
        "    ```\n",
        "    ρ_1 = Xρ_0X† = |1⟩⟨1| = [0, 0]\n",
        "                                [0, 1]\n",
        "    ```\n",
        "\n",
        "    where X† is the conjugate transpose (also known as the Hermitian adjoint) of X, and it's equal to X because X is a Hermitian operator.\n",
        "\n",
        "2. **Quantum Channel**: The quantum channel describes a quantum operation. It is a map that takes the density matrix of the input state to the density matrix of the output state. For the X gate, the map is given by:\n",
        "\n",
        "    ```\n",
        "    Λ_X(ρ) = XρX†\n",
        "    ```\n",
        "\n",
        "    where ρ is the density matrix of the input state. This map tells us how the X gate transforms any given input state.\n",
        "\n",
        "In the above examples, we have treated a classical bit as a qubit in a definite state (either |0⟩ or |1⟩), and we have treated a classical NOT operation as a quantum X operation. This shows how classical operations and states can be embedded in the quantum framework. However, remember that this doesn't capture many of the unique features of quantum states and operations, such as superposition and entanglement."
      ],
      "metadata": {
        "id": "mNZHZ4RQ4wC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is the function space in a quantum computing operation (cptp map)?**\n",
        "\n",
        "In quantum computing, operations (also known as quantum gates or quantum channels) are often represented as Completely Positive Trace-Preserving (CPTP) maps. These maps represent the evolution of a quantum state in a quantum computation.\n",
        "\n",
        "**A quantum state is typically described as a density matrix**, which is a positive semidefinite operator with trace 1 on a Hilbert space. A Hilbert space is a complex vector space equipped with an inner product operation, and it is a key structure in quantum mechanics as it provides the stage on which quantum states exist and evolve.\n",
        "\n",
        "> **The \"function space\" in this context is the set of all possible quantum states, i.e., the set of all density matrices on the Hilbert space.**\n",
        "\n",
        "A CPTP map is a linear, completely positive, and trace-preserving transformation on this function space. It takes an initial quantum state (a point in the function space) and produces a final quantum state (another point in the same function space), describing the evolution of the state due to the quantum operation.\n",
        "\n",
        "In other words, **a CPTP map is a function that maps the function space of initial quantum states to the function space of final quantum states. Therefore, it is said to act on the \"function space\" of quantum states**.\n",
        "\n",
        "To make this a bit more concrete, consider a single qubit. Its Hilbert space is a two-dimensional complex vector space, and the set of density matrices on this space is the set of all 2x2 positive semidefinite matrices with trace 1. A single-qubit quantum operation is a CPTP map on this set of density matrices.\n",
        "\n",
        "CPTP maps are crucial in quantum information theory because they can represent not only idealized quantum gates but also realistic quantum operations that include effects such as decoherence and noise.\n"
      ],
      "metadata": {
        "id": "ztGyMd0ZfllE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Not all physical errors can be linear CPTP maps in a correlation space (quantum channels)**\n",
        "\n",
        "https://www.nature.com/articles/srep00508\n",
        "\n",
        "In the framework of quantum computational tensor network, which is a general framework of measurement-based quantum computation, the resource many-body state is represented in a tensor-network form (or a matrix-product form) and universal quantum computation is performed in a virtual linear space, which is called a correlation space, where tensors live. Since any unitary operation, state preparation and the projection measurement in the computational basis can be simulated in a correlation space, it is natural to expect that fault-tolerant quantum circuits can also be simulated in a correlation space. However, we point out that not all physical errors on physical qudits appear as linear completely-positive trace-preserving errors in a correlation space. Since the theories of fault-tolerant quantum circuits known so far assume such noises, this means that the simulation of fault-tolerant quantum circuits in a correlation space is not so straightforward for general resource states.\n",
        "\n"
      ],
      "metadata": {
        "id": "hvypLz1NhWFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What are quantum channel and Kraus operators?**\n",
        "\n",
        "In quantum mechanics, a quantum channel is a mathematical model used to describe the evolution of quantum states due to physical processes, which could be the deterministic dynamics of an isolated quantum system, or could include the effects of noise, dissipation, and decoherence that result from interactions with an environment. Quantum channels are crucial in quantum information theory and quantum computing, where they are used to model realistic, noisy quantum operations.\n",
        "\n",
        "A quantum channel is a completely positive, trace-preserving (CPTP) map. These properties reflect the basic requirements that any physical process must satisfy:\n",
        "\n",
        "- **Complete positivity** ensures that the evolution is physically valid not only for individual quantum states, but also for quantum states that are part of larger systems. This is essential because quantum systems can be entangled, meaning that the state of one system can't be described independently of the state of another system.\n",
        "- **Trace preservation** ensures that the total probability remains 1, reflecting the probabilistic interpretation of quantum mechanics.\n",
        "\n",
        "One common way to represent a quantum channel is by using Kraus operators. Given a quantum channel Λ, we can find a set of operators {K_i} such that the action of the channel on any state ρ is given by\n",
        "\n",
        "Λ(ρ) = Σ_i K_i ρ K_i†\n",
        "\n",
        "where † denotes the conjugate transpose, and the sum is over all i. The operators K_i are called the Kraus operators, or Kraus representation, of the channel.\n",
        "\n",
        "The Kraus operators must satisfy the completeness condition Σ_i K_i† K_i = I, where I is the identity operator, to ensure that the channel is trace-preserving.\n",
        "\n",
        "The Kraus representation is not unique; there can be many different sets of Kraus operators that represent the same quantum channel. The specific form of the Kraus operators can depend on the physical interpretation of the channel. For example, in a quantum system subject to dissipative processes or measurement, each Kraus operator might represent a different possible outcome or error process.\n"
      ],
      "metadata": {
        "id": "8XKy0JpymlW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is a quantum channel?**\n",
        "\n",
        "A quantum channel is a mathematical construct used in quantum information theory to describe the process of transmitting quantum information from one location to another, or more generally, the evolution of quantum states in a system over time. This evolution can be due to the natural dynamics of the system or because of an interaction with an environment, which might cause phenomena like decoherence or noise.\n",
        "\n",
        "Mathematically, a quantum channel is a completely positive, trace-preserving (CPTP) map. It takes a density matrix (which represents a quantum state) as input and returns another density matrix as output.\n",
        "\n",
        "The \"completely positive\" part means that the map preserves the positive semi-definiteness of the density matrix, which is a requirement for it to represent a valid physical state. The \"trace-preserving\" part means that the total probability of all possible outcomes (which is represented by the trace of the density matrix) remains equal to 1.\n",
        "\n",
        "One common example of a quantum channel is the depolarizing channel, which introduces a certain probability of error into each qubit of information transmitted through it. There are many other types of quantum channels that model different kinds of physical processes, including lossy channels, dephasing channels, amplitude damping channels, and more. Each channel has a different impact on the quantum states that pass through it, often reflecting the effects of different types of environmental noise or decoherence."
      ],
      "metadata": {
        "id": "u6AwpEdL1zvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Can you give me an example of a quantum channel?**\n",
        "\n",
        "Certainly, a straightforward example of a quantum channel is the \"bit-flip channel.\" This channel models the possible flipping of a qubit due to errors in a quantum computing environment.\n",
        "\n",
        "Let's denote the basis states of our qubit as |0⟩ and |1⟩. Suppose we have a single qubit quantum state ρ which we send through the bit-flip channel. After going through the channel, each qubit can either stay the same or be flipped, i.e., |0⟩ goes to |1⟩ and |1⟩ goes to |0⟩.\n",
        "\n",
        "Let's also say that the probability of a flip occurring is p. Then the probability that nothing happens is (1-p).\n",
        "\n",
        "The behavior of the bit-flip channel Λ can be described as:\n",
        "\n",
        "Λ(ρ) = (1-p)ρ + p XρX\n",
        "\n",
        "where X is the Pauli-X gate, which flips the state of a qubit.\n",
        "\n",
        "This description of the channel is essentially a probabilistic mixture of the identity operation (which leaves the state ρ unchanged) with weight (1-p), and the bit-flip operation (XρX) with weight p.\n",
        "\n",
        "This is a completely positive, trace-preserving (CPTP) map: it's \"completely positive\" because it preserves the positive semi-definiteness of the density matrix, and it's \"trace-preserving\" because the sum of the probabilities of all outcomes is 1 ((1-p) + p = 1), ensuring that the total quantum state remains normalized.\n",
        "\n",
        "As a consequence of going through this channel, quantum information can be lost or corrupted, which is a significant consideration in the design of quantum computing systems and quantum error correction codes."
      ],
      "metadata": {
        "id": "qANEZaHQ2g4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum Channels and How could you formalize stochastic maps between basis changes into quantum circuits?**\n",
        "\n",
        "Basis changes in quantum circuits are usually modeled with unitary transformations. A unitary transformation is a linear transformation that preserves the inner product in the space, and in quantum mechanics, it corresponds to a deterministic evolution of the quantum state.\n",
        "\n",
        "However, if we're looking to introduce stochastic elements into quantum circuits, there are ways to do so, primarily through the use of quantum channels.\n",
        "\n",
        "A quantum channel is a completely positive, trace-preserving (CPTP) map that represents a physical process in quantum mechanics. While unitary transformations correspond to ideal, noiseless operations, quantum channels can represent realistic, noisy operations. This includes both coherent operations, represented by unitary transformations, and incoherent or stochastic operations, represented by non-unitary transformations.\n",
        "\n",
        "To introduce stochasticity, you can consider the notion of a mixed state, represented by a density matrix, which can be understood as a statistical mixture of different pure states. A quantum channel can take a pure state and produce a mixed state, representing a stochastic process.\n",
        "\n",
        "More precisely, a quantum channel Λ can be represented by a set of Kraus operators {K_i}. These Kraus operators act on a state ρ as follows:\n",
        "\n",
        "Λ(ρ) = Σ_i K_i ρ K_i†\n",
        "\n",
        "where the sum is over all i, and † denotes the Hermitian adjoint (conjugate transpose). The Kraus operators are required to satisfy the completeness condition Σ_i K_i† K_i = I, where I is the identity operator.\n",
        "\n",
        "To encode a stochastic map into a quantum circuit, you'd need to find a suitable set of Kraus operators representing the stochastic process, and incorporate them into your circuit model.\n",
        "\n",
        "Keep in mind, however, that not all stochastic maps can be physically realized as quantum channels. The map must satisfy the conditions for a CPTP map, i.e., it must be completely positive and preserve the trace of the density matrix.\n",
        "\n",
        "Also note that while quantum channels provide a way to model stochastic processes, they are not usually implemented directly in quantum circuits on current quantum computers, which typically only perform unitary transformations directly. However, they can be used to model the effects of noise and errors in these circuits, and can be implemented indirectly using techniques like quantum error correction and quantum teleportation.\n",
        "\n"
      ],
      "metadata": {
        "id": "hOo54ImZma0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *$\\hookrightarrow$ Operators*"
      ],
      "metadata": {
        "id": "EBxdSfTogMN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classical: what is a signal-processing operator?**\n",
        "\n",
        "In signal processing, an operator is a mathematical function that acts on a signal to transform it in some way. Signal processing operators are used to perform a wide variety of tasks, such as filtering, modulation, and compression.\n",
        "\n",
        "**Types of Signal Processing Operators**\n",
        "\n",
        "There are many different types of signal processing operators, but they can be broadly categorized into two groups: linear and nonlinear.\n",
        "\n",
        "* **Linear operators** satisfy the principle of superposition, which means that if the operator is applied to the sum of two signals, the result is the sum of the operator's outputs on the two individual signals. Linear operators are also characterized by the fact that they preserve the magnitude and phase of the signal's frequency components. Examples of linear operators include filters, amplifiers, and delay lines.\n",
        "\n",
        "* **Nonlinear operators** do not satisfy the principle of superposition. Nonlinear operators can change the shape of the signal's waveform, introduce distortion, and even create new signal components. Examples of nonlinear operators include squaring, clipping, and thresholding.\n",
        "\n",
        "**Applications of Signal Processing Operators**\n",
        "\n",
        "Signal processing operators are used in a wide variety of applications, including:\n",
        "\n",
        "* **Audio signal processing:** Filtering, equalization, noise reduction, compression, and enhancement\n",
        "* **Speech processing:** Speech recognition, speaker identification, and speech synthesis\n",
        "* **Image processing:** Noise reduction, sharpening, compression, and enhancement\n",
        "* **Radar and sonar processing:** Target detection, tracking, and classification\n",
        "* **Telecommunications:** Signal modulation, demodulation, and error correction\n",
        "\n",
        "**Examples of Signal Processing Operators**\n",
        "\n",
        "Here are some examples of common signal processing operators:\n",
        "\n",
        "* **Convolution:** Combines two signals by summing their overlapping segments.\n",
        "* **Correlation:** Measures the similarity between two signals by calculating the sum of their product over time or frequency.\n",
        "* **Fourier transform:** Converts a signal from the time domain to the frequency domain, or vice versa.\n",
        "* **Discrete Fourier transform (DFT):** A specific implementation of the Fourier transform for discrete-time signals.\n",
        "* **Fast Fourier transform (FFT):** A more efficient algorithm for computing the DFT.\n",
        "* **Laplace transform:** Converts a signal from the time domain to the frequency-domain, or vice versa, using the Laplace transform function.\n",
        "* **Z-transform:** Converts a discrete-time signal from the time domain to the frequency-domain using the Z-transform function.\n",
        "\n",
        "These are just a few examples of the many signal processing operators that are used in a variety of applications."
      ],
      "metadata": {
        "id": "emRVcbLzqs98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is the rank of an operator?**\n",
        "\n",
        "* The term \"rank\" in the context of matrices refers to the dimension of the column space (or equivalently, the row space) of the matrix. Specifically, the rank of a matrix is the maximum number of linearly independent column vectors (or equivalently, row vectors) in the matrix. It gives a measure of the \"information content\" of the matrix, in the sense of how many independent directions it spans.\n",
        "\n",
        "* However, when discussing quantum mechanics and, more broadly, linear operators in a Hilbert space, the term \"rank\" is less commonly used in the same way as for matrices. Nonetheless, for operators that can be represented as matrices (as is the case in finite-dimensional Hilbert spaces), the rank of the operator is equivalent to the rank of its matrix representation.\n",
        "\n",
        "* For a given operator \\( \\hat{O} \\) with a matrix representation \\( O \\), the rank of \\( \\hat{O} \\) is the rank of \\( O \\). In this context, the rank of the operator essentially tells you the number of non-zero eigenvalues (counted with multiplicity) or, equivalently, the dimension of the subspace onto which the operator has non-trivial action.\n",
        "\n",
        "* In summary, when talking about operators in quantum mechanics or other areas of functional analysis, the rank of an operator (when it's represented as a matrix) is the dimension of the subspace in which the operator acts non-trivially.\n",
        "\n",
        "The rank of an operator is the maximum number of linearly independent rows or columns of the matrix that represents the operator. In other words, it is the dimension of the subspace of the Hilbert space that the operator maps to itself.\n",
        "\n",
        "* **Rank 1 operators:** Rank 1 operators are also known as dyads. They are operators that can only project onto a one-dimensional subspace of the Hilbert space. For example, the Pauli X operator is a rank 1 operator. (->questionable)\n",
        "\n",
        "* **Rank 2 operators:** Rank 2 operators are operators that can project onto a two-dimensional subspace of the Hilbert space. For example, the Pauli Z operator is a rank 2 operator. (->questionable)\n",
        "\n",
        "* **Rank 3 operators:** Rank 3 operators are operators that can project onto a three-dimensional subspace of the Hilbert space. For example, the Pauli Y operator is a rank 3 operator. (->questionable)\n",
        "\n",
        "Higher-rank operators can also exist, but they are less common.\n",
        "\n",
        "Rank 1, 2, and 3 operators are important in quantum computing because they can be used to implement a variety of quantum algorithms and protocols. For example, the Hadamard gate is a rank 3 operator, and it is used in many quantum algorithms, such as Shor's algorithm.\n",
        "\n",
        "Here are some examples of rank 1, 2, and 3 operators in quantum computing:\n",
        "\n",
        "* **Rank 1:** Pauli X, Pauli Y, Pauli Z\n",
        "* **Rank 2:** Hadamard gate, Controlled-NOT gate\n",
        "* **Rank 3:** Toffoli gate, Swap gate\n",
        "\n",
        "I hope this helps!\n"
      ],
      "metadata": {
        "id": "OZ5QxG31fR3-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**super-operator**\n",
        "\n",
        "In the field of quantum mechanics and quantum information theory, a superoperator is a type of operator that acts on other operators, rather than on states. In the context of quantum mechanics, these \"other operators\" are usually the density matrices that represent quantum states.\n",
        "\n",
        "This concept is needed because in quantum mechanics, the evolution of a system can often be represented as an operator acting on the state of the system. However, when we consider more complicated situations, like a quantum system interacting with an environment (leading to phenomena such as decoherence), the evolution of the system can involve operations that change the nature of the operator that represents the state itself. This kind of operation is represented by a superoperator.\n",
        "\n",
        "Formally, a superoperator Φ acting on an operator A would be written as Φ(A), and this results in another operator.\n",
        "\n",
        "One common example of a superoperator is the Liouville superoperator, which appears in the Liouville-von Neumann equation describing the time evolution of a quantum system. If H is the Hamiltonian of the system and ρ is the density operator, the Liouville superoperator L acting on ρ is defined as:\n",
        "\n",
        "L(ρ) = -i[H, ρ]\n",
        "\n",
        "where [ , ] denotes the commutator.\n",
        "\n",
        "***Another important class of superoperators are the completely positive trace preserving (CPTP) maps***, which are used to describe the evolution of quantum systems in the presence of decoherence. A quantum operation (also called a quantum channel) is a CPTP map and can be represented as a superoperator acting on the density matrix of a quantum state."
      ],
      "metadata": {
        "id": "1-daOZv2mFJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For what do you need a kraus operator?**\n",
        "\n",
        "Kraus operators are a useful tool for representing and working with quantum channels, which are mathematical models that describe the evolution of quantum states due to physical processes. These processes can include both the deterministic dynamics of an isolated quantum system, and the effects of noise, dissipation, and decoherence due to interactions with an environment.\n",
        "\n",
        "Here are some specific uses for Kraus operators:\n",
        "\n",
        "1. **Modeling realistic quantum operations**: In quantum computing and quantum information theory, we often need to model not just ideal, noiseless operations (which are represented by unitary transformations), but also realistic, noisy operations. Kraus operators provide a way to do this. Each Kraus operator can represent a different possible outcome or error process that can occur during the operation.\n",
        "\n",
        "2. **Calculating the effect of a quantum channel**: Given the Kraus operators for a quantum channel, we can calculate how the channel will transform any quantum state. This is useful for predicting the results of quantum computations or quantum communications in the presence of noise.\n",
        "\n",
        "3. **Studying quantum decoherence**: Kraus operators provide a mathematical framework for studying decoherence, which is the process by which a quantum system loses its quantum properties due to interactions with its environment. Each Kraus operator can represent a different type of interaction with the environment.\n",
        "\n",
        "4. **Quantum error correction**: Kraus operators can represent different types of errors that can occur in a quantum system. This is crucial for designing quantum error correction codes, which are schemes for detecting and correcting errors in quantum computations or communications.\n",
        "\n",
        "5. **Quantum process tomography**: This is a technique for experimentally determining the Kraus operators of a quantum channel, which can provide insights into the physical processes occurring in a quantum system.\n",
        "\n",
        "Overall, Kraus operators provide a flexible and powerful mathematical tool for describing and analyzing the dynamics of quantum systems, especially in the presence of noise and other non-ideal effects.\n"
      ],
      "metadata": {
        "id": "n4Impp-7m0bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What are Lindblad operators?**\n",
        "\n",
        "Lindblad operators (also sometimes referred to as \"jump\" operators) are a fundamental component of Lindblad equations, which are used in the field of quantum mechanics to describe the evolution of quantum systems that interact with an environment. This interaction leads to effects such as decoherence and dissipation, which are not captured by the basic Schrödinger equation.\n",
        "\n",
        "The general form of a Lindblad equation is:\n",
        "\n",
        "dρ/dt = -i[H, ρ] + Σ_k γ_k (L_k ρ L_k† - 1/2 {L_k† L_k, ρ})\n",
        "\n",
        "Here:\n",
        "\n",
        "- H is the Hamiltonian of the system, which describes its energy and governs its unitary (non-dissipative) evolution.\n",
        "- ρ is the density matrix of the system, which encapsulates the state of the system.\n",
        "- The brackets [ , ] and { , } denote the commutator and anticommutator respectively.\n",
        "- The L_k are the Lindblad operators, which describe how the system interacts with its environment.\n",
        "- The γ_k are positive decay rates associated with each Lindblad operator.\n",
        "\n",
        "Each Lindblad operator L_k represents a certain type of interaction between the quantum system and its environment. The precise form of these operators depends on the specifics of the system and its environment. For example, in a system of quantum harmonic oscillators, the Lindblad operators might be the creation and annihilation operators for each oscillator.\n",
        "\n",
        "The non-unitary part of the Lindblad equation (the second term on the right-hand side) describes how these interactions cause the system to decay towards a steady state, and is responsible for phenomena such as relaxation and decoherence. The Lindblad equation is the most general form for the time evolution of a quantum system that ensures complete positivity and trace preservation of the density matrix, two crucial physical requirements."
      ],
      "metadata": {
        "id": "2TfI0tinl43W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What‘s the difference between kraus operator and lindblatt operator?**\n",
        "\n",
        "Kraus operators and Lindblad operators are both tools used to represent and study the evolution of quantum systems, especially when these systems are interacting with an environment. However, they are used in slightly different contexts and represent different types of processes.\n",
        "\n",
        "1. **Kraus Operators**: Kraus operators are used to represent quantum channels, which are completely positive, trace-preserving (CPTP) maps that describe the evolution of quantum states. The Kraus representation is a way to express a quantum channel as a sum of terms, each of which consists of a Kraus operator acting on the quantum state. The Kraus operators can represent different types of interactions with the environment or different possible outcomes of a quantum process.\n",
        "\n",
        "2. **Lindblad Operators**: Lindblad operators are used specifically to represent the generators of Markovian, open quantum systems in the Lindblad equation (also called the Gorini–Kossakowski–Sudarshan–Lindblad equation). The Lindblad equation describes the time evolution of a quantum system that is undergoing continuous, irreversible dynamics due to its interaction with a large, uncontrolled environment (a process called \"decoherence\"). Each Lindblad operator represents a different type of interaction with the environment.\n",
        "\n",
        "So, in brief: Kraus operators are used to represent discrete transformations of quantum states in general quantum channels, while Lindblad operators are used to represent continuous, Markovian dynamics in open quantum systems.\n",
        "\n",
        "It's also worth noting that the Lindblad equation is one way to derive Kraus operators for a quantum channel, specifically when the channel represents the evolution of a system over a small time interval under continuous, Markovian dynamics. In this case, the Lindblad operators determine the form of the Kraus operators."
      ],
      "metadata": {
        "id": "hFbdLJLMm4re"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Can one say that Kraus operators are bounded, and Lindblad operators unbounded? Or is that wrong?**\n",
        "\n",
        "In quantum mechanics, both Kraus and Lindblad operators act on a finite-dimensional Hilbert space (when we're considering finite quantum systems such as qubits, which are the building blocks of quantum computers), and hence they are indeed bounded operators. A bounded operator is an operator that doesn't amplify any vector in the Hilbert space by more than a certain factor, the operator norm.\n",
        "\n",
        "When the quantum system is finite-dimensional, the concepts of \"bounded\" and \"unbounded\" don't really come into play, because all operators on a finite-dimensional Hilbert space are automatically bounded.\n",
        "\n",
        "However, if you are considering infinite-dimensional systems, such as quantum fields or harmonic oscillators, then it becomes meaningful to talk about bounded and unbounded operators. In this case, Lindblad operators (the ones appearing in the Lindblad equation, governing the dynamics of open quantum systems) are typically unbounded.\n",
        "\n",
        "This difference arises because the Lindblad equation is a differential equation, and the Lindblad operators often represent physical quantities such as position and momentum, which are unbounded operators on infinite-dimensional Hilbert spaces. On the other hand, a Kraus representation of a quantum channel represents the action of the channel on the quantum state at a specific point in time, and this action can usually be expressed in terms of bounded operators.\n",
        "\n",
        "But to summarize, in the finite-dimensional case (which is the relevant case for most quantum computing applications), both Kraus and Lindblad operators are bounded. In the infinite-dimensional case, Kraus operators are generally still bounded, while Lindblad operators can be unbounded.\n"
      ],
      "metadata": {
        "id": "0SJBdUtqnADp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Do you have an example of a Kraus operator and a Lindblad operator in the context of quantum computing?**\n",
        "\n",
        "Sure, I can provide some simple examples of both Kraus and Lindblad operators in the context of quantum computing.\n",
        "\n",
        "1. **Kraus Operators**: Kraus operators are used to describe the evolution of quantum states in the presence of noise or decoherence. They form a set of matrices {K_i} such that the sum of the Hermitian conjugates of each K_i times K_i is the identity matrix.\n",
        "\n",
        "    For instance, let's consider a single qubit undergoing bit flip error with a certain probability p. The error can be described by two Kraus operators:\n",
        "\n",
        "    K_0 = sqrt(1-p) * I,\n",
        "    K_1 = sqrt(p) * X,\n",
        "\n",
        "    where I is the identity operator and X is the Pauli-X operator. These operators satisfy the condition K_0†K_0 + K_1†K_1 = I, which ensures the resulting quantum state is still a valid density matrix.\n",
        "\n",
        "2. **Lindblad Operators**: Lindblad operators (also known as jump operators) are used in the Lindblad equation, which describes the time evolution of an open quantum system.\n",
        "\n",
        "    For instance, a common Lindblad operator for a single qubit undergoing amplitude damping (energy relaxation) is:\n",
        "\n",
        "    L = sqrt(γ) * |0><1|,\n",
        "\n",
        "    where |0> and |1> are the computational basis states of the qubit, and γ is the damping rate. This Lindblad operator represents the process of the qubit transitioning from the excited state |1> to the ground state |0>.\n",
        "\n",
        "    In the context of a Lindbladian superoperator (describing the complete evolution), you might see this operator appearing in a term like L ρ L† in the master equation.\n",
        "\n",
        "These are quite simplified examples. In practice, the Kraus and Lindblad operators for a realistic quantum system could be more complex and might depend on the specific physical details of the system.\n",
        "\n"
      ],
      "metadata": {
        "id": "Zyvxk6BPnnh8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is an example of unbounded operators that lead to pathological behavior in the study of infinite-dimensional spaces in functional analysis?**\n",
        "\n",
        "Unbounded operators in infinite-dimensional spaces often require careful treatment because they can lead to \"pathological\" behavior, i.e., behavior that violates our usual intuitions or expectations based on finite-dimensional spaces.\n",
        "\n",
        "One classical example is the momentum operator in quantum mechanics, which is defined on the space of square-integrable functions over the real numbers (which is an infinite-dimensional space). The momentum operator is given by -iħd/dx, where i is the imaginary unit, ħ is the reduced Planck constant, and d/dx is the derivative operator.\n",
        "\n",
        "This operator is unbounded, meaning there's no finite number B such that the norm of the momentum operator acting on any state is less than or equal to B times the norm of the state. As a result, the momentum operator can't be defined on the entire Hilbert space, but only on a dense subset (the set of differentiable functions, in this case).\n",
        "\n",
        "One \"pathological\" behavior of the momentum operator is that it doesn't have any eigenstates that belong to the Hilbert space. In quantum mechanics, we often want to find eigenstates of operators because these correspond to \"observable\" states of the system with definite values of the associated physical quantity. For the momentum operator, the eigenstates are plane waves, which are not square-integrable and hence do not belong to the Hilbert space.\n",
        "\n",
        "This behavior is quite different from what we see with bounded operators, where the eigenstates always belong to the same space as the operator. In order to deal with this kind of issue, physicists often have to introduce additional mathematical structures, such as rigged Hilbert spaces, or use indirect methods, such as the spectral theorem for unbounded self-adjoint operators, to make sense of the physical meaning of unbounded operators like the momentum operator."
      ],
      "metadata": {
        "id": "0ZubXnvmnE2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sign structure in quantum operators**\n",
        "\n",
        "The term \"sign structure\" is not standard terminology in quantum mechanics, so it may be interpreted in different ways depending on the context. In general, the mathematical operators used in quantum mechanics can have complex values and can act on complex-valued wavefunctions or on operators themselves, so they don't have a \"sign\" in the way that real numbers do.\n",
        "\n",
        "However, there are a few contexts where the notion of sign can be important in quantum mechanics:\n",
        "\n",
        "1. **Parity**: The parity operator is a specific quantum mechanical operator that represents spatial inversion (flipping the sign of the spatial coordinates). Eigenstates of the parity operator can have positive or negative eigenvalues, often interpreted as \"even\" or \"odd\" parity.\n",
        "\n",
        "2. **Spin**: In quantum mechanics, particles like electrons have a property called spin, which can take on positive or negative values (typically +1/2 or -1/2 for electrons).\n",
        "\n",
        "3. **Commutation relations**: Certain pairs of quantum operators have commutation relations that involve the imaginary unit \"i\", which could be interpreted as a kind of \"sign\" structure. For example, the position operator x and momentum operator p have the commutation relation [x, p] = iħ, where ħ is the reduced Planck's constant.\n",
        "\n",
        "4. **Phase factors**: In quantum mechanics, the overall sign (or more generally, phase factor) of a wavefunction is not observable, which leads to the principle of quantum superposition and interference effects.\n",
        "\n",
        "If you're asking about a specific aspect of quantum mechanics or a specific type of quantum operator, I'd be happy to provide more information!"
      ],
      "metadata": {
        "id": "fgSc_9VsmNdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what is meant by the sign of a trace?**\n",
        "\n",
        "The \"sign\" of a trace simply refers to whether the trace of a matrix (or operator in the context of quantum mechanics) is positive, negative, or zero.\n",
        "\n",
        "The trace of a matrix is the sum of its diagonal elements. If this sum is greater than zero, we say that the trace (and hence the matrix or operator) is positive. If the sum is less than zero, the trace is negative. If the sum is exactly zero, the trace is zero.\n",
        "\n",
        "This concept is often used in the context of quantum mechanics, where the trace of an operator can provide important physical information. For example, in the context of quantum density matrices, a trace of one is associated with a valid physical state.\n",
        "\n",
        "Please note that the sign of the trace of a matrix does not necessarily indicate that all elements, or even all eigenvalues, of the matrix are of the same sign. It's possible for a matrix to have both positive and negative eigenvalues but for their sum (i.e., the trace) to be positive, negative, or zero. Similarly, it's possible for a matrix to have positive and negative elements but for their diagonal sum (i.e., the trace) to be positive, negative, or zero."
      ],
      "metadata": {
        "id": "2LjS8JA23j-T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RscthBMzOLUM"
      },
      "source": [
        "###### *Schrödinger Equation*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [Hamiltonian Time Evolution](https://youtu.be/1zrtUmXR7Ew?si=bL-UX6NIPzbu1zV2)"
      ],
      "metadata": {
        "id": "IcfleABCelIy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Understand effects of environment (noise)**\n",
        "\n",
        "A spin does not indefinitely precess around the magnetic field (according to the Schrödinger equation), because it interacts with the environment (electrons, photons, nuclear spins from outside), which makes it stop. (Lots of noise = degrees of freedom that interact)\n",
        "\n",
        "[Universal Lindblad equation for open quantum systems - Frederik Nathan](https://www.youtube.com/watch?v=j5yW2MtOwwA&list=WL&index=10&t=294s)\n",
        "\n",
        "Impossible to track evolution of entire universe: If the universe is 10^26 degrees of freedom then we need 2^10^26 numbers to just keep track of the wave function.\n",
        "\n",
        "Impossible to solve the Schrodinger equation for an open quantum system\n",
        "\n",
        "> $\\begin{gathered}H=H_{\\mathrm{S}}+H_{\\mathrm{B}}+\\sqrt{\\gamma} X B \\\\ \\left|\\psi_0\\right\\rangle=\\left|\\psi_S\\right\\rangle \\times\\left|\\psi_B\\right\\rangle \\quad \\partial_t|\\psi(t)\\rangle=-i H|\\psi(t)\\rangle\\end{gathered}$\n",
        "\n",
        "instead: use reduced density matrix that encodes all information of the system:\n",
        "\n",
        "> $\\rho(t)=\\operatorname{Tr}_{\\mathrm{B}}|\\psi(t)\\rangle(\\psi(t) \\mid, \\quad\\langle(t))=\\operatorname{Tr}[O \\rho(t)]$"
      ],
      "metadata": {
        "id": "8FPtRRg90PbB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIrMWsUSPKj2"
      },
      "source": [
        "> for fast moving electrons or electrons in electro-magnetic fields, the Schroedinger equation gives the wrong answers (see quantum field theory, spinor field)\n",
        "\n",
        "<font color=\"blue\">**From Newton's 2nd Law of Motion to the Schrödinger Equation**\n",
        "\n",
        "**Step 1: Starting with Newton's 2nd law of motion**\n",
        "\n",
        "* let's assume a particle is moving along an x-axis and we apply several forces on it $\\overrightarrow{F}_1$, $\\overrightarrow{F}_2$, .. $\\overrightarrow{F}_n$\n",
        "\n",
        "* these forces depend on the position $x$ of the particle and the time elapsed $t$\n",
        "\n",
        "Then we can find the particle's position $x$ as a function of time using **Newton's 2nd law**:\n",
        "\n",
        "> $\\vec{F}_{net}=\\sum \\vec{F}_{i}(x, t)=m \\vec{a}  \\quad(\\text { Newton's 2nd law })$\n",
        "\n",
        "But the law of acceleration $\\vec{a}$ can be also written as the second time derivative of position, so we end up with a [governing equation](https://en.wikipedia.org/wiki/Governing_equation) like this, the **Equation of Motion**:\n",
        "\n",
        "> $m \\frac{d^{2} x}{d t^{2}}=\\sum_{i=1}^{n} F_{i}(x, t) \\quad(\\text { Equation of Motion })$\n",
        "\n",
        "* (another way of writing it is: $m \\ddot x = -kx$, see Colab 'Variationsrechnung')\n",
        "\n",
        "* Once we solve this equation for the particle's position, we could infer many things about the particle's state, such as its velocity, kinetic energy etc.\n",
        "\n",
        "* *Exkurs: The governing equations of a mathematical model describe how the values of the unknown variables (i.e. the dependent variables) change when one or more of the known (i.e. independent) variables change*\n",
        "\n",
        "**Step 2: Schrödinger Equation & Operator /Functionals**\n",
        "* The goal of quantum mechanics is to solve the Schrödinger Equation, which is very similar conceptually\n",
        "\n",
        "> $i \\hbar \\frac{\\partial \\Psi}{\\partial t}=\\frac{-\\hbar^{2}}{2 m} \\frac{\\partial^{2} \\psi}{\\partial x^{2}}+V \\psi$\n",
        "\n",
        "\n",
        "* in contrast to classical equation of motion, where we solve for position and then get velocity, kinetic energy etc about particle's state, **in the Schrodinger equation we solve for wavefunction** $\\psi$! (because that is kind of it's position :)\n",
        "\n",
        "  * $\\frac{-\\hbar^{2}}{2 m} \\frac{\\partial^{2}}{\\partial x^{2}}$ this is the Kinetic energy operator $L$ on the wavefunction $\\psi$\n",
        "\n",
        "  * $V$ represents the potential energy operator\n",
        "\n",
        "<font color=\"red\">**In quantum mechanics we use the term operator because you generally don't get fixed numerical values for kinetic and potential energy.**</font>\n",
        "\n",
        "* Instead you need to perform operations on the wavefunction to extract those kinetic and potential energy values. That's what these operators do.\n",
        "\n",
        "* You can think of Schrodinger equation as a statement of energy conservation: kinetic energy + potential energy = total energy (which is on the left side of the v)\n",
        "\n",
        "**Step 3: Wavefunction & (Dirac) Delta Function**\n",
        "\n",
        "* the wavefunction represents the state of a system - related to the probability of finding a particle at a particular region in the domain which it occupies\n",
        "\n",
        "* the square of the norm of the wavefunction gives the probability density function of a particle.\n",
        "\n",
        "* if you integrate this norm squared over the entire domain you will get 1\n",
        "\n",
        "> $\\int_{-\\infty}^{\\infty}|\\Psi|^{2} d x=1$\n",
        "\n",
        "* you can't tell exactly where the position of a particle is before measurement, just a probability, same for velocity, momentum, kinetic energy etc.\n",
        "\n",
        "* But if you **apply the measurement operator, you change the wavefunction**! after one measurement, or further measurements will always get you the same result\n",
        "\n",
        "**So instead of being a probability distribution that covers multiple values, <font color=\"red\">by taking a measurement I change the wavefunction to a [delta function](https://de.wikipedia.org/wiki/Delta-Distribution) with one spike at what my measurement gave me. If I take more measurement on the same system, the delta function doesnt change.</font> This is called the wavefunction collapse.**\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_174.png)\n",
        "\n",
        "* However, if I let the system settle so that it eventually occupies its original wavefunction it had and then if I take my measurement, I might get something different according to the probability distribution corresponding to my original wavefunction\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_175.png)\n",
        "\n",
        "**Step 4: Partial Differential Equation**\n",
        "\n",
        "> $i \\hbar \\frac{\\partial \\Psi}{\\partial t}=\\frac{-\\hbar^{2}}{2 m} \\frac{\\partial^{2} \\psi}{\\partial x^{2}}+V \\psi$\n",
        "\n",
        "* when solving a partial differential equation we also need auxiliary conditions in order to determine the unknown constants that you get from the integration process that's inherent in solving a differential equation\n",
        "\n",
        "* auxiliary conditions = initial conditions and boundary conditions\n",
        "\n",
        "* however the Schrodinger equation doesn't come with your typical boundary conditions that you might be used to seeing\n",
        "\n",
        "**Instead,the auxiliary condition we have on our solution is the normalization constraint: $\\int_{-\\infty}^{\\infty}|\\Psi|^{2} d x=1$**\n",
        "\n",
        "* Solutions to the Schrodinger equation have two be normalizable because they are wavefunctions, and in a way they represent probability density functions\n",
        "\n",
        "\t* if the solutions to Schrodinger's equation are not normalizable, we can't use them to represent a physical system\n",
        "\n",
        "\t* the trivial solution $\\psi$ (x,t) = 0 is not normalizable, because its integral from negative infinity to infinity will always be 0, it can never be 1, which is why $\\psi$ (x,t) = 0 is an unphysical solution, because the particle has to be somewhere\n",
        "\n",
        "**Step 5: Solving Schrodinger's Equation under the normalization condition**\n",
        "\n",
        "Let's say we solve Schrodinger's equation and we get following solution:\n",
        "\n",
        "> $\\Psi (x,t) = A f(x,t)$ with $A$ being an arbitrary constant\n",
        "\n",
        "* The process of normalization is to find the value of the constant $A$ so that the solution obeys the normalization condition:\n",
        "\n",
        "> $\\int_{-\\infty}^{\\infty}|\\psi|^{2} d x=\\int_{-\\infty}^{\\infty}|A f|^{2} d x = 1$\n",
        "\n",
        "* we might end up with a difficult task if the wavefunction is dependent on time, which means it has a different shape for different times, then wouldn't the normalization constant change with time as well?\n",
        "\n",
        "* the answer is NO!\n",
        "\n",
        "**Theorem**: If you normalize the wavefunction once then you don't need to normalize for other times = the normalization stays preserved !\n",
        "\n",
        "**Proof**:\n",
        "\n",
        "* the norm squared of a wavefunction is just the complex conjugate of that wavefunction time the wavefunction: $|\\psi|^{2}=(\\psi)^{*} \\psi$\n",
        "\n",
        "* if we go back to the Schrodinger equation we would see that the complex conjugate of the equation would be something like this with all they size turned into their conjugates and all the imaginary terms with their signs switched:\n",
        "\n",
        "> $i \\hbar \\frac{\\partial \\Psi}{\\partial t}=\\frac{-\\hbar^{2}}{2 m} \\frac{\\partial^{2} \\psi}{\\partial x^{2}}+V \\psi$\n",
        "\n",
        "> $-i \\hbar \\frac{\\partial \\psi^{*}}{\\partial t}=\\frac{-\\hbar^{2}}{2 m} \\frac{\\partial^{2} \\psi^{*}}{\\partial x^{2}}+V \\psi^{*}$\n",
        "\n",
        "* the goal of the proof is to show that this normalization integral $\\int_{-\\infty}^{\\infty}|\\psi|^{2} d x=$ const doesn't change with time, it stays the same:\n",
        "\n",
        "* the way to do this is to take the time derivate: if we can show that the time derivative of the normalization integral is 0 then our proof is complete $\\frac{d}{a t}\\left[\\int_{-\\infty}^{\\infty}|\\varphi|^{2} d x\\right]=0$\n",
        "\n",
        "* see complete proof in [video](https://www.youtube.com/watch?v=kUm4q0UIpio&list=WL&index=72&t=651s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HCh0gYIJv8x"
      },
      "source": [
        "<font color=\"blue\">**Schrödinger Equation (Time Independent / Eigenvalue Equation)**</font>\n",
        "\n",
        "Time independent = Total energy of a system does NOT change with time\n",
        "\n",
        "**The Schroedinger equation can be written as a type of Eigenvalue equation**\n",
        "\n",
        "> $\\hat{H}|\\psi\\rangle= -i \\hbar \\frac{d}{d t}|\\psi\\rangle =\\frac{\\hbar}{i} \\frac{d}{d t}|\\psi\\rangle$\n",
        "\n",
        "**Simplified (when system is not changing over time: time-independent Schroedinger equation):**\n",
        "\n",
        "> $\\hat{H}|\\psi\\rangle=E |\\psi\\rangle$\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_151.png)\n",
        "\n",
        "> $E \\Psi(x)=\\frac{-\\hbar^{2}}{2 m} \\frac{d^{2} \\Psi(x)}{d x^{2}}+V \\Psi(x)$\n",
        "\n",
        "* E = **Energy the electron** is allowed to have\n",
        "\n",
        "* $\\Psi$ = **Wavefunction** (most likely position of an electron)\n",
        "\n",
        "* **Kinetic energy**: $\\frac{-\\hbar^{2}}{2 m} \\frac{d^{2} \\Psi(x)}{d x^{2}}$ (klassische Form: $K E=\\frac{1}{2} m v^{2}$)\n",
        "\n",
        "* **Potential energy**: $V \\Psi(x)$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ELVzEm879_7"
      },
      "source": [
        "*What would a typical Schroedinger solution look like? - All the solutions to the wave function take these two forms:*\n",
        "\n",
        "> $\\Psi(x)=\\sqrt{\\frac{2}{L}} \\cos \\left(\\frac{\\pi n x}{L}\\right)$ when $n=1,3,5 \\ldots$ (is odd $)$\n",
        "\n",
        "> $\\Psi(x)=\\sqrt{\\frac{2}{L}} \\sin \\left(\\frac{\\pi n x}{L}\\right)$ when $n=2,4,6 \\ldots$ (is even)\n",
        "\n",
        "*Now looking at $\\psi$, the probable position of an electron:*\n",
        "\n",
        "* central question: where is the electron?\n",
        "\n",
        "* n is the energy state / level of an electron (look above at quantum numbers)\n",
        "\n",
        "* When an electron is state n=1 (its first energy state) we apply the first formula: $\\Psi(x)=\\sqrt{\\frac{2}{L}} \\cos \\left(\\frac{\\pi n x}{L}\\right)$\n",
        "\n",
        "* then we get wave function for the electron that is in a given box in this case:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_147.png)\n",
        "\n",
        "* And if we square it, we get the probability distribution (the probable position of an electron):\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_148.png)\n",
        "\n",
        "\n",
        "* And here some wave functions and probability densities for other energy states:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_149.png)\n",
        "\n",
        "*And the solution that popped out was this:*\n",
        "\n",
        "> $E=\\frac{\\hbar^{2} n^{2} \\pi^{2}}{2 m L^{2}}$\n",
        "\n",
        "* Everything is a constant ($\\hbar$, $\\pi$, 2, m, L) or a whole number (here: n, which stands for the different states of an electron)\n",
        "\n",
        "* which means that energy E can ony have certain discrete (=quantum) values\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIv5tk_B7h9Q"
      },
      "source": [
        "<font color=\"blue\">**How to solve the Schrödinger Equation (Time Independent)**\n",
        "\n",
        "Assumption: particle is moving on one line between 0 and a and limited by infinite blocks left and right, where its probability is 0 and the potential energy infinite = this means that the particle can only be found on the line between 0 and a.\n",
        "\n",
        "[SOLVING the SCHRODINGER EQUATION | Quantum Physics by Parth G](https://www.youtube.com/watch?v=sPZWtZ8vt1w)\n",
        "\n",
        "**Step 1: Take Schrodinger Equation, remove $V$ and focus on differential equation of kinetic energy term**\n",
        "\n",
        "* now we want to compute the wavefunction of this particle with the (Time Independent) Schrödinger Equation\n",
        "\n",
        "> $\\frac{-\\hbar^{2}}{2 m} \\frac{d^{2} \\Psi}{d x^{2}}+V \\Psi=E \\Psi$\n",
        "\n",
        "* the potential energy V is zero between 0 and a because nothing influences the particle, so it becomes this **differential equation** that we need to solve:\n",
        "\n",
        "> $\\frac{-\\hbar^{2}}{2 m} \\frac{d^{2} \\Psi}{d x^{2}}=E \\Psi$\n",
        "\n",
        "* $\\frac{d^{2} \\Psi}{d x^{2}}$ is second derivative of $\\Psi$ with respect to x\n",
        "\n",
        "We want to solve this equation:\n",
        "\n",
        "> $\\frac{-\\hbar^{2}}{2 m}$ <font color=\"red\">$ \\frac{d^{2} \\Psi}{d x^{2}}$</font> $=E \\Psi$\n",
        "\n",
        "* Normally try to solve <font color=\"red\">$ \\frac{d^{2} \\Psi}{d x^{2}}$</font> which is second derivative of $\\Psi$ with respect to x, when you know what $\\Psi$ is,\n",
        "\n",
        "* but we don't. We want to go the other way around, which is trickier.\n",
        "\n",
        "**Step 2: Rearrange the constants**\n",
        "\n",
        "Luckily we have two constants in our equation (blue):\n",
        "\n",
        "> <font color=\"blue\">$\\frac{-\\hbar^{2}}{2 m}$</font> $ \\frac{d^{2} \\Psi}{d x^{2}}$ = <font color=\"blue\">$E$</font> $\\Psi$\n",
        "\n",
        "Which means we can rearrange the equation to this:\n",
        "\n",
        "> $ \\frac{d^{2} \\Psi}{d x^{2}}$ = <font color=\"blue\">$\\frac{-2m E}{\\hbar^{2}}$</font>  $\\Psi$\n",
        "\n",
        "Now we can combine all constants in one constant $-k^2$ = $\\frac{-2m E}{\\hbar^{2}}$\n",
        "\n",
        "> $ \\frac{d^{2} \\Psi}{d x^{2}}$ = <font color=\"blue\">$-k^2$</font>  $\\Psi$\n",
        "\n",
        "**Step 3: Identify suitable function for this equation**\n",
        "\n",
        "* So which type of function obeys this relation $ \\frac{d^{2} \\Psi}{d x^{2}}$ = <font color=\"blue\">$-k^2$</font>  $\\Psi$? - Would be a [sinusoid](https://de.wikipedia.org/wiki/Sinusoid)!\n",
        "\n",
        "* $\\frac{d^2 y}{d x^{2}}=-y$ - when you start with a sine and differentiate it twice you still end up with a sinusoidal term\n",
        "\n",
        "* so if we carefully account for the constants in our equation, our solution is going to look like a sinusoid:\n",
        "\n",
        "> $\\Psi$ = $\\sin \\left(\\frac{\\sqrt{2 m E}}{\\hbar} x\\right)$ and replacing <font color=\"blue\">$\\frac{\\sqrt{2 m E}}{\\hbar}$</font> with $k$ $\\rightarrow$ $\\Psi$ = $\\sin ($ <font color=\"blue\">$k$</font> $x)$\n",
        "\n",
        "*Compare this with before (above is no minus and root taken is first term):*\n",
        "\n",
        "> $ \\frac{d^{2} \\Psi}{d x^{2}}$ = <font color=\"blue\">$\\frac{-2m E}{\\hbar^{2}}$</font>  $\\Psi$ =  <font color=\"blue\">$-k^2$</font>  $\\Psi$\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_176.png)\n",
        "\n",
        "**Step 4: Work our the boundaries to solve the differential equation, which means to get wavefunction**\n",
        "\n",
        "\n",
        "**When x = 0 $\\rightarrow$ $\\Psi$ = 0**\n",
        "\n",
        "* so at the wall at point a $\\Psi$ = 0, so that we first derivative is not getting infinite!\n",
        "\n",
        "* this works quite nice with sinusoidal, since $\\Psi = sin(kx)$ $\\rightarrow$ 0 = sin(k(0)) = 0\n",
        "\n",
        "**When x = a $\\rightarrow$ $\\Psi$ = 0**\n",
        "\n",
        "* 0 = sin(k(a)) since $\\Psi$ = sin(kx) $\\rightarrow$ 0 = sin(k(a)) = 0\n",
        "\n",
        "* we essentially find a restriction on the kind of sine wave that we can have as a solution\n",
        "\n",
        "* for example half a sine wave is a possible solution\n",
        "\n",
        "  * it's y=0 at point x=0 and x=a (at the walls), so $sin(ka) = 0$\n",
        "\n",
        "  * so we went through half a sine wave which means that this part in brackets (ka) must be equal to 180 degrees (because that's half a sine wave) $y = \\frac{1}{2}sin(x)$\n",
        "\n",
        "  * and if we use radians instead of degrees, which is the other unit of measuring angles, and a much more natural unit of measuring angles, then 180 degrees is actually equal to <font color=\"blue\">$\\pi$ radians = (ka)</font>\n",
        "\n",
        "  * So: $y = \\frac{1}{2}sin(x) = \\pi$\n",
        "\n",
        "* this means that this equation holds true if our wavefunction is half a sine wave <font color=\"blue\">$(ka)$ = $\\pi$ = $\\frac{\\sqrt{2m E}}{\\hbar}a$</font> , recall: k = $\\frac{\\sqrt{2m E}}{\\hbar}$\n",
        "\n",
        "* from earlier: $\\Psi$ = $\\sin \\left(\\frac{\\sqrt{2 m E}}{\\hbar} x\\right)$ =  $\\sin ($ <font color=\"blue\">$k$</font> $x)$\n",
        "\n",
        "**Step 5: Rearrange that equation to get the energy value**\n",
        "\n",
        "\n",
        "* and if we rearrange that <font color=\"blue\">$(ka)$ = $\\frac{\\sqrt{2m E}}{\\hbar}a$ = $\\pi$ </font> we have something that tells us the value of the energy $E$:\n",
        "\n",
        "> $E=\\frac{h^{2} \\pi^{2}}{2 m a^{2}}$\n",
        "\n",
        "* (with reduced Planck constant: $\\hbar=\\frac{h}{2 \\pi} =1.054571817 \\ldots \\times 10^{-34} \\mathrm{~J} \\cdot \\mathrm{s}$)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_178.png)\n",
        "\n",
        "* in other words: if our wavefunction looks like this (half a sine function), then the energy of our particle is this $E=\\frac{h^{2} \\pi^{2}}{2 m a^{2}}$\n",
        "\n",
        "* another possibe solution is a full sine wave fitting into this region, just that the value at the end of the wall is 360 degrees, because we went through the whole sine wave = 2*$\\pi$ radians\n",
        "\n",
        "  * if the wavefunction looks like a whole sine wave <font color=\"blue\">$\\frac{\\sqrt{2m E}}{\\hbar}a$</font> = 2*$\\pi$\n",
        "\n",
        "  * then the  energy of the particle is $E=\\frac{4h^{2} \\pi^{2}}{2 m a^{2}}$\n",
        "\n",
        "* We can continue doing this for lots of half sine waves, so we could have three or four half fine waves in our region - and in each case we can calculate the energy of a particle when its wavefunction looks like those sine waves.\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_177.png)\n",
        "\n",
        "* This phenomenom is called \"Quantization\".\n",
        "\n",
        "  * because we can only have specific wave functions, and they correspond to specific energies, a particle can therefore only have specific energies\n",
        "\n",
        "  * so it cannot be anyhting in between and it cannot be less than the minimum of half a sine wave $E_{1}=\\frac{h^{2} \\pi^{2}}{2 m a^{2}}$\n",
        "\n",
        "  * this is also why for this particular setup cosine doesnt work (normally it does though) $\\Psi=\\cos \\left(\\frac{\\sqrt{2 m E}}{\\hbar} x\\right)$\n",
        "\n",
        "**Step 6: Normalization to get probabilities**\n",
        "\n",
        "*Normalization of the wavefunction*\n",
        "\n",
        "* there is one more thing to consider when finding a solution to the Schrodinger equation: Normalization\n",
        "\n",
        "> $\\Psi = \\sqrt{\\frac{2}{a}} \\sin \\left(\\frac{\\sqrt{2 m E}}{\\hbar} x\\right)$\n",
        "\n",
        "* it adds a factor of $\\sqrt{\\frac{2}{a}}$ to our solution\n",
        "\n",
        "* physical meaning: if our particle is in the lowest energy level $E_1$. Then in our specific setup with the two walls the wavefunction looks like half a sine wave. And remember the wavefunction corresponds directly to the probability of us finding that particle at a particular point in space. And this relationshipn is if we square our wavefunction $|\\Psi|^2$ (we take the square modulus), then we get the probability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnCYfCNzqmG9"
      },
      "source": [
        "<font color=\"blue\">**Schrödinger Equation (Time Dependent)**\n",
        "\n",
        "**Consider: Difference of probability in the position basis (changes over time) and the energy basis (doesn't change):**\n",
        "\n",
        "> <font color=\"red\">**The electron is still in the same shell, represented by the principal quantum number for example, because if the electron changes the shell, energy needs to be added or removed from the overall system. however if energy stays the same, it means the electron is still in the same shell, but \"moving\" around = probability distribution of finding it somewhere in this shell changes over time which is represented by the rotation $e^{i \\frac{\\hat{H} * t}{\\hbar}}$**</font>\\\n",
        "\n",
        ">$\n",
        "\\left[-\\frac{\\hbar^{2}}{2 m} \\nabla^{2}+V(\\vec{r})\\right] \\psi(\\vec{r})=E \\psi(\\vec{r})\n",
        "$\n",
        "\n",
        "The object on the left that acts on $\\psi(x)$ is an example of an operator.\n",
        "\n",
        ">$\n",
        "\\left[-\\frac{\\hbar^{2}}{2 m} \\nabla^{2}+V(\\vec{r})\\right]\n",
        "$ = Operator\n",
        "\n",
        "In effect, what is says to do is \"take the second derivative of $\\psi(x)$, multiply the result by $-\\left(\\hbar^{2} / 2 m\\right)$ and then add $V(x) \\psi(x)$ to the result of that.\"\n",
        "\n",
        "Quantum mechanics involves many different types of operators. This one, however, plays a special role because it appears on the left side of the Schrödinger equation. **It is called the Hamiltonian operator and is denoted as**\n",
        "\n",
        "> $\n",
        "\\hat{H}=-\\frac{\\hbar^{2}}{2 m} \\nabla^{2}+V(\\vec{r})\n",
        "$\n",
        "\n",
        "**Therefore the time-dependent Schrödinger equation can be written as**:\n",
        "\n",
        "> $\n",
        "\\hat{H} \\psi(x, t)=i \\hbar \\frac{\\partial}{\\partial t} \\psi(x, t)\n",
        "$\n",
        "\n",
        "with $\\hat{H}$ = $(-\\frac{\\hbar^{2}}{2 m} \\nabla^{2}+V(\\vec{r}))$ will be:\n",
        "\n",
        "> $\n",
        "(-\\frac{\\hbar^{2}}{2 m} \\nabla^{2}+V(\\vec{r})) \\; \\psi(x, t)=i \\hbar \\frac{\\partial}{\\partial t} \\psi(x, t)\n",
        "$\n",
        "\n",
        "bzw. rewritten:\n",
        "\n",
        "> $\\left[-\\frac{\\hbar^{2}}{2 m} \\frac{\\partial^{2}}{\\partial x^{2}}+V(x, t)\\right] \\Psi(x, t) = i \\hbar \\frac{\\partial}{\\partial t} \\Psi(x, t)$\n",
        "\n",
        "bzw written in another way (single particle variant):\n",
        "\n",
        "> <font color=\"red\">$[-\\frac{\\hbar^{2}}{2 m} \\nabla^{2} $</font> + <font color=\"green\">$V(x, t)$</font> ]\n",
        " <font color=\"blue\">$|\\psi\\rangle$</font> = $i \\hbar \\frac{\\partial}{\\partial t}$ <font color=\"blue\">$|\\psi\\rangle$</font>\n",
        "\n",
        "* <font color=\"red\">$[-\\frac{\\hbar^{2}}{2 m} \\nabla^{2} $</font> Kinetic energy\n",
        "\n",
        "* <font color=\"green\">$V(x, t)$</font> Potential energy\n",
        "\n",
        "* <font color=\"blue\">$|\\psi\\rangle$</font>  the wave function\n",
        "\n",
        "<font color=\"blue\">*Schrodinger equation: Derivation and how to use it (in Time Evolution)*\n",
        "\n",
        "Important rules of physics:\n",
        "\n",
        "* Conservation of energy -> deeply integrated into Schrodinger equation\n",
        "* total energy doesn't change\n",
        "* you can't make of destroy energy\n",
        "\n",
        "**Since we can write a quantum state $|\\Psi \\rangle$ in whatever basis we want, we can choose the energy Eigenbasis**. <font color=\"red\">what is meant by that? is that the principle quantum number for example</font>\n",
        "\n",
        "* We can write a state as the superposition of different energies.\n",
        "\n",
        "* And if we measure the energy of the particle it will be one of these with their probability\n",
        "\n",
        "> $|\\Psi \\rangle$ = $\\alpha |\\Psi \\rangle + \\beta |\\Psi \\rangle + \\gamma |\\Psi \\rangle$\n",
        "\n",
        "* with probability for example $|\\beta|^2$ for measuring second state\n",
        "\n",
        "**Say the state evolves in time, in other words we apply the time evolution $U$ (or $T$) to $|\\Psi \\rangle$, so $T |\\Psi \\rangle$**\n",
        "\n",
        "* what condition do we want to impose on the new energies of the state?\n",
        "\n",
        "* In other words: how we want conservation of energy to look in quantum mechanics?\n",
        "\n",
        "**Let's start where a particle just has one energy $E$ when we start**\n",
        "\n",
        "* means: it is an energy Eigenstart !!\n",
        "\n",
        "* we evolve it forward in time and look at the energy of the new state. That energy should be also $E$, otherwise energy wouldn't be conserved (Like in classical mechanics).\n",
        "\n",
        "> $|\\Psi \\rangle$ = $|1 \\rangle$ $\\rightarrow$ $T|\\Psi \\rangle$\n",
        "\n",
        "* Now also the average energy shouldn't change after some time, otherwise the energy wouldn't be conserved either.\n",
        "\n",
        "> $|\\Psi \\rangle$ = $\\alpha |\\Psi \\rangle + \\beta |\\Psi \\rangle + \\gamma |\\Psi \\rangle$\n",
        "\n",
        "* if you measured athe particle's energy initially with a certain probability $|\\beta|^2$, and then after time evolution again, it should be the same probability to measure that energy!\n",
        "\n",
        "* this is so strong, it gives us the schroedinger equation\n",
        "\n",
        "\n",
        "**We need to how the coefficients have changed in the new equation after time evolution**:\n",
        "\n",
        "> $|\\Psi \\rangle$ = $\\alpha |\\Psi \\rangle + \\beta |\\Psi \\rangle + \\gamma |\\Psi \\rangle$ (before)\n",
        "\n",
        "> $T |\\Psi \\rangle$ = $\\alpha' |\\Psi \\rangle + \\beta' |\\Psi \\rangle + \\gamma' |\\Psi \\rangle$ (after)\n",
        "\n",
        "* We want the probability to be the same, but that probability is just the lenght of this compex number squared $|\\gamma|^2 = |\\gamma'|^2 = 1$\n",
        "\n",
        "> <font color=\"red\">**So each coefficient can be represented as an arrow with equal length $|\\gamma|^2$ and $|\\gamma'|^2$ (hence the probability of measuring that energy this state is still the same!!), BUT $|\\gamma'|^2$ may be rotated by an angle $\\phi$**. This angle is new vector = rotation * old vector:</font>\n",
        "\n",
        "> <font color=\"red\">$\\gamma' = e^{i\\phi}\\gamma$</font>\n",
        "\n",
        "Let's plug that rotation $e^{i\\phi}$ in to our previous equation:\n",
        "\n",
        "> <font color=\"red\">$T |\\Psi \\rangle$ = $e^{i\\phi_1}\\alpha |\\Psi \\rangle + e^{i\\phi_2}\\beta |\\Psi \\rangle + e^{i\\phi_3}\\gamma |\\Psi \\rangle$</font>\n",
        "\n",
        "* where the angles / rotations $e^{i\\phi}$ are different for every energy = they are all rotated by a different amount !! Otherwise the rotation can be brought out and present and future state would be the essentially same:\n",
        "\n",
        "> $T |\\Psi \\rangle$ = $e^{i\\phi}\\alpha |\\Psi \\rangle + e^{i\\phi}\\beta |\\Psi \\rangle + e^{i\\phi}\\gamma |\\Psi \\rangle$ = $e^{i\\phi} (\\alpha |\\Psi \\rangle + \\beta |\\Psi \\rangle + \\gamma |\\Psi \\rangle)$ (this is showing that it's wrong!)\n",
        "\n",
        "The overall rotation wouldn't affect any measurement outcomes. Means no matter in which crazy situation you brought the particle in, it does nothing, which can't be right.\n",
        "\n",
        "> $T |\\Psi \\rangle$ = $e^{i\\phi}|\\Psi \\rangle$ (this is showing that it's wrong!\n",
        "\n",
        "\n",
        "* also the amount of rotation depends on time (little going forwardf = little rotation). That suggests the right amount of angle to rotate is Energy x Time. Plus some constants to deal with units and scaling etc.\n",
        "\n",
        "> <font color=\"red\">$\\phi = \\frac{E * t}{\\hbar}$</font>\n",
        "\n",
        "* And that's what the Schroedinger equation will tell you will happen to the state:\n",
        "\n",
        "> $T |\\Psi \\rangle$ = $e^{i \\frac{E * t}{\\hbar}}\\alpha |\\Psi \\rangle + e^{i \\frac{E * t}{\\hbar}}\\beta |\\Psi \\rangle + e^{i \\frac{E * t}{\\hbar}}\\gamma |\\Psi \\rangle$\n",
        "\n",
        "* And that's the same: (with $\\hat{H}$ for energy measurement operator, Hamiltonian):\n",
        "\n",
        "> <font color=\"red\">$T(t) |\\Psi \\rangle = e^{i \\frac{\\hat{H} * t}{\\hbar}}|\\Psi \\rangle$</font>\n",
        "\n",
        "*Common result for 2 observations:*\n",
        "\n",
        "Time Evolution per each step, observer 1:\n",
        "\n",
        "> $| \\Psi \\rangle$ $\\rightarrow$ at $t_1$ = $e^{\\frac{i \\mathcal{H} t_1}{\\hbar}} | \\Psi \\rangle$ $\\rightarrow$ at $t_2$ = <font color=\"blue\">$e^{\\frac{i \\mathcal{H} t_2}{\\hbar}} (e^{\\frac{i \\mathcal{H} t_1}{\\hbar}} | \\Psi \\rangle)$</font>\n",
        "\n",
        "Time Evolution at the end for observer 2 (not seeing time step 1):\n",
        "\n",
        "\n",
        "> $| \\Psi \\rangle$ $\\rightarrow$ at $t_2$ = <font color=\"orange\">$e^{\\frac{i \\mathcal{H} (t_1 + t_2)}{\\hbar}} | \\Psi \\rangle$</font>\n",
        "\n",
        "Where:\n",
        "\n",
        "> <font color=\"orange\">$e^{\\frac{i \\mathcal{H} (t_1 + t_2)}{\\hbar}} | \\Psi \\rangle$</font> = <font color=\"blue\">$e^{\\frac{i \\mathcal{H} t_2}{\\hbar}} (e^{\\frac{i \\mathcal{H} t_1}{\\hbar}} | \\Psi \\rangle)$\n",
        "\n",
        "Why? - because our angle of rotation depends on $t$ (and not $t^2$ or anything): $T\\left(t_{1}+t_{2}\\right)=T\\left(t_{2}\\right) T\\left(t_{1}\\right)$\n",
        "\n",
        "Taken from [Schrodinger equation comment response and homework answers video](https://www.youtube.com/watch?v=M_2h5uQ0SIc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Harmonic Oscillator (Hamiltonians / Solution of Schrodinger equation)**\n",
        "\n",
        "* The nuclear motion Schrödinger equation can be solved in a space-fixed (laboratory) frame, **but then the translational and rotational (external) energies are not accounted for**. Only the (internal) atomic vibrations enter the problem.\n",
        "\n",
        "* Further, for molecules larger than triatomic ones, it is quite common to introduce the **harmonic approximation, which approximates the potential energy surface** as a [quadratic function](https://en.m.wikipedia.org/wiki/Quadratic_function) of the atomic displacements. **This gives the harmonic nuclear motion Hamiltonian**.\n",
        "\n",
        "* Making the harmonic approximation, we can **convert the Hamiltonian into a sum of uncoupled one-dimensional [harmonic oscillator](https://en.m.wikipedia.org/wiki/Harmonic_oscillator) Hamiltonians**.\n",
        "\n",
        "> **The one-dimensional harmonic oscillator is one of the few systems that allows an exact solution of the Schrödinger equation.**\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Nullpunktsenergie#Harmonischer_Oszillator\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Harmonischer_Oszillator_(Quantenmechanik)"
      ],
      "metadata": {
        "id": "EKeKuaJkf4Pw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sf5tauFtttx"
      },
      "source": [
        "###### ***Matrix Mechanics*** *(Heisenberg, discrete basis, spin representation, Kronecker delta function)*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matrix Mechanics (spin representation - discrete basis) - (Heisenberg)**\n",
        "\n",
        "* Matrix Mechanics (spin representation - discrete basis)\n",
        "\n",
        "* Video: [Matrix formulation of quantum mechanics](https://www.youtube.com/watch?v=wIwnb1ldYTI)\n",
        "\n",
        "* **Matrix mechanics ('matrix formulation'): Most useful when we deal with finite, discrete bases (like spin representation).**\n",
        "\n",
        "* **Matrix formulation of quantum mechanics reduces to the rules of simple matrix multiplication.**\n",
        "\n",
        "> $\\hat{A}=\\sum_{i j} A_{i j}\\left|u_{i}\\right\\rangle\\left\\langle u_{j}\\right| \\quad A_{i j}=\\left\\langle u_{i}|\\hat{A}| u_{j}\\right\\rangle$\n",
        "\n",
        "* An operator A can be written in the u basis as the sum over the outer products of the basis states\n",
        "* And the expansion coefficients Aij are given by the matrix elements of A with respect to the basis states\n",
        "* The expansion coefficients for an operator are labeled by 2 indices, so we will arrange them in a form of a square matrix, with the first index denoting the row of the matrix and the second index the column of the matrix\n",
        "* There operators are written as matrices\n",
        "\n",
        "> $\\left(\\begin{array}{ccccc}A_{11} & A_{12} & \\cdots & A_{1 j} & \\cdots \\\\ A_{21} & A_{22} & \\cdots & A_{2 j} & \\cdots \\\\ \\vdots & \\vdots & & \\vdots & \\\\ A_{i 1} & A_{i 2} & \\cdots & A_{i j} & \\cdots \\\\ \\vdots & \\vdots & & \\vdots & \\end{array}\\right)$\n",
        "\n",
        "Kets are written as column vectors:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_218.png)\n",
        "\n",
        "Matrix formulation of Bra's: re-arrange complex, conjugate coefficient as a row vector:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_219.png)\n",
        "\n",
        "An operator A can be written in the u basis as the sum over the outer products of the basis states. An Aij are the expansion coefficient in this case. Operators are written as matrices:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_220.png)\n",
        "\n",
        "Summary of the matrix formulation of quantum mechanics for kets, bras and operators:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_221.png)\n",
        "\n",
        "We will see how simple matrix multiplication rules work for the following 4 operations:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_222.png)\n",
        "\n",
        "First, in the matrix formulation of quantum mechanics, a bracket is the matrix product of a row vector with a column vector, and gives a scalar:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_223.png)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_224.png)\n",
        "\n",
        "Adjoint operator: describe the action of an operator in the dual space:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_225.png)\n",
        "\n",
        "Write an operator as an outer product of two states:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_226.png)\n",
        "\n",
        "Summary:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_227.png)"
      ],
      "metadata": {
        "id": "FdyLdYgFeqFK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdJ5yNTZibYy"
      },
      "source": [
        "###### ***Wave Mechanics*** *(Schrödinger, continuous basis, position representation, Dirac delta function)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYIaQDNv0C1c"
      },
      "source": [
        "**First: let's go from discrete basis $u_i$ to continuous basis $v_{\\alpha}$**\n",
        "\n",
        "* Much used **discrete basis**: Spin of quantum particles\n",
        "\n",
        "* Much used **continuous basis**: position of quantum particles (this one leads to the idea of wave function)\n",
        "\n",
        "> **The generalization is straightforward: it amounts to replacing Kronecker delta functions $\\delta_{i j}$ of two discrete variables with the Dirac delta function $\\delta (\\alpha - \\beta)$ of two continuous variables and sum over these indices by integrals over continuous indices**.\n",
        "\n",
        "* first concept: we work with an orthonormal basis $\\left\\langle u_{i} \\mid u_{j}\\right\\rangle=\\delta_{i j}$. replacing Kronecker delta functions $\\delta_{i j}$ of two discrete variables with the Dirac delta function $\\delta (\\alpha - \\beta)$\n",
        "\n",
        "* then we look at the expansion of Ket in a particular basis: replacing a sum over i with an integral over alpha\n",
        "\n",
        "* in yellow: just a proof why we would write a Dirac delta function only under an integral sign\n",
        "\n",
        "* last part: representation of an operator in a particular basis (for continuous basis)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_217.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWBTMFaxI7Ie"
      },
      "source": [
        "**Wave Mechanics (Schrödinger)**\n",
        "\n",
        "* Wave Mechanics: Wave Function (position representation - continuous basis)\n",
        "\n",
        "* Check also part under Operator: Translation Operators (**Wave Mechanics: Translation Operator**)\n",
        "\n",
        "* Video: [Wave functions in quantum mechanics](https://www.youtube.com/watch?v=2lr3aA4vaBs)\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Wave_function\n",
        "\n",
        "* wave functions is one possible way looking at a quantum system\n",
        "\n",
        "* is the so called position representation of quantum mechanics\n",
        "\n",
        "* leads to wave mechanics (for continuous basis)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_232.png)\n",
        "\n",
        "Computing scalar between two states and the normalization:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_233.png)\n",
        "\n",
        "How to get from the position representation to the momentum representation (via a first order differential equation):\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_234.png)\n",
        "\n",
        "**Transformation matrix $\\langle x|p\\rangle$ to go from the position representation to the momentum representation**:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_235.png)\n",
        "\n",
        "To change between both representations we use Fourier transform:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_236.png)\n",
        "\n",
        "If we go to 3 dimensions:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_237.png)\n",
        "\n",
        "Summary:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_238.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XCE4EGuJJij"
      },
      "source": [
        "**Wave Mechanics: Position and momentum operators acting on wave functions**\n",
        "\n",
        "* Video: [Position and momentum operators acting on wave functions](https://www.youtube.com/watch?v=Yw2YrTLSq5U)\n",
        "\n",
        "* Action of position and momentum operators on wave functions\n",
        "\n",
        "* The action of the position operator: it multiplies a wave function by x:\n",
        "\n",
        "> $x \\psi(x)$\n",
        "\n",
        "* the action of a momentum operator: it acts by calculating the derivative of a wave function\n",
        "\n",
        "> $-i \\hbar \\frac{d \\psi(x)}{d x}$\n",
        "\n",
        "* First: describe the act of a position operator in the position basis, and the act of a momentum operator in the momentum basis:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_239.png)\n",
        "\n",
        "Second: describe the act of the momentum operator on a state Psi when written in the position representation (=basis) is such that the momentum operator calculates the derivative of the wavefunction and then multiplies the result by minus i h-bar (we need the translation operator):\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_240.png)\n",
        "\n",
        "Third: what happens when we act with the position operator in the momentum basis (proof: the momentum space wavefunction is related to the real space wavefcunction by a Fourier transform):\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_241.png)\n",
        "\n",
        "Generalize this to 3 dimensions:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_242.png)\n",
        "\n",
        "Summary: as you can see there are different representations for the same thing, but the maths is differently difficult. So the task is to find a representation that is easy for a certain problem:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_243.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ-w7Fv4O91T"
      },
      "source": [
        "###### *Wavefunction & Global Phase Difference (Why we factor it out and leave phase difference only)*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maybe you have, but from where I stand it was the first time to see the global phase represented in a Bloch Sphere. Thanks Professor Ioannis G. Karafyllidis for this insight. ⬇\n",
        "\n",
        "☸ The global phase is actually an inclination of the Bloch Sphere.\n",
        "\n",
        "⚛ In quantum field theory, the concept of global phase in a one-qubit system can be understood in the context of symmetries, particularly the global U(1) phase symmetry. U(1) is a mathematical group that represents a continuous symmetry associated with global phase transformations. We can outline how quantum field theory incorporates this symmetry to explain the concept:\n",
        "\n",
        "✅ Global U(1) Phase Symmetry:\n",
        "In quantum field theory, we work with fields and operators that are often complex-valued. The global U(1) phase symmetry refers to the ability to multiply the entire quantum state by a complex phase factor without affecting the physical observables. Mathematically, for a one-qubit system, the global U(1) phase transformation can be represented as follows:\n",
        "|ψ⟩ → e^(iθ)|ψ⟩ where, θ is a real number representing the phase transformation.\n",
        "\n",
        "✅ No Observable Impact: The key feature of this global phase transformation is that it does not change the probabilities of measurement outcomes or any other physically observable quantities. The global phase is, in a sense, \"gauged out\" because it affects both the quantum state and its complex conjugate, so it cancels out in terms of probabilities.\n",
        "\n",
        "✅ Conservation of Probability: The conservation of probability is ensured by the U(1) phase symmetry. The probabilities of measuring a qubit in any state remain constant under global phase transformations. This property is closely related to the conservation of probability in quantum systems.\n",
        "\n",
        "✅ Interference and Relative Phases: While the global phase itself is not physically meaningful, relative phases between different quantum states are significant. Quantum field theory allows for interference effects, which arise from relative phases between states. This interference is crucial in understanding phenomena like quantum entanglement and quantum superposition.\n",
        "\n",
        "✴ In summary, quantum field theory incorporates the global U(1) phase symmetry to explain the concept of global phase in a one-qubit system. This symmetry allows for phase transformations that do not affect the probabilities of measurement outcomes, highlighting the importance of relative phases in quantum interference effects and quantum phenomena.\n"
      ],
      "metadata": {
        "id": "163At1BtkCqb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIwU3Qnjifn-"
      },
      "source": [
        "**How does the Wavefunction (one type) look like?**\n",
        "\n",
        "> $\\psi=e^{\\frac{1}{\\hbar}(px - Et)}$\n",
        "\n",
        "* p = momentum in direction x, x = position along x direction, E = energy, t = time\n",
        "\n",
        "* e is the exponential function, normally it doesn't look like a wave, like $e^{-x}$ or $e^{x}$\n",
        "\n",
        "* but the imaginary number $i=\\sqrt{-1}$ turns an exponential function into a wave\n",
        "\n",
        "* sinoisdal functions (sine and cosine) can be written in terms of the exponential function with $i$ in the exponent\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_244.png)\n",
        "\n",
        "* we could take one complex wave function and break it down into simpler waves, then we apply same maths on the simpler waves:\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_245.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVcEGLc6rS9p"
      },
      "source": [
        "Global phase factor $e^{i\\theta}$:\n",
        "\n",
        "* Eigenvalues and Eigenvectors exist also in other vector spaces than state spaces, but because state space is a complex vector space there is one important extra subtlety compared to real vector spaces which has to do with the global phase factor $e^{i\\theta}$\n",
        "\n",
        "* after choosing alpha to make the length of an Eigenstate equal to 1, we still have some extra freedom in the Eigenstate\n",
        "\n",
        "* multiplying $|\\Psi\\rangle$ with a Global phase factor $e^{i\\theta}$ makes the length of the resulting $|\\Psi'\\rangle$ still = 1\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_258.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what happens when we square the wave function:\n",
        "* the function is an oscillation in quantum possibilities moving through space and time\n",
        "* but it's a complex wave with one real and one imaginary component\n",
        "* **the components oscillate in sync with each other - but they are offset, shifted in phase by a constant amount**\n",
        "> phase is just the wave's current state in its up-down oscillation\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0964.png)"
      ],
      "metadata": {
        "id": "KiDe4HzbgNh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we apply the Born rule we are squaring these two waves and adding them together\n",
        "* but it turns out that this value doesn't depend on phase. The magnitude squared of the real and imaginary components stays the same, even as those components move up and down\n",
        "* It is that magnitude squared that we can observe, it determines the particles position\n",
        "* the phase itself is fundamentally unobservable. You can shift phase by any amount and you wouldnt change the resulting position of the particle, as long as you do the same shift to both the real and the imaginary components.\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0965.png)\n"
      ],
      "metadata": {
        "id": "T6Kn28ZZgUsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In fact as long as you make the same shift across the entire wave function, all the observables are unchanged.\n",
        "* We call this form of transformation a global phase shift, and it's analogous to transforming our altitude zero point up or down by the same amount everywhere.\n",
        "* the equations of quantum mechanics have what we call **global phase invariance**\n",
        "* **Global phase is a Gauge symmetry of the system**\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_0966.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "70R04sWsgbFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reminder: Trigonometrie:\n",
        "\n",
        "> $\\begin{aligned} \\mathrm{e}^{\\mathrm{i} x} &=\\sum_{k=0}^{\\infty} \\frac{(\\mathrm{i} x)^{k}}{k !}=\\sum_{l=0}^{\\infty} \\frac{(\\mathrm{i} x)^{2 l}}{(2 l) !}+\\sum_{l=0}^{\\infty} \\frac{(\\mathrm{i} x)^{2 l+1}}{(2 l+1) !} \\\\ &=\\underbrace{\\sum_{l=0}^{\\infty}(-1)^{l} \\frac{x^{2 l}}{(2 l) !}}_{\\cos x}+\\underbrace{\\mathrm{i} \\sum_{l=0}^{\\infty}(-1)^{l} \\frac{x^{2 l+1}}{(2 l+1) !}}_{\\sin x} \\\\  \\mathrm{e}^{\\mathrm{i} x}&=\\cos x+\\mathrm{i} \\sin x \\\\  \\mathrm{e}^{\\mathrm{i} x}&=\\cos \\varphi+\\mathrm{i} \\sin \\varphi \\\\ \\mathrm{e}^{\\mathrm{i} x}&=x+\\mathrm{i} y \\end{aligned}$ Das ist die sogenannte [Eulerformel](https://de.m.wikipedia.org/wiki/Eulersche_Formel)!\n",
        "\n",
        "\n",
        "![ggg](https://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Sine_cosine_one_period.svg/600px-Sine_cosine_one_period.svg.png)\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_040.jpg)\n",
        "\n",
        "![ggg](https://upload.wikimedia.org/wikipedia/commons/3/3b/Circle_cos_sin.gif)"
      ],
      "metadata": {
        "id": "QX7SeO65gi0O"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBGbzlHLPGlp"
      },
      "source": [
        "* The only reason phase is important is because it brings about interference effects. And interference effects are only dependent on the difference in phase between the two waves (we will abstract basis states to waves for now).\n",
        "\n",
        "> **Therefore, we can say that it’s the difference that counts, and not the absolute value.**\n",
        "\n",
        "* For example, if the phase difference is π radians then the waves would cancel each other out.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sd8WkT9PbZX"
      },
      "source": [
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/quantum_179.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8WPjzqBPfSd"
      },
      "source": [
        "We can conclude that the absolute value of the phase shift for both waves is meaningless to the interference. For as long as they both retain the phase difference, then the interference effect will be constant, and that’s what matters!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOiHZhJKPkMX"
      },
      "source": [
        "**Why the global phase doesn’t matter**\n",
        "\n",
        "As observed above, what matters is the phase difference. So think about it, if you’re describing the phase of two waves, it’s redundant to state both phases. **The better approach is to just state the phase difference**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjLdM9G6PojT"
      },
      "source": [
        "* The global phase is the absolute value of the phase shift for both waves.\n",
        "\n",
        "* For example, wave one and two each have a phase of (π/2) radians and (3π/2) radians, respectively. In this case, the phase (π/2) is a global phase since the phase difference (what actually counts) is π radians → (3π/2 - π/2 ).\n",
        "\n",
        "* Using the same example, we can define the relative phase (also known as the local phase) as the phase difference (π rad)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCUI_HZzP43M"
      },
      "source": [
        "We’ve found a method to **bypass the need for a fourth dimension by factoring out the global phase** and replacing the second phase with the relative phase. We can represent this mathematically.\n",
        "\n",
        "A general qubit state can be written\n",
        "\n",
        "> $|\\psi\\rangle=\\alpha|0\\rangle+\\beta|1\\rangle$\n",
        "\n",
        "with complex numbers, α and β, and the normalization constraint require that:\n",
        "\n",
        "\n",
        "> $|\\alpha|^{2}+|\\beta|^{2}=1$\n",
        "\n",
        "As previously stated, we can express the amplitudes in polar coordinates as (General equation for a qubit state):\n",
        "\n",
        "> $|\\psi\\rangle=r_{\\alpha} e^{i \\phi_{\\alpha}}|0\\rangle+r_{\\beta} e^{i \\phi_{\\beta}}|1\\rangle$\n",
        "\n",
        "with four real parameters:\n",
        "\n",
        "> $r_{\\alpha}, \\phi_{\\alpha}, r_{\\beta}$ and $\\phi_{\\beta}$\n",
        "\n",
        "**However, the only measurable quantities are the probabilities |α|² and |β|², so multiplying the state by an arbitrary factor $e^{iγ}$ (global phase) has no observable consequences, because**:\n",
        "\n",
        "> $\\left|e^{i \\gamma} \\alpha\\right|^{2}=\\left(e^{i \\gamma} \\alpha\\right)^{*}\\left(e^{i \\gamma} \\alpha\\right)=\\left(e^{-i \\gamma} \\alpha^{*}\\right)\\left(e^{i \\gamma} \\alpha\\right)=\\alpha^{*} \\alpha=|\\alpha|^{2}$\n",
        "\n",
        "Therefore, we can factor out $e^{iΦ}$ from the general equation:\n",
        "\n",
        "> $|\\psi\\rangle=e^{i \\phi_{\\alpha}}\\left(r_{\\alpha}|0\\rangle+r_{\\beta} e^{i\\left(\\phi_{\\beta}-\\phi_{\\alpha}\\right)}|1\\rangle\\right)$\n",
        "\n",
        "Now, if you calculate the amplitude |ψ|², the factor ($e^{iΦ_α}$) in front will vanish by the argument above. This is why we called it the global phase. However, the relative phase is the phase difference noted as (Φ_α - Φ_β). This is an observable-ish quantity which manifests through interference effects.\n",
        "\n",
        "Let’s consolidate the above equation into:\n",
        "\n",
        "> $|\\psi\\rangle=r_{\\alpha}|0\\rangle+r_{\\beta} e^{i\\left(\\phi_{\\beta}-\\phi_{\\alpha}\\right)}|1\\rangle=r_{\\alpha}|0\\rangle+r_{\\beta} e^{i \\phi}|1\\rangle$\n",
        "\n",
        "> $r_{\\alpha} \\in \\mathbb{R}, r_{\\beta} \\in \\mathbb{R}, \\phi \\in \\mathbb{R} \\mid \\phi=\\phi_{\\beta}-\\phi_{\\alpha}$\n",
        "\n",
        "where r_α, r_β and Φ all real parameters.\n",
        "\n",
        "**Notice that this equation can be represented in 3-D, as the global phase is gone.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odWaJ8hJPDMa"
      },
      "source": [
        "https://pavanjayasinha.medium.com/but-what-is-a-quantum-phase-factor-d05c15c321fe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8P-evW3U0Vx"
      },
      "source": [
        "**Physical Meaning of Phase**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Remember: $e^{2 \\pi i}$ = 1 (Identity)"
      ],
      "metadata": {
        "id": "lQpy1dj0iHji"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhNcqwo6R4lV"
      },
      "source": [
        "* In quantum mechanics, a phase factor is a complex coefficient $e^{i \\theta}$ that multiplies a ket $|\\psi\\rangle$ or bra $\\langle\\phi|$.\n",
        "\n",
        "* <font color=\"blue\">**It does not, in itself, have any physical meaning**, since the introduction of a phase factor does not change the expectation values of a Hermitian operator.\n",
        "\n",
        "> That is, the values of $\\langle\\phi|A| \\phi\\rangle$ and $\\left\\langle\\phi\\left|e^{-i \\theta} A e^{i \\theta}\\right| \\phi\\right\\rangle$ are the same.\n",
        "\n",
        "* <font color=\"red\">However, differences in phase factors between two interacting quantum states can sometimes be measurable (such as in the Berry phase) and this can have important consequences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syr76IkvRoPD"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Phase_factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9T3nptBTPNo"
      },
      "source": [
        "* When people say that the phase doesn't matter, they mean the overall, \"global\" phase. In other words, the state $|0\\rangle$ is equivalent to $e^{i \\theta}|0\\rangle$, the state $|1\\rangle$ is equivalent to $e^{i \\theta^{\\prime}}|1\\rangle$, and the state $|0\\rangle+|1\\rangle$ is equivalent to $e^{i \\theta^{\\prime \\prime}}(|0\\rangle+|1\\rangle)$.\n",
        "\n",
        "> Siehe auch Eulersche Formel: $e^{i \\phi}$ https://mathepedia.de/Eulersche_Formel.html\n",
        "\n",
        "> Note that \"equivalence\" is not preserved under addition, since $e^{i \\theta}|0\\rangle+e^{i \\theta^{\\prime}}|1\\rangle$ is not equivalent to $|0\\rangle+|1\\rangle$, because there can be a relative phase $e^{i\\left(\\theta-\\theta^{\\prime}\\right)}$.\n",
        "\n",
        "* If we wanted to describe this very simple fact with unnecessarily big words, we could say something like \"the complex projective Hilbert space of rays, the set of equivalence classes of nonzero vectors in the Hilbert space under multiplication by complex phase, cannot be endowed with the structure of a vector space\".\n",
        "\n",
        "* Because the equivalence doesn't play nicely with addition, **it's best to just ignore the global phase ambiguity whenever you're doing real calculations**. Finally, when you're done with the entire calculation, and arrive at a state, you are free to multiply that final result by an overall phase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBLDuK4vRpXR"
      },
      "source": [
        "https://physics.stackexchange.com/questions/552796/the-importance-of-the-phase-in-quantum-mechanics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hew4HucSHKJ"
      },
      "source": [
        "* Phase: Any one point or portion in a recurring series of changes, as in the changes of motion of one of the particles constituting a wave or vibration; one portion of a series of such changes, in distinction from a contrasted portion, as the portion on one side of a position of equilibrium, in contrast with that on the opposite side.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxiSY8ddRqi1"
      },
      "source": [
        "https://courses.lumenlearning.com/boundless-chemistry/chapter/orbital-shapes/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CThWPZdFEXlO"
      },
      "source": [
        "In principle, we need four real numbers to describe a qubit, two for $\\alpha$ and two for $\\beta$. The constraint $|\\alpha|^{2}+|\\beta|^{2}=1$ reduces to three numbers.\n",
        "\n",
        "In quantum mechanics, two vectors that differ from a global phase factor are considered equivalent. A global phase factor is a complex number of unit modulus multiplying the state. By eliminating this factor, a qubit can be described by two real numbers $\\theta$ and $\\phi$ as follows:\n",
        "\n",
        ">$\n",
        "|\\psi\\rangle=\\cos \\frac{\\theta}{2}|0\\rangle+\\mathrm{e}^{\\mathrm{i} \\phi} \\sin \\frac{\\theta}{2}|1\\rangle\n",
        "$\n",
        "\n",
        "where $0 \\leq \\theta \\leq \\pi$ and $0 \\leq \\phi<2 \\pi .$ In the above notation, state $|\\psi\\rangle$ can be represented by a point on the surface of a sphere of unit radius, called Bloch sphere. Numbers $\\theta$ and $\\phi$ are spherical angles that locate the point that describes $|\\psi\\rangle$, as shown in Fig. A.1. The vector showed there is given by\n",
        "\n",
        "> $\\left[\\begin{array}{c}\\sin \\theta \\cos \\phi \\\\ \\sin \\theta \\sin \\phi \\\\ \\cos \\theta\\end{array}\\right]$\n",
        "\n",
        "When we disregard global phase factors, there is a one-to-one correspondence between the quantum states of a qubit and the points on the Bloch sphere. State $|0\\rangle$ is in the north pole of the sphere, because it is obtained by taking $\\theta=0 .$ State $|1\\rangle$ is in the south pole. States\n",
        "\n",
        "> $\n",
        "|\\pm\\rangle=\\frac{|0\\rangle \\pm|1\\rangle}{\\sqrt{2}}\n",
        "$\n",
        "\n",
        "are the intersection points of the $x$-axis and the sphere, and states $(|0\\rangle \\pm \\mathrm{i}|1\\rangle) / \\sqrt{2}$ are the intersection points of the $y$-axis with the sphere.\n",
        "\n",
        "The representation of classical bits in this context is given by the poles of the Bloch sphere and the representation of the probabilistic classical bit, that is, 0 with probability $p$ and 1 with probability $1-p$, is given by the point in $z$-axis with coordinate $2 p-1$. The interior of the Bloch sphere is used to describe the states of a qubit in the presence of decoherence."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Macroscopic Quantum Superpositions*"
      ],
      "metadata": {
        "id": "k5rk1UYyjFyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pro-physik.de/nachrichten/dunkelheit-macht-makro-quanteneffekte-sichtbar\n",
        "\n",
        "M. Roda-Llordes et al.: Macroscopic Quantum Superpositions via Dynamics in a Wide Double-Well Potential, Phys. Rev. Lett. 132, 023601 (2024); DOI: 10.1103/PhysRevLett.132.023601\n",
        "\n",
        "https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.132.023601"
      ],
      "metadata": {
        "id": "JHMu1wg7jKWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cramer rao bound amd Cauchy–Schwarz inequality, Frobeniusnorm:\n",
        "variance ideal for quantum Hilbert space?\n",
        "\n",
        "How much is a loss function concentrated around its mean (not partial derivative concentration)?\n",
        "\n",
        "\n",
        "**Currently: how to study Parametrized Quantum Circuits (PQCs)?**\n",
        "\n",
        "* Expressivity / Capacity\n",
        "* Trainability\n",
        "  * subset of computational complexity and circuit complexity?\n",
        "* Generalization > which model or algorithm to choose best?\n",
        "* Sample complexity\n",
        "\n",
        "**Generalization in Machine Learning:**\n",
        "\n",
        "* Generalization refers to the ability of an algorithm to **perform accurately on new, unseen data after being trained on a sample dataset**. The goal is to learn patterns that are not just specific to the training data but also applicable to new data.\n",
        "\n",
        "* Uniform Generalization Bounds: These bounds provide a measure of how well the learned model will generalize across all possible data distributions, not just the one it was trained on. They are called 'uniform' because they provide a guarantee that holds uniformly over a class of functions or models.\n",
        "\n",
        "* Role of Sample Size: One key aspect of these bounds is that they typically improve with an increase in the size of the training sample. As more data is used to train the model, we can be more confident that the model will generalize well.\n",
        "\n",
        "* Complexity of the Hypothesis Class: **The bounds are also influenced by the complexity of the hypothesis class** (the set of models being considered). More complex classes, such as those with a large number of parameters, typically have **looser bounds, meaning they need more data to ensure good generalization**.\n",
        "\n",
        "* Mathematical Formulation: **The bounds are often derived using tools from probability and statistics, such as concentration inequalities (like Hoeffding’s inequality or McDiarmid's inequality)**. These tools help quantify the likelihood that the observed performance of a model on a sample is close to its true performance on the entire population.\n",
        "\n",
        "* Practical Implication: In practical terms, **uniform generalization bounds help in understanding and choosing models and algorithms**. They provide a theoretical foundation for preferring certain models over others based on their generalization capabilities, given a finite amount of data."
      ],
      "metadata": {
        "id": "lQTFSjJ1bWlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Besides model complexity, sample complexity and computational complexity, are there more dimension that need to be considered on computational learning theory?**\n",
        "\n",
        "Yes, besides model complexity, sample complexity, and computational complexity, there are several other dimensions and factors that are important in computational learning theory:\n",
        "\n",
        "1. **Algorithmic Stability**:\n",
        "    - This refers to how sensitive a learning algorithm is to small changes in the training set. Algorithms that are more stable are generally better at generalizing, as they don't overfit to the noise or specific details in the training data.\n",
        "\n",
        "2. **Noise Tolerance**:\n",
        "    - The ability of a learning algorithm to perform well in the presence of noise (errors or randomness in the training data) is crucial. This includes dealing with mislabeled data or data with measurement errors.\n",
        "\n",
        "3. **Robustness**:\n",
        "    - Robustness is the ability of the model to maintain performance when faced with input data that differs from the training data. This includes handling adversarial examples, where small, intentional changes to input data can mislead the model.\n",
        "\n",
        "4. **Learning Rate and Convergence**:\n",
        "    - This pertains to how quickly a learning algorithm converges to a good solution. Fast convergence is desirable for efficiency, but it's also important that the convergence leads to a solution that generalizes well.\n",
        "\n",
        "5. **Bias-Variance Tradeoff**:\n",
        "    - A fundamental concept in statistical learning, the bias-variance tradeoff involves balancing underfitting (bias) and overfitting (variance). It's about finding the right level of model complexity that neither oversimplifies (high bias) nor overcomplicates (high variance) the problem.\n",
        "\n",
        "6. **Data Distribution**:\n",
        "    - The nature of the data distribution, including how representative the training data is of the real-world scenarios the model will encounter, plays a crucial role in the effectiveness of learning.\n",
        "\n",
        "7. **Feature Representation**:\n",
        "    - The way data is represented or pre-processed can significantly impact the performance of a learning algorithm. Good feature representation can ease the learning process and improve generalization.\n",
        "\n",
        "8. **Scalability**:\n",
        "    - Scalability refers to how well a learning algorithm or model can handle increasing amounts of data or more complex problems. This is particularly important in big data applications.\n",
        "\n",
        "9. **Ethical and Social Considerations**:\n",
        "    - This includes considerations of fairness, privacy, and transparency. It's essential to ensure that learning algorithms do not perpetuate or exacerbate biases and are respectful of privacy and ethical norms.\n",
        "\n",
        "10. **Transferability and Adaptability**:\n",
        "    - This refers to the ability of a model to adapt to new tasks or transfer learned knowledge to different but related problems. It's a key aspect of research in areas like transfer learning and domain adaptation.\n",
        "\n",
        "11. **Interpretability and Explainability**:\n",
        "    - The ability to understand and interpret the decisions made by a model is increasingly important, especially for applications in sensitive areas like healthcare or finance.\n",
        "\n",
        "Each of these dimensions adds complexity to the design and evaluation of learning algorithms, and they are often interrelated. Balancing these factors is a key challenge in developing effective and responsible machine learning systems."
      ],
      "metadata": {
        "id": "h8b1e__XbWlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What are standard scientific methods to measure model complexity, sample complexity and computational complexity?**\n",
        "\n",
        "Measuring model complexity, sample complexity, and computational complexity in machine learning involves a blend of theoretical analysis and empirical evaluation. Each type of complexity has standard scientific methods associated with it:\n",
        "\n",
        "*1. Model Complexity*\n",
        "Model complexity refers to the ability of a model to fit a wide range of functions. It's often associated with the flexibility of the model to adapt to the underlying data structure.\n",
        "\n",
        "**Standard Methods to Measure:**\n",
        "- **VC Dimension**: For classification models, the Vapnik-Chervonenkis (VC) dimension is a theoretical measure of model capacity. It's the size of the largest set of points that the model can shatter.\n",
        "- **Number of Parameters**: In many models, such as neural networks, the number of trainable parameters is a direct measure of complexity.\n",
        "- **Model Depth and Architecture**: For neural networks, depth (number of layers) and architecture details (like types of layers and connections) indicate complexity.\n",
        "- **Information Criteria**: Metrics like AIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion) are used in statistical modeling to balance model fit and complexity.\n",
        "\n",
        "- Number of Parameters: One of the most common measures of model complexity is the number of parameters. This is a simple and intuitive measure, as it directly reflects the number of degrees of freedom in the model. However, it is not always the most informative measure, as it does not take into account the structure of the model or the relationships between its parameters.\n",
        "\n",
        "- Effective Number of Parameters: A more sophisticated measure of model complexity is the effective number of parameters. This measure takes into account the fact that some parameters may be more important than others, and it can be used to compare models with different numbers of parameters.\n",
        "\n",
        "- VC Dimension: The VC dimension is a theoretical measure of model complexity that is based on the concept of shattering. A shattered set of points is a set of points that can be perfectly classified by a hypothesis class in all possible ways. The VC dimension of a hypothesis class is the maximum size of a shattered set. A higher VC dimension indicates a more complex hypothesis class.\n",
        "\n",
        "- Kolmogorov Complexity: Kolmogorov complexity is a measure of the information content of an object. It is based on the idea that the complexity of an object is the shortest possible program that can generate it. Kolmogorov complexity can be used to measure the complexity of models, as well as the complexity of data.\n",
        "\n",
        "*2. Sample Complexity*\n",
        "Sample complexity relates to the amount of data required for a model to achieve a certain level of performance.\n",
        "\n",
        "**Standard Methods to Measure:**\n",
        "- **Empirical Evaluation**: Experimentally determining how model performance varies with different training set sizes. This often involves plotting learning curves.\n",
        "- **PAC Learning Framework**: Probably Approximately Correct (PAC) learning provides theoretical bounds on the number of samples needed for a model to learn a concept within a certain error margin and confidence level.\n",
        "- **Cross-validation**: Techniques like k-fold cross-validation can help assess how well a model with certain complexity performs with the available data.\n",
        "\n",
        "- Learning Curves: Learning curves are a simple and effective way to measure sample complexity. A learning curve is a plot of the training and generalization error of a model as a function of the number of training examples. A steeper learning curve indicates that the model is more sensitive to the number of training examples and therefore has higher sample complexity.\n",
        "\n",
        "- Error Bounds: Error bounds are a more theoretical way to measure sample complexity. Error bounds provide an upper bound on the generalization error of a model with a given level of confidence. A smaller error bound indicates lower sample complexity.\n",
        "\n",
        "- Rademacher Complexity: Rademacher complexity is a measure of the generalization error of a model that is based on the concept of Rademacher averages. Rademacher averages are a type of random average that is used to control for the randomness of the training data. A smaller Rademacher complexity indicates lower sample complexity.\n",
        "\n",
        "*3. Computational Complexity*\n",
        "Computational complexity is about the resources (time, memory) required to train or use a model.\n",
        "\n",
        "**Standard Methods to Measure:**\n",
        "- **Big O Notation**: Theoretical analysis of algorithms in terms of time and space complexity (e.g., O(n), O(n^2)) is standard.\n",
        "- **Time Profiling**: Empirically measuring the actual time taken to train models on datasets of varying sizes.\n",
        "- **Space Profiling**: Measuring the memory requirements of a model during training and inference.\n",
        "- **Algorithm Analysis**: Analyzing the specific steps of an algorithm to determine their computational requirements.\n",
        "\n",
        "- Time Complexity: Time complexity is a measure of the amount of time that an algorithm takes to run as a function of the input size. Time complexity is typically expressed using Big O notation, which provides an upper bound on the worst-case performance of the algorithm.\n",
        "\n",
        "- Space Complexity: Space complexity is a measure of the amount of memory that an algorithm requires to run as a function of the input size. Space complexity is also typically expressed using Big O notation.\n",
        "\n",
        "- Scalability: Scalability is a measure of how well an algorithm can handle increasing input sizes. An algorithm is said to be scalable if its time and space complexity grow sublinearly with the input size.\n",
        "\n",
        "*Integrating Theoretical and Empirical Approaches*\n",
        "In practice, a combination of these methods is often used. Theoretical measures provide a guideline or a framework, while empirical methods offer practical insights based on real-world data and computing environments. The choice of method depends on the specific model, the nature of the task, and the available resources. For example, in deep learning, empirical evaluation is heavily relied upon due to the complexity and non-linearity of the models, while in more traditional machine learning or statistical models, theoretical measures might be more prominently used."
      ],
      "metadata": {
        "id": "6ZyTxTqpbWls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dimensions**\n",
        "\n",
        "[Dimension](https://en.m.wikipedia.org/wiki/Dimension).Dimensionality measures are used to quantify the complexity of a set of points or a function class. They are often used in machine learning to bound the sample complexity of learning algorithms.\n",
        "* in mathematics, is a particular way of describing the size of an object (contrasting with measure and other, different, notions of size). Dimensionality measures are also used to study the relationships between different complexity classes. For example, it is known that the complexity class PSPACE is contained in the complexity class EXPTIME. This can be shown using the following theorem: Theorem: The metric entropy of any hypothesis class with VC dimension d is at most d. This theorem tells us that the complexity class PSPACE, which contains all problems that can be solved by a polynomial space Turing machine, is contained in the complexity class EXPTIME, which contains all problems that can be solved by an exponential time Turing machine. Dimensionality measures are a powerful tool for studying the complexity of computational problems. They can be used to bound the resource requirements of algorithms, and to study the relationships between different complexity classes.\n",
        "\n",
        "*Examples:*\n",
        "\n",
        "* [Effective dimension](https://en.m.wikipedia.org/wiki/Effective_dimension) is a modification of Hausdorff dimension and other fractal dimensions that places it in a computability theory setting. There are several variations (various notions of effective dimension) of which the most common is effective Hausdorff dimension.\n",
        "\n",
        "  * effective dimension is a modification of Hausdorff dimension and other fractal dimensions that places it in a computability theory setting\n",
        "\n",
        "  * to measure power / capacity of a model [Source](https://www.youtube.com/watch?v=fDIGmkq9xNE&t=2067s)\n",
        "\n",
        "  ![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1398.png)\n",
        "\n",
        "* [Hausdorff dimension](https://en.m.wikipedia.org/wiki/Hausdorff_dimension) generalizes the well-known integer dimensions assigned to points, lines, planes, etc. by allowing one to distinguish between objects of intermediate size between these integer-dimensional objects.\n",
        "\n",
        "* [Intrinsic dimension](https://en.m.wikipedia.org/wiki/Intrinsic_dimension): The intrinsic dimension of a set of points is the smallest number of parameters needed to represent the points accurately.\n",
        "\n",
        "* [Fractal dimension](https://en.m.wikipedia.org/wiki/Fractal_dimension) provides a rational statistical index of complexity detail in a pattern. A fractal pattern changes with the scale at which it is measured. It is also a measure of the space-filling capacity of a pattern, and it tells how a fractal scales differently, in a fractal (non-integer) dimension.\n",
        "\n",
        "* [Lebesgue covering dimension](https://en.m.wikipedia.org/wiki/Lebesgue_covering_dimension) or topological dimension of a topological space is one of several different ways of defining the dimension of the space in a topologically invariant way\n",
        "\n",
        "* [Krull dimension](https://en.m.wikipedia.org/wiki/Krull_dimension)\n",
        "\n",
        "* [Inductive dimension](https://en.m.wikipedia.org/wiki/Inductive_dimension)\n",
        "\n",
        "* [Minkowski–Bouligand dimension](https://en.m.wikipedia.org/wiki/Minkowski–Bouligand_dimension) also known as Minkowski dimension or box-counting dimension, is a way of determining the fractal dimension of a set S in a Euclidean space $\\mathbb {R} ^{n}$, or more generally in a metric space (X,d).\n",
        "\n",
        "* [Information dimension](https://en.m.wikipedia.org/wiki/Information_dimension) is a measure of the fractal dimension of a probability distribution. It characterizes the growth rate of the Shannon entropy given by successively finer discretizations of the space.\n",
        "\n",
        "  * In 2010, Wu and Verdú gave an operational characterization of [Rényi information dimension = Rényi entropy](https://en.m.wikipedia.org/wiki/Rényi_entropy) as the fundamental limit of almost lossless data compression for analog sources under various regularity constraints of the encoder/decoder.\n",
        "\n",
        "  * Enge Verbindung zwischen Entropy und Dimension measures.\n",
        "\n",
        "* [Correlation dimension](https://en.m.wikipedia.org/wiki/Correlation_dimension) is a measure of the dimensionality of the space occupied by a set of random points, often referred to as a type of fractal dimension.\n",
        "\n",
        "* [Packing dimension](https://en.m.wikipedia.org/wiki/Packing_dimension)\n",
        "\n",
        "* [Equilateral dimension](https://en.m.wikipedia.org/wiki/Equilateral_dimension)\n",
        "\n",
        "* [Dimensions of commutative algebra](https://en.m.wikipedia.org/wiki/Glossary_of_commutative_algebra#dimension), like Embedding dimension"
      ],
      "metadata": {
        "id": "HwVq-y4ibWls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Vapnik-Chervonenkis, Pseudo- and Fat-Shattering Dimensions are three distinct notions of “dimension”. The phrase “dimension” is rather unfortunate, as the three “dimensions” have nothing to do with the dimension of a vector space, except in very special situations. Rather, these “dimensions” are combinatorial parameters that measure the “richness” of concept classes or function classes.*\n",
        "\n",
        "* [Vapnik–Chervonenkis dimension](https://en.m.wikipedia.org/wiki/Vapnik–Chervonenkis_dimension)\n",
        "  * It quantifies the expressive power or complexity of a hypothesis class in terms of its ability to \"shatter\" sets of points. It's a scalar value that provides insight into the capacity of a class of functions or models.\n",
        "  * A hypothesis class is said to \"shatter\" a set of points if, for every possible labeling of the points, there exists a hypothesis in the class that can perfectly classify those points according to that labeling. VC dimension is defined in terms of shattering.\n",
        "  * It is the most widely used complexity metric in PAC learning, and it has been used to prove a number of important theoretical results.\n",
        "  * However, the VC dimension is not a perfect metric for the complexity of a hypothesis class. For example, the VC dimension of the class of all linear classifiers is infinite, even though linear classifiers can be learned efficiently from a small number of training examples.\n",
        "  * In PAC learning: Let H be a hypothesis class with VC dimension d. Then, the sample complexity of PAC learning H is given by: $n >= O(d / ε^2 * ln(1/δ))$, where ε is the desired error tolerance and δ is the desired confidence level.\n",
        "  \n",
        "  * [*Bias-Variance Tradeoff*](https://en.m.wikipedia.org/wiki/Bias–variance_tradeoff): This is a key principle in statistical learning that helps to understand the tradeoff between model complexity and the risk of overfitting, which impacts the number of samples needed for learning.\n",
        "\n",
        "  * Higher VC-dimension of a class = more samples are required to learn that class. Bounds on sample complexity using VC-dimension are often given in the form, where d is the VC-dimension:\n",
        "\n",
        "  * $m \\geq \\frac{8}{\\epsilon} \\ln \\left(\\frac{4}{\\delta}\\right)+\\frac{4}{\\epsilon} d \\ln \\left(\\frac{2 e m}{d}\\right)$\n",
        "\n",
        "  * measure of the capacity: The more complex the hypothesis space, the more likely it is that the learning algorithm will overfit the training data and make errors on new data (-that was assumed for neural nets).\n",
        "\n",
        "  * The VC dimension can be used to choose a hypothesis space that is not too complex, so that the learning algorithm can generalize well to new data. sample complexity of C is tightly determined by a combinatorial parameter called the VC dimension of C. measure of the capacity of a hypothesis space, which is the set of all possible hypotheses that can be learned by a machine learning algorithm.\n",
        "\n",
        "  * A hypothesis space with a higher VC dimension can learn more complex functions, but it will also be more likely to overfit the training data. The VC Dimension can provide an **upper bound on the sample complexity in terms of the size of the hypothesis class**, the desired error rate, and the confidence level.\n",
        "\n",
        "  ![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1397.png)\n",
        "\n",
        "  * *Shatter points = separate points: how these functions can separate or \"shatter\" sets of points. If you can find large sets of points that can be arbitrarily labeled (i.e., \"shattered\") by functions in your class, then the class has high complexity. - Shattered:  A set of points is shattered by H if for every possible labeling of the points, there exists a hypothesis in H that agrees with that labeling.*\n",
        "\n",
        "  * One of the most fundamental results in learning theory is that the sample complexity of C is tightly determined by a combinatorial parameter called the VC dimension of C (Source: Optimal Quantum Sample Complexity of Learning Algorithms)\n",
        "\n",
        "  ![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1643.png)\n",
        "\n",
        "  * VC dimension is still a useful concept in machine learning. It can be used to understand the complexity of a neural network and to choose a neural network that is not too complex, so that it can generalize well to new data.\n",
        "\n",
        "  * Limitations of the VC dimension (VC dimension theorem would seem to imply that large neural networks would overfit very badly and never generalize well):\n",
        "    * The VC dimension is only a theoretical bound, and it is not always accurate in practice. The VC dimension theorem assumes that the training data is drawn from an i.i.d. (independent and identically distributed) distribution. However, in practice, the training data is often not i.i.d., and this can make the VC dimension theorem less accurate.\n",
        "    * The VC dimension does not take into account the complexity of the target function. The VC dimension is only a bound on the generalization error. It is possible for a neural network to have a large VC dimension and still generalize well, if the training data is large enough.\n",
        "    * The VC dimension does not take into account the optimization algorithm used to train the neural network. There are a number of techniques that can be used to prevent neural networks from overfitting, such as regularization and dropout. These techniques can help to reduce the complexity of the neural network and make it more likely to generalize well.\n",
        "\n",
        "  * https://www.bogotobogo.com/python/scikit-learn/scikit_machine_learning_VC_Dimension_Shatter.php\n",
        "\n",
        "  * Code example: https://www.geeksforgeeks.org/vapnik-chervonenkis-dimension/\n",
        "\n",
        "  * Video: https://youtu.be/puDzy2XmR5c?si=FTPneApRNiWQkJey\n",
        "\n",
        "  * VC dimension is a method to measure model complexity. It is a measure of the capacity of a hypothesis space, which is the set of all possible hypotheses that can be learned by a machine learning algorithm. A hypothesis space with a higher VC dimension can learn more complex functions, but it will also be more likely to overfit the training data.\n",
        "\n",
        "  * The VC Dimension can provide an upper bound on the sample complexity in terms of the size of the hypothesis class, the desired error rate, and the confidence level.\n",
        "\n",
        "  * In [Vapnik–Chervonenkis theory](https://en.m.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_theory), the [Vapnik–Chervonenkis (VC) dimension](v) is a **measure of the capacity (complexity, expressive power, richness, or flexibility)** of a set of functions that can be learned by a statistical binary classification algorithm.\n",
        "\n",
        "  * It is defined as the cardinality of the largest set of points that the algorithm can [shatter](https://en.m.wikipedia.org/wiki/Shattered_set), which means the algorithm can always learn a perfect classifier for any labeling of at least one configuration of those data points.\n",
        "\n",
        "  * Relationship:\tThe VC dimension can be used to derive bounds on the sample complexity.\tThe sample complexity can be used to estimate the VC dimension.\n",
        "\n",
        "  * The VC dimension of a set of functions can be used to bound the generalization error of a learning algorithm. The generalization error is the error that a learning algorithm makes on new data that it has not seen before. The VC dimension theorem states that the generalization error of a learning algorithm is bounded by the VC dimension of the hypothesis space divided by the number of training examples. In other words, **the more complex the hypothesis space, the more likely it is that the learning algorithm will overfit the training data and make errors on new data** (-that was assumed for neural nets). The VC dimension can be used to choose a hypothesis space that is not too complex, so that the learning algorithm can generalize well to new data.\n",
        "\n",
        "* [Sauer's Lemma (or Sauer–Shelah Lemma)](https://en.wikipedia.org/wiki/Sauer%E2%80%93Shelah_lemma): A combinatorial bound that relates the growth function to the VC dimension and the number of data points. It says that if a hypothesis class has a VC dimension \\( d \\) and does not shatter any set of \\( d+1 \\) points, then the number of dichotomies it can produce on any set of \\( n \\) points is bounded by the sum of binomial coefficients from \\( i = 0 \\) to \\( d \\).\n",
        "\n",
        "* [Natarajan dimension](https://en.m.wikipedia.org/wiki/Natarajan_dimension): An extension of VC dimension to multiclass classification problems.\n",
        "\n",
        "* **Fat-shattering dimension**:\n",
        "\n",
        "  * An extension of the VC dimension that considers the ability of a hypothesis class to shatter sets of points with margins. It's useful for analyzing algorithms that make use of margins, like Support Vector Machines. / [Fat-shattering dimension](https://mlweb.loria.fr/book/en/fatshattering.html) at a certain scale of a function class is defined as the maximal number of points that can be fat-shattered by this function class at that scale. It can be bounded for popular function classes such as for the set of linear functions.\n",
        "\n",
        "  * https://mathoverflow.net/questions/307201/vc-dimension-fat-shattering-dimension-and-other-complexity-measures-of-a-clas\n",
        "\n",
        "  * Covering Numbers and Fat-Shattering Dimension: measures of complexity of function classes that can be used to **derive upper bounds on sample complexity** (bounds on expressivity of class of CPTP maps (or unitaries) that a quantum machine learning model (QMLM) can implement in terms of number of trainable elements)\n",
        "\n",
        "  * **fat-shattering dimension and VC dimension (Vapnik-Chervonenkis dimension)** fat-shattering dimension is not an example of an inequality. It is a measure of the complexity of a function class. A function class with a small fat-shattering dimension is said to be easy to learn, while a function class with a large fat-shattering dimension is said to be difficult to learn.\n",
        "\n",
        "  * The fat-shattering dimension is a complexity measure used in statistical learning theory. It's one way of quantifying the **complexity or expressive power of a class of functions, and it's used to derive bounds on the generalization error** of a learning algorithm.\n",
        "\n",
        "  * The formal definition of the fat-shattering dimension is a bit technical, but here's the general idea: suppose you have a class of functions, and you want to understand how complex this class is. One way of doing this is to look at how these functions can separate or \"shatter\" sets of points. If you can find large sets of points that can be arbitrarily labeled (i.e., \"shattered\") by functions in your class, then the class has high complexity.\n",
        "\n",
        "  * **Now, for the fat-shattering dimension, you add an additional constraint: you require a certain margin (the \"fatness\") between points that are labeled differently**. The largest set of points that can be shattered with a given margin is used to define the fat-shattering dimension of the function class.\n",
        "\n",
        "  * The fat-shattering dimension is related to the VC dimension (Vapnik-Chervonenkis dimension), another complexity measure that is widely used in statistical learning theory. However, **while the VC dimension only considers exact separation of points, the fat-shattering dimension takes into account this idea of a margin, which makes it more suitable for dealing with \"noisy\" or non-separable data.**\n",
        "\n",
        "  * the concept of the fat-shattering dimension is often used in the analysis of machine learning algorithms, particularly those based on empirical risk minimization. It can help to understand the trade-off between the expressive power of a function class (which often corresponds to the complexity of a learning algorithm) and the ability of the algorithm to generalize well to unseen data.\n",
        "\n",
        "* **Pseudo-Dimension**: Similar in spirit to the VC dimension but adapted for real-valued function classes rather than binary classifiers. / [Pseudo-dimension](https://link.springer.com/chapter/10.1007/978-1-4471-3748-1_4), also Pollard dimension, is a generalization of the VC-dimension to real-valued functions. The fat-shattering dimension, unlike the Pseudo-dimension, is a “scale-sensitive” measure of richness.\n"
      ],
      "metadata": {
        "id": "FiGM7LUAbWls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Concentration inequalities**](https://en.m.wikipedia.org/wiki/Concentration_inequality) = bounds probability of estimator deviating from its expected value by a certain amount = provide guarantees on accuracy of estimator. Inequalities above just bound magnitude of deviation, bound probability. Will a learning algorithm converge to correct hypothesis with high probability, even if data is noisy or incomplete? Concentration inequalities can be used to bound VC dimension of hypothesis space to design ML algorithms that are guaranteed to generalize well to new data. And in regularization (to control complexity of ML models): analyze effects of regularization on generalization performance of ML models. Concentration inequalities don't guarantee learning a function with small error, but provide high degree of confidence that algorithm is likely to learn a good function, given a sufficient number of training samples and a suitable regularization scheme.\n",
        "\n",
        "* Matrix concentration inequalities: use by Ewin tang for dequantization, see also: https://arxiv.org/abs/1501.01571 - An Introduction to Matrix Concentration Inequalities. Some common matrix concentration inequalities that might appear in Tang's work include:\n",
        "\n",
        "  * Matrix Bernstein Inequality: Provides bounds on the deviation of the sum of random matrices from its expectation. It has variants tailored to handling sums of matrices that aren't independent.\n",
        "  * Matrix Hoeffding Inequality: Generalizes Hoeffding's inequality (which is for sums of random variables) to the matrix setting.\n",
        "  * Matrix Chernoff Bound: Gives tail bounds on how much a random matrix might deviate from its mean.\n",
        "\n",
        "\n",
        "* [Markov's inequality](https://en.m.wikipedia.org/wiki/Markov%27s_inequality): simplest concentration inequality. Bounds probability that random variable deviates from its expected value by a certain amount = bounds probability of errors in statistical estimators, proves convergence of learning algorithms, analyzes performance of randomized algorithms.\n",
        "\n",
        "* [Hoeffding's inequality](https://en.m.wikipedia.org/wiki/Hoeffding%27s_inequality):\n",
        "  * We want to guarantee that a hypothesis with a small training error will have good accuracy on unseen examples, and one way to do so is with Hoeffding bounds. This characterizes the deviation between the true probability of some event and its observed frequency over m independent trails. [Source](https://www.cis.upenn.edu/~danroth/Teaching/CS446-17/LectureNotesNew/colt/main.pdf)\n",
        "  * states that probability that average of a number of independent and identically distributed random variables deviates from its expected value by more than a certain amount is exponentially small in number of random variables.\n",
        "  * average of n independent random variables deviates from its expected value by more than ε at most $2e^{(-2nε^2)}$ probability and decays exponentially with number of random variables -> Probability of deviation becomes very small as number of random variables increases. **This inequality bounds generalization error of a learning algorithm, regardless of the model complexity or the sample complexity. Can show that sample complexity of learning a linear regression model with a certain level of accuracy is proportional to logarithm of number of features.**  \n",
        "  * Hoeffding's inequality is a **special case of the Azuma–Hoeffding inequality and McDiarmid's inequality**. It is **similar to the Chernoff bound**, but tends to be less sharp, in particular when the variance of the random variables is small. It is **similar to, but incomparable with, one of Bernstein's inequalities**.\n",
        "  * Example: bound sample complexity of online learning algorithm (with perceptron):\n",
        "    * $X_1, X_2, ..., X_n$ be independent random variables with mean $\\mu$ and variance $\\sigma^2$.\n",
        "    * For any $\\delta > 0$, $P(\\bar{X} - \\mu > \\delta) \\leq \\exp(-\\delta^2 n / 2 \\sigma^2)$ where $\\bar{X}$ is average of $X_i$.\n",
        "    * $L_i$ be loss of Perceptron on $i$th training sample. Average loss of Perceptron on training data is: $\\bar{L} = \\frac{1}{n} \\sum_{i=1}^n L_i$.\n",
        "    * Objective: Use concentration inequality to show that average loss of Perceptron on training data is close to its expected value with high probability, given a sufficient number of training samples: $P(\\bar{L} - \\mu > \\delta) \\leq \\exp(-\\delta^2 n / 2 \\sigma^2)$ where $\\mu$ is expected loss of Perceptron on training data.\n",
        "    * With probability at least $1 - \\exp(-\\delta^2 n / 2 \\sigma^2)$, average loss of Perceptron on training data is within $\\delta$ of its expected value.\n",
        "    * Set $\\delta$ to be a small value, such as $0.01$, to ensure that average loss of Perceptron on training data is very close to its expected value with high probability.\n",
        "    * Hoeffdings inequality bounds sample complexity: $n \\geq \\frac{2 \\sigma^2 \\ln(1 / \\delta)}{\\delta^2}$ tells us that if we have $n$ training samples, then average loss of Perceptron on training data is within $\\delta$ of its expected value with probability at least $1 - \\exp(-\\delta^2 n / 2 \\sigma^2)$.\n",
        "\n",
        "* [Azuma's inequality](https://en.m.wikipedia.org/wiki/Azuma%27s_inequality)\n",
        "\n",
        "* [Chernoff bounds](https://en.m.wikipedia.org/wiki/Chernoff_bound): Bound probability of sum of independent random variables deviating from its expected value by more than a certain amount, even if the random variables are not identically distributed. Generalization of Hoeffding's inequality, used to bound tails of probability distributions.\n",
        "\n",
        "* [Bernstein's inequality](https://en.m.wikipedia.org/wiki/Bernstein_inequalities_(probability_theory)): generalization of Chernoff bounds. Bounds probability, even if the random variables are not identically distributed and have non-identical variances (used to bound tails of sub-Gaussian distributions).\n",
        "\n",
        "* [McDiarmid's inequality](https://en.m.wikipedia.org/wiki/McDiarmid%27s_inequality): bounds deviation between sampled value and expected value of certain functions (= functions that satisfy a bounded differences property, meaning that replacing a single argument to the function while leaving all other arguments unchanged cannot cause too large of a change in the value of the function) when they are evaluated on independent random variables.\n",
        "\n",
        "* [Bennett's inequality](https://en.m.wikipedia.org/wiki/Bennett%27s_inequality): provides an upper bound on the probability that the sum of independent random variables deviates from its expected value by more than any specified amount. **Can be used to: Bound the generalization error of learning algorithms.**\n",
        "\n",
        "* [(Bienaymé–) Chebyshev's inequality](https://en.m.wikipedia.org/wiki/Chebyshev%27s_inequality): provide upper bounds on the probability that a random variable deviates from its expected value by more than a certain amount. Chebyshev's inequality is particularly useful for bounding the deviations of random variables with finite mean and variance. One way to think about Chebyshev's inequality is that it provides a measure of how concentrated the probability distribution of a random variable is around its expected value. The more concentrated the probability distribution is, the lower the probability is that the random variable will deviate from its expected value by more than a certain amount. **Can be used to: Bound the probability of rare events**. Design confidence intervals for population parameters. Develop efficient algorithms for statistical testing.\n",
        "\n",
        "* [Vysochanskij–Petunin inequality](https://en.m.wikipedia.org/wiki/Vysochanskij%E2%80%93Petunin_inequality):  It is a refinement of Chebyshev's inequality that provides tighter bounds on the probability that a random variable deviates from its expected value by more than a certain amount, especially for random variables with unimodal distributions."
      ],
      "metadata": {
        "id": "EyLCNuiFbWlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[Inequality (complexities)](https://en.m.wikipedia.org/wiki/Inequality_(mathematics)): bound probability of random variable deviating from its expected value. Analyze reliability and stability of algorithm. Computational complexity: analysis of randomized algorithms to bound error probabilities.** See [Inequalities in information theory](https://en.m.wikipedia.org/wiki/Inequalities_in_information_theory), [Information geometry](https://en.m.wikipedia.org/wiki/Information_geometry), [Information projection](https://en.m.wikipedia.org/wiki/Information_projection), and [Confidence Interval](https://en.m.wikipedia.org/wiki/Confidence_interval).\n",
        "\n",
        "Evaluate performance of estimators: bounds on Prediction Errors, Sample Complexity, Model complexity, and Deviation of Estimators. By bounding error: ensure that model is not too far from optimal solution (Regularize models by bounding complexity of model: L1 norm to bound number of parameters, L2 norm to bound sum of squared parameters).\n",
        "\n",
        "* [Triangle inequality](https://en.m.wikipedia.org/wiki/Triangle_inequality). K-means clustering: cost function is sum of squared distances between data points and cluster centroids. Squared distances can be bounded by triangle inequality.\n",
        "\n",
        "* [Cramér–Rao bound](https://en.m.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound): lower bound (min value) on variance of an unbiased estimator (but cannot tell about probability of deviation) - this value is inverse of [Fisher information](https://de.m.wikipedia.org/wiki/Fisher-Information#Verwendung)(how much information data provides about parameters being estimated). Used to design estimators that are as efficient as possible.\n",
        "\n",
        "  * [*Quantum Cramér-Rao Bound*](https://en.m.wikipedia.org/wiki/Quantum_Cramér–Rao_bound)\n",
        "\n",
        "  * QFIM and Quantum Cramér-Rao Bound used in quantum metrology to **quantify ultimate limit to precision** that can be achieved in estimating parameters (CRB (derived from FIM) tells us smallest possible variance (or covariance in the multivariate case) that we can expect from an unbiased estimator. Fisher Information is a measure of how much information a random variable provides about an unknown parameter).\n",
        "\n",
        "  * Is an inequality: bound probability of random variable deviating from its expected value. Analyze reliability and stability of algorithm. Computational complexity: analysis of randomized algorithms to bound error probabilities.\n",
        "\n",
        "  * The Cramér-Rao bound (CRB) belongs to **model complexity** = Bounds on Precision of Estimator. It gives a measure of the best possible precision that can be achieved when estimating that parameter from a given set of data. The **quantum Cramér-Rao bound provides a limit on the precision with which these properties can be estimated, given the inherent uncertainties of quantum mechanics**.\n",
        "\n",
        "  * It provides a lower bound on the covariance matrix of any unbiased quantum estimator (The covariance matrix determines the uncertainty or precision of the estimated parameter). It characterizes the best possible precision that can be achieved in estimating a parameter of interest from quantum measurements.\n",
        "\n",
        "  * The quantum Cramér-Rao bound serves as a powerful tool for understanding the fundamental limits of precision in quantum state estimation (without consoidering noise, imperfections etc).\n",
        "\n",
        "  * The quantum Cramér-Rao bound is given by the inverse of the **Fisher information matrix**, which in the quantum case is calculated using the quantum state and the POVM (Positive Operator-Valued Measure) elements describing the measurements. It can provide insights into the optimal measurement strategies for estimating the parameters of a quantum state, and can help guide the design of quantum sensors and other quantum technologies.\n",
        "\n",
        "  * The basic formula for calculating the quantum Cramér-Rao bound (QCRB) for parameter estimation:\n",
        "\n",
        "  * $QCRB = Tr(F^{-1} M)$\n",
        "\n",
        "  * where:\n",
        "\n",
        "    - QCRB is the quantum Cramér-Rao bound, which provides a lower bound on the covariance matrix of any unbiased estimator.\n",
        "    - $F$ is the Fisher information matrix, which quantifies the amount of information provided by the measurements about the parameter of interest.\n",
        "    - $M$ is the symmetric, positive semidefinite matrix representing the measurement operators' influence on the parameter estimation.\n",
        "\n",
        "  * To calculate the QCRB, you'll need to obtain the Fisher information matrix (F) and the measurement matrix (M) for the chosen estimation strategy. The Fisher information matrix can be computed based on the measurement operators and the quantum state being measured.\n",
        "\n",
        "  * Cramér-Rao is a lower bound on the variance of any unbiased estimator of a parameter, given a fixed model. The CRB depends on the Fisher information, which is a measure of how much information the data provides about the parameter. A higher Fisher information means that the data is more informative about the parameter, and therefore the CRB is lower.\n",
        "\n",
        "  * In general, the CRB is a more fundamental concept than the sample complexity. It is used to understand the fundamental limits of parameter estimation, regardless of the amount of data available. The sample complexity, on the other hand, is more practical, as it tells us how much data we need to achieve a certain level of accuracy.\n",
        "\n",
        "  * In machine learning, the Cramér-Rao Bound (CRB) is often used as a tool for **understanding the fundamental limits of learning algorithms, particularly in the field of parameter estimation and model selection**. Here are some specific applications:\n",
        "\n",
        "    1. Variance Estimation: Similar to financial economics, the CRB provides a theoretical lower limit for the variance of an unbiased estimator. This can help understand how well a learning algorithm might perform in terms of parameter estimation, given a certain amount of data.\n",
        "\n",
        "    2. Model Complexity: The CRB can provide insights into how model complexity affects estimation accuracy. A model with too many parameters may have a higher CRB (i.e., higher variance for the best possible estimator), indicating that it could be more prone to overfitting.\n",
        "\n",
        "    3. Algorithm Evaluation: Researchers might use the CRB to evaluate and compare the performance of different learning algorithms. If an algorithm's performance is close to the CRB, it might be deemed near-optimal.\n",
        "\n",
        "    4. Designing Neural Networks: In the design of neural networks, the CRB can be used to understand the limit of what the network can learn from the data, which can help in making decisions about network architecture and training strategies.\n",
        "\n",
        "* [Trace_inequality](https://en.m.wikipedia.org/wiki/Trace_inequality) bounds the trace of a matrix by the sum of the traces of its eigenvalues. Trace inequality, also known as the triangle inequality for the trace distance, states that for any three quantum states ρ, σ, and τ, the following inequality holds:\n",
        "  * $δ(ρ, σ) + δ(σ, τ) ≥ δ(ρ, τ)$\n",
        "  * where δ(ρ, σ) is the trace distance between ρ and σ.\n",
        "  * Bounding the error of quantum learning algorithms: The trace inequality can be used to derive upper bounds on the error of quantum learning algorithms. This is useful for understanding the performance of quantum learning algorithms and for comparing them to classical learning algorithms.\n",
        "  *  The trace inequality can be used to derive bounds on the error of a wide variety of quantum learning algorithms, including algorithms for learning linear classifiers, support vector machines, and neural networks.\n",
        "  * It is important to note that the bounds derived using the trace inequality are often loose. This is because the trace inequality is a very general tool, and it does not take into account the specific structure of the quantum learning algorithm or the training data. However, the trace inequality can still be used to get a rough estimate of the error of a quantum learning algorithm.\n",
        "\n",
        "* [Bohnenblust-Hille inequality](https://en.m.wikipedia.org/wiki/Littlewood%27s_4/3_inequality):\n",
        "\n",
        "  * The Bohnenblust-Hille inequality says that the $\\ell^{\\frac{2 m}{m+1}}$-norm of the coefficients of an $m$-homogeneous polynomial $P$ on $\\mathbb{C}^n$ is bounded by $\\|P\\|_{\\infty}$ times a constant independent of $n$, where $\\|\\cdot\\|_{\\infty}$ denotes the supremum norm on the polydisc $\\mathbb{D}^n$. [Source](https://annals.math.princeton.edu/wp-content/uploads/annals-v174-n1-p13-s.pdf)\n",
        "\n",
        "\n",
        "* [Littlewood's 4/3 inequality](https://en.m.wikipedia.org/wiki/Littlewood%27s_4/3_inequality)\n",
        "\n",
        "  * is a norm inequality for multilinear forms and polynomials. It is used to study the behavior of random variables and multilinear forms. Can be used to derive concentration inequalities in some cases. For example, it can be used to prove that the coefficients of a random homogeneous polynomial are concentrated around their expected values. This can then be used to prove concentration inequalities for other random variables, such as the output of a neural network. Used in \"Learning to predict arbitrary quantum processes\".\n",
        "\n",
        "\n",
        "* [Golden–Thompson inequality](https://en.m.wikipedia.org/wiki/Golden%E2%80%93Thompson_inequality) bounds difference between logarithm of trace of a matrix and sum of logarithms of its eigenvalues. Used in 'A survey on the complexity of learning quantum states' page 17 - difference between real state and shadow tomography state)\n",
        "\n",
        "* [Cauchy–Schwarz inequality](https://en.m.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality). Cauchy-Schwarz inequality used to bound sum of squared residuals (cost function for linear regression) by the sum of the squared predicted values and the sum of the squared actual values. Used in *A Survey of Quantum Learning Theory* page 11 to compute upper bounds of learning algorithm.\n",
        "\n",
        "* [Chebyshev's inequality](https://en.m.wikipedia.org/wiki/Chebyshev%27s_inequality) bounds probability that a random variable deviates from its expected value by more than a certain amount (k standard deviations at most 1/k^2).\n",
        "\n",
        "* [Rademacher Complexity](https://en.m.wikipedia.org/wiki/Rademacher_complexity):\n",
        "  * upper bound on sample complexity = on learnability of function classes (deriving generalization bounds). Measures ability of functions in class to fit to random noise. [Rademacher Complexity PDF](https://www.cs.cmu.edu/~ninamf/ML11/lect1117.pdf).\n",
        "  * When the Rademacher complexity is small, it is possible to learn the hypothesis class H using [empirical risk minimization](https://en.m.wikipedia.org/wiki/Empirical_risk_minimization).\n",
        "\n",
        "* [Gaussian complexity](https://en.m.wikipedia.org/wiki/Rademacher_complexity#Gaussian_complexity):  similar complexity to Rademacher. Can be obtained from Rademacher using random variables $g_i$ instead of $\\sigma_i$, where $g_i$ are Gaussian i.i.d. random variables with zero-mean and variance 1, i.e. $g_i \\sim \\mathcal{N}(0,1)$. Gaussian and Rademacher are equivalent up to logarithmic factors.\n",
        "\n",
        "* [Fano's inequality](https://en.m.wikipedia.org/wiki/Fano%27s_inequality): is a lower bound on the average probability of error in a multiple hypothesis testing problem. It states that the average probability of error in a multiple hypothesis testing problem is at least as high as the entropy of the hypothesis distribution divided by the natural logarithm of two. It can be used to: Design efficient multiple hypothesis testing algorithms. Lower bound the generalization error of learning algorithms. Develop new algorithms for information compression and transmission. Fano's inequality is a powerful tool for analyzing the performance of multiple hypothesis testing algorithms and other machine learning algorithms.\n",
        "\n",
        "* [Data processing inequality](https://en.m.wikipedia.org/wiki/Data_processing_inequality): is a concept that states that the information content of a signal cannot be increased via a local physical operation. This can be expressed concisely as 'post-processing cannot increase information'. It is an inequality that relates the mutual information between two random variables before and after a data processing channel. It states that the mutual information between two random variables after a data processing channel cannot be greater than the mutual information between the two random variables before the channel. It can be used to: prove that certain learning problems are impossible to solve perfectly.\n",
        "Design efficient algorithms for information compression and transmission. It is a powerful tool for analyzing the flow of information through systems."
      ],
      "metadata": {
        "id": "SeHmvo96bWlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A norm inequality (like Bohnenblust-Hille inequalities) is an inequality that involves the norms of vectors and matrices. Norms are functions that measure the size of vectors and matrices. There are many different types of norms, but some of the most common include the Euclidean norm, the $p$-norm, and the Frobenius norm.\n",
        "\n",
        "Norm inequalities are useful in many different areas of mathematics, including functional analysis, numerical linear algebra, and machine learning. For example, norm inequalities can be used to prove bounds on the error of numerical algorithms, to design efficient machine learning algorithms, and to analyze the stability of differential equations.\n",
        "\n",
        "Here are some examples of norm inequalities:\n",
        "\n",
        "* **Triangle inequality:** $\\|x + y\\| \\leq \\|x\\| + \\|y\\|$ for all vectors $x$ and $y$.\n",
        "* **Cauchy-Schwarz inequality:** $\\|⟨x, y⟩\\| \\leq \\|x\\| \\|y\\|$ for all vectors $x$ and $y$.\n",
        "* **Hölder's inequality:** $\\left\\| \\sum_{i=1}^n a_i b_i \\right\\| \\leq \\left\\| \\sum_{i=1}^n |a_i|^p \\right\\|^{1/p} \\left\\| \\sum_{i=1}^n |b_i|^q \\right\\|^{1/q}$, where $p$ and $q$ are conjugate exponents (i.e., $1/p + 1/q = 1$).\n",
        "* **Submultiplicativity of the Frobenius norm:** $\\|AB\\|_F \\leq \\|A\\|_F \\|B\\|_F$ for all matrices $A$ and $B$.\n",
        "\n",
        "Norm inequalities can be used to prove many other important results in mathematics. For example, the triangle inequality can be used to prove the existence and uniqueness of solutions to differential equations. The Cauchy-Schwarz inequality can be used to prove the Bessel inequality, which is a fundamental result in Fourier analysis. Hölder's inequality can be used to prove the Minkowski inequality, which is another important result in functional analysis.\n",
        "\n",
        "Norm inequalities are a powerful tool in mathematics, and they have many applications in science and engineering.\n",
        "\n",
        "*Yes, the triangle inequality is a norm inequality. The triangle inequality states that the norm of the sum of two vectors is less than or equal to the sum of the norms of the two vectors. In other words, for any two vectors $x$ and $y$, we have:*\n",
        "\n",
        "```\n",
        "||x + y|| <= ||x|| + ||y||\n",
        "```\n",
        "\n",
        "This inequality holds for any norm, including the Euclidean norm, the $p$-norm, and the Frobenius norm.\n",
        "\n",
        "The triangle inequality is a fundamental property of norms, and it has many important consequences. For example, the triangle inequality can be used to prove the existence and uniqueness of solutions to differential equations, and it can also be used to design efficient machine learning algorithms.\n",
        "\n",
        "The triangle inequality is also related to the triangle inequality in Euclidean geometry. The triangle inequality in Euclidean geometry states that the sum of the lengths of any two sides of a triangle must be greater than or equal to the length of the third side. This inequality can be proven using the triangle inequality for norms.\n",
        "\n",
        "In conclusion, the triangle inequality is a norm inequality that has many important applications in mathematics, science, and engineering."
      ],
      "metadata": {
        "id": "TyeMFHRnbWlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what means that a generalization bound is uniform?**\n",
        "\n",
        "A generalization bound is said to be uniform if it holds for all hypotheses in a given hypothesis class, rather than just for a specific hypothesis. This is important because it allows us to make guarantees about the performance of our learning algorithm on any new data, regardless of the specific hypothesis that it learns.\n",
        "\n",
        "Uniform generalization bounds are typically derived using a technique called **Rademacher complexity**. Rademacher complexity is a measure of the complexity of a hypothesis class, and it can be used to bound the generalization error of any learning algorithm that uses that hypothesis class.\n",
        "\n",
        "Uniform generalization bounds are particularly useful for complex hypothesis classes, such as the class of all neural networks. These hypothesis classes have infinite VC-dimension, which makes it difficult to derive generalization bounds using traditional methods. However, uniform generalization bounds based on Rademacher complexity can be applied to any hypothesis class, regardless of its VC-dimension.\n",
        "\n",
        "Some examples of uniform generalization bounds include:\n",
        "\n",
        "* The generalization bound for uniformly stable learning algorithms\n",
        "* The generalization bound for overparameterized neural networks in kernel regimes\n",
        "\n",
        "Uniform generalization bounds are an important tool for understanding and analyzing the performance of machine learning algorithms. They allow us to make guarantees about the ability of our algorithms to generalize to new data, even when the hypothesis class is complex.\n",
        "\n",
        "Here is a simple analogy to help understand uniform generalization bounds:\n",
        "\n",
        "Imagine that you are trying to train a model to predict whether a given email is spam or not. You have a dataset of labeled emails, and you use this dataset to train a machine learning algorithm.\n",
        "\n",
        "Once the algorithm is trained, you want to be able to use it to predict the spam/ham label of any new email, even if that email is not in the training dataset.\n",
        "\n",
        "A uniform generalization bound tells you that the probability that your algorithm will make a mistake on any new email is less than a certain threshold. This threshold is independent of the specific email that you are trying to predict.\n",
        "\n",
        "In other words, a uniform generalization bound guarantees that your algorithm will generalize well to any new data, even if that data is very different from the training data."
      ],
      "metadata": {
        "id": "0QgIgipSbWlu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Google: <font color=\"blue\">Machine Learning***"
      ],
      "metadata": {
        "id": "xdsgEUJ4jW7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Computer Science*"
      ],
      "metadata": {
        "id": "Y5obzMR9bSTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Flow of Compilation in Programming Languages*"
      ],
      "metadata": {
        "id": "_wegxQZg6Cql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Flow of Compilation in Programming Languages**\n",
        "\n",
        "* **First generation (1GL)**:\n",
        "  * Machine code (binary befehle), written in binary code\n",
        "  * machine-specific = each language designed for a specific type of computer\n",
        "\n",
        "* **Second generation (2GL)**:\n",
        "  * Assembly Language, mit [Hexadezimalsystem](https://de.m.wikipedia.org/wiki/Hexadezimalsystem), wie Intel x86, still machine-specific, but easier to write and read than binary code. Assembly languages used mnemonics (=abbreviations for machine instructions)\n",
        "  * Shell: command-line interpreter to control operating system (automate tasks). Book: [Assembler-Programmierung für x86-Prozessoren\n",
        "  ](https://de.m.wikibooks.org/wiki/Assembler-Programmierung_für_x86-Prozessoren/_Druckversion)\n",
        "\n",
        "* **Third generation (3GL)**:\n",
        "  * high-mid level progamming language, like BASIC, COBOL, FORTRAN, Pascal, C, Python, C++, Java, Perl\n",
        "  * (high-mid level progamming language):\n",
        "  * were a major breakthrough in programming: 3GL languages were not machine-specific anymore\n",
        "  * 3GL languages also used English-like keywords = easier to learn and use than assembly languages\n",
        "\n",
        "* **Fourth generation (4GL)**:\n",
        "  * SQL, PL/SQL, Visual Basic, PowerBuilder, TensorFlow\n",
        "  * also known as non-procedural languages, were designed to make programming even easier.\n",
        "  4GL languages use natural language statements to describe what the program should do, rather than how to do it. This makes 4GL languages ideal for business applications.\n",
        "\n",
        "* **Fifth generation (5GL)**:\n",
        "  * [Prolog](https://en.m.wikipedia.org/wiki/Prolog), OPS5, Mercury\n",
        "  * also known as logic programming languages, are based on AI: use logic to solve problems, rather than traditional programming techniques\n",
        "  * 5GL languages are still in their early stages of development\n",
        "\n",
        "**Modern flow of compilation involves following steps**:\n",
        "\n",
        "1. **Preprocessing:** This step removes comments and other non-essential text from the source code.\n",
        "2. **Lexical analysis:** This step breaks the source code into tokens, which are the basic building blocks of the language.\n",
        "3. **Parsing:** This step constructs a parse tree, which is a graphical representation of the syntactic structure of the source code.\n",
        "4. **Semantic analysis:** This step checks the source code for errors in its meaning.\n",
        "5. **Code generation:** This step generates machine code from the parse tree.\n",
        "6. **Optimization:** This step can improve the performance of the machine code by removing unnecessary instructions or by rearranging the instructions in a more efficient order."
      ],
      "metadata": {
        "id": "yAO-PIoC6Atc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Transistors*"
      ],
      "metadata": {
        "id": "6IeXoanHRwy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video: [1.2 - Racing Down the Slopes of Moore’s Law (Bram Nauta)](https://www.youtube.com/watch?v=THJP_HB5HEk&list=WL&index=5&t=596s)\n",
        "\n",
        "Video: [Why We're Reaching the Theoretical Limit of Computer Power](https://www.youtube.com/watch?v=Qlv5pB6u534&list=WL&index=6&t=1s)\n",
        "\n",
        "Video: [Integrated Circuit Design – EE Master Specialisation](https://www.youtube.com/watch?v=jZIxNIzi-I8&list=WL&index=7)\n",
        "\n",
        "Video: [Jim Keller: Moore's Law, Microprocessors, and First Principles | Lex Fridman Podcast #70](https://www.youtube.com/watch?v=Nb2tebYAaOA)"
      ],
      "metadata": {
        "id": "ZgToug2OXUfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transistor: [New Microchip Breakthrough: New Era in Electronics?](https://youtu.be/wGzBuspS9JI?si=AxNQFBEttoOzeSDX)\n"
      ],
      "metadata": {
        "id": "LQ-KyX_3u3iA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chips und Transistoren**\n",
        "\n",
        "https://www.heise.de/news/Intel-und-TSMC-arbeiten-an-Transistoren-der-Zukunft-9568367.html\n",
        "\n",
        "https://www.golem.de/news/smic-3-nm-prozessoren-aus-china-auch-ohne-westliche-unterstuetzung-2312-180619.amp.html\n",
        "\n",
        "https://www.pcgameshardware.de/CPU-CPU-154106/News/Doppelte-Dichte-TSMC-CFET-Fertigung-90-Prozent-Yield-1436998/\n",
        "\n",
        "https://www.tomshardware.com/tech-industry/semiconductors/intels-ceo-says-moores-law-is-slowing-to-a-three-year-cadence-but-its-not-dead-yet\n"
      ],
      "metadata": {
        "id": "wzyPXaZ2R53L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Physical Limits of Moore's Law**\n",
        "\n",
        "https://www.derstandard.de/story/3000000201716/auf-dem-weg-zu-graphen-chips-der-zukunft\n",
        "\n",
        "https://www.derstandard.at/story/2000143050519/chipherstellung-2d-kristalle-sollen-moores-law-zurueckbringen\n",
        "\n",
        "* [Moore's Law](https://en.m.wikipedia.org/wiki/Moore%27s_law), *Keywords: Wafer, semiconductor, microchips, silicon, transistors*\n",
        "\n",
        "* We have 1000x1000x1000 atoms distance. for quantum tunneling we would need 10x10x10\n",
        "\n",
        "* exponential improvement is the result of 1000 innovations at the same time\n",
        "\n",
        "* [Jim Keller: Moore's Law, Microprocessors, and First Principles | Lex Fridman Podcast #70](https://www.youtube.com/watch?v=Nb2tebYAaOA)\n",
        "\n",
        "* **Silicium** ist [Halbleiter](https://www.halbleiter.org/waferherstellung/silicium/): Leitfähigkeit zwischen der von Leitern und Nichtleitern. [Mikroelektronik](https://de.m.wikipedia.org/wiki/Mikroelektronik) und [Computerchips](https://de.m.wikipedia.org/wiki/Integrierter_Schaltkreis). Reinheitsgrade elementares Silicium: **Sieg** (electronic grade, Halbleitersilicium, Verunreinigungen kleiner 10^−9).\n",
        "\n",
        "* **Alternative: 2D waferswith molten sodium molybdate salt (Na₂MoO₄)** [Source (dt)](https://efahrer.chip.de/news/china-entwickelt-ultraduenne-halbleiter-revolution-in-der-technologiebranche_1014836) & [Source (en)](https://www.scmp.com/news/china/science/article/3232116/revolutionising-semiconductor-industry-chinese-scientists-unveil-12-inch-wafer-groundbreaking-2d)\n",
        "  * Ultra-thin 2D semiconductor: thickness is hardly higher than **thickness of an atom**. The layer is almost two-dimensional.\n",
        "  * succeeded in making 12-inch wafers (300 millimeters in diameter) from the material (standard measure for wafers in semiconductors).\n",
        "  * \"When silicon transistors become thinner, control of voltage deteriorates. Electricity flows even when device is not working. This brings additional energy costs and heat development\"\n",
        "  * For 2D wafers: molten sodium molybdate salt (Na2MoO4) - makes easier to control tension.\n",
        "\n",
        "* ***The size of today's transistors and microchips is measured in nanometers (nm). As of 2023, the smallest transistors that have been produced are around 5nm in size. This means that 5 billion transistors can fit on a single square millimeter of chip.***\n",
        "\n",
        "* The size of microchips is measured in square millimeters (mm2). The largest microchips that are currently being produced are around 1,000mm2 in size. These chips can contain tens of billions of transistors.\n",
        "\n",
        "* Moore's law states that the number of transistors on a microchip doubles every two years. This has held true for over 50 years, but there are signs that it is starting to slow down. This is because it is becoming increasingly difficult to manufacture transistors that are smaller and smaller.\n",
        "\n"
      ],
      "metadata": {
        "id": "DnUtKY5hSAgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ***How many atoms distance have today‘s smallest transistors?***\n",
        "\n",
        "* The smallest transistors that have been produced as of 2023 are around 5nm in size. A silicon atom is about 0.117nm in diameter. This means that the smallest transistors are about 43 atoms wide.\n",
        "\n",
        "* However, it is important to note that the gate length of a transistor is not the only factor that determines its size. The transistor also has other components, such as the source, drain, and body. These components also take up space.\n",
        "\n",
        "* As a result, the actual size of a transistor is typically larger than the gate length. For example, a 5nm transistor might actually be 10nm or more in width.\n",
        "\n",
        "* This means that the smallest transistors today are made up of hundreds or even thousands of atoms.\n",
        "\n",
        "* It is also important to note that the size of transistors is constantly shrinking. Researchers are working on developing new materials and manufacturing techniques that will allow them to produce even smaller transistors.\n",
        "\n",
        "* So, the answer to the question of how many atoms distance today's smallest transistors have is that it depends on how you measure it. If you measure the gate length, then the smallest transistors are about 43 atoms wide. However, if you measure the overall size of the transistor, then the smallest transistors are made up of hundreds or even thousands of atoms.\n",
        "\n",
        "* ***And is it true that transistors need a distance of 10 atoms ao that for quantum tunneling takes effect and limits further shrinking physically?***\n",
        "\n",
        "* Yes, it is true that transistors need a distance of about 10 atoms in order for quantum tunneling to take effect and limit further shrinking physically.\n",
        "\n",
        "* Quantum tunneling is a phenomenon in which particles can pass through barriers that they would not be able to overcome classically. This is because particles have a wave-like nature, and they can have a certain probability of being found on the other side of a barrier, even if they do not have enough energy to overcome it.\n",
        "\n",
        "* In the case of transistors, quantum tunneling can cause electrons to leak from the source to the drain, even when the transistor is turned off. This can lead to increased power consumption and reduced performance.\n",
        "\n",
        "* The distance at which quantum tunneling becomes a problem depends on a number of factors, including the height of the barrier and the energy of the particles. However, it is generally believed that quantum tunneling becomes a significant problem when the distance between the source and drain is less than about 10 atoms.\n",
        "\n",
        "* This means that the smallest transistors that can be made using current technology are around 10nm in size. However, researchers are working on new materials and manufacturing techniques that could allow them to produce even smaller transistors in the future.\n",
        "\n",
        "* One way to reduce the effects of quantum tunneling is to use new materials that have a higher bandgap. The bandgap is the energy difference between the valence band and the conduction band. Electrons in the valence band are bound to atoms, while electrons in the conduction band are free to move around. The higher the bandgap, the more energy it takes for an electron to move from the valence band to the conduction band.\n",
        "\n",
        "* Another way to reduce the effects of quantum tunneling is to use new manufacturing techniques that create sharper interfaces between the different layers of the transistor. This helps to create a higher barrier that electrons need to tunnel through.\n",
        "\n",
        "* Researchers are also investigating new transistor designs that are less susceptible to quantum tunneling. For example, some researchers are developing transistors that use vertical channels instead of horizontal channels. Vertical channels are more difficult for electrons to tunnel through than horizontal channels.\n",
        "\n",
        "* It is still too early to say when or if transistors that are smaller than 10nm will be possible to manufacture. However, the research that is being done in this area is very promising.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZeuqaZABR9i-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Physical Limits of CPU-Clockspeed**\n",
        "* There are a few reasons why CPU clock speed is not increasing anymore. See article: [why-cpu-clock-speed-isnt-increasing](https://www.maketecheasier.com/why-cpu-clock-speed-isnt-increasing/)\n",
        "* **The physical limits of transistors.** Transistors are the basic building blocks of a CPU, and they can only switch so fast. As transistors get smaller, they also get slower. This is because the distance between the transistors gets smaller, and the electrons have to travel a shorter distance to switch them on and off.\n",
        "* **The power consumption of CPUs.** As the clock speed of a CPU increases, so does its power consumption. This is because the transistors have to switch more often, and this requires more energy.\n",
        "* **The heat generated by CPUs.** When a CPU consumes more power, it also generates more heat. This heat can cause the CPU to throttle its clock speed, or even shut down, to prevent damage.\n",
        "* As a result of these factors, CPU manufacturers have shifted their focus to other ways to improve CPU performance, such as increasing the number of cores and using new technologies like multithreading.\n",
        "* Here are some of the ways that CPU manufacturers are increasing performance without increasing clock speed:\n",
        "\n",
        "  * **Adding more cores.** A CPU with multiple cores can run multiple tasks at the same time, which can significantly improve performance.\n",
        "  * **Using multithreading.** Multithreading allows a single core to run multiple tasks by dividing each task into smaller parts that can be executed independently.\n",
        "  * **Using new technologies.** New technologies such as 3D stacking and chiplets are allowing CPU manufacturers to pack more transistors into a smaller space, which can improve performance without increasing clock speed.\n"
      ],
      "metadata": {
        "id": "TN3MLVdwSCzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zero power computing**:\n",
        "* a perfect fredkin gate doesnt cost energy! (Information theory & Entropy Limits) [How to Perform Calculations Using Zero Power](https://medium.com/hackernoon/zero-power-computing-how-to-perform-calculations-using-zero-power-e2b4bfcd4d7e).\n",
        "* **What costs the energy is not the computation itself, but‘s the raising information**. Take a look at this original Fredkin/Toffoli paper on the subject, section 5 (**nondissipative computation**): https://cqi.inf.usi.ch/qic/82_Fredkin.pdf.\n",
        "* Fredkin: 3 in 3 out, reversable?[Fredkin gate](https://www.wikiwand.com/en/Fredkin_gate). Stackexchange: [Why are reversible gates not used?](https://cs.stackexchange.com/questions/38049/why-are-reversible-gates-not-used/38053#38053).\n",
        "* Science: [A quantum Fredkin gate](https://www.science.org/doi/10.1126/sciadv.1501531). Paper: Thermodynamic [The Cost of computation](https://arxiv.org/abs/1905.05669).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7P8TyPKLSga0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *ALU and Processors*"
      ],
      "metadata": {
        "id": "GjKhUGg9zYhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So sortieren Prozessoren Befehle um\n",
        "Algorithmus des Monats\n",
        "Ohne Out-of-Order-Execution wären Prozessoren deutlich langsamer. Der grundlegende Algorithmus dazu ist über 50 Jahre alt – wir erklären, wie er funktioniert.\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Out-of-order_execution\n",
        "\n",
        "https://www.golem.de/specials/cpu/\n",
        "\n",
        "https://www.golem.de/specials/adm/"
      ],
      "metadata": {
        "id": "ML2jtqF1zpiE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Binär- und Terniärsysteme*"
      ],
      "metadata": {
        "id": "EOjTIfBF5mfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gleitkommazahl\n",
        "\n",
        "https://www.golem.de/news/bitnet-statt-gleitkommazahlen-forscher-versprechen-massive-effizienzsteigerung-bei-ki-2403-182763.html"
      ],
      "metadata": {
        "id": "Syy95Ocq5Ch3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FP8\n",
        "https://en.wikipedia.org/wiki/Minifloat\n",
        "\n",
        "half precision (sometimes called FP16 or float16)\n",
        "https://en.wikipedia.org/wiki/Half-precision_floating-point_format\n",
        "\n",
        "bfloat16 (brain floating point with 16 bits). In TPUs.\n",
        "https://de.wikipedia.org/wiki/Bfloat16\n",
        "\n",
        "Double-precision floating-point format (sometimes called FP64 or float64)\n",
        "https://en.wikipedia.org/wiki/Double-precision_floating-point_format\n",
        "\n",
        "Terniärsystem\n",
        "https://de.wikipedia.org/wiki/Tern%C3%A4rsystem\n",
        "\n",
        "https://en.wikipedia.org/wiki/Floating-point_arithmetic\n",
        "\n",
        "https://de.wikipedia.org/wiki/Gleitkommazahl"
      ],
      "metadata": {
        "id": "0vY8qYEH5lc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Special: Pre-electronic computing machines (why are we working with binary?)**\n",
        "- Greece: [Antikythera](https://de.m.wikipedia.org/wiki/Mechanismus_von_Antikythera) to predict solar esclipses\n",
        "- Charles Babbage and [Difference engine and Analytical Engine](https://de.m.wikipedia.org/wiki/Analytical_Engine)\n",
        "- Fur Dezimalsystem: kann man ein Mechanisches Zahnrad erstellen, zehn Zähne schleifen and jeweils equal distances apart um genau zu rechnen?\n",
        "- But Charles had complains from their gear cutters. He had to pay a lot, because manufacturing wasn’t advance at that time yet (no large-scale automation in manufacturing).\n",
        "- Later: electro-mechanical era of relays\n",
        "- Then: early electronic era (1930/40s): the first electronic logic elements. you talked about [thermionic valves (Röhrencomputer)](https://de.m.wikipedia.org/wiki/Röhrencomputer)\n",
        "    -  Röhrenrechner stellen den Übergang zwischen den [Analogrechnern](https://de.m.wikipedia.org/wiki/Analogrechner) (=Berechnungen mit Hilfe von kontinuierlichen mechanischen oder elektrischen Vorgängen) zu den auf [Halbleitertechnik](https://de.m.wikipedia.org/wiki/Halbleitertechnik) basierenden [Minirechnern](https://de.m.wikipedia.org/wiki/Minirechner) dar.\n",
        "- How they works: vacuum tubes as a logic element on and off. Cathode with boils off electrons and anode with a big voltage on it, sucking off the electrons up, and in the middle there is a grid. By putting a bias voltage on the grid. If you put a heavy negative voltage on the grid, it repelled the electrons back to the cathode plate and didn’t let them through. So you switched it off. But you needed heaters to boil the electrons off the cathode. Heaters, power consumption was huge.\n",
        "- One reason to use binary was that it’s perfect for the logic. They are simpler to build!\n",
        "- But: For decimal you need fewer digits (binary is a lot longer)\n",
        "- How many more circuitry and components do you need if you go for a binary computing than if you go for a decimal one (how many more digits we need?): log_2 10 = 3.322 (= you need 3.3 times as much binary circuitry if you did binary)\n",
        "    - e.g. how many bits do you need to represent 99 in binary?\n",
        "    - 8 bits = 256, 7 = 128. So 99 requires 7 bits\n",
        "    - Taking 99 in decimal are 2 bits, using the formula above: 2 x 3.322 = 6.644 ~ 7 bits\n",
        "- Alternaive approach in 1930s: bi-quinary: base 5 ([“Colossus”](https://de.m.wikipedia.org/wiki/Colossus))\n",
        "- [Why Use Binary? - Computerphile](https://www.youtube.com/watch?v=thrx3SBEpL8) by [Tommy Flowers](https://de.m.wikipedia.org/wiki/Tommy_Flowers)\n",
        "\n",
        "*Warum sind 8 Bit 1 Byte?*\n",
        "* Bit = Datentransferrate (Geschwindigkeit).\n",
        "* Byte = Speichergröße (Kapazität)\n",
        "* 1 Byte in Bits umgerechnet sind 8 Bits.\n",
        "* 1 Byte kann somit 2^8 (256 Bits) verschiedene Zustände darstellen. Somit ist 1 Byte meist die kleinste, adressierbare Speichereinheit, um Zeichen wie einen Buchstaben abzubilden."
      ],
      "metadata": {
        "id": "jVPHK8KmrZTr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *GPUs*"
      ],
      "metadata": {
        "id": "zXJ4KIadIPuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Sparsity: https://www.golem.de/news/sparsity-erklaert-wie-ki-beschleuniger-ihre-rechenleistung-vervielfachen-2312-180480.html"
      ],
      "metadata": {
        "id": "RvXK0nhfw1aM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matrix Multiplication on Classical Computers**\n",
        "\n",
        "Video 1: [How do GPUs speed up Neural Network training?](https://www.youtube.com/watch?v=EKD1kEMNeeU&list=WL&index=27)\n",
        "\n",
        "Video 2: [EE5332 L11.3 - Matrix Multiplication on NVidia GPUs](https://www.youtube.com/watch?v=fpwq5zDBO2o&list=WL&index=28&t=362s)\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1633.png)\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1634.png)\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1635.png)\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1636.png)\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1637.png)\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1638.png)"
      ],
      "metadata": {
        "id": "ZZPqdWX4RiZ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *TPU*"
      ],
      "metadata": {
        "id": "5_P1_6vvyHEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.golem.de/news/google-erklaert-tpu-v4-ki-supercomputer-mit-flexiblem-optischen-netz-2304-173234.html"
      ],
      "metadata": {
        "id": "-cTeexksHl6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/tpu/docs/run-calculation-jax?hl=de"
      ],
      "metadata": {
        "id": "eXiNo4uuyNa5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/tpu/docs/run-calculation-tensorflow?hl=en"
      ],
      "metadata": {
        "id": "AfVnmi1cGDEb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TPUs\n",
        "\n",
        "Distributive linear algebra system for TPUs (tensor contraction engine)\n",
        "\n",
        "Mammals: write a couple can them routines, > Guifre\n",
        "\n",
        "Not a lot of money in comp chemistry, not much spent\n",
        "\n",
        "10 engineers necessary (2 months ago), we couldn’t find someone in google 3 to take over the repo\n",
        "\n",
        "Gas research , reports mike o Brenner , bifrost called, they took over.\n",
        "\n",
        "No production level support for com them on TPUs\n",
        "\n",
        "3 Mio\n",
        "\n",
        "Electronic structure in general in hardware acceptors, quan chem through JAX\n",
        "\n",
        "Customer needs to challengers:\n",
        "- on paper good for physcaosiimualtion\n",
        "- Everything is at half precision, going to double precision is 11x slow down\n",
        "- Savings grace at TPUs is memory, but 10x slow down is bad\n",
        "- Very good theoretical chemist\n",
        "- qNumeric from Nvidia, sophistic knowledge of JAX (but many bugs)\n",
        "- Distributed memory model is other problem: you need to have acid with distributed generation what you want to multiply, have an engine that does tensor contraction, we have something , but JAX internal, at least a year to go public by this team\n",
        "- Also they are very expensive, some cases cost 50 bucks sin physical simulation: that’s the benchmark. Accelerates SCF on GPU to density fitting type generation, into jam operations one after the other. You fron load operations, no commutation of integrals anymore. There aren’t any codes you can go and buy this.\n",
        "- Split operator for nonlinear wave equation (FFT, inverse FFT) maybe (Vincent) - mostly toy examples.\n",
        "- weather: PDE operations recently implemented , c2 engine\n",
        "- Largest matrix to decompose on latest TPU (eigenvalues): TPUs don’t use Egenvalues thesmselv, aj oeprations and then matrix decompsion (QR), here comes qubic over n comes from. Efficiently use it, put terabyte of data, MPI code stream in in distributed fashion, every second terabyte of data\n",
        "- ML models for chemistry it’s more interesting you can get away with single precision, or deep minds paper for cohn sham potential where you can use single precision enough (deepmind 21), https://www.deepmind.com/blog/simulating-matter-on-the-quantum-scale-with-ai\n",
        "- For JAX version 6 TPUs: double precision still not part (next 4-5 years not yet probably, also not easy)\n",
        "- Get close enough with TPU as an initial condition /rough estimate: metals: starting with single precision and finishing with double is not possible. Some say it’s possible for others. Tough call.\n",
        "- Nick focuses on DFT and ML problems in chemistry with TPU\n",
        "- ——\n",
        "\n",
        "Discussion with qsimulate  \n"
      ],
      "metadata": {
        "id": "NaxZA7kVmUhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *HPC*"
      ],
      "metadata": {
        "id": "HPFi-nppjRQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.pcgameshardware.de/Hardware-Thema-130320/News/Jupiter-Deutscher-Exascalerechner-Nvidia-Technik-staerkster-KI-Supercomputer-1439199/"
      ],
      "metadata": {
        "id": "i7Aj2l5ejT_H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FPGA HPC refers to the use of Field Programmable Gate Arrays (FPGAs) in High-Performance Computing (HPC) environments to accelerate computationally demanding tasks. Here's a breakdown of the concept:\n",
        "\n",
        "**What are FPGAs?**\n",
        "\n",
        "* FPGAs are reconfigurable semiconductor devices containing arrays of programmable logic blocks and interconnects.\n",
        "* Unlike CPUs or GPUs that have fixed architectures, FPGAs can be reprogrammed on-the-fly to create custom hardware circuits tailored to specific algorithms.\n",
        "\n",
        "**Why FPGAs for HPC?**\n",
        "\n",
        "FPGAs offer several advantages in the HPC domain:\n",
        "\n",
        "* **Customization:** FPGAs can implement the exact hardware structures needed for an algorithm, leading to highly optimized and efficient execution.\n",
        "* **Energy Efficiency:** For certain types of computations, FPGAs can be much more energy-efficient than CPUs or GPUs, reducing the power footprint of large HPC systems.\n",
        "* **Low Latency:** The customizable nature of FPGAs allows for ultra-low latency data processing, crucial in real-time HPC applications.\n",
        "* **Flexibility:** FPGAs can be reprogrammed for different algorithms or updated with evolving computational needs, providing flexibility in HPC infrastructure.\n",
        "\n",
        "**Typical Use Cases of FPGA HPC**\n",
        "\n",
        "* **Scientific Simulations:**  Simulations in physics, chemistry, biology, fluid dynamics, and other fields can be accelerated by creating hardware implementations of compute-heavy mathematical models.\n",
        "* **Financial Computing:** FPGA acceleration is used in risk analysis, option pricing, and algorithmic trading, where low latency and complex computations are key.\n",
        "* **Genomics:**  Analysis of DNA sequences for pattern recognition and alignment tasks can  benefit significantly from FPGA hardware acceleration.\n",
        "* **Machine Learning:**  Some machine learning inference tasks can be efficiently offloaded to FPGAs, especially in edge or embedded computing settings with power constraints.\n",
        "* **Image and Video Processing:**  Real-time video analytics, image enhancement, and computer vision algorithms can see large speedups from FPGA implementations.\n",
        "\n",
        "**Challenges and Considerations**\n",
        "\n",
        "* **Programming Complexity:** Programming FPGAs typically requires specialized hardware design languages (like Verilog or VHDL) which have a steeper learning curve than traditional software programming.\n",
        "* **Integration:** Integrating FPGAs into existing HPC systems can require expertise in both hardware and software design.\n",
        "\n",
        "**The increasing utilization of FPGAs in HPC reflects the evolving needs of computationally intensive applications. If you have specific applications in mind, I'd be happy to discuss their potential suitability for FPGA acceleration!**\n"
      ],
      "metadata": {
        "id": "yTQmZhbAt-5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**is there a connection between FPGA and quantum computing?**\n",
        "\n",
        "Yes, there's a strong connection between FPGA and quantum computing in several key areas:\n",
        "\n",
        "1. **Control and Measurement Systems:**\n",
        "\n",
        "   * **Complex Control:** Quantum computers require precise control of qubits, which involves generating precise waveforms, timing signals, and feedback mechanisms. FPGAs, due to their reconfigurability and high-speed signal processing, are ideal for implementing these complex control systems.\n",
        "   * **Data Acquisition:**  The measurement data from quantum experiments needs to be acquired, digitized, and processed rapidly. FPGAs excel at  real-time signal processing, making them invaluable in handling measurement outputs from quantum systems.\n",
        "\n",
        "2. **Classical Computation Acceleration:**\n",
        "\n",
        "   * **Hybrid Algorithms:** Many quantum algorithms involve a mix of classical and quantum computations. FPGAs can speed up the classical components of these algorithms, improving the overall execution time and efficiency.\n",
        "   * **Pre/Post-Processing:** Data preparation before an algorithm runs on a quantum processor, and result processing afterward, can often be offloaded to FPGAs for better performance.\n",
        "\n",
        "3. **Quantum Circuit Simulation:**\n",
        "\n",
        "   * **Emulation:** Large-scale quantum circuit simulations are essential to test and optimize quantum algorithms before running on actual hardware. The customizable nature of FPGAs allows researchers to emulate quantum systems on a smaller scale, accelerating the design cycle.\n",
        "\n",
        "4. **Quantum Error Correction:**\n",
        "\n",
        "   * **Decoding Algorithms:** Quantum error correction schemes involve iterative decoding algorithms that can be computationally intensive. FPGAs offer the potential to implement these decoding algorithms with high speed and efficiency, facilitating real-time error correction.\n",
        "\n",
        "5. **Research and Prototyping:**\n",
        "\n",
        "  * **Flexibility:** The reprogrammability of FPGAs makes them well-suited for research environments where rapid prototyping and exploration of different control and measurement systems for quantum devices is crucial.\n",
        "\n",
        "**Examples:**\n",
        "\n",
        "* **Quantum control systems from companies like Quantum Machines and Zurich Instruments heavily use FPGAs for managing quantum experiments.**\n",
        "* **Projects like QubiC: [https://arxiv.org/pdf/2101.00071](https://arxiv.org/pdf/2101.00071) demonstrate entire FPGA-based control and measurement frameworks for quantum computing.**\n",
        "\n",
        "**The Bottom Line:**  FPGAs are vital in the development and operation of quantum computers. They play a pivotal role in overcoming control challenges, accelerating algorithm execution, and facilitating research breakthroughs.\n"
      ],
      "metadata": {
        "id": "9awT4YWvutQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *FLOPS*"
      ],
      "metadata": {
        "id": "gPeePps2begU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eine derart gigantische Simulation konnte nur mit entsprechender Rechenleistung bewältigt werden, die der Supercomputer HPE SGI ICE XA (Cheyenne) dankenswerterweise zur Verfügung gestellt hat.\n",
        "* **Mit 145.152 Prozessoren, 40 Petabyte Speicherplatz und insgesamt 5,3 Petaflops** waren die nötigen Modellierungen realisierbar. Und die detaillierten Ergebnisse sind beachtenswert.\n",
        "\n",
        "https://www.notebookcheck.com/Aufforstung-kein-Allheilmittel-Waelder-mit-komplexem-Einfluss-auf-Klima-und-Umwelt.807845.0.html"
      ],
      "metadata": {
        "id": "0ycT8U37bhB6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Distributed Training*"
      ],
      "metadata": {
        "id": "uM9V1BBQGHTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=NbID_AqdZXM"
      ],
      "metadata": {
        "id": "i4DIXwcbHFVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=S1tN9a4Proc"
      ],
      "metadata": {
        "id": "ZJ7hEebdHDXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/guide/distributed_training"
      ],
      "metadata": {
        "id": "tiCklVoxGoFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/guide/keras/distributed_training"
      ],
      "metadata": {
        "id": "BmRIRKb9G3yA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/tutorials/distribute/keras"
      ],
      "metadata": {
        "id": "VA8BRTjDHArx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Quantum Libraries*"
      ],
      "metadata": {
        "id": "crQgUFkRk-XB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Qualtran**\n",
        "\n",
        "https://github.com/quantumlib/Qualtran/blob/main/qualtran/surface_code/magic_state_factory.py\n",
        "\n",
        "https://github.com/quantumlib/Qualtran/tree/main/qualtran"
      ],
      "metadata": {
        "id": "K-VJ5ea6lArD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QuTip**\n",
        "\n",
        "https://qutip.org/qutip-tutorials/#visualizations\n",
        "\n",
        "https://nbviewer.org/urls/qutip.org/qutip-tutorials/tutorials-v4/visualization/bloch_sphere_with_colorbar.ipynb"
      ],
      "metadata": {
        "id": "lCeP13HblFCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QubiC**\n",
        "\n",
        "An open source FPGA-based control and measurement system for superconducting quantum information processors, https://arxiv.org/pdf/2101.00071.pdf"
      ],
      "metadata": {
        "id": "UVy4V3ayu4Hc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Speichersichere Programmiersprachen*"
      ],
      "metadata": {
        "id": "6uUn645o-PmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://m.winfuture.de/news/141447\n",
        "\n",
        "* Konkret hat das White House Office of the National Cyber Director (ONCD) einen Bericht (PDF) veröffentlicht (via Infoworld), in dem man Entwicklern nahelegt, \"speichersichere Programmiersprachen\" zu verwenden - und dazu zählen C und C++ eben nicht. Laut ONCD können IT-Unternehmen mit der Einführung speichersicherer Programmiersprachen verhindern, \"dass ganze Klassen von Schwachstellen in das digitale Ökosystem eindringen\".\n",
        "\n",
        "* Der Begriff bezieht sich auf Fehler und Schwachstellen bzw. deren Schutz, die den Speicherzugriff betreffen, dazu zählen **Buffer Overflows, Out-of-Bound-Reads und Memory Leaks**. Mit dieser Meinung ist das Weiße Haus auch nicht alleine, da auch Microsoft und Google in Studien festgestellt haben, dass rund 70 Prozent aller Schwachstellen auf das Konto von Speicherproblemen zurückgehen.\n",
        "\n",
        "* [Laut der National Security Agency (NSA)](https://m.winfuture.de/news/132951) werden folgende Programmiersprachen als \"Memory-Safe\" bzw. sicher eingestuft:\n",
        "Rust\n",
        "Go\n",
        "C#\n",
        "Java\n",
        "Swift\n",
        "JavaScript\n",
        "Ruby"
      ],
      "metadata": {
        "id": "xUdNWhEP-ShT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *JAX*"
      ],
      "metadata": {
        "id": "EkdQBmsWyXyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://jax.readthedocs.io/en/latest/jax-101/index.html"
      ],
      "metadata": {
        "id": "TyH5oxOchjqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://jax.readthedocs.io/en/latest/notebooks/quickstart.html"
      ],
      "metadata": {
        "id": "MNTTlgnLyXBm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html"
      ],
      "metadata": {
        "id": "sKF2rI6NhaHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Linux*"
      ],
      "metadata": {
        "id": "NpX_msD1vmi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.digitalocean.com/community/tutorials/linux-commands"
      ],
      "metadata": {
        "id": "D1N-de6GwqUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ls - The most frequently used command in Linux to list directories\n",
        "* pwd - Print working directory command in Linux\n",
        "* cd - Linux command to navigate through directories\n",
        "* mkdir - Command used to create directories in Linux\n",
        "* mv - Move or rename files in Linux\n",
        "* cp - Similar usage as mv but for copying files in Linux\n",
        "* rm - Delete files or directories\n",
        "* touch - Create blank/empty files\n",
        "* ln - Create symbolic links (shortcuts) to other files\n",
        "* cat - Display file contents on the terminal\n",
        "* clear - Clear the terminal display\n",
        "* echo - Print any text that follows the command\n",
        "* less - Linux command to display paged outputs in the terminal\n",
        "* man - Access manual pages for all Linux commands\n",
        "* uname - Linux command to get basic information about the OS\n",
        "* whoami - Get the active username\n",
        "* tar - Command to extract and compress files in Linux\n",
        "* grep - Search for a string within an output\n",
        "* head - Return the specified number of lines from the top\n",
        "* ail - Return the specified number of lines from the bottom\n",
        "* diff - Find the difference between two files\n",
        "* cmp - Allows you to check if two files are identical\n",
        "* comm - Combines the functionality of diff and cmp\n",
        "* sort - Linux command to sort the content of a file while outputting\n",
        "* export - Export environment variables in Linux\n",
        "* zip - Zip files in Linux\n",
        "* unzip - Unzip files in Linux\n",
        "* ssh - Secure Shell command in Linux\n",
        "* service - Linux command to start and stop services\n",
        "* ps - Display active processes\n",
        "* kill and killall - Kill active processes by process ID or name\n",
        "* df - Display disk filesystem information\n",
        "* mount - Mount file systems in Linux\n",
        "* chmod - Command to change file permissions\n",
        "* chown - Command for granting ownership of files or folders\n",
        "* ifconfig - Display network interfaces and IP addresses\n",
        "* traceroute - Trace all the network hops to reach the destination\n",
        "* wget - Direct download files from the internet\n",
        "* ufw - Firewall command\n",
        "* iptables - Base firewall for all other firewall utilities to interface with\n",
        "* apt, pacman, yum, rpm - Package managers depending on the distro\n",
        "* sudo - Command to escalate privileges in Linux\n",
        "* cal - View a command-line calendar\n",
        "* alias - Create custom shortcuts for your regularly used commands\n",
        "* dd - Majorly used for creating bootable USB sticks\n",
        "* whereis - Locate the binary, source, and manual pages for a command\n",
        "* whatis - Find what a command is used for\n",
        "* top - View active processes live with their system usage\n",
        "* useradd and usermod - Add new user or change existing users data\n",
        "* passwd - Create or update passwords for existing users"
      ],
      "metadata": {
        "id": "uO0J0iBAwjsG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Python*"
      ],
      "metadata": {
        "id": "-bgPYHGr1kCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For (Loop)**"
      ],
      "metadata": {
        "id": "bHxVacZSzNRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute n^3\n",
        "\n",
        "example_list = [1,4,9]\n",
        "cube_list = []\n",
        "\n",
        "for value in example_list:\n",
        "    cube_list.append(value**3)\n",
        "\n",
        "print(cube_list)"
      ],
      "metadata": {
        "id": "HEOrl3Il0Y-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3068cf41-07be-4f60-968d-ffca9b658a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 64, 729]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Range**\n",
        "\n",
        "https://www.freecodecamp.org/news/python-for-loop-for-i-in-range-example/"
      ],
      "metadata": {
        "id": "axn8EIN20d2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(6):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9JzPC-Xzf8L",
        "outputId": "dd541f76-1c0c-4c6e-e316-0fe38a849606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,6,2): # Start, Stop, Steps\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T76OMRBtzjHJ",
        "outputId": "5b5fdd74-eb6c-4466-ed24-6bdec39359e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "2\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Now outsource one value to get generic function:*"
      ],
      "metadata": {
        "id": "y1phzBwszy2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_function(x):\n",
        "  for i in range(0,x,2): # Start, Stop, Steps\n",
        "    print(i)\n",
        "\n",
        "x = 10\n",
        "my_function(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMM3qKJyOFqF",
        "outputId": "802138dc-c551-4c3d-e85e-483749ee6862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "2\n",
            "4\n",
            "6\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**While** (Loop)\n",
        "\n",
        "* while = as long as: *While Loop (simplest loop): is given a condition, and executes the loop until the condition is false. (If the condition is false, it does nothing.)*\n",
        "\n",
        "* https://www.w3schools.com/python/python_while_loops.asp\n"
      ],
      "metadata": {
        "id": "D3C3Frwh0FU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Berechne den Restwert in der Modulurechnung\n",
        "\n",
        "# Setup Variables\n",
        "modulus = 51 # moduland\n",
        "modulo = 7\n",
        "\n",
        "# Compute Modulus\n",
        "while modulus > modulo:\n",
        "    modulus = modulus - modulo\n",
        "\n",
        "# Show Restwert\n",
        "print(modulus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vhM4pD40A0K",
        "outputId": "e519a1bd-437f-49d1-f054-60564d4186f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Break**\n",
        "\n",
        "*Break escapes the current loop, and moves on after it. This is mostly used for searching for particular values - iterating until something happens.*"
      ],
      "metadata": {
        "id": "IYhDJ4SI0tBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "  if i==5:\n",
        "    break\n",
        "print(i)"
      ],
      "metadata": {
        "id": "65DXNSnQ0n0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Else** (Rekursion)\n",
        "\n",
        "*It is a better pattern than while loops for high intensity computing because of your easy ability to set an upper limit for loop length. But if the calculation fails, you need a way to determine it: fortunately, for supports an else clause which triggers if and only if the loop exists without hitting a break statement.*"
      ],
      "metadata": {
        "id": "HFsqRuLw053E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 101\n",
        "\n",
        "for i in range(100):\n",
        "  if i==n:\n",
        "    break\n",
        "else:\n",
        "  print(\"Unable to find\" + str(n))\n",
        "\n",
        "print(i)"
      ],
      "metadata": {
        "id": "PSva2CdA09cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Continue**\n",
        "\n",
        "*Break only breaks out of the closest loop. There is no way to easily break out of a higher loop just using break. Continue works similarly, but instead of escaping the loop, it starts the next iteration immediately. This is great for discarding cases, and is a common task in the algorithm:*"
      ],
      "metadata": {
        "id": "49wpgaI61FV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  if i==5:\n",
        "    continue\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "L03w27k71Gov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7fd5a1f-52be-480a-d4e9-13cf6d27189a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# != means not equal\n",
        "# i%3 means\n",
        "# Restwerte berechnen in Modulo hiermit: 51%7\n",
        "# \\leq means ≤, so less than or equal to ..\n",
        "\n",
        "for i in range(10):\n",
        "  if i%3 != i%2:\n",
        "    continue\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "od2pk8MN1VGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Print and Return**\n",
        "\n",
        "* Return keeps value\n",
        "\n",
        "* [More about print statement](https://realpython.com/python-print/#printing-in-a-nutshell)"
      ],
      "metadata": {
        "id": "NjmO1Y-0zJyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Flow Control: Conditionals**"
      ],
      "metadata": {
        "id": "tJqcIKCr3Dss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=3\n",
        "if x>10:\n",
        "    print(\"x is big.\")\n",
        "if x<= 10:\n",
        "    print(\"x is small.\")"
      ],
      "metadata": {
        "id": "wGXplj2U3Eh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=3\n",
        "if x>10:\n",
        "    print(\"x is big.\")\n",
        "elif x>0:\n",
        "    print(\"x is small.\")\n",
        "else:\n",
        "    print(\"x is not positive.\")"
      ],
      "metadata": {
        "id": "TwrTdspJ3IqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yield**\n",
        "\n",
        "* Generators: like yield: https://www.python-kurs.eu/generatoren.php\n",
        "\n",
        "* there is one reason we must bring them up; you cannot create tuples with a comprehension directly; they instead create a generator.\n",
        "\n",
        "* You can think of generators as single-use lists. This makes them considerably faster, and with a lower memory footprint, in many use cases. We have already talked about a few generators - in Python 3, range is a generator.\n",
        "\n",
        "* These can be used as arguments without the enclosing. For example, you could construct a string containing the integers with:"
      ],
      "metadata": {
        "id": "aOjvMkgg3iWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fibonacci(n):\n",
        "    \"\"\"Ein Fibonacci-Zahlen-Generator\"\"\"\n",
        "    a, b, counter = 0, 1, 0\n",
        "    while True:\n",
        "        if (counter > n): return\n",
        "        yield a\n",
        "        a, b = b, a + b\n",
        "        counter += 1\n",
        "f = fibonacci(5)\n",
        "for x in f:\n",
        "  print x,\n",
        "print"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "Sz47xQO936wm",
        "outputId": "21a1c7b8-a0ef-416d-d51c-4c5a910d3614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-fb5705716190>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    print x\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(x)?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def firstn(g, n):\n",
        "\tfor i in range(n):\n",
        "\t\tyield g.next()\n",
        "\n",
        "\n",
        "firstn(5, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUCdS4iv5iXL",
        "outputId": "8f79513d-6a67-47cf-8473-516cc3d7c2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object firstn at 0x7f162b6846d0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.python-kurs.eu/generatoren.php"
      ],
      "metadata": {
        "id": "3-kxvfnn5TZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Enumerate** (Aufzählen)\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Enumeration\n",
        "\n",
        "* https://realpython.com/python-enumerate/"
      ],
      "metadata": {
        "id": "oaYQE4Q23jMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "values = [\"a\", \"b\", \"c\"]\n",
        "for count, value in enumerate(values):\n",
        "  print(count, value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5FfJ9pf4hzk",
        "outputId": "7db098ae-d0c5-4de9-c8dc-822c59db9384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 a\n",
            "1 b\n",
            "2 c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Miscellaneous**"
      ],
      "metadata": {
        "id": "hkDgUCb546zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 10\n",
        "a += 5\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpKfGQeX46UN",
        "outputId": "2298cd82-0f47-4b44-a6cf-afa98c889f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Functions in Maths & Physics I (Def)**"
      ],
      "metadata": {
        "id": "fLMArogly99J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.w3schools.com/python/python_functions.asp\n",
        "\n",
        "http://www-personal.umich.edu/~mejn/computational-physics/"
      ],
      "metadata": {
        "id": "w_B7I77I6aKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_function(x):\n",
        "  return x + 2\n",
        "\n",
        "my_function(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdyUIe0tK7O8",
        "outputId": "b4df5afd-c957-4444-ffe2-4cb99a548dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_function(x):\n",
        "  for i in range(1,x):\n",
        "    print(i**2)\n",
        "\n",
        "my_function(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUCfTgihCl9v",
        "outputId": "ea876fcd-2cca-4912-c05d-eee817785753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "4\n",
            "9\n",
            "16\n",
            "25\n",
            "36\n",
            "49\n",
            "64\n",
            "81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def isqrt(n):\n",
        "  return int(math.sqrt(n))\n",
        "\n",
        "n = 100\n",
        "isqrt(n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjS5fc4C2UMM",
        "outputId": "c78c2f48-21f9-43ce-c03d-b6acda0c8392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_function(n):\n",
        "  if n = (1):\n",
        "    return 1,\n",
        "  else:\n",
        "    return alg2d(n-1) + n\n",
        "\n",
        "alg2d(3)"
      ],
      "metadata": {
        "id": "ZkLNDfQ99hSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_function(x):\n",
        "  return 5 * x\n",
        "\n",
        "print(my_function(3))\n",
        "print(my_function(5))\n",
        "print(my_function(9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgVKnVjc7o4u",
        "outputId": "6b9b66cc-90c4-40b5-eb37-b31084f93ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "25\n",
            "45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def selectionsort(seq):\n",
        "  for i in range(len(seq) - 1):\n",
        "    k = i\n",
        "    for j in range(i, len(seq)):\n",
        "      if seq[j] < seq[k]:\n",
        "        k = j\n",
        "    seq[i], seq[k] = seq[k], seq[i]\n",
        "\n",
        "result = selectionsort([1, 3, 5, 2, 4])\n",
        "result"
      ],
      "metadata": {
        "id": "qs_2cqJU8Ifu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def function(input):\n",
        "  for i in range(len(input) + 1):\n",
        "\n",
        "function([1, 2, 4])"
      ],
      "metadata": {
        "id": "BCUcl2Yf7vwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the Fibonacci numbers up to 1000\n",
        "f1,f2 = 1,1\n",
        "while f2<1000:\n",
        "    print(f2)\n",
        "    f1,f2 = f2,f1+f2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqI9EP3s68wt",
        "outputId": "24c3f412-b883-49c1-f4f7-6a77bcd51f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "5\n",
            "8\n",
            "13\n",
            "21\n",
            "34\n",
            "55\n",
            "89\n",
            "144\n",
            "233\n",
            "377\n",
            "610\n",
            "987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the wavelengths of hydrogen lines\n",
        "R = 1.097e-2\n",
        "for m in range(1,4):\n",
        "    print(\"Series for m =\",m)\n",
        "    for n in range(m+1,m+6):\n",
        "        invlambda = R*(1/m**2-1/n**2)\n",
        "        print(\"  \",1/invlambda,\"nm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA7mkKRZ8fcy",
        "outputId": "589eb076-750b-48c0-f174-875a916d72c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series for m = 1\n",
            "   121.5436037678517 nm\n",
            "   102.55241567912488 nm\n",
            "   97.23488301428137 nm\n",
            "   94.95594044363415 nm\n",
            "   93.76220862091418 nm\n",
            "Series for m = 2\n",
            "   656.3354603463993 nm\n",
            "   486.1744150714068 nm\n",
            "   434.084299170899 nm\n",
            "   410.2096627164995 nm\n",
            "   397.04243897498225 nm\n",
            "Series for m = 3\n",
            "   1875.2441724182836 nm\n",
            "   1281.9051959890612 nm\n",
            "   1093.8924339106654 nm\n",
            "   1005.013673655424 nm\n",
            "   954.6697605038536 nm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the internal energy of a quantum simple harmonic oscillator at temperature T\n",
        "from math import exp\n",
        "\n",
        "terms = 1000\n",
        "beta = 1/100\n",
        "S = 0.0\n",
        "Z = 0.0\n",
        "for n in range(terms):\n",
        "    E = n + 0.5\n",
        "    weight = exp(-beta*E)\n",
        "    S += weight*E\n",
        "    Z += weight\n",
        "\n",
        "print(S/Z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr3JAICQ7I80",
        "outputId": "835890b7-3433-4fee-e584-8bd48e8d10ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99.95543134093475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_5():\n",
        "  for i in range(100):\n",
        "    for j in range(20):\n",
        "      if i == 5:\n",
        "        return i\n",
        "  print(\"Couldn't find 5.\")"
      ],
      "metadata": {
        "id": "7p_dm_Bi1iOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def natural_language(message):\n",
        "    print(message)\n",
        "\n",
        "message = \"Hello World\"\n",
        "natural_language(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDLQQt7E2IeL",
        "outputId": "1cdaf4c1-bc75-4bbd-e1ff-a68eac58c8f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Functions in Maths & Physics II (Class)**"
      ],
      "metadata": {
        "id": "xEP2z9S719Ep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Video: Methoden in Klassen](https://www.youtube.com/watch?v=58IjjwHs_4A)"
      ],
      "metadata": {
        "id": "aBZdbhCcFgF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tweet:\n",
        "  def __init__(self):\n",
        "    print('Hi')\n",
        "\n",
        "result = Tweet()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq8z1hDi18sH",
        "outputId": "a5330983-f9ae-4e1f-9e6d-45e9a5ed0b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class and function / self is referring to the instances below\n",
        "class Tweet:\n",
        "  def __init__(self, message):\n",
        "    self.x = message\n",
        "\n",
        "# Define messages (instances)\n",
        "a = Tweet('Hello 42')\n",
        "b = Tweet('Hello 88')\n",
        "\n",
        "# Call messages\n",
        "print('a is ' + a.x)\n",
        "print('b is ' + b.x)"
      ],
      "metadata": {
        "id": "mZqS96oX2gLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class and function\n",
        "class Tweet:\n",
        "  def __init__(self, message):\n",
        "    self.message = message\n",
        "  def print_tweet(self):\n",
        "    print(self.message)\n",
        "\n",
        "# Define messages (objects?)\n",
        "c = Tweet('Hello 100')\n",
        "\n",
        "# Call messages\n",
        "c.print_tweet()"
      ],
      "metadata": {
        "id": "5PpAf4es2hmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Car():\n",
        "\n",
        "    # init method or constructor\n",
        "    # (these are not functions, because functions have no self and also within class they are called methods)\n",
        "    def __init__(self, model, color):\n",
        "        self.model = model\n",
        "        self.color = color\n",
        "\n",
        "    def show(self):\n",
        "        print(\"Model is\", self.model )\n",
        "        print(\"color is\", self.color )\n",
        "\n",
        "# both objects have different self which\n",
        "# contain their attributes\n",
        "audi = Car(\"audi a4\", \"blue\")\n",
        "ferrari = Car(\"ferrari 488\", \"green\")\n",
        "\n",
        "audi.show()     # same output as car.show(audi)\n",
        "ferrari.show()  # same output as car.show(ferrari)\n",
        "\n",
        "# Behind the scene, in every instance method\n",
        "# call, python sends the instances also with\n",
        "# that method call like car.show(audi)"
      ],
      "metadata": {
        "id": "y0r0UEgi2kB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "self parameter: https://www.youtube.com/watch?v=CLoK-_qNTnU\n",
        "\n",
        "klassen und objekte: https://www.youtube.com/watch?v=XxCZrT7Z3G4\n",
        "\n",
        "methoden: https://www.youtube.com/watch?v=58IjjwHs_4A"
      ],
      "metadata": {
        "id": "cSeBZR6g2mU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization of Functions**"
      ],
      "metadata": {
        "id": "DSkCPO-97ZAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://scriptverse.academy/tutorials/python-matplotlib-plot-function.html"
      ],
      "metadata": {
        "id": "y1ALPQD18XwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize':(10, 6), \"lines.linewidth\": 1.0})\n",
        "\n",
        "# 100 linearly spaced numbers\n",
        "x = np.linspace(0,10,10)\n",
        "\n",
        "# the function\n",
        "y = x**2\n",
        "\n",
        "# setting the axes at the centre\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.xaxis.set_ticks_position('bottom')\n",
        "ax.yaxis.set_ticks_position('left')\n",
        "\n",
        "# plot the function\n",
        "#plt.plot(x,y, 'g')\n",
        "plt.plot(x,y, 'b', label='y=sin(x)')\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cbiVzNHZDJmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize':(10, 6), \"lines.linewidth\": 1.0})\n",
        "\n",
        "\n",
        "# 100 linearly spaced numbers\n",
        "x = np.linspace(0,1,100)\n",
        "x = np.linspace(-np.pi,np.pi,100)\n",
        "\n",
        "# the function\n",
        "y = x**20\n",
        "y = np.sin(x)\n",
        "\n",
        "# setting the axes at the centre\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.xaxis.set_ticks_position('bottom')\n",
        "ax.yaxis.set_ticks_position('left')\n",
        "\n",
        "# plot the function\n",
        "#plt.plot(x,y, 'g')\n",
        "plt.plot(x,y, 'b', label='y=sin(x)')\n",
        "plt.plot(x,2*y, 'c', label='y=2sin(x)')\n",
        "plt.plot(x,3*y, 'r', label='y=3sin(x)')\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "8JuGtYMGPwpx",
        "outputId": "abc363b7-cec6-4d43-df48-94aa3acdb440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 100 linearly spaced numbers\n",
        "x = np.linspace(-5,5,100)\n",
        "\n",
        "# the function, which is y = x^3 here\n",
        "y = x**2\n",
        "y = np.exp(x)\n",
        "\n",
        "# setting the axes at the centre\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.spines['left'].set_position('center')\n",
        "ax.spines['bottom'].set_position('center')\n",
        "ax.spines['right'].set_color('none')\n",
        "ax.spines['top'].set_color('none')\n",
        "ax.xaxis.set_ticks_position('bottom')\n",
        "ax.yaxis.set_ticks_position('left')\n",
        "\n",
        "# plot the function\n",
        "plt.plot(x,y, 'g')\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "Rt99Vbv1OmFX",
        "outputId": "7394fe92-6469-4dd6-b58b-b53bd63b0009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vFQCvRyaxKAR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Foundation Model*"
      ],
      "metadata": {
        "id": "86rBYa_u4urx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A foundation model development cheatsheet, from foundation model developers.\n",
        "\n",
        "The folks over at EleutherAI, in collaboration with MIT, AI2, HuggingFace, Stanford, Princeton, and more, have released the foundation model development cheatsheet, a quick-start guide to familiarize new developers with useful tools and resources for developing new open models.\n",
        "\n",
        "You can use it to easily find, for example, pre-training data sources, tools and frameworks for data preparation, model training, model evaluation, and more.\n",
        "\n",
        "This is a great initiative aligned with EleutherAI's mission to lower barriers to entry of research and development of foundation models.\n",
        "\n",
        "Cheat sheet (interactive): https://fmcheatsheet.org/\n",
        "Github repo: https://lnkd.in/dSDkbY-K\n",
        "Paper: https://lnkd.in/d5DRns4i\n",
        "Blog: https://lnkd.in/dg4drU_3"
      ],
      "metadata": {
        "id": "E433hvia4xsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Finetune LLMs*"
      ],
      "metadata": {
        "id": "JgPN5UHup5lH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mixer of Experts(MOE) — Modern architecture for divide and concur learning\n",
        "\n",
        "https://medium.com/@sthanikamsanthosh1994/the-mixer-of-experts-moe-modern-architecture-for-divide-and-concur-learning-dbe10ffa8436"
      ],
      "metadata": {
        "id": "_J_MRflWh0Je"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Overview*"
      ],
      "metadata": {
        "id": "CBU1tb4vs16v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1704.png)"
      ],
      "metadata": {
        "id": "2WTi1ggcqbc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Finetuning LLMs*\n",
        "\n",
        "* Supervised\n",
        "* RLHF\n",
        "* Distillation\n",
        "* deprecated: Parameter-Efficient Fine-Tuning using PEFT: https://arxiv.org/abs/2312.12148\n",
        "* pending (?): Lora and QLora\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2023/08/fine-tuning-large-language-models/\n",
        "\n",
        "https://www.deeplearning.ai/short-courses/finetuning-large-language-models/"
      ],
      "metadata": {
        "id": "XEjwjS3Lsp2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Parameter efficient Turning (PEFT)*"
      ],
      "metadata": {
        "id": "WikX85R-r4I2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-text-models-supervised"
      ],
      "metadata": {
        "id": "TqEuagbhr7fP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* This is a good primer go/parameter-efficient-tuning-primer\n",
        "* what I didn't get very well is why the candidate related int-8 with LoRA tuning\n",
        "* for hosting on CPU\n",
        "* I think the candidate mixed-up things\n",
        "* LoRA tuning is to do fine-tuning efficiently by just changing some of the weights inside the model. The amount of weights to change is decided by its rank, currently in Vertex we only offer rank 1, but this is hidden. OpenAI offers a way larger rank, and it's more powerful\n",
        "* there's QLoRA as well for quantized models.\n",
        "* What actually reduces memory is quantization, and there you can go to int-8 and host it inCPU if the model permits it\n",
        "* In fact, gemini-pro and bison@002 are quantized\n",
        "* obviously as these are bigs the quantization still requires a good amount of TPUs 😀\n"
      ],
      "metadata": {
        "id": "rE0R1YjchIO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### $\\hookrightarrow$ *Prompt Engineering (incl. Chain-of-Thoughts - CoT)*"
      ],
      "metadata": {
        "id": "bkXljK6xhBPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://ploomber.io/blog/prompt-engineering-techniques/"
      ],
      "metadata": {
        "id": "gQtUYa9whALK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/2401.14423 Prompt Design and Engineering: Introduction and Advanced Methods"
      ],
      "metadata": {
        "id": "caVuz9hgGMIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Engineering: Längere \"Chain of Thoughts\" verbessern die Leistung von Sprachmodellen\n",
        "\n",
        "https://the-decoder.de/prompt-engineering-laengere-chain-of-thoughts-verbessern-die-leistung-von-sprachmodellen/"
      ],
      "metadata": {
        "id": "LPk_jDKukQNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### $\\hookrightarrow$ *Low-Rank Adaptation (Lora and qLora)*"
      ],
      "metadata": {
        "id": "Cqusdv76O-Bx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just wrote a new article on \"Improving LoRA: Implementing Weight-Decomposed Low-Rank Adaptation (DoRA) from Scratch\": https://magazine.sebastianraschka.com/p/lora-and-dora-from-scratch\n"
      ],
      "metadata": {
        "id": "wBbEKuA9zESS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "qLora and Lora to move from floating to integers in models (can damage a bit performance but still acceptable), but we can use then CPUs to train some of these models instead of only GPUs.\n",
        "\n",
        "can one use qLora and Lora to move from floating to integers in LLM models in order to use CPUs to train LLMs instead of only GPUs.\n",
        "\n",
        "Yes, qLora and Lora are techniques that can potentially enable the use of CPUs for training large language models (LLMs) by moving from floating-point to integer representations. Here's a breakdown of how this works and the considerations involved:\n",
        "\n",
        "**Traditional LLM Training and GPUs**\n",
        "\n",
        "* **Floating-point precision:** LLMs are typically trained using floating-point numbers (e.g., float32) because they offer a wide dynamic range necessary to represent the subtle gradients and relationships between parameters during the learning process.\n",
        "* **GPU advantage:** GPUs are highly optimized for parallel computations involving floating-point numbers. This makes them significantly faster than CPUs for traditional LLM training.\n",
        "\n",
        "**qLora and Lora for CPU Training**\n",
        "\n",
        "* **Quantization:** qLora (quantized Lora) is a method for reducing the precision of LLM parameters. Instead of storing them as full 32-bit floating-point numbers, it's possible to represent them using lower-precision integers (e.g., 8-bit integers). This drastically reduces memory footprint and computational cost.\n",
        "* **Lora:** Lora (Low-Rank Adaptation) is a technique that decomposes weight matrices in LLMs into smaller, more manageable components. This decomposition can then be exploited during quantization for efficiency.\n",
        "* **CPU efficiency:**  By reducing the memory and computational requirements through quantization, it becomes feasible to train, or at least perform inference of, LLMs on CPUs, which are more generally available and cost-effective than GPUs in many scenarios.\n",
        "\n",
        "**Challenges and Considerations**\n",
        "\n",
        "* **Accuracy trade-off:** Quantization generally leads to a slight loss in model accuracy compared to full-precision floating-point representations. The goal is to find the right balance between quantization level and acceptable performance.\n",
        "* **Optimization:** Techniques like qLora and Lora are relatively new, and ongoing research is focused on making them more efficient and minimizing the accuracy loss.\n",
        "* **Deployment:**  If you aim to deploy a quantized LLM on CPUs,  you'll likely need specialized software and hardware support to ensure optimal performance.\n",
        "\n",
        "**In Conclusion**\n",
        "\n",
        "qLora and Lora offer a promising path towards making LLM training and inference more accessible by potentially allowing the use of CPUs. However, it's essential to be aware of the potential accuracy trade-offs and the fact that this field is still under active development.\n",
        "\n",
        "**Let me know if you'd like more details on any specific aspect or have another related question!**\n"
      ],
      "metadata": {
        "id": "1kQP9sfnhvO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Lora*\n",
        "\n",
        "\"𝗟𝗼𝗥𝗔, which stands for Low-Rank Adaptation, is a popular technique to finetune #llms more efficiently. Instead of adjusting all the parameters of a deep neural network, LoRA focuses on updating only a small set of low-rank matrices.\"\n",
        "\n",
        "https://lightning.ai/lightning-ai/studios/code-lora-from-scratch?utm_source=tldrai\n",
        "\n",
        "  * LoRA: Low-Rank Adaptation of Large Language Models\n",
        "  * Edward J. Hu*, Yelong Shen*, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen\n",
        "  * Paper: https://arxiv.org/abs/2106.09685\n",
        "  * Video explainer: https://www.youtube.com/watch?v=DhRoTONcyZE\n",
        "  * https://github.com/microsoft/LoRA"
      ],
      "metadata": {
        "id": "n3TCWKhJZvRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### $\\hookrightarrow$ *Dora*"
      ],
      "metadata": {
        "id": "0MXqdUuKJZ37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While everyone is talking about Sora, there's a potential successor to LoRA (low-rank adaptation) called DoRA. Here's a closer look at the \"DoRA: Weight-Decomposed Low-Rank Adaptation\" paper: https://arxiv.org/abs/2402.09353\n",
        "LoRA is probably the most widely used parameter-efficient finetuning method for LLMs and vision transformers, and DoRA can be seen as an improvement or extension of LoRA that is built on top of it.\n",
        "\n",
        "A brief LoRA recap: Assuming we have pretrained model weights W, LoRA uses low-rank matrices to approximate weight changes ΔW. I.e., in regular finetuning we have W' = W + ΔW, and in LoRA, we approximate ΔW with BA.\n",
        "\n",
        "Now, the DoRA method first decomposes the pretrained weight matrix into a magnitude vector (m) and a directional matrix (V). Then, it takes the directional matrix V and applies standard LoRA to it, i.e., W' = m (V + ΔV)/norm = m (W + BA)/norm.\n",
        "\n",
        "The motivation for developing this method is based on analyzing and comparing the LoRA and full finetuning learning patterns. They found that LoRA either increases or decreases magnitude and direction updates proportionally but seems to lack the capability of making only subtle directional changes as found in full finetuning. Hence, the researchers propose the decoupling of magnitude and directional components. In other words, their DoRA method aims to apply LoRA only to the directional component (while also allowing the magnitude component to be trained separably.)\n",
        "\n",
        "Note that introducing the magnitude vector m in DoRA adds 0.01% more parameters than standard LoRA. However, across both LLM and vision transformer benchmarks, they found that DoRA even outperforms LoRA if the DoRA rank is halved, i.e., when DoRA only uses half the parameters of regular LoRA.\n",
        "\n",
        "Overall, I am actually quite impressed by the results and need to toy with this method in practice. It should not be too big of a lift to upgrade a LoRA implementation to DoRA."
      ],
      "metadata": {
        "id": "Z4vmfiEHJdKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### $\\hookrightarrow$ (?) *Proxy-tuning*"
      ],
      "metadata": {
        "id": "PFZKZOdMPBfF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Proxy-tuning*\n",
        "\n",
        "Proxy-tuning is a way to adapt LLMs without changing the model's weights. This is especially attractive if a given LLM is too resource-intensive to train or if a user doesn't have access to the LLM's weights.\n",
        "Following up on the proxy-tuning paper discussion from last week, I implemented it in code and gave it a try. It actually works!\n",
        "\n",
        "In a nutshell, it works like this:\n",
        "\n",
        "1. Select a base LLM (e.g., an untuned 7B Llama 2 model) smaller and cheaper than the target LLM (e.g., a 10x larger, untuned 70B Llama 2 model).\n",
        "\n",
        "2. Finetune this smaller base LLM to obtain a small finetuned LLM (e.g., instruction-finetune a 7B Llama 2 model to get a finetuned 7B model).\n",
        "\n",
        "3. Compute the output difference between the base model (step 1) and the tuned model (step 2).\n",
        "\n",
        "4. Add this difference in outputs to the target LLM's outputs.\n",
        "\n",
        "5. Normalize the modified outputs from step 4, and then generate the answer.\n",
        "\n",
        "I tried the following query:\n",
        "\n",
        "\"If I have 5 apples and eat 2, but then find 3 more on my way home, how many do I have?\"\n",
        "\n",
        "The proxy-tuned model was indeed able to answer correctly, whereas the base models failed: \"You start with 5 apples and eat 2, so you have 5 - 2 = 3 apples left. Then, you find 3 more apples on your way home, so you have 3 + 3 = 6 apples in total.\"\n",
        "\n",
        "Using the same approach, it was also possible to give Llama 2 13B coding abilities via CodeLlama 7B.\n",
        "\n",
        "More details and code in my write-up and associated code Studio:\n",
        "\n",
        "https://lightning.ai/lightning-ai/studios/improve-llms-with-proxy-tuning?view=public"
      ],
      "metadata": {
        "id": "RJJgo0tk_4aQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While proxy-tuning and prompting have connections and some potential overlap, they are not precisely the same approach. Here's a breakdown of the differences and where they might intersect:\n",
        "\n",
        "**Proxy-Tuning**\n",
        "\n",
        "* **Core Focus:** Parameter-efficient fine-tuning of large language models (LLMs). The goal is to adapt a pre-trained LLM to a new task without fully fine-tuning its vast number of parameters.\n",
        "* **Mechanism:** Introduces a small set of learnable \"proxy\" parameters. These might be:\n",
        "    * Additional vectors that learn relationships between input embeddings.\n",
        "    * Small adapter modules placed between layers of the LLM.\n",
        "* **Advantage:** Reduces computational cost and memory footprint of fine-tuning compared to training the entire LLM.\n",
        "\n",
        "**Prompting**\n",
        "\n",
        "* **Core Focus:** Eliciting a desired response or behavior from an LLM by carefully crafting the input text.  Prompts include instructions, examples, or textual structures that guide the model's generation.\n",
        "* **Mechanism:** No internal model parameters are directly modified.  Prompts guide the LLM to use its pre-existing knowledge and abilities to complete the task.\n",
        "* **Advantage:** Highly flexible and can be applied to a wide range of tasks without fine-tuning.\n",
        "\n",
        "**Connections and Overlaps**\n",
        "\n",
        "* **Semantic Tuning:**  Proxy-tuning could be employed with  prompts that have rich semantic representations. This fine-tuning could refine the proxy parameters to better  align with complex queries or instructions provided in the prompts.\n",
        "* **Prompt Design as Lightweight Fine-tuning:** Sometimes,  prompting involves finding prompts that essentially 'trick' the LLM into performing a task it  wasn't explicitly trained for.  This fine-grained task adaptation through crafting prompts can have a similar spirit to proxy-tuning, in the sense that both aim to modify how the LLM behaves without major internal changes.\n",
        "\n",
        "**In Summary**\n",
        "\n",
        "Proxy-tuning and prompting are distinct but complementary techniques. Proxy-tuning focuses on efficient internal parameter modification of LLMs. Prompting focuses on steering model output through clever input design.  There could be interesting potential in the use of these two approaches together."
      ],
      "metadata": {
        "id": "Ej7C082gtwyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Adapter Tuning*"
      ],
      "metadata": {
        "id": "0IdZ1gStv7HP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-models"
      ],
      "metadata": {
        "id": "1etW7dnRGOp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://services.google.com/fh/files/misc/adaptation_of_foundation_models_whitepaper_google_cloud.pdf"
      ],
      "metadata": {
        "id": "6QyPscgUGCu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://magazine.sebastianraschka.com/p/finetuning-llms-with-adapters"
      ],
      "metadata": {
        "id": "_-8jp5b6FbOJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/abs/2106.03164 On the Effectiveness of Adapter-based Tuning for Pretrained Language Model Adaptation"
      ],
      "metadata": {
        "id": "i5vNXkQPF0d3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a breakdown of Adapter Tuning, its advantages, and how it works:\n",
        "\n",
        "**What is Adapter Tuning?**\n",
        "\n",
        "Adapter tuning is a technique used to fine-tune large language models (LLMs) for new tasks more efficiently. Here's the core idea:\n",
        "\n",
        "* **Pre-trained Models:** Large language models have been trained on vast amounts of text data, giving them a deep understanding of language patterns.\n",
        "* **Bottleneck:** Fine-tuning these massive models to a specific task (like question answering or translation) often means updating millions or billions of parameters, which is computationally expensive and time-consuming.\n",
        "* **Adapters to the Rescue:** Adapter tuning introduces compact \"adapter\" modules (small sets of new neural network layers) within the pre-trained model's architecture.  Instead of updating the entire model, only the parameters within these adapters are trained for the new task.\n",
        "\n",
        "**Advantages of Adapter Tuning**\n",
        "\n",
        "* **Efficiency:** Adapter tuning greatly reduces the number of parameters needing updates, making fine-tuning significantly faster and less computationally demanding.\n",
        "* **Preserving Knowledge:** By freezing most of the original model's weights, adapter tuning preserves the language knowledge the model has acquired during pre-training.\n",
        "* **Multi-Task Learning:** A single pre-trained model can have multiple adapters, each trained for a different task. This allows the model to switch between tasks easily without needing to retrain the entire model.\n",
        "\n",
        "**How Adapter Tuning Works**\n",
        "\n",
        "1. **Pre-trained Model:** Start with a large, pre-trained language model.\n",
        "2. **Insert Adapters:** Add small adapter modules (new layers) between existing layers of the pre-trained model.\n",
        "3. **Freeze the Original Model:** Keep the weights of the pre-trained model frozen.\n",
        "4. **Train the Adapters:** Train only the parameters of the newly added adapters on the data for the specific task at hand.\n",
        "\n",
        "**In Summary**\n",
        "\n",
        "Adapter tuning is a clever way to fine-tune large language models. It saves time and computing resources, maintains the model's core knowledge, and facilitates efficient multi-task capabilities.\n",
        "\n",
        "**Let me know if you'd like a more technical explanation or examples of how adapter tuning is used!**\n"
      ],
      "metadata": {
        "id": "dfCkiw8zwImy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *ASPIRE*"
      ],
      "metadata": {
        "id": "3cyZhA5TuEuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://blog.research.google/2024/01/introducing-aspire-for-selective.html"
      ],
      "metadata": {
        "id": "DPpnWeV-uGA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes! \"Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs\" (ASPIRE) is primarily a framework for finetuning LLMs. Here's why:\n",
        "\n",
        "**Focus of ASPIRE:**\n",
        "\n",
        "* **Selective Prediction:**  ASPIRE aims to teach LLMs to evaluate their own output and decide whether to provide an answer or abstain (\"I don't know\"). This aligns with finetuning goals of improving model behavior rather than directly changing its architecture.\n",
        "* **Self-Evaluation:** The framework trains the LLM on target-task data to learn to assess its own predictions, rather than relying on external retrieval mechanisms.\n",
        "\n",
        "**How ASPIRE Finetunes LLMs:**\n",
        "\n",
        "ASPIRE involves finetuning a pre-trained LLM on a portion of question-answering datasets like CoQA. During finetuning, the model learns to output both an answer and a selection score. The selection score indicates the model's confidence in its answer.  This approach directly modifies the LLM's output behavior, aligning with finetuning.\n",
        "\n",
        "**Difference from RAG:**\n",
        "\n",
        "RAG (Retrieval-Augmented Generation) frameworks enhance LLMs by teaching them to retrieve relevant information from external sources during answer generation.  ASPIRE, in contrast, focuses on internal self-assessment.\n",
        "\n",
        "**ASPIRE vs. RLHF:**\n",
        "\n",
        "While both ASPIRE and RLHF (Reinforcement Learning from Human Feedback) aim to improve the quality and reliability of LLM responses, they differ in approach:\n",
        "\n",
        "* **RLHF:** Uses human feedback to directly reward desirable responses and penalize undesirable ones.\n",
        "* **ASPIRE:** Focuses on the LLM learning to evaluate itself based on data.\n",
        "\n",
        "**In conclusion, ASPIRE falls firmly within the domain of finetuning LLMs by teaching them the crucial skill of selective prediction.**\n"
      ],
      "metadata": {
        "id": "0qZ6IWEiuO_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*RHLF*"
      ],
      "metadata": {
        "id": "l_kkJp3mtIyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/blog/products/ai-machine-learning/rlhf-on-google-cloud?hl=en\n",
        "\n",
        "https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-text-models-rlhf"
      ],
      "metadata": {
        "id": "iXpqxCF4lcDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RLHF stands for \"Reinforcement Learning from Human Feedback\"**\n",
        "\n",
        "* is a crucial technique for improving the performance and alignment of these models. It involves a combination of methods that leverage human feedback to refine and guide the learning process of the model.\n",
        "\n",
        "* Here's how RLHF is applied to LLMs:\n",
        "\n",
        "1. **Supervised Fine-Tuning (SFT)**: Initially, the language model is trained on a large dataset of text from the internet. This phase is purely supervised learning, where the model learns to predict the next word in a sequence. However, this dataset might not perfectly represent desirable outputs, as it contains a wide range of materials, including low-quality or harmful content.\n",
        "\n",
        "2. **Reward Modeling**: After the initial training, human reviewers assess the outputs of the model, providing feedback on its responses. This feedback could be in the form of rankings, ratings, or direct corrections. This human feedback is then used to create a reward model. The reward model essentially predicts how a human would rate a given output, serving as a proxy for human judgment.\n",
        "\n",
        "3. **Proximal Policy Optimization (PPO)**: With the reward model in place, the LLM is further trained using reinforcement learning, specifically a method called Proximal Policy Optimization. In this phase, the model learns to generate outputs that are more likely to receive higher ratings from the reward model. This step is crucial for aligning the model's outputs with human values and preferences.\n",
        "\n",
        "4. **Iterative Refinement**: The process can be iterative, with further rounds of human feedback and model refinement. This ongoing interaction helps in continuously improving the quality and relevance of the model's responses, ensuring they align well with ethical guidelines, factual accuracy, and user expectations.\n",
        "\n",
        "Applying RLHF to LLMs is important for several reasons:\n",
        "\n",
        "- **Alignment with Human Values**: It helps ensure that the model's outputs are aligned with human ethical standards and societal norms.\n",
        "- **Reduction of Harmful Outputs**: By training the model with human feedback, it's possible to reduce the likelihood of generating unsafe, biased, or otherwise undesirable content.\n",
        "- **Enhanced Relevance and Utility**: Feedback-driven training can make the model more useful and relevant to users by focusing on generating high-quality, contextually appropriate responses.\n",
        "\n",
        "This approach represents a significant advancement in the development of more responsible and effective AI language models."
      ],
      "metadata": {
        "id": "iXz7p2YntKQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Direct Preference Optimization (DPO)*"
      ],
      "metadata": {
        "id": "qoluFPb7O8Vv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Direct Preference Optimization (DPO)**\n",
        "\n",
        "Interesting article from Andrew Ng about a new research paper that proposes DPO (direct preference optimization) over RLHF. A promise is that you won‘t need to deal with a separately represented reward function -- you just need the LLM transformer -- and you can train the LLM directly and more efficiently to optimize the same objective as RLHF. Enjoy the read 🤓🙌\n",
        "\n",
        "https://www.deeplearning.ai/the-batch/issue-231/\n",
        "\n",
        "https://browse.arxiv.org/html/2305.18290v2\n",
        "\n",
        "https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023\n",
        "\n",
        "and here his thoughts more ind details in case you dont want to read the paper: https://magazine.sebastianraschka.com/p/llm-training-rlhf-and-its-alternatives\n",
        "\n",
        "\n",
        "Direct Preference Optimization (DPO) is pretty amazing. Surely, it can't be this straightforward to replace the whole reinforcement learning on human feedback (RLHF) phase?\n",
        "1. Treat a foundational (or instruction tuned) LLM\n",
        "as the reference LLM\n",
        "1.    Generate pairs of outputs to prompts and have humans choose which one they like (human feedback)\n",
        "2.    Add a linear layer to the LLM so that it outputs a scalar value, and tune this new model with a new loss function (compute log-ratio of scalar outputs of the reference LLM and the one being tuned, multiply by a divergence parameter ... -- very cool math insight here, but end-of-the-day this is just a new training loss function called dpo_loss or something that Keras and Pytorch will ship with)\n",
        "3.    Drop the last linear layer, and you have a fine tuned LLM on human feedback\n",
        "Amazing stuff. RLHF was the most dicey part of LLM training and the one that needed the most art vs science. Expect a lot of convergence between LLMs trained on the same data\n",
        "\n",
        "---\n",
        "\n",
        "Direct Preference Optimization (DPO) in the context of machine learning, and specifically for large language models (LLMs) like GPT-3 or GPT-4, is an approach that focuses on optimizing the model's outputs based directly on human preferences. This method is a part of the broader framework of Reinforcement Learning from Human Feedback (RLHF). Here's a closer look at how DPO works and its significance:\n",
        "\n",
        "1. **Collecting Human Preferences**: The first step in DPO involves gathering data on human preferences. This is typically done by presenting human reviewers with pairs of outputs generated by the model in response to the same prompt or query. The reviewers are then asked to indicate which of the two responses they prefer.\n",
        "\n",
        "2. **Training a Preference Model**: The collected preference data is used to train a preference model. This model learns to predict the likelihood of one output being preferred over another by humans. Essentially, it aims to understand and quantify what makes one response more favorable or acceptable than another.\n",
        "\n",
        "3. **Optimizing the Language Model**: Once the preference model is trained, it is used to guide the training of the language model. The language model is optimized to generate outputs that are more likely to align with the preferences indicated by humans. This optimization can be done using various techniques, including reinforcement learning algorithms.\n",
        "\n",
        "4. **Iterative Process**: Like other RLHF techniques, DPO is often iterative. The model's outputs can be continuously evaluated and compared by human reviewers, and the preference model can be updated based on new data. This leads to ongoing improvements in the language model's alignment with human preferences.\n",
        "\n",
        "The significance of DPO lies in its focus on aligning the model's outputs with what humans explicitly prefer. This is particularly important for applications where the quality of an output is subjective and can vary based on context and the specific needs or values of the user.\n",
        "\n",
        "For example, in a conversational AI, different users might have different preferences for the style, tone, and type of responses they find engaging or helpful. DPO allows the model to be tuned to these preferences, potentially leading to more personalized and satisfactory interactions.\n",
        "\n",
        "Overall, Direct Preference Optimization represents a powerful method for increasing the alignment of AI systems with human values, preferences, and expectations, thereby enhancing their usefulness, safety, and acceptance in various applications."
      ],
      "metadata": {
        "id": "5VEtMTUkQz3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Distillation*"
      ],
      "metadata": {
        "id": "JC96LcJUvxwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vertex-ai/docs/generative-ai/models/distill-text-models"
      ],
      "metadata": {
        "id": "d5qpyD1AHvFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-models"
      ],
      "metadata": {
        "id": "v6w_qgUoGs4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-models#tune-distill"
      ],
      "metadata": {
        "id": "DstE8mSrGp7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning and distillation - Distillation is a good option if you have a large model that you want to make smaller without degrading its ability to do what you want. The process of distilling a model creates a new, smaller trained model that costs less to use and has lower latency than the original model"
      ],
      "metadata": {
        "id": "M66NW8rjGlAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://arxiv.org/pdf/1503.02531.pdf Distilling the Knowledge in a Neural Network"
      ],
      "metadata": {
        "id": "zvawWRmev2O1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://blog.research.google/2024/02/intervening-on-early-readouts-for.html?m=1"
      ],
      "metadata": {
        "id": "3jWTvDr-v0EX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Self-instruct*"
      ],
      "metadata": {
        "id": "w4FmSc4QvQsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Context - Consider a LLM use-case where we only have access to a handful of HQ few-shot examples that are not sufficient for a full fine-tuning (or even LoRA). Then, is it possible to use an LLM to generate similar examples that can then be used for fine-tuning the model?\n",
        "\n",
        "Concerns\n",
        "1) Model bias - using a model to generate examples and then fine-tuning it based on those sounds like a classic case of introducing bias.\n",
        "\n",
        "2) Role of fine-tuning - If the model is capable of generating the additional examples, then is fine-tuning even necessary? it seems like the model is already able to generalize to the use-case quite well.\n",
        "\n",
        "https://arxiv.org/pdf/2212.10560.pdf\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Yes, this approach is quite effective for training.\n",
        "\n",
        "(1).  Yes, you need to ensure you aren't entrenching existing idiosyncrasies.  Typically this is done in one of three ways: (a) Human review+annotation of machine-generated examples or (b) spending more compute time at inference to generate+filter/select only the best examples for the next round of training, and discarding the low-quality generations.\n",
        "\n",
        "(2).  Generally, given enough time and temperature, all models are capable of generating anything (monkies on a typewriter).  The goal of additional training is always and exclusively to improve the quality of the results in a pass@1 fashion.  If you sample from pass@100, use additional compute to rank the results, and select the top 1% of generations for additional training, then you are increasingly biasing the model toward the highest quality results (which is the purpose of training).  It is true the model is already \"able to generalize to the use-case quite well if given enough compute\", but training is all about paying at training time in order to increase the ROI at inference time.\n",
        "\n",
        "---\n",
        "This sounds like go/datasynth. You can start with a few high quality examples and use LLMs to generate a synthetic dataset for fine-tuning. They also provide tools to mitigate bias you mentioned in #1 (e.g. diversity scores, topic visualizations, etc).  \n"
      ],
      "metadata": {
        "id": "Knw1fQeYvUUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self-instruct is a fascinating technique in the realm of large language models (LLMs) that straddles the line between fine-tuning and augmentation. Here's what it entails:\n",
        "\n",
        "**Core Idea**\n",
        "\n",
        "Self-instruct aims to improve an LLM's ability to follow instructions and perform tasks by having it generate its own training data. Essentially, the LLM acts as both teacher and student.\n",
        "\n",
        "**The Process**\n",
        "\n",
        "1. **Task Generation:** The LLM is given a few initial examples of tasks and desired solutions. It then attempts to generate new, similar tasks itself.\n",
        "2. **Solution Generation:** The LLM also tries to provide solutions or completions to the tasks it has created.\n",
        "3. **Filtering:** Human experts or automated quality checks filter out poorly generated tasks and solutions.\n",
        "4. **Instruction Fine-tuning:** The remaining high-quality, self-generated data is used to fine-tune the LLM using instruction-following techniques.\n",
        "\n",
        "**Why It's Both Fine-tuning and Augmentation**\n",
        "\n",
        "* **Fine-tuning:**  Self-instruct directly modifies the LLM's parameters based on the data it generates, just like other fine-tuning processes. This refines its ability to execute instructions.\n",
        "* **Augmentation:** The main difference is that self-instruct augments the existing training process by creating a novel and customized dataset that caters specifically to the desired task format.\n",
        "\n",
        "**Benefits**\n",
        "\n",
        "* **Addresses Dataset Limitations:** Human-written instruction datasets are often limited in scale and diversity. Self-instruct expands these training resources.\n",
        "* **Reduces Expert Effort:** Creating large datasets manually is time-consuming. Self-instruct lessens the burden on human annotators.\n",
        "* **Iterative Improvement:** As the LLM becomes better at following instructions, its self-generated training data also improves, creating a positive feedback loop.\n",
        "\n",
        "**Example**\n",
        "\n",
        "Imagine you want the LLM to summarize articles.\n",
        "\n",
        "* **Initial Input:**  A few articles with provided human-written summaries.\n",
        "* **Self-Instruct:** The LLM generates new articles and creates summaries for them. These are filtered for quality.\n",
        "* **Fine-tuning:**  The LLM is fine-tuned on the self-generated dataset to improve its summarization skills.\n",
        "\n",
        "**Let me know if you'd like to delve into the technical details of self-instruct methods or want to explore practical applications!**\n"
      ],
      "metadata": {
        "id": "uXbRtyYZvWES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Token*"
      ],
      "metadata": {
        "id": "ON5x3x5CPe7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Token*\n",
        "\n",
        "* basic unit of text representation.\n",
        "* sequences of characters that are treated as individual elements in the LLM's internal representation of the input text.\n",
        "* used to build up more complex language structures, such as words, phrases, and sentences.\n",
        "* Tokenization is the process of breaking down a piece of text into tokens. This can be done using various methods, such as word-level tokenization, character-level tokenization, or subword tokenization. The choice of tokenization method depends on the specific task and the characteristics of the input text.\n",
        "* LLMs use tokens to extract features from the input text and to generate output text. For example, when generating text, the LLM will consider the surrounding tokens to determine the most likely next word or phrase. Tokens also play a role in LLM performance evaluation. Evaluation metrics such as accuracy and F1 score are often calculated based on the similarity between predicted and ground truth tokens.\n",
        "  * Text-to-text translation: When translating a sentence from one language to another, the LLM breaks down the input sentence into tokens and then uses these tokens to generate the corresponding tokens in the target language.\n",
        "  * Text summarization: When summarizing a document, the LLM identifies the most important tokens in the document and then uses these tokens to generate a concise summary.\n",
        "  * Question answering: When answering a question about a text, the LLM extracts the relevant tokens from the text and uses these tokens to identify the answer to the question."
      ],
      "metadata": {
        "id": "C2x7aHgiWuOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I get better results with no training. See how, at https://mltblog.com/42l51rJ\n",
        "Eventually, I will add training: user based (self-tuning) rather than based on algorithms. Of course, fully automated and transparent to the user.\n"
      ],
      "metadata": {
        "id": "A0wqPksljzJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *SLM (Small Language Model)*"
      ],
      "metadata": {
        "id": "jK7vTB6GIQpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://the-decoder.de/microsoft-prognostiziert-drei-grosse-ki-trends-fuer-2024/\n",
        "\n"
      ],
      "metadata": {
        "id": "5YNYNHmIH-7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Microsoft investiert in diesen Bereich, hat bereits die SLMs Phi und Orca vorgestellt und soll seine eigenen Abteilungen auf effizientere KI-Modelle ausgerichtet haben."
      ],
      "metadata": {
        "id": "6iMpdYbDID5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://the-decoder.de/microsofts-mini-llm-phi-2-ist-jetzt-open-source-und-angeblich-besser-als-google-gemini-nano/"
      ],
      "metadata": {
        "id": "KBKBgFLeIJZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://the-decoder.de/microsofts-orca-2-ist-ein-kleines-ki-modell-mit-verbesserter-denkfaehigkeit/"
      ],
      "metadata": {
        "id": "C_vrvQL9IMrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://the-decoder.de/generative-ki-ist-teuer-und-microsoft-will-die-kosten-senken/"
      ],
      "metadata": {
        "id": "EPit7Ws7IPr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[How to Build an LLM from Scratch | An Overview](https://www.youtube.com/watch?v=ZLbVdvOoTKM&list=WL&index=8&t=480s)"
      ],
      "metadata": {
        "id": "UdSIcDIUu6uH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Augment LLMs*"
      ],
      "metadata": {
        "id": "QaGfSVYXp_gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Grounding*"
      ],
      "metadata": {
        "id": "Y7EMAgb2PJDH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grounding**: Out-of-the-box grounding against structured and unstructured data\n"
      ],
      "metadata": {
        "id": "wK-YLsg4sTJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Grounding*\n",
        "\n",
        "https://cloud.google.com/vertex-ai/docs/generative-ai/grounding/overview\n",
        "\n",
        "Grounding in large language models (LLMs) refers to the process of connecting their responses to real-world entities and concepts. This is crucial for ensuring that LLMs generate accurate, relevant, and meaningful outputs. LLMs are trained on massive datasets of text and code, but this knowledge is often abstract and lacks specific context. Grounding allows LLMs to access and incorporate external information to make their responses more grounded in reality.\n",
        "\n",
        "There are several different approaches to grounding LLMs, but they typically involve some combination of the following techniques:\n",
        "\n",
        "* **Knowledge base access:** LLMs can be connected to knowledge bases, such as Wikidata or Google Search, to access information about real-world entities and concepts. This information can be used to refine and improve their responses.\n",
        "* **Data retrieval:** LLMs can be used to retrieve relevant data from external sources, such as databases or web pages. This data can then be used to ground their responses in real-world context.\n",
        "* **Physical interaction:** In some cases, LLMs can be directly connected to the real world through sensors and actuators. This allows them to interact with their environment and gather information directly.\n",
        "\n",
        "Grounding is an essential part of developing reliable and useful LLMs. By grounding their responses in real-world knowledge, LLMs can be more accurate, relevant, and informative. This makes them more suitable for a wider range of applications, such as question answering, summarization, and natural language generation.\n",
        "\n",
        "Here are some of the benefits of grounding LLMs:\n",
        "\n",
        "* **Improved accuracy:** Grounding can help to reduce the number of factual errors in LLM responses.\n",
        "* **Increased relevance:** Grounding can help to ensure that LLM responses are relevant to the context in which they are generated.\n",
        "* **Enhanced creativity:** Grounding can help LLMs to generate more creative and interesting text formats.\n",
        "* **Expanded capabilities:** Grounding can allow LLMs to perform tasks that require more knowledge of the real world, such as answering questions about physical entities or events.\n",
        "\n",
        "Overall, grounding is a powerful technique for improving the performance and usefulness of large language models. As LLMs continue to develop, grounding is likely to play an even more important role in their development and application."
      ],
      "metadata": {
        "id": "HcdUr67tZ6JW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Retrieval-Augmented Generation (RAG)*"
      ],
      "metadata": {
        "id": "6Z0vHScrO3Nw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/blog/products/ai-machine-learning/rags-powered-by-google-search-technology-part-1?hl=en"
      ],
      "metadata": {
        "id": "Mnmh9oFDYQjU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Long tokens vs RAG**\n",
        "\n",
        "https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024\n",
        "\n",
        "https://youtu.be/wa0MT8OwHuk?si=4DeetM9gi9yI1i-T\n",
        "\n",
        "the demo is using a movie. That explains why the 1.5 version landed on the Multimodal part of Studio. Will that context window not apply to the text-only endpoint?\n",
        "\n",
        "Good thing I didn't invest too much time learning about chunking strategies with RAG 😅\n",
        "\n",
        "Apparently Deepmind tested 10M token successfully in research\n",
        "\n",
        "I think chunking will still make sense for RAG use cases, especially if you care about latency or have significantly more than 1M tokens. But it's great to see that there are lots of improvements on the input token limit."
      ],
      "metadata": {
        "id": "wyDsltggM6_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1710.png)"
      ],
      "metadata": {
        "id": "x6b56-TiMMHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.linkedin.com/posts/alexwang2911_genai-llm-technology-activity-7164438306871603200--mgt/?utm_source=share&utm_medium=member_ios"
      ],
      "metadata": {
        "id": "Onb9kYmoIzDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/blog/products/ai-machine-learning/rags-powered-by-google-search-technology-part-1?hl=en"
      ],
      "metadata": {
        "id": "mdFXP_TgVQA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/blog/products/ai-machine-learning/rags-powered-by-google-search-technology-part-2?hl=en"
      ],
      "metadata": {
        "id": "UkJKK25Xlvbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/blog/products/ai-machine-learning/context-aware-code-generation-rag-and-vertex-ai-codey-apis?hl=en"
      ],
      "metadata": {
        "id": "HYCk0zmUl4Ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have a question about chatbot and RAG. Is there any good/easy approach which we can add RAG layer between data source and conversation AI app? The challenge is today we show great demo in Playbooks with cleaned data but in the reality, customers usually have more complicated/messy data source (source data against each others), so the first step of doing data retrieval is critical.  Say customer is ok to use our DFCX/Playbooks but they need to add extra RAG layer. Any experience ?\n"
      ],
      "metadata": {
        "id": "iorG22NB44ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrieval Augmented Generation (RAG)**: Fully managed vector database for high-scale, low latency vector search\n",
        "\n",
        "[What is Retrieval-Augmented Generation (RAG)?](https://www.youtube.com/watch?v=T-D1OfcDW1M&list=WL&index=9&t=23s)\n"
      ],
      "metadata": {
        "id": "YTf3gJSGsUsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG stands for **Retrieval-Augmented Generation** in the context of Large Language Models (LLMs). Here's a breakdown of what it is and why it's important:\n",
        "\n",
        "**How LLMs Typically Work**\n",
        "\n",
        "* Traditional LLMs are trained on massive amounts of text data. They learn to predict the next word in a sequence based on patterns they've seen during training.\n",
        "* This makes them great at generating text, translating languages, etc.\n",
        "* **Limitation:** LLMs can't easily access and incorporate new knowledge or information that wasn't part of their original training data.\n",
        "\n",
        "**How RAG Solves This**\n",
        "\n",
        "RAG combines the power of LLMs with traditional information retrieval systems:\n",
        "\n",
        "1. **Retrieval:** When you ask a question, RAG first searches through a knowledge base (like Wikipedia, internal company documents, news articles, etc.) to find relevant passages of text.\n",
        "2. **Augmentation:** This relevant text is appended to your original question, creating a richer, more informative prompt.\n",
        "3. **Generation:** The LLM uses this combined information (original question + retrieved knowledge) to generate a more comprehensive and accurate answer.\n",
        "\n",
        "**Benefits of RAG**\n",
        "\n",
        "* **Up-to-date Information:** RAG models aren't stuck with the knowledge they were trained on. They can access and integrate fresh information on demand.\n",
        "* **Factual Grounding:** Answers generated by RAG models can be linked back to the knowledge sources they are based on, providing sources or citations.\n",
        "* **Domain-Specific Adaptation:** A RAG model can be customized to work well in specific fields (legal, medical, etc.) by using a knowledge base tailored to that domain.\n",
        "* **Improved Accuracy:** RAG models often significantly outperform traditional LLMs on tasks that require external knowledge\n",
        "\n",
        "**In summary:**  RAG is a technique that allows LLMs to go beyond their internal training data, access external knowledge, and provide more informed, accurate, and trustworthy responses.\n"
      ],
      "metadata": {
        "id": "m0FaHYgS1ygi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Prompting and RAG*\n",
        "\n",
        "Prompting and RAG are equivalent to feature engineering (data augmentation to be exact) in the traditional ML paradigm, while finetuning is equivalent to model training. So, all three are needed for the best result.\n",
        "* rag is more like a key point selection based on features. That's more like an attention mechanism rather than feature engineering.\n",
        "* When you do RAG, you use the user's original input to find relevant pieces of external information and add them to the input you send to the model. This is by definition feature engineering.\n"
      ],
      "metadata": {
        "id": "tq-iqkJhyA1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrieval-Augmented Generation (RAG)**\n",
        "\n",
        "Retrieval-Augmented Generation (RAG) is a framework for improving the accuracy and reliability of large language models (LLMs) by incorporating external knowledge bases during the generation process. It combines the strengths of two approaches: dense retrieval and sequence-to-sequence modeling.\n",
        "\n",
        "**Dense retrieval** is used to identify relevant documents from a knowledge base that are related to the query or prompt provided to the LLM. This ensures that the LLM has access to the most up-to-date and accurate information before generating its response.\n",
        "\n",
        "**Sequence-to-sequence modeling** is used to generate the final output text, taking into account the retrieved documents and the original query. This allows the LLM to incorporate factual information from the knowledge base into its response while maintaining its natural language fluency and coherence.\n",
        "\n",
        "RAG has been shown to improve the performance of LLMs on a variety of tasks, including question answering, summarization, and translation. It has also been found to be more robust to errors in the knowledge base than traditional LLM approaches.\n",
        "\n",
        "**Benefits of RAG:**\n",
        "\n",
        "* **Improved accuracy:** RAG can help to prevent LLMs from generating incorrect or misleading information by providing them with access to a broader range of information.\n",
        "\n",
        "* **Reduced factual errors:** RAG can reduce the number of factual errors in LLM responses by incorporating information from a knowledge base.\n",
        "\n",
        "* **Improved coherence:** RAG can help to improve the coherence of LLM responses by ensuring that they are consistent with the information in the knowledge base.\n",
        "\n",
        "**Drawbacks of RAG:**\n",
        "\n",
        "* **Increased computational complexity:** RAG is more computationally complex than traditional LLM approaches, as it requires both dense retrieval and sequence-to-sequence modeling.\n",
        "\n",
        "* **Dependency on knowledge base:** RAG is dependent on the quality of the knowledge base that is used. If the knowledge base is inaccurate or incomplete, RAG's performance will suffer.\n",
        "\n",
        "Despite these drawbacks, RAG is a promising approach for improving the accuracy and reliability of LLMs. As knowledge bases continue to improve, RAG is likely to become an even more valuable tool for natural language processing."
      ],
      "metadata": {
        "id": "2L0kvygNz4MO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### $\\hookrightarrow$ *LangChain*"
      ],
      "metadata": {
        "id": "ut_14zjENSyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/blog/products/databases/build-rag-applications-with-langchain-and-google-cloud"
      ],
      "metadata": {
        "id": "JTmQ6pFyNQqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### $\\hookrightarrow$ *LLamaindex*"
      ],
      "metadata": {
        "id": "QFiC9iq1uchk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLamaindex**\n",
        "\n",
        "Video: [Llamaindex webinar](https://youtu.be/aoLtTIYAafY?si=r2iEJC_bqTsPRlnf)\n",
        "\n",
        "LlamaIndex is a powerful data framework designed to streamline the development of applications powered by Large Language Models (LLMs). Here's a breakdown of what it is and why it's important:\n",
        "\n",
        "**Key Functions**\n",
        "\n",
        "* **Data Ingestion & Management:**\n",
        "    * **Diverse Formats:** Handles structured, semi-structured, and unstructured data sources (documents, PDFs, APIs, SQL databases, etc.).\n",
        "    * **Organization:** Structures data in ways LLMs can easily understand and access.\n",
        "* **Indexing:** Creates efficient indices (like a virtual library) of your data, allowing quick retrieval of relevant information.\n",
        "* **Query Interface:** Provides a user-friendly way to interact with your data using prompts or questions. The responses are augmented with knowledge retrieved from your indexed data.\n",
        "\n",
        "**Why It Matters (Benefits)**\n",
        "\n",
        "* **Retrieval-Augmented Generation (RAG):** LlamaIndex is core to implementing RAG, a method where LLMs first consult an external knowledge base before generating a text response. This leads to more informed, grounded, and less likely to hallucinate answers.\n",
        "* **Custom Applications:** It simplifies building a range of LLM-driven applications:\n",
        "    * Question-answering systems over specific information (company docs, product manuals, etc.).\n",
        "    * Sophisticated chatbots or conversational AI.\n",
        "    * Intelligent tools that interact with your personal data.\n",
        "* **Flexibility:** Offers both high-level APIs for easy use and low-level APIs for finer control.\n",
        "\n",
        "**How it Works (Simplified)**\n",
        "\n",
        "1. **Import & Structure:** You import data into LlamaIndex, where it's organized.\n",
        "2. **Indexing:**  LlamaIndex creates efficient indices to speed up search within your data.\n",
        "3. **Query:** You give the system a question or prompt.\n",
        "4. **Retrieval:** LlamaIndex uses vector search techniques to find relevant bits of information in your data.\n",
        "5. **Augmented Generation:** The LLM takes your question AND the retrieved knowledge to generate a comprehensive response.\n",
        "\n",
        "**In Summary**\n",
        "\n",
        "LlamaIndex offers a powerful framework for harnessing the capabilities of LLMs with your own diverse data. It simplifies the process of building LLM-based applications that rely on external knowledge sources."
      ],
      "metadata": {
        "id": "f-MDnUAvuPmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Extensions*"
      ],
      "metadata": {
        "id": "KcuadzY1rHe3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extensions**: Integrate easily real-time data and real-world actions, e.g. Ingest internal codebases and automatically lookup evolving security threats in real time\n"
      ],
      "metadata": {
        "id": "YPwk16g1rKKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Function Calling*"
      ],
      "metadata": {
        "id": "hrYb8_OIPhhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function Calling**: enables LLMs to interact with external tools, databases, and APIs or code snippets that perform specific tasks (e.g., weather lookup, math calculations, sending emails) to improve model responses"
      ],
      "metadata": {
        "id": "6h-cCeTcsX-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Function Calling*\n",
        "\n",
        "https://codelabs.developers.google.com/codelabs/gemini-function-calling#0\n"
      ],
      "metadata": {
        "id": "KhkJHDb7j29X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a breakdown of the differences between function calling and extensions in the context of LLMs:\n",
        "\n",
        "**Function Calling**\n",
        "\n",
        "* **Focus:** Executing specific, well-defined tasks or retrieving information from external sources.\n",
        "* **Nature:** Dynamic and on-demand. Functions are called in response to specific prompts and instructions.\n",
        "* **Scope:** Actions are usually limited to external tools and APIs the LLM is connected to.\n",
        "* **Example:** A function to look up the current temperature in a specific city.\n",
        "\n",
        "**Extensions**\n",
        "\n",
        "* **Focus:** Expanding the core capabilities of the LLM with new features or knowledge domains.\n",
        "* **Nature:** More persistent. Extensions are installed or integrated into the model.\n",
        "* **Scope:** Can fundamentally change how the LLM processes information and generates responses.\n",
        "* **Example:** An extension designed for summarizing scientific papers, allowing the LLM to better understand and answer questions about complex research.\n",
        "\n",
        "**Key Differences Table**\n",
        "\n",
        "| Feature            | Function Calling                                    | Extensions                                                   |\n",
        "|--------------------|-----------------------------------------------------|--------------------------------------------------------------|\n",
        "| Purpose            | Perform external actions, retrieve real-world data  | Expand the LLM's capabilities and knowledge                   |\n",
        "| Nature             | Dynamic, task-specific                              | Persistent, integrated into the LLM                           |\n",
        "| Scope              | Focused on external tools the LLM can access       | Can affect the LLM's internal processing and understanding    |\n",
        "| Implementation     | LLM generates code to call external functions      | Often require installing code or packages within the LLM's environment |\n",
        "\n",
        "**In Summary**\n",
        "\n",
        "* **Function calling** is about letting the LLM interact with the outside world to get things done.\n",
        "* **Extensions** are about making the LLM itself smarter or more capable by adding new skills or knowledge.\n",
        "\n",
        "**Let me know if you'd like more clarification or examples!**\n"
      ],
      "metadata": {
        "id": "cJbYYtJO11zH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Special: Vector Retrieval / Vector Search*"
      ],
      "metadata": {
        "id": "r2-fNN88Cb7S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vector Retrieval / Vector Search both refer to the core process of finding similar items within a large dataset of vectors generated by an LLM. Here's how it works:\n",
        "\n",
        "1. Embedding Generation: The LLM takes a query (e.g., a piece of text or an image) and creates a vector representation of it.\n",
        "2. Vector Database: The LLM has a pre-computed database of vectors representing items like text passages, images, or code snippets.\n",
        "3. Similarity Calculation: The LLM calculates the similarity (often using cosine similarity) between the query vector and all the vectors in the database.\n",
        "4. Retrieval: The vectors with the highest similarity scores (closest distance to the query vector) are retrieved. These returned items are considered the most relevant matches to the original query.\n",
        "\n",
        "Applications - Vector retrieval (a.k.a. vector search) is a powerful tool used across various LLM-based applications:\n",
        "\n",
        "* Semantic Search: Searching for information based on meaning rather than just keywords.\n",
        "* Recommendation Systems: Recommending products, content, etc. based on a user's preferences and similarity between items.\n",
        "* Question Answering: Finding relevant passages in a large corpus of text to answer a question.\n",
        "* Image Search: Searching for images similar to a query image."
      ],
      "metadata": {
        "id": "wbIfqyYxr7at"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a breakdown of ANN and MMR in the context of information retrieval using LLMs:\n",
        "\n",
        "**ANN (Approximate Nearest Neighbor)**\n",
        "\n",
        "* **Purpose:**  ANN algorithms are designed to find items (\"neighbors\") in a dataset that are most similar to a given query, even in very high-dimensional spaces. In LLM retrieval, the query would be the user's input, and the items in the dataset are potential text passages containing relevant information.\n",
        "\n",
        "* **Role in LLM Retrieval:**\n",
        "    * **Efficiency:**  ANN is crucial for LLM-based retrieval because naively comparing a query to every piece of text in a large database would be extremely computationally expensive. ANN makes this process tremendously faster.\n",
        "    * **Understanding Similarity:** ANN focuses on finding passages that are semantically similar to the user's query, even if they don't contain exact keyword matches. This aligns well with LLMs' ability to understand nuanced meaning.\n",
        "\n",
        "* **Types of ANN:** Several ANN algorithms exist (e.g., HNSW, FAISS), each with trade-offs in accuracy, speed, and memory usage.\n",
        "\n",
        "**MMR (Maximal Marginal Relevance)**\n",
        "\n",
        "* **Purpose:** MMR is a ranking algorithm used to ensure diversity and avoid redundancy in search results. In LLM retrieval, it works after ANN has identified potential relevant passages.\n",
        "\n",
        "* **Role in LLM Retrieval:**\n",
        "    * **Diversification of Results:** MMR aims to prevent the top results from all being too similar to each other. Instead, it promotes including passages that, while relevant, also cover different aspects or perspectives related to the query.\n",
        "    * **Improving User Experience:** This diversification helps the LLM provide a more comprehensive and informative set of responses to the user, reducing the likelihood of receiving repetitive information.\n",
        "\n",
        "**How ANN and MMR Work Together**\n",
        "\n",
        "1. **User Query:** The user enters a query or question.\n",
        "2. **ANN Retrieval:** Using the ANN algorithm, a set of potentially relevant passages is efficiently retrieved from a large text corpus.\n",
        "3. **MMR Ranking:** MMR analyzes the retrieved passages and reranks them, prioritizing both relevance to the query and diversity within the results.\n",
        "4. **Return to LLM:** The top-ranked passages may be fed back into the LLM for further processing, allowing the LLM to generate a more informed and helpful response.\n",
        "\n",
        "**Let me know if you'd like more details on the technical aspects of specific ANN algorithms or how MMR calculates diversity!**\n"
      ],
      "metadata": {
        "id": "weryLPVwuvxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your favorite cloud data warehouse now supports vector search and vector indexes, see https://lnkd.in/g3ztYWWy. How cool is that? BigQuery vector search lets you find semantically similar items in a table using by comparing the distance of  vector embeddings. Find similar customers, articles, products, locations. This is super useful for integrating LLMs with your data and validating LLM output. The best thing is that you don't need another product to do it."
      ],
      "metadata": {
        "id": "lVvlo-1MCdjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " are announcing the Public Preview of BigQuery Vector Search. This functionality, also commonly referred to as approximate nearest-neighbor search, is key to empowering numerous new data and AI use cases such as semantic search, similarity detection, and retrieval-augmented generation (RAG) with a large language model (LLM).\n",
        "\n",
        "Vector search is often performed on high-dimensional numeric vectors, a.k.a. embeddings, which incorporate a semantic representation for an entity and can be generated from numerous sources, including text, image, or video. BigQuery vector search relies on an index to optimize the lookups and distance computations required to identify closely matching embeddings.\n",
        "\n",
        "Our framework supports multiple Vector Index types, with the first implemented type (IVF) combining (a) an optimized [BQML](https://cloud.google.com/bigquery/docs/bqml-introduction) KMeans clustering model with (b) an inverted row locator, which is automatically updated as the underlying table data mutates (similar to [BigSearch](https://cloud.google.com/bigquery/docs/search-index)). It works with BigQuery’s embedding-generation capabilities, notably via LLM-based or pre-trained models. Yet the generic interface allows users to use embeddings generated via other means as well.\n",
        "\n",
        "New optimizations, features, index types, and the GA launch are expected in Q2/Q3 2024.\n",
        "\n",
        "Public Launch Material\n",
        "* Launch blog: https://cloud.google.com/blog/products/data-analytics/introducing-new-vector-search-capabilities-in-bigquery?hl=en\n",
        "* Public documentation: https://cloud.google.com/bigquery/docs/vector-search-intro\n",
        "* Tutorial 1 for using with existing embeddings: https://cloud.google.com/bigquery/docs/vector-search\n",
        "* Tutorial 2 for combining with embedding generation and RAG: https://cloud.google.com/bigquery/docs/vector-index-text-search-tutorial\n",
        "* LangChain integration: https://python.langchain.com/docs/integrations/vectorstores/bigquery_vector_search\n",
        "\n",
        "What does the introduced syntax and usage look like?\n",
        "1. Create Vector Index\n",
        "CREATE OR REPLACE VECTOR INDEX <my_index> ON <my_table>(embedding_col)\n",
        "OPTIONS (distance_type=\"COSINE\", index_type=\"IVF\");\n",
        "2. Vector SearchSELECT <columns> FROM VECTOR_SEARCH (TABLE <my_table>, 'embedding_col', (SELECT embedding_col FROM <test_table> WHERE <>));\n",
        "\n",
        "3. (Optional) Monitor Indexing Progress AnytimeSELECT table_name, index_name, coverage_percentage, unindexed_row_count\n",
        "FROM `<myproject.mydataset>.INFORMATION_SCHEMA.VECTOR_INDEXES` WHERE index_status = 'ACTIVE';\n",
        "4. Example RAG query, combining embedding generation, vector search, and LLM text generation:SELECT ml_generate_text_llm_result AS generated, prompt\n",
        "FROM ML.GENERATE_TEXT(\n",
        "   MODEL `<LLM_text_generation_model>`,\n",
        "   (SELECT CONCAT('Propose some project ideas to improve user password security using the context below: ', STRING_AGG(FORMAT(\"patent title: %s, patent abstract: %s\", base.title, base.abstract), ',\\n')) AS prompt, FROM VECTOR_SEARCH(\n",
        "         TABLE `<patents_my_embeddings_table>`, 'text_embedding',\n",
        "         (SELECT text_embedding, content AS query\n",
        "           FROM ML.GENERATE_TEXT_EMBEDDING(\n",
        "               MODEL `<LLM_embedding_model>`,\n",
        "               (SELECT 'improving password security' AS content))), top_k => 5)\n",
        "   ), STRUCT(0.4 AS temperature, 300 AS max_output_tokens, 0.5 AS top_p, 5 AS top_k, TRUE AS flatten_json_output));\n"
      ],
      "metadata": {
        "id": "LHnqM83Capic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Vector Retrieval*\n",
        "\n",
        "https://arxiv.org/abs/2401.09350: Foundations of Vector Retrieval"
      ],
      "metadata": {
        "id": "nRhWlzbKrZ5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Special: Knowledge Graph*"
      ],
      "metadata": {
        "id": "NxI60357-N2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://neo4j.com/labs/genai-ecosystem/"
      ],
      "metadata": {
        "id": "-QrtL9Cs-QXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Evaluate LLMs*"
      ],
      "metadata": {
        "id": "J4ZBVKqKqAbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Evaluation*\n",
        "\n",
        "**Automatic Side-by-Side (AutoSxS)**\n",
        "\n",
        "https://cloud.google.com/vertex-ai/docs/generative-ai/models/side-by-side-eval\n",
        "\n",
        "**Metrics-based evaluation**\n",
        "\n",
        "https://cloud.google.com/vertex-ai/docs/generative-ai/models/evaluate-models\n",
        "\n",
        "**Vertex AI Model Evaluation**\n",
        "\n",
        "Vertex AI Model Evaluation provides a comprehensive framework for evaluating LLMs across a wide range of tasks, including natural language understanding (NLU), natural language generation (NLG), and question answering. It allows you to define custom evaluation metrics and compare performance over time.\n",
        "\n"
      ],
      "metadata": {
        "id": "d2RwjKyMVbg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*MLOps*"
      ],
      "metadata": {
        "id": "vOqtFAy5GKtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's for example a reference architecture for an infrastructure to run a retrieval-augmented generation (RAG) application using Vertex AI. Obviously not the only way to do it, but a good way to do it.\n",
        "\n",
        "This architecture includes three components:\n",
        "- Data ingestion subsystem\n",
        "- Serving subsystem\n",
        "- Quality evaluation subsystem\n",
        "\n",
        "https://cloud.google.com/architecture/rag-capable-gen-ai-app-using-vertex-ai?hl=de"
      ],
      "metadata": {
        "id": "m46jcaVOtJMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vertex-ai/docs/general/deployment?hl=de\n",
        "\n",
        "https://blog.ml6.eu/vertex-pipelines-vertex-ai-vs-ai-platform-6c2f799d6e2e?gi=5a1dbe25d735"
      ],
      "metadata": {
        "id": "mdsVo5zvjjd_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excited to share that a new tutorial on Ray on Vertex AI is now available! 🔥\n",
        "\n",
        "This tutorial will take you through the process of distributing PyTorch model training using Ray on Vertex AI and deploying it to Vertex AI Endpoint.\n",
        "\n",
        "To learn more, you can find the notebook link on GitHub 👇 . And if you have any ideas for more Ray on Vertex AI content you'd like to see, let me know.\n",
        "\n",
        "Get started with PyTorch on Ray on Vertex AI\n",
        "https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/ray_on_vertex_ai/get_started_with_pytorch_rov.ipynb"
      ],
      "metadata": {
        "id": "J5QrNO-MIfPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/google-cloud/machine-learning-pipeline-development-on-google-cloud-5cba36819058"
      ],
      "metadata": {
        "id": "Fq4EBdvhFC13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning"
      ],
      "metadata": {
        "id": "8MmOgfMSHSYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vertex-ai/docs/start/introduction-mlops"
      ],
      "metadata": {
        "id": "It97BIplHWWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Google*"
      ],
      "metadata": {
        "id": "EV6x8bY7pvDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Three Decades of Activations: A Comprehensive Survey of 400 Activation Functions for Neural Networks offers the most extensive overview of activation functions to date. It aims to streamline the selection process for researchers and practitioners, reducing redundancy and the unintentional rediscovery of functions.\n",
        "\n",
        "https://arxiv.org/abs/2402.09092\n",
        "\n",
        "\n",
        "Unifying Large Language Models and Knowledge Graphs: A Roadmap\n",
        "\n",
        "https://arxiv.org/abs/2306.08302"
      ],
      "metadata": {
        "id": "JKXH9meQFzR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Google Products*"
      ],
      "metadata": {
        "id": "WnAvpRxbPSwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vertex AI! 🎉\n",
        "\n",
        "🔎 You can now query an index from the Vector Search console, making it even easier to validate your retrievals.\n",
        "\n",
        "🌻 New models have been added to the Model Garden, including Stable Diffusion XL LCM, LLaVA 1.5, PyTorch-ZipNeRF, WizardLM, and more.\n",
        "\n",
        "🎥 Multimodal Embeddings video support went GA, giving you the possibility to extend your AI applications.\n",
        "\n",
        "✨ Vertex AI Gemini 1.0 Pro and Gemini 1.0 Pro Vision multimodal language models also went GA!\n",
        "\n",
        "Overview of multimodal models\n",
        "https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/overview\n",
        "\n",
        "Multimodal video embeddings\n",
        "https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-multimodal-embeddings#vid-img-txt-request\n",
        "\n",
        "Vertex AI Vector search\n",
        "https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index"
      ],
      "metadata": {
        "id": "J_TrPlyPP6Um"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview\n",
        "\n",
        "https://www.linkedin.com/in/deltorobarba/recent-activity/reactions/\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1699.jpeg)"
      ],
      "metadata": {
        "id": "ImUnO-bDTkNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "book: Official Google Cloud Certified Professional Machine Learning Engineer Study Guide, https://www.amazon.com/dp/1119944465?ref_=cm_sw_r_mwn_dp_QEQREW6ES28470H5333A&language=en-US"
      ],
      "metadata": {
        "id": "ehkWx65LkI5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.linkedin.com/pulse/use-mistral-llms-locally-your-computer-lm-studio-windows-molina-ldmje"
      ],
      "metadata": {
        "id": "tkRhOULDj_Xz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.linkedin.com/pulse/gemini-look-my-food-give-me-new-ideas-filipe-gracio-phd-tl4be"
      ],
      "metadata": {
        "id": "EiWGjWMykCYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Lumiere*\n",
        "\n",
        "The first generative video goodness of 2024 is in: Lumiere. A text-to-video, image-to-video, and stylized video generation model from Google Research.\n",
        "\n",
        "Lumiere demonstrates state-of-the-art video generation results with a new model design that facilitates a wide range of content creation tasks such as video editing, video in-painting, and stylized generation.\n",
        "\n",
        "While existing video models first synthesize distant keyframes then apply temporal super-resolution to make videos look temporally consistent, Lumiere generates the entire temporal duration of the video at once, through a single pass in the model. This makes the videos look more realistic.\n",
        "\n",
        "Paper: https://lnkd.in/dvcWNCtp\n",
        "Video: https://lnkd.in/deQHkxFj"
      ],
      "metadata": {
        "id": "3fNy3RrnyTa3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Appendix: Models*"
      ],
      "metadata": {
        "id": "1Amg0O9YxNcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Differentiable Programming and Probabilistic Programming*\n",
        "\n",
        "![ggg](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1701.jpg)\n",
        "\n",
        "https://www.lokad.com/blog/2024/1/29/probabilistic-exponential-smoothing-for-explainable-ai-in-supply-chain/"
      ],
      "metadata": {
        "id": "or8sN-Vzjadz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Computational Learning*"
      ],
      "metadata": {
        "id": "dEY-ynaCNWkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Model vs Circuit Capacity (Complexity / Expressivity)*"
      ],
      "metadata": {
        "id": "YY-9SFOGdbPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Model vs Circuit Capacity (Complexity / Expressivity)*\n",
        "\n",
        "- What is meant by: In neural networks the differentiation rules, that we use, scale linearly with the number of parameters. In variational circuits the differentiation rules, that we use, scale quadratically with the number of parameters.\n",
        "- Automatic differentiation is based on recycling values of gradients, so that not for every parameter they have to run the whole network again, forwards and backwards.\n",
        "- Challenge: Just guessing an ansatz (expressive)\n",
        "- Adding more layers = Increase the frequency of the cosine kernel?? - Min 27: [QML Meetup: Dr Maria Schuld, Taking stock of quantum machine learning - a critical perspective](https://youtu.be/8bfUMdj0-x4), then just repeating these layers of encoding would be better. In many cases making an embedding and then repeating it makes the model class richer.\n",
        "- Quantum advantage for learning is currently still ill-posed.\n",
        "- What is meant by quantum speedup? Different concepts. It’s always relative to something.\n",
        "- And what do you mean by ‘more powerful’: learning or speedup? Etc.\n",
        "\n",
        "> How can I prove that my ansatz is classically intractable? versus **What is an ansatz design that allows gradient-descent to scale as efficient as it does when training neural networks?**\n",
        "\n",
        "> How can I show that QML is more powerful? versus **How can I understand what QML is doing?**\n",
        "\n",
        "https://www.youtube.com/watch?v=8bfUMdj0-x4&t=1621s\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1609.png)\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1610.png)"
      ],
      "metadata": {
        "id": "zrowK8QAUvAg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Concept and Hypothesis*"
      ],
      "metadata": {
        "id": "L_xE9c7WKnUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Jens Eisert - Do quantum computers have application in machine learning & combinatorial optimization](https://www.youtube.com/watch?v=DgCNmk4kvVs&list=WL&index=11&t=827s)"
      ],
      "metadata": {
        "id": "IzhwAXtGdmvy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis class = Function Family I'm considering for learning\n",
        "\n",
        "Concept class = true relationship between data and labels"
      ],
      "metadata": {
        "id": "uxUNTV6yhxzT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Concept class**\n",
        "\n",
        "A concept class in computational learning theory is a set of target concepts or functions that a learning algorithm is trying to learn. For example, a concept class could be the set of all Boolean functions, or the set of all linear functions.\n",
        "\n",
        "Concept class refers to the set of all possible concepts or functions that the learner is trying to learn or approximate. It represents the underlying target concept that the learner is trying to capture.\n",
        "\n",
        "\n",
        "**Hypothesis**\n",
        "\n",
        "A hypothesis in computational learning theory is a candidate solution to a learning problem. For example, a hypothesis for learning a Boolean function could be a decision tree, or a neural network.\n",
        "\n",
        "Hypothesis is a subset of the concept class that the learner uses to approximate or represent the target concept. It's the set of functions or models that the learner considers as potential solutions to the learning problem.\n",
        "\n",
        "\n",
        "**Learner**\n",
        "\n",
        "A learner in computational learning theory is an algorithm that takes training examples as input and outputs a hypothesis. The goal of the learner is to find a hypothesis that is consistent with the training data and that will generalize well to new data.\n",
        "\n",
        "The learner is the algorithm or method used to search through the hypothesis space and select the best hypothesis that approximates the target concept based on available training data.\n",
        "\n",
        "\n",
        "Here are some specific examples of concept classes, hypotheses, and learners in computational learning theory:\n",
        "\n",
        "Example 1:\n",
        "\n",
        "* **Concept class:** The set of all Boolean functions\n",
        "* **Hypothesis:** A decision tree\n",
        "* **Learner:** The ID3 algorithm\n",
        "\n",
        "Example 2:\n",
        "\n",
        "* **Concept class:** The set of all linear functions\n",
        "* **Hypothesis:** A linear regression model\n",
        "* **Learner:** The least squares algorithm\n",
        "\n",
        "Example 3:\n",
        "\n",
        "* **Concept class:** The set of all images of cats\n",
        "* **Hypothesis:** A convolutional neural network\n",
        "* **Learner:** The Adam optimizer\n",
        "\n",
        "Other examples:\n",
        "\n",
        "* **Concept class:**\n",
        "  * Equivalently, a concept c is a subset of {0,1}n, namely {x : c(x) = 1}. Let C ⊆ {f : {0,1}n → {0,1}} be a concept class. This could for example be the class of functions computed by disjunctive normal form (DNF) formulas of a certain size, or Boolean circuits or decision trees of a certain depth. https://arxiv.org/pdf/1607.00932.pdf\n",
        "  * Set of all Boolean functions: If you are dealing with a problem where the underlying target concept or function you want to learn is inherently Boolean in nature (i.e., it maps inputs to binary outputs, such as 0 or 1), then Boolean functions can be the concept class.\n",
        "  * set of all linear functions: Linear functions can be considered the concept class when the underlying target concept is believed to be a linear relationship between inputs and outputs. In this case, the concept class consists of all possible linear functions that could describe the target concept. Example: If you are working on a regression problem where you want to predict a numerical value based on input features, and you believe that the relationship is linear, the concept class could be all possible linear functions.\n",
        "  * Unitary transformations\n",
        "  * Example: In a binary classification problem where you want to distinguish between spam and non-spam emails, the concept class could be the set of all possible decision boundaries that separate spam emails from non-spam emails in the feature space. Each decision boundary represents a different concept in the concept class.\n",
        "  * For agnostic learner:  In the case of binary classification (e.g., spam vs. non-spam email classification), the agnostic concept class might represent all possible ways to separate the two classes in the feature space without assuming any specific data distribution. It could include various decision boundaries, non-linear separations, or complex relationships between features and labels.\n",
        "  * Gibbs states, also known as Gibbs distributions or Gibbs measures, are mathematical constructs from statistical physics and probability theory. They are used to model the probability distributions of physical systems consisting of multiple interacting components (particles, spins, etc.). In the context of computational learning theory, Gibbs states can be considered as a concept class when they are used to model or represent the set of all possible probability distributions over a space of random variables. Concept classes represent the set of all possible underlying target concepts or functions that the learner is trying to learn or approximate. In this case, Gibbs states represent a class of possible probability distributions.\n",
        "* **Hypothesis:**\n",
        "  * Boolean functions: Boolean functions can also be used as the hypothesis set, representing the set of candidate models or classifiers that the learner considers as potential solutions to the problem. In this case, you are considering Boolean functions as candidate hypotheses for approximating the target concept. Example: In binary classification tasks, you might consider simple Boolean functions (e.g., \"If feature A is true and feature B is false, output 1; otherwise, output 0\") as potential hypotheses for classifying data points.\n",
        "  * Linear functions: Linear functions can also be used as the hypothesis set when you are considering linear models as potential hypotheses for approximating the target concept. In this case, you are using linear functions as candidate models to fit the data and learn the mapping between inputs and outputs. Example: Linear regression models, which use linear functions to model relationships between features and outcomes, can be considered as hypotheses in a regression problem.\n",
        "  * decision tree with regularization\n",
        "  * linear regression model with regularization\n",
        "  * neural network: As a hypothesis, a neural network can be used to represent a specific function or concept. For example, a neural network could be trained to represent the function that maps an image to a probability distribution over different categories. e.g.: convolutional neural network with regularization\n",
        "  * Example: In the context of linear classification, the hypothesis space could be the set of all possible linear classifiers (e.g., support vector machines, logistic regression). Each linear classifier within this space is a hypothesis used to approximate the target concept.\n",
        "  * For agnostic learner: The agnostic hypothesis set could include various types of models, such as decision trees, support vector machines, neural networks, or any other model that can be used for binary classification. These models are chosen based on their flexibility and general applicability, allowing the learner to explore a wide range of possibilities without being tied to specific distributional assumptions.\n",
        "* **Learner:**\n",
        "  * agnostic learner, and examples of agnostic learners:\n",
        "    * Support vector machines\n",
        "    * Random forests\n",
        "    * Neural networks: As a learner, a neural network can be used to learn a wide variety of functions and concepts. This is because neural networks are able to approximate any continuous function to arbitrary accuracy, given enough neurons and hidden layers. In practice, neural networks are typically used as learners. This is because neural networks are able to learn from data without being given any prior knowledge about the function or concept that they are trying to learn.\n",
        "    * A perceptron is a type of artificial neuron that is used in machine learning. It is the simplest type of artificial neuron and is the building block of more complex neural networks.\n",
        "  * proper learner\n",
        "  * online learner (spam filter, stock trading algorithm, recommendation system)\n",
        "  * active learner\n",
        "  * Example: For supervised learning tasks, a learner could be a decision tree algorithm, a neural network, or a k-nearest neighbors classifier. The learner's role is to use the training data to find the hypothesis (model) that minimizes a certain loss function or error measure.\n",
        "\n",
        "\n",
        "*It is important to note that a learning algorithm may use different hypotheses for different concept classes. For example, the ID3 algorithm can be used to learn decision trees for any concept class, but the least squares algorithm can only be used to learn linear functions.*\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dpelTUvXhJ2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problems / Use Cases (and representations of states and operations):**\n",
        "* **Hamiltonian learning**: is the process of learning the Hamiltonian of a quantum system. The Hamiltonian is a mathematical object that describes the energy of a quantum system. Knowing the Hamiltonian of a quantum system allows us to predict its behavior and to design experiments to control it.\n",
        "  * Designing quantum computers to perform specific tasks\n",
        "  * Developing new quantum algorithms\n",
        "  * Understanding the fundamental properties of quantum matter\n",
        "  * The main difference between Hamiltonian learning and learning unitary dynamics is that Hamiltonian learning is more general. By learning the Hamiltonian of a quantum system, we can learn its unitary evolution, as well as other properties of the system. However, learning the unitary evolution of a quantum system does not necessarily tell us anything about the Hamiltonian of the system.\n",
        "  * Another difference between Hamiltonian learning and learning unitary dynamics is that Hamiltonian learning is typically more difficult. This is because the Hamiltonian of a quantum system is typically a complex function of many parameters. In contrast, the unitary evolution of a quantum system can often be described by a simpler mathematical object, such as a matrix.\n",
        "  * Hamiltonian learning is a process of learning the Hamiltonian of a quantum system. The Hamiltonian of a quantum system is a mathematical object that describes the energy of the system. Knowing the Hamiltonian of a quantum system allows us to predict its behavior and to design experiments to control it.\n",
        "  * Hamiltonian learning can be used to learn a variety of quantum concepts and functions. For example, Hamiltonian learning can be used to learn the ground state of a quantum system, the energy levels of a quantum system, and the unitary evolution of a quantum system.\n",
        "* **Learning unitary dynamics**: is the process of learning the unitary evolution of a quantum system. The unitary evolution of a quantum system describes how the state of the system changes over time. Knowing the unitary evolution of a quantum system allows us to design experiments to perform specific tasks, such as quantum computing and quantum teleportation.\n",
        "  * Controlling quantum systems to perform specific tasks, such as quantum teleportation and quantum cryptography\n",
        "  * Developing new quantum measurement techniques\n",
        "  * Understanding the dynamics of complex quantum systems\n",
        "* **Learning unknown element U of the Clifford group on n qubits**\n",
        "  * learning a Clifford element U is a special case of both Hamiltonian learning and learning unitary dynamics.\n",
        "  * The Clifford group is a subset of the unitary group, which is the group of all unitary transformations on n qubits. This means that every Clifford element U can be represented by a unitary matrix. Therefore, learning a Clifford element U is equivalent to learning a unitary transformation.\n",
        "  * The Hamiltonian of a quantum system is a unitary operator. This means that the evolution of a quantum system over time can be described by a unitary transformation. Therefore, learning the Hamiltonian of a quantum system is equivalent to learning a unitary transformation.\n",
        "* **Gibbs state**\n",
        "  * Gibbs states are a type of probability distribution over the states of a physical system. They are typically used in statistical physics to model the behavior of systems at equilibrium.\n",
        "  * Gibbs states can be used to learn about the properties of a physical system. For example, we can use Gibbs states to learn about the energy levels of a system, or the phase transitions that the system can undergo.\n",
        "* **Tomography, both quantum state tomography (QST) and quantum shadow tomography (QST)**\n",
        "* **DNF formulas** themselves are not hypotheses or learners. They are simply a way of representing Boolean functions.\n",
        "* **Bell sampling**:\n",
        "  * Bell sampling is a technique for measuring the correlations between pairs of qubits. It can be used to learn about the properties of quantum states, but it is not a learner in the traditional sense.\n",
        "  * Bell sampling does not take training examples as input. Instead, it takes measurements of a quantum state as input.\n",
        "  * Bell sampling does not output a hypothesis. Instead, it outputs a set of correlation measurements.\n",
        "  * However, Bell sampling can be used as part of a learning algorithm. For example, Bell sampling can be used to learn the Hamiltonian of a quantum system.\n",
        "* **stabilizer state** can be a concept class or hypothesis:\n",
        "  * Stabilizer states as a concept class\n",
        "    * A stabilizer state is a quantum state that is invariant under the action of a set of Pauli operators. Pauli operators are unitary operators that act on individual qubits.\n",
        "    * Stabilizer states are a useful concept in quantum computing because they can be efficiently prepared and manipulated.\n",
        "    * Stabilizer states can be used to represent a wide variety of quantum concepts and functions. For example, stabilizer states can be used to represent Boolean functions, linear functions, and unitary transformations.\n",
        "    * Therefore, stabilizer states can be used to define a concept class in computational learning theory.\n",
        "  * Stabilizer states as a hypothesis\n",
        "    * A stabilizer state can also be used as a hypothesis for learning a quantum concept or function.\n",
        "    * For example, we can use a quantum algorithm to learn a stabilizer state that represents a Boolean function.\n",
        "    * Once we have learned the stabilizer state, we can use it to evaluate the Boolean function on any input.\n",
        "    * Therefore, stabilizer states can be used as hypotheses in computational learning theory.\n",
        "* **Thermal state learning**:\n",
        "  * Thermal state learning is a technique for learning the thermal state of a quantum system. The thermal state of a quantum system is the state that the system will eventually reach if it is allowed to interact with its environment for a long time.\n",
        "  * Thermal state learning can be used to learn about the properties of quantum systems. However, it is not a concept class, hypothesis, or learner in the traditional sense."
      ],
      "metadata": {
        "id": "eR530ZtNhisC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning classical functions (through quantum encoding)**\n",
        "\n",
        "\n",
        "* **Boolean functions**: [Boolean functions](https://de.m.wikipedia.org/wiki/Boolesche_Funktion): Fourier analysis of functions on the Boolean cube, [Boolesche_Algebra](https://de.m.wikipedia.org/wiki/Boolesche_Algebra), [Boolean_circuit](https://en.m.wikipedia.org/wiki/Boolean_circuit) and [Analysis_of_Boolean_functions](https://en.m.wikipedia.org/wiki/Analysis_of_Boolean_functions): A concept c : {0,1}$^n$ → {0,1} by its N-bit truth-table (with N = 2$^n$), hence C ⊆ {0,1}$^N$\n",
        "\n",
        "  * An **N-bit truth table is a truth table that has N rows**, where each row represents one possible combination of truth values for the N input variables. The output variable is listed in the last column of the truth table.\n",
        "  \n",
        "  * For example, a **2-bit truth table would have 2 rows**, representing the two possible combinations of truth values for the two input variables. The output variable would be listed in the third column.\n",
        "  \n",
        "  * Below is an example of a 2-bit truth table for the logical function AND.\n",
        "\n",
        "> ```\n",
        "Input 1 | Input 2  | Output\n",
        "------- | -------- | --------\n",
        "0       | 0        | 0\n",
        "0       | 1        | 0\n",
        "1       | 0        | 0\n",
        "1       | 1        | 1\n",
        "```\n",
        "\n",
        "\n",
        "* **Parities**: The concept classes consisting of parities\n",
        "\n",
        "* **DNF formulas** [(Disjunctive Normal Form)](https://de.m.wikipedia.org/wiki/Disjunktive_Normalform)\n",
        "\n",
        "  * it is not known whether DNF is PAC-learnable\n",
        "\n",
        "* **Juntas**: Special case of DNF: (log n) juntas.\n",
        "\n",
        "  * A k-junta is a Boolean function that depends on at most k variables. In other words, a k-junta is a function f : {0, 1}^n → {0, 1} such that there exists a set S ⊆ [n] of size |S| ≤ k such that f(x) = f(y) for all x, y ∈ {0, 1}^n such that x and y agree on all variables in S.\n",
        "\n",
        "  * K-juntas are a natural class of functions to study in computational learning theory because they are relatively simple to learn. In fact, it is known that k-juntas can be learned in time polynomial in n and k. In circuit complexity, k-juntas can be used to lower bound the complexity of certain problems. Here are some examples of k-juntas:\n",
        "\n",
        "    * The function f(x) = x1 AND x2 AND x3 is a 3-junta.\n",
        "    * The function f(x) = x1 OR x2 OR x3 is not a 3-junta, because it depends on all 3 variables.\n",
        "    * The function f(x) = ¬x1 is a 1-junta.\n",
        "\n",
        "* **Sparse functions**, can be learned under the uniform distribution in the QSQ model."
      ],
      "metadata": {
        "id": "bylhFiAhcFVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning physical quantum states (through quantum encoding)** with classical or quantum computers\n",
        "\n",
        "* **Quantum state identification problem**: *Fully learning arbitrary quantum states could require exponentially many copies of the unknown state. But: Look at physical subclasses of quantum states which can be learned using polynomially many copies. So what classes of quantum states are learnable efficiently and why some classes of states are hard to learn? (Source: Survey on the complexity of learning quantum states)*\n",
        "* Learning **Quantum k-uniform states**\n",
        "* Learning **Stabilizer states** (Clifford gates)\n",
        "* Learning **Gibbs states**\n",
        "* Learning **States from Clifford hierarchy** and **Distributions induced by Clifford circuits** (*can be learned in the QSQ framework, however, if we add a single T gate, then classical SQ learning the output distribution is as hard as learning parities with noise*)\n",
        "* Learning **Circuits with non-Clifford gates**\n",
        "* Learning **Phase states**\n",
        "* Learning **Matrix Product States**\n",
        "* Learning **Product States**\n",
        "\n"
      ],
      "metadata": {
        "id": "nSmcViuznOTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Concept Class and Hypothesis Class** - What can be learnt?\n",
        "\n",
        "The [Concept Class](https://en.m.wikipedia.org/wiki/Concept_class) (=limited by our use case) contains the true relationships (all possible things) we want to learn = Linear and non-linear functions for a spam filter.\n",
        "  * The \"true\" function or the actual relationship might be unknown to us. Our goal in learning is to approximate it.\n",
        "  * A concept class is a set of **all possible concepts that can be learned**. A concept is a set of inputs that produce the same output. For example, the concept class is the set of all possible images of cats and dogs. The hypothesis class is the set of all possible neural networks with 3 layers. The learner is the gradient descent algorithm.\n",
        "  * See also [Concept learning](https://en.m.wikipedia.org/wiki/Concept_learning)\n",
        "\n",
        "The [Hypothesis Class](https://en.m.wikipedia.org/wiki/Hypothesis_Theory) (=limited by our learner from space of concept classes, used to approximate a concept) (e.g. neural network or ID3 decision tree) : While the concept class denotes the true relationships, the hypothesis class is the set of functions that a learning algorithm considers when trying to produce a model from dat\n",
        "  * = Set of models we consider based on our chosen learning method (set of all possible ways we can represent the things we want to learn). Set of models or functions that our chosen learning algorithm can possibly produce = only linear functions (This might miss out on some true nonlinear relationships present in the concept class).\n",
        "  * goal of a learning algorithm (the learner) is to probably approximate some unknown target concept c ∈ C from random labeled examples (from \"Optimal Quantum Sample Complexity of Learning Algorithms\")\n",
        "  * An ideal situation is when our chosen hypothesis class contains the true function (from the concept class). However, this is not always the case, which is why choosing the right type of model (and thereby the right hypothesis class) is crucial in machine learning.\n",
        "  * Hypothesis Class: In classification in general, the hypothesis class is the **set of possible (classification) functions** you're considering; the **learning algorithm picks a function from the hypothesis class**. For a decision tree learner, the hypothesis class would just be the set of all possible decision trees. [Source](https://stats.stackexchange.com/questions/270324/what-is-a-hypothesis-class-in-svm)\n",
        "  * Example: **A quantum PAC learner is given copies of the quantum example state, performs a POVM (where each outcome of the POVM is associated with an hypothesis) and outputs the resulting hypothesis.** *from: Survey on the complexity of learning quantum states,page 20*\n",
        "\n",
        "**Differentiate:** [Induktive_Verzerrung](https://de.wikipedia.org/wiki/Induktive_Verzerrung), [Hypothesenraum](https://de.wikipedia.org/wiki/Hypothesenraum), [Versionsraum](https://de.wikipedia.org/wiki/Versionsraum) und [Sample_space (Ergebnisraum)](https://en.m.wikipedia.org/wiki/Sample_space)"
      ],
      "metadata": {
        "id": "TJyjPP6sPHXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Concept class**\n",
        "\n",
        "A concept class in computational learning theory is a set of target concepts or functions that a learning algorithm is trying to learn. For example, a concept class could be the set of all Boolean functions, or the set of all linear functions.\n",
        "\n",
        "**Hypothesis**\n",
        "\n",
        "A hypothesis in computational learning theory is a candidate solution to a learning problem. For example, a hypothesis for learning a Boolean function could be a decision tree, or a neural network.\n",
        "\n",
        "**Learner**\n",
        "\n",
        "A learner in computational learning theory is an algorithm that takes training examples as input and outputs a hypothesis. The goal of the learner is to find a hypothesis that is consistent with the training data and that will generalize well to new data.\n",
        "\n",
        "Here are some specific examples of concept classes, hypotheses, and learners in computational learning theory:\n",
        "\n",
        "**Concept class:** The set of all Boolean functions\n",
        "**Hypothesis:** A decision tree\n",
        "**Learner:** The ID3 algorithm\n",
        "\n",
        "**Concept class:** The set of all linear functions\n",
        "**Hypothesis:** A linear regression model\n",
        "**Learner:** The least squares algorithm\n",
        "\n",
        "**Concept class:** The set of all images of cats\n",
        "**Hypothesis:** A convolutional neural network\n",
        "**Learner:** The Adam optimizer\n",
        "\n",
        "It is important to note that a learning algorithm may use different hypotheses for different concept classes. For example, the ID3 algorithm can be used to learn decision trees for any concept class, but the least squares algorithm can only be used to learn linear functions.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "Concept classes, hypotheses, and learners are the fundamental building blocks of computational learning theory. By understanding these concepts, we can better understand how machine learning algorithms work and how to choose the right algorithm for a particular problem."
      ],
      "metadata": {
        "id": "J9VhxgFyXAQp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In computational learning theory, there are three fundamental components: concept class, hypothesis, and learner. Let's define each of these concepts and provide examples:\n",
        "\n",
        "1. Concept Class:\n",
        "   - Concept class refers to the set of all possible concepts or functions that the learner is trying to learn or approximate. It represents the underlying target concept that the learner is trying to capture.\n",
        "   - Example: In a binary classification problem where you want to distinguish between spam and non-spam emails, the concept class could be the set of all possible decision boundaries that separate spam emails from non-spam emails in the feature space. Each decision boundary represents a different concept in the concept class.\n",
        "\n",
        "2. Hypothesis:\n",
        "   - Hypothesis is a subset of the concept class that the learner uses to approximate or represent the target concept. It's the set of functions or models that the learner considers as potential solutions to the learning problem.\n",
        "   - Example: In the context of linear classification, the hypothesis space could be the set of all possible linear classifiers (e.g., support vector machines, logistic regression). Each linear classifier within this space is a hypothesis used to approximate the target concept.\n",
        "\n",
        "3. Learner:\n",
        "   - The learner is the algorithm or method used to search through the hypothesis space and select the best hypothesis that approximates the target concept based on available training data.\n",
        "   - Example: For supervised learning tasks, a learner could be a decision tree algorithm, a neural network, or a k-nearest neighbors classifier. The learner's role is to use the training data to find the hypothesis (model) that minimizes a certain loss function or error measure.\n",
        "\n",
        "To summarize with an example:\n",
        "Suppose you have a binary classification problem of identifying whether an email is spam or not. The concept class includes all possible ways to separate spam and non-spam emails in the feature space. Hypotheses within this class might include different decision trees, support vector machines with various kernel functions, or neural network architectures. The learner is the specific algorithm you choose to train on your labeled data, like a decision tree learning algorithm or a neural network training algorithm. The learner's job is to select the best hypothesis (e.g., the best decision tree or neural network parameters) to approximate the underlying concept of distinguishing spam from non-spam emails."
      ],
      "metadata": {
        "id": "MzFCmSojXBxq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning [quantum circuit complexity](https://en.m.wikipedia.org/wiki/Circuit_complexity)**\n",
        "\n",
        "*For example Minimum Circuit Size Problem (MCSP), a Meta-Complexity problem*\n",
        "\n",
        "> [Linear growth of quantum circuit complexity](https://arxiv.org/abs/2106.05305): Consider constructing deeper and deeper circuits for an n-qubit system, by applying random two-qubit gates. At what rate does the circuit complexity increase?\n",
        "\n",
        "> [The geometry of quantum computation](https://arxiv.org/abs/quant-ph/0701004): Determining the quantum circuit complexity of a unitary operation is closely related to the problem of finding minimal length paths in a particular curved geometry.\n",
        "\n",
        "* [Quantum Computation as Geometry](https://arxiv.org/abs/quant-ph/0603161)\n",
        "\n",
        "\n",
        "* [Linear growth of quantum circuit complexity](https://www.nature.com/articles/s41567-022-01539-6)\n",
        "\n",
        "* [On the average-case complexity of learning output distributions of quantum circuits](https://arxiv.org/abs/2305.05765)\n",
        "\n",
        "* [Quantum circuit complexity](https://en.m.wikipedia.org/wiki/Quantum_complexity_theory)"
      ],
      "metadata": {
        "id": "tHuhYcixzHNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Undecidability of Learnability (Learnability = Computable?)**\n",
        "* https://arxiv.org/abs/2106.01382\n",
        "* However, there is no known general-purpose procedure for rigorously evaluating whether newly proposed models indeed successfully learn from data. We show that such a procedure cannot exist.\n",
        "* For PAC binary classification, uniform and universal online learning, and exact learning through teacher-learner interactions, learnability is in general undecidable, both in the sense of independence of the axioms in a formal system and in the sense of uncomputability.\n",
        "* Our proofs proceed via computable constructions of function classes that encode the consistency problem for formal systems and the halting problem for Turing machines into complexity measures that characterize learnability.\n",
        "* Our work shows that undecidability appears in the theoretical foundations of machine learning: There is no one-size-fits-all algorithm for deciding whether a machine learning model can be successful. **We cannot in general automatize the process of assessing new learning models.**\n",
        "* Figure 1: A depiction of our line of reasoning. “Complexity” is to be understood in terms of VC-dimension, teaching dimension, Littlestone dimension, or Littlestone trees, depending on the learning model. To conclude undecidability, we use G ̈odel’s second incompleteness theorem and the uncomputability of the halting problem, respectively.\n",
        "* [Lat96] made an early investigation into the relationship between computability and learnability. The main question in [Lat96] is whether and under which notions of “learnability” one can consider an uncomputable problem to be learnable. More precisely, [Lat96] considered the task of learning the halting problem relative to an oracle."
      ],
      "metadata": {
        "id": "yYkMF8Fk3lwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Learning unitary dynamics, which is a fundamental primitive for a range of QML algorithms (from: Out-of-distribution generalization for learning quantum dynamics)*\n",
        "\n",
        "* **Quantum dynamics learning**: At its simplest, the target unitary could be the unknown dynamics of an experimental quantum system. For this case, which has close links with quantum sensing [26] and Hamiltonian learning [27– 29], the aim is essentially to learn a digitalization of an analog quantum process.\n",
        "* **Quantum compilation learning**: Alternatively, the target unitary could take the form of a known gate sequence that one seeks to compile into a shorter depth circuit or a particular structured form\n",
        "\n",
        "The compilation could be performed either on a quantum computer, see Fig. 1c), or entirely classically, see Fig. 1d)\n"
      ],
      "metadata": {
        "id": "2NP3VL4OlRWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classical Shadows to Learn Quantum States**\n",
        "\n",
        "* Machine Learning Aids Classical Modeling of Quantum Systems. By using “classical shadows,” ordinary computers can beat quantum computers at the tricky task of understanding quantum behaviors.\n",
        "\n",
        "* By combining a new way of modeling quantum systems with increasingly sophisticated machine learning algorithms, researchers have established a method for classical machines to model and predict quantum behavior.\n",
        "\n",
        "https://www.quantamagazine.org/machine-learning-aids-classical-modeling-of-quantum-systems-20230914/"
      ],
      "metadata": {
        "id": "XE06-XJ0mf7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Learner (Model)*"
      ],
      "metadata": {
        "id": "qMfQjLMqmzuw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The Learner or learning algorithm (e.g. gradient descent, logic regression, linear regression, decision trees and random forests) is **the algorithm that produces a specific model from the hypothesis class using data** - the learner is the algorithm that **chooses the best hypothesis from the hypothesis class** given the training data.*"
      ],
      "metadata": {
        "id": "tvnsAeoaoQm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PAC learning**\n",
        "\n",
        "* **PAC Learning**: is a method to measure sample complexity. The Probably Approximately Correct (PAC) learning framework provides a formal definition of learning and can be used to derive bounds on the sample complexity needed to learn a function to a given degree of accuracy with a certain probability.\n",
        "\n",
        "* PAC learning is a framework in computational learning theory where an algorithm aims to learn a target function based on samples such that it performs well on unseen data with high probability.\n",
        "\n",
        "* **For linear regression to be a PAC learner, the following conditions are typically required:**\n",
        "\n",
        "  * The true relationship between the variables is (approximately) linear.\n",
        "  * The noise in the data is bounded.\n",
        "  * The features (input data) have a bounded range.\n",
        "\n",
        "* Under these conditions, with a sufficiently large sample size, the linear regression model can be shown to generalize well to unseen data with high probability, thereby satisfying the PAC learning criteria.\n",
        "\n",
        "> **However, if the true underlying relationship is non-linear or if the noise is unbounded, then linear regression might not be a PAC learner.**\n",
        "\n",
        "* Several algorithms and models in machine learning can be considered PAC learners under appropriate conditions. Here are some examples:\n",
        "\n",
        "  1. **Decision Trees**: Decision tree algorithms, like ID3, C4.5, and CART, can be PAC learners under certain conditions. They can approximate discrete-valued functions well given a sufficient number of samples.\n",
        "\n",
        "  2. **Finite Automata Learning**: Algorithms that learn regular languages, like the L* algorithm, can be seen as PAC learners for certain classes of regular languages.\n",
        "\n",
        "  3. **Neural Networks**: Under certain assumptions, feed-forward neural networks with a fixed number of hidden layers can be PAC learners. However, their sample complexity can be high, especially as the size of the network grows.\n",
        "\n",
        "  4. **k-Nearest Neighbors (k-NN)**: Under certain conditions, the k-NN algorithm can be a PAC learner, particularly when the data is uniformly distributed.\n",
        "\n",
        "  5. **Support Vector Machines (SVM)**: SVMs can be considered PAC learners when the margin between classes is reasonably large.\n",
        "\n",
        "  6. **Boosting Algorithms**: Algorithms like AdaBoost, which combine multiple weak learners to create a strong learner, can be seen as PAC learners under the right conditions.\n",
        "\n",
        "  7. **Monotone DNF**: Algorithms that learn disjunctive normal form (DNF) expressions where all literals are positive can be PAC learners.\n",
        "\n",
        "* It's worth noting that for any learning algorithm to be a PAC learner, it must be able to produce hypotheses that generalize well to unseen data with high probability, given polynomially many samples in the size of the concept/class, the error bound, and the confidence level. The specific conditions under which these algorithms are PAC learnable can vary based on the complexity of the model, the nature of the data, and the distribution from which the data is drawn.\n",
        "\n",
        "*Under which conditions is a neural network or a k-Nearest Neighbors (k-NN) not a PAC learner?*\n",
        "\n",
        "* Both neural networks and k-Nearest Neighbors (k-NN) have conditions under which they might not be PAC learners:\n",
        "\n",
        "  1. **Neural Networks**:\n",
        "\n",
        "   - **Complexity and Overfitting**: If the neural network is too complex (e.g., too many layers or neurons) relative to the amount of training data available, it can overfit. Overfitting means the network memorizes the training data rather than generalizing from it, leading to poor performance on unseen data.\n",
        "   \n",
        "   - **Non-IID Data**: Neural networks assume that data is identically and independently distributed (IID). If there's a temporal or spatial structure in the data, without appropriate handling, a standard neural network might not generalize well.\n",
        "   \n",
        "   - **Unbounded Activation Functions**: Activation functions that aren't bounded might lead to weights that grow indefinitely, causing issues with learning.\n",
        "   \n",
        "   - **Unsuitable Data Distribution**: If the data distribution is not well-suited for the neural network's assumptions or if it changes over time (non-stationary), the network might not be a PAC learner for that distribution.\n",
        "\n",
        "  2. **k-Nearest Neighbors (k-NN)**:\n",
        "\n",
        "   - **Curse of Dimensionality**: As the dimensionality of the dataset increases, the volume of the space increases exponentially, and data becomes sparse. k-NN suffers in high-dimensional spaces because the notion of \"nearness\" becomes less meaningful. This can cause k-NN to be a poor learner in high dimensions unless the dataset is exceptionally large.\n",
        "   \n",
        "   - **Non-uniform Feature Scales**: If features have different scales and aren't normalized, the distance measure used by k-NN can be dominated by certain features, making it a poor learner.\n",
        "   \n",
        "   - **Noisy Data**: k-NN is sensitive to noise in the dataset. If a significant portion of the data has errors or misclassifications, k-NN's performance can degrade, and it may not be a PAC learner for very noisy datasets.\n",
        "   \n",
        "   - **Variable Densities**: If some regions of the input space are densely populated and others are sparse, k-NN might not generalize well across all regions.\n",
        "\n",
        "* For both neural networks and k-NN, it's important to note that being a PAC learner is about the ability to generalize to unseen data with high probability given a polynomial number of samples. If either model fails to meet this criterion under certain conditions, it's not considered a PAC learner under those conditions.\n",
        "\n",
        "*Why is a query learner not a PAC learner?*\n",
        "\n",
        "* A query learner and a PAC learner are not inherently mutually exclusive. They are two different frameworks within computational learning theory that describe the manner and conditions under which learning happens. However, the methods by which they acquire data and their learning objectives are what differentiate them:\n",
        "\n",
        "  1. **Data Acquisition**:\n",
        "   - **Query Learner**: The learner can actively ask an oracle about specific inputs or hypotheses. The types of questions might include membership queries (asking if a specific instance belongs to the target concept) and equivalence queries (proposing a hypothesis and asking if it's correct). There might be other types of queries as well.\n",
        "   - **PAC Learner**: The learner passively receives random samples drawn from a distribution. It doesn't get to choose specific examples it wants to learn from.\n",
        "\n",
        "  2. **Learning Objective**:\n",
        "   - **Query Learner**: Depending on the model, the goal might be exact learning, where the learner tries to find a hypothesis that exactly matches the target concept. This is often the objective in models that use equivalence queries.\n",
        "   - **PAC Learner**: The goal is to find a hypothesis that is probably approximately correct. That is, with high probability, the hypothesis should be approximately accurate on new, unseen examples drawn from the same distribution.\n",
        "\n",
        "* Given these distinctions, a learning algorithm could theoretically be both a query learner and a PAC learner under different circumstances or with different assumptions. For instance, one might imagine a scenario where a learner uses queries to gather information and then ensures that its hypothesis is probably approximately correct for a given distribution.\n",
        "\n",
        "* However, the traditional definitions of these models focus on their distinct characteristics, which is why they are often treated as separate learning paradigms in computational learning theory.\n",
        "\n",
        "\n",
        "*Leslie Valiant’s Probably Approximately Correct (PAC) model gives a precise complexity- theoretic definition of what it means for a concept class to be (efficiently) learnable. - Source: Optimal Quantum Sample Complexity of Learning Algorithms (2017)*\n",
        "\n",
        "* [PAC Learning](https://en.m.wikipedia.org/wiki/Error_tolerance_(PAC_learning)): learner is evaluated on its predictive power of a test set.\n",
        "\n",
        "  * Dimensionality measures are important tools in machine learning because they can be used to bound the sample complexity of learning algorithms. For example, the following theorem provides an upper bound on the sample complexity of PAC learning in terms of the VC dimension:\n",
        "\n",
        "  * **Theorem:** Let H be a hypothesis class with VC dimension d. Then, the sample complexity of PAC learning H is given by:\n",
        "\n",
        "  * $n >= O(d / ε^2 * ln(1/δ))$\n",
        "\n",
        "  * where ε is the desired error tolerance and δ is the desired confidence level.\n",
        "\n",
        "  * This theorem tells us that if we know the VC dimension of a hypothesis class, then we can bound the number of training examples needed to learn a hypothesis in that class with high probability.\n",
        "  \n",
        "  * In general, the VC dimension is the most widely used dimensionality measure in PAC learning. It is simple to compute and easy to interpret. However, there are other dimensionality measures that can be more effective for certain types of learning problems.\n",
        "  \n",
        "* [PAC learning](https://en.m.wikipedia.org/wiki/Probably_approximate) (Probably approximate learner): A PAC learner is a machine learning algorithm that can learn a function from a set of labeled examples with high accuracy. The PAC learner is given a set of labeled examples, where each example is a pair of an input and its corresponding output. The PAC learner then learns a function that maps from inputs to outputs. The function learned by the PAC learner should have high accuracy, meaning that it should output the correct output for most inputs.\n",
        "\n",
        "* Hypothesis class is finite and labeling function is consistent with some hypothesis in the hypothesis class. Ideal for more simpler applications like Classification, regression, clustering.\n",
        "\n",
        "* PAC learning (Probably Approximately Correct learning) is a framework for machine learning that allows us to measure the accuracy of a learning algorithm. In PAC learning, we assume that the learner has access to a training set of labeled examples, and the goal is to learn a hypothesis that predicts the label of new, unseen examples with high accuracy.\n",
        "\n",
        "* **Proper quantum PAC learner** with optimal sample complexity, i.e., one whose output hypothesis lies in C itself\n",
        "\n",
        "* ps: sample complexity for the PAC and agnostic models, quantum examples do not provide an advantage (*Survey of Quantum Learning Theory*)\n",
        "\n",
        "* „quantum sample complexity of PAC learning“ versus „sample complexity of PAC learning n-qubit quantum states“?\n",
        "\n",
        "  * The quantum sample complexity of PAC learning refers to the number of quantum examples needed to learn a concept class with probability 1-delta, where each example is a coherent quantum state.\n",
        "\n",
        "  * The sample complexity of PAC learning n-qubit quantum states refers to the number of classical examples needed to learn a concept class of n-qubit quantum states, where each example is a classical description of an n-qubit quantum state.\n",
        "\n",
        "  * In general, the quantum sample complexity of PAC learning is lower than the sample complexity of PAC learning n-qubit quantum states. This is because quantum examples can contain more information than classical examples.\n",
        "\n",
        "  * For example, consider the task of learning a concept class of binary functions. A classical example of a binary function is a pair of inputs (x, y), where x is a binary number and y is the output of the function on x. A quantum example of a binary function is a quantum state |ψ⟩ that encodes the function. **It can be shown that the quantum sample complexity of PAC learning binary functions is O(log(d)/ε), where d is the VC dimension of the concept class and ε is the error tolerance. The classical sample complexity of PAC learning binary functions is O(d/ε), which is larger than the quantum sample complexity.**\n",
        "\n",
        "  * This shows that quantum examples can be more powerful than classical examples for some learning tasks. However, it is important to note that the quantum sample complexity of PAC learning is still an active area of research, and there are many open questions."
      ],
      "metadata": {
        "id": "IqioVhxR7yy5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Linear regression is an example of a PAC learner. A PAC learner is a type of machine learning algorithm that can learn a concept class with high probability, given a sufficient number of training examples. The concept class is the set of all possible functions that the learner is trying to learn. In the case of linear regression, the concept class is the set of all linear functions.*\n",
        "\n",
        "* Linear regression has been shown to be PAC learnable under a variety of different conditions. For example, if the training data is drawn from a distribution where the target values are generated by a linear function, then linear regression can learn the correct function with high probability, given a sufficient number of training examples.\n",
        "\n",
        "* However, it is important to note that the PAC learnability of linear regression depends on the specific hypothesis class that is being used. For example, if the hypothesis class includes all possible linear functions, then linear regression is not PAC learnable. This is because there are infinitely many linear functions, and it is not possible to learn any infinite hypothesis class with a finite number of training examples.\n",
        "\n",
        "* In practice, linear regression is often used with a restricted hypothesis class. For example, the hypothesis class might be restricted to only include linear functions that have a certain number of parameters. This makes the problem of learning the correct function more feasible, and linear regression can often be used to learn the correct function with a relatively small number of training examples.\n",
        "\n",
        "* Here is an example of how linear regression can be used as a PAC learner:\n",
        "\n",
        "* Suppose we want to learn a linear function that predicts the weight of a person based on their height. We can collect a training dataset of people's heights and weights. Then, we can use a linear regression algorithm to learn a linear function that fits the training data.\n",
        "\n",
        "* The PAC learnability of linear regression tells us that, if the training data is drawn from a distribution where the weights are generated by a linear function of height, then the linear regression algorithm will learn the correct function with high probability, given a sufficient number of training examples.\n",
        "\n",
        "* Of course, we cannot guarantee that the linear regression algorithm will always learn the correct function. However, the PAC learnability of linear regression tells us that the algorithm will learn the correct function with high probability, if the training data is sampled from the correct distribution."
      ],
      "metadata": {
        "id": "OrqN6xS5PYJD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, a PAC learner would be a learner in computational learning theory. A PAC learner is a machine learning algorithm that can learn a hypothesis that generalizes well to new examples, with high probability.\n",
        "\n",
        "The PAC model is a theoretical framework for evaluating the performance of learning algorithms. In the PAC model, the learner is given a set of training examples and is asked to learn a hypothesis that generalizes well to new examples. The hypothesis is a function that maps from inputs to outputs, and the learner's goal is to find a hypothesis that is close to the target function, which is the unknown function that generated the training examples.\n",
        "\n",
        "A PAC learner is a learner that can learn a hypothesis that generalizes well to new examples, with high probability. This means that the learner can learn a hypothesis that will make few mistakes on new examples, most of the time.\n",
        "\n",
        "PAC learners are important because they provide a way to evaluate the performance of learning algorithms in a rigorous way. The PAC model is also useful for understanding the theoretical limitations of learning algorithms.\n",
        "\n",
        "Here are some examples of PAC learners:\n",
        "\n",
        "* Linear regression\n",
        "* Logistic regression\n",
        "* Decision trees\n",
        "* Support vector machines\n",
        "* Neural networks\n",
        "\n",
        "These algorithms can all be used to learn hypotheses that generalize well to new examples, with high probability.\n",
        "\n",
        "It is important to note that the PAC model is a theoretical framework, and it is not always possible to find a PAC learner that works well in all practical settings. However, the PAC model provides a useful way to think about the problem of learning and to evaluate the performance of learning algorithms."
      ],
      "metadata": {
        "id": "lf78dXP8PpNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ARIMA stands for AutoRegressive Integrated Moving Average, and it is a statistical model that is used to forecast time series data. ARIMA models are based on the assumption that the future values of a time series can be predicted from its past values.\n",
        "\n",
        "In the context of computational learning theory, ARIMA can be considered a learner, but it is a special type of learner that is designed for time series forecasting. ARIMA models learn a hypothesis that maps from past time series values to future time series values. The hypothesis is a linear function of the past values, and it is estimated using a statistical procedure called maximum likelihood estimation.\n",
        "\n",
        "ARIMA models are widely used in a variety of applications, such as forecasting sales, stock prices, and weather patterns. They are relatively simple to implement and interpret, and they can be used to generate accurate forecasts for a variety of time series data.\n",
        "\n",
        "Here is an example of how ARIMA could be used as a learner in computational learning theory:\n",
        "\n",
        "Suppose we have a time series of daily sales data for a particular product. We want to learn a hypothesis that can be used to predict future sales. We can use an ARIMA model to learn this hypothesis.\n",
        "\n",
        "First, we would need to identify the order of the ARIMA model. The order of the model determines how many past values of the time series are used to predict future values. We can use a statistical procedure called autocorrelation to help us identify the order of the model.\n",
        "\n",
        "Once we have identified the order of the model, we can estimate the parameters of the model using maximum likelihood estimation. This procedure will give us a hypothesis that is the best fit to the training data.\n",
        "\n",
        "We can then use the hypothesis to predict future sales. To do this, we would simply plug the past values of the time series into the hypothesis. The output of the hypothesis will be the predicted value for the next time step.\n",
        "\n",
        "ARIMA models are a powerful tool for time series forecasting, and they can be used as learners in computational learning theory. However, it is important to note that ARIMA models are only suitable for forecasting time series data that is stationary. Stationary time series data is data that has a constant mean, variance, and autocorrelation over time. If the time series data is not stationary, then it may be necessary to transform the data before using an ARIMA model."
      ],
      "metadata": {
        "id": "xSVXX1H7PxnX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the PAC model, the learner is given a set of training examples and is asked to learn a hypothesis that generalizes well to new examples. The hypothesis is a function that maps from inputs to outputs, and the learner's goal is to find a hypothesis that is close to the target function, which is the unknown function that generated the training examples.\n",
        "\n",
        "The PAC model is used to measure the generalization error of a learning algorithm. The generalization error is the probability that the hypothesis will make a mistake on a new example. The PAC model guarantees that, with high probability, the learning algorithm will output a hypothesis with low generalization error.\n",
        "\n",
        "And what would be an example of a learner in this context?\n",
        "\n",
        "An example of a learner in the context of computational learning theory is a machine learning algorithm, such as linear regression, decision trees, or support vector machines. These algorithms are given a set of training examples and are asked to learn a hypothesis that generalizes well to new examples.\n",
        "\n",
        "For example, a linear regression algorithm could be used to learn a hypothesis that predicts the price of a house based on its square footage, number of bedrooms, and other features. The algorithm is given a set of training examples, which are houses with known prices and features. The algorithm then learns a linear function that best fits the training data. This function can then be used to predict the price of a new house, given its features.\n",
        "\n",
        "Another example of a learner is a decision tree algorithm. Decision tree algorithms learn a hypothesis by constructing a tree structure, where each node in the tree represents a decision and each leaf node represents a prediction. The algorithm is given a set of training examples, and it constructs a tree that best separates the positive examples from the negative examples. The tree can then be used to predict the class of a new example by traversing the tree from the root node to a leaf node.\n",
        "\n",
        "These are just two examples of learners in computational learning theory. There are many other machine learning algorithms that can be used as learners in this context.\n",
        "\n",
        "It is important to note that the PAC model is a theoretical framework, and it is not always possible to find a learning algorithm that works well in all practical settings. However, the PAC model provides a useful way to think about the problem of learning and to evaluate the performance of learning algorithms."
      ],
      "metadata": {
        "id": "NkAyGxjLP8__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One example of a quantum PAC learner is the Grover's algorithm. Grover's algorithm is a quantum search algorithm that can search through a database of unsorted items in polynomial time, whereas classical search algorithms require exponential time.\n",
        "\n",
        "Grover's algorithm can be used to implement a quantum PAC learner by using it to search through the space of all possible hypotheses to find one that is consistent with the training data. This can be done by constructing a quantum oracle that takes a hypothesis as input and outputs 1 if the hypothesis is consistent with the training data and 0 otherwise.\n",
        "\n",
        "Once the oracle is constructed, Grover's algorithm can be used to search for a hypothesis that outputs 1. Grover's algorithm will find such a hypothesis in polynomial time, even if the space of all possible hypotheses is very large.\n",
        "\n",
        "Another example of a quantum PAC learner is the HHL algorithm. The HHL algorithm is a quantum algorithm for solving linear systems of equations. It can be used to implement a quantum PAC learner by using it to solve the linear system of equations that represents the training data.\n",
        "\n",
        "Once the linear system of equations is solved, the coefficients of the solution can be interpreted as the weights of a hypothesis. This hypothesis can then be used to predict the labels of new examples.\n",
        "\n",
        "Both Grover's algorithm and the HHL algorithm have been shown to achieve polynomial speedups over classical PAC learners for certain types of concepts. However, it is important to note that these algorithms are still in their early stages of development, and it is not yet clear how well they will perform on real-world problems.\n",
        "\n",
        "Here is a simple example of how Grover's algorithm could be used to implement a quantum PAC learner:\n",
        "\n",
        "\n",
        "1. Initialize a quantum register to be in the superposition of all possible hypotheses.\n",
        "2. Apply the quantum oracle to the quantum register.\n",
        "3. Measure the quantum register.\n",
        "4. If the measurement result is 1, then the hypothesis is consistent with the training data and the algorithm terminates.\n",
        "5. Otherwise, apply the Grover diffusion operator to the quantum register and repeat steps 2-4.\n",
        "\n",
        "\n",
        "The Grover diffusion operator is a quantum operator that amplifies the probability of measuring the correct hypothesis. After a few iterations of the Grover algorithm, the probability of measuring the correct hypothesis will be very high.\n",
        "\n",
        "I hope this helps!"
      ],
      "metadata": {
        "id": "Lwlt5nzkwpfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agnostic learning**:\n",
        "\n",
        "  * Hypothesis class is finite but labeling function is not assumed to be consistent with any hypothesis in the hypothesis class. Ideal for more general applications, such as natural language processing and computer vision.\n",
        "  * The PAC model assumes that the labeled examples are generated according to a target concept c ∈ C . However, in many learning situations that is not a realistic assumption, for example when the examples are noisy in some way or when we have no reason to believe there is an underlying target concept at all. The agnostic model of learning, introduced by Haussler [Hau92] and Kearns et al. [KSS94], takes this into account (Optimal Quantum Sample Complexity of Learning Algorithms).\n",
        "\n",
        "  * Agnostic learning is a more general concept than PAC learning. PAC learning is a framework for machine learning that guarantees that a learner can find a hypothesis that is approximately correct with high probability, given a finite amount of training data. The learner does this by making two assumptions:\n",
        "\n",
        "    1. The hypothesis class is finite.\n",
        "    2. The labeling function is consistent with some hypothesis in the hypothesis class.\n",
        "\n",
        "  * Agnostic learning relaxes the second assumption. In agnostic learning, the learner does not assume that the labeling function is consistent with any hypothesis in the hypothesis class. This makes agnostic learning a more challenging problem, but it also allows the learner to learn more complex concepts.\n",
        "\n",
        "  * In other words, PAC learning is a special case of agnostic learning where the labeling function is consistent with some hypothesis in the hypothesis class."
      ],
      "metadata": {
        "id": "8DexccI_oHSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Online learning**\n",
        "  * The online model can be viewed as a variant of tomography and PAC learning (Survey on the complexity of learning quantum states, page 15)\n",
        "  * [PAC Learning and Online Learning](https://courses.corelab.ntua.gr/pluginfile.php/7949/course/section/925/lecture2.pdf)"
      ],
      "metadata": {
        "id": "8vQUT-kMoE3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Active Learning**\n",
        "\n",
        "* Semi-supervised learning problems include active learning, where the algorithm can ask for labels to specifically chosen inputs in order to reduce the cost of obtaining many labels."
      ],
      "metadata": {
        "id": "WQ80qL7y_oSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exact learning** (uses queries, not sample!)\n",
        "\n",
        "* This is a specific type of query learning where the objective is to learn the target concept exactly.\n",
        "\n",
        "* Exact learning is a part of PAC learning. Exact learning is a special case of PAC learning where the learner is guaranteed to learn the correct hypothesis with certainty, given enough training examples. This is in contrast to PAC learning, where the learner is only guaranteed to learn a hypothesis that is accurate with high probability.\n",
        "* **Query complexity of exact learning**. In quantum computational learning theory, exact learning is typically studied in the context of Probably Approximately Correct (PAC) learning, where the learner is given a set of labeled examples, and is asked to learn a hypothesis that classifies new examples with high accuracy.\n",
        "* There are a number of different ways to perform exact learning in quantum computational learning theory. One approach is to use quantum algorithms to perform tomography on the target function. However, this approach is often inefficient, as it requires a large number of measurements.\n",
        "* Another approach is to use quantum algorithms to perform machine learning directly, without the need for tomography. This approach is more promising, as it can be more efficient. However, it is still a relatively new area of research, and there are many open problems.\n",
        "* (N,M)-quantum query complexity of exact learning. Page 8 under \"4.1 Query complexity of exact learning\" notation: **{s ∈ S : s_i = 0}** in this [paper](https://arxiv.org/abs/1701.06806)\n",
        "\n",
        "  * The notation {s ∈ S : s_i = 0} is a set comprehension notation that selects all elements s in a set S such that the ith index of s is equal to 0. In other words, it is the set of all elements in S whose ith digit is 0.\n",
        "    * For example, if S is the set {1, 2, 3, 4, 5}, then the set {s ∈ S : s_i = 0} is the set {0, 2, 4}.\n",
        "    * Compare in binary: 0 : **00**, 1 : **01**, 2: **10**, 3: **11**, 4 : **100**, 5: **101** (look at the last digit, the ith digit)\n",
        "\n",
        "  * The (N,M)-quantum query complexity of exact learning is **the minimum number of queries to an oracle that a quantum algorithm needs to make in order to learn a Boolean function f : {0, 1}^n → {0, 1} with error probability at most 1/M, where N is the number of input variables and M is a positive integer**.\n",
        "\n",
        "  * In other words, the (N,M)-quantum query complexity is the quantum analogue of the (N,M)-classical query complexity, which is the minimum number of queries to an oracle that a classical algorithm needs to make in order to learn f with error probability at most 1/M.\n",
        "\n",
        "  * The (N,M)-quantum query complexity of exact learning is a difficult problem to study, and it is not known for many functions f. However, there are some functions for which the (N,M)-quantum query complexity is known to be better than the (N,M)-classical query complexity.\n",
        "\n",
        "  * For example, it is known that the (N,M)-quantum query complexity of learning a k-junta with error probability at most 1/M is O(n(log n)/k) queries, while the (N,M)-classical query complexity is Ω(n^k/k^2) queries. This means that a quantum algorithm can learn a k-junta with fewer queries than a classical algorithm, if M is sufficiently large.\n",
        "\n",
        "*Exact Learning with Membership and Equivalence Queries: In this model, the learner tries to identify a target concept exactly (not approximately) by asking two types of queries:*\n",
        "\n",
        "  * Membership Queries: The learner poses an input and asks the oracle if it belongs to the target concept.\n",
        "  * Equivalence Queries: The learner proposes a hypothesis and asks the oracle if it's equivalent to the target concept. If not, the oracle provides a counterexample."
      ],
      "metadata": {
        "id": "13qWjplwoCW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query Learning**\n",
        "\n",
        "* This is a broader category where the learner has access to an oracle (similar to the membership and equivalence query model) but may have various types of queries at its disposal. The nature of the queries and the information that can be extracted determine the learnability of the target concept.\n",
        "\n",
        "* both query learning and exact learning involve the use of queries. However, the distinction lies in the objective of the learning and the broader context in which the terms are used.\n",
        "\n",
        "  1. **Objective**:\n",
        "   - **Query Learning**: The term \"query learning\" refers broadly to any learning model where the learner can actively query an oracle about the target concept. The queries might include membership queries, equivalence queries, and potentially other types of queries. The goal is not necessarily to learn the target concept exactly—it could be approximate or within certain bounds.\n",
        "   - **Exact Learning**: This is a specific type of query learning where the objective is to learn the target concept exactly. Exact learning often involves equivalence queries, where the learner proposes a hypothesis and asks the oracle if it exactly matches the target concept. If not, the oracle provides a counterexample.\n",
        "\n",
        "  2. **Types of Queries**:\n",
        "   - **Query Learning**: Can encompass various types of queries, depending on the specific learning model.\n",
        "   - **Exact Learning**: Primarily uses equivalence queries but may also use membership queries to refine its hypothesis based on the counterexamples received.\n",
        "\n",
        "3. **Context**:\n",
        "   - **Query Learning**: This is a broader term in computational learning theory, covering any model that uses some form of queries to gather information about the target concept.\n",
        "   - **Exact Learning**: This is a more specific model under the umbrella of query learning. It represents a subset of query learning models where the objective is to pinpoint the target concept without any approximation.\n",
        "\n",
        "In essence, all exact learning can be considered a form of query learning, but not all query learning aims for exact learning. Some query learning models might be content with approximate solutions or may have other objectives beyond exactness.\n"
      ],
      "metadata": {
        "id": "A25h4TlTNxRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Empirical Risk Minimization (ERM)**\n",
        "\n",
        "* Bounding the sample complexity of empirical risk minimization (ERM): ERM is a popular machine learning algorithm that learns a function by minimizing the empirical risk, which is the average loss on the training data.\n",
        "\n",
        "* Concentration inequalities can be used to show that ERM learns a function with a small generalization error with high probability, given a sufficient number of training samples."
      ],
      "metadata": {
        "id": "7Bm4nqqWQEJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Occam learning**\n",
        "\n",
        "* [Occam learning](https://en.m.wikipedia.org/wiki/Occam_learning): the objective of the learner is to output a succinct representation of received training data.\n",
        "* Though Occam and PAC learnability are equivalent, the Occam framework can be used to produce tighter bounds on the sample complexity of classical problems including conjunctions, conjunctions with few relevant variables and decision lists.\n",
        "* Occam algorithms have also been shown to be successful for PAC learning in the presence of errors, probabilistic concepts, function learning and Markovian non-independent examples."
      ],
      "metadata": {
        "id": "tUzyFOZagC2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Fourier features and Classical Surrogates for QML**\n",
        "\n",
        "* [Potential and limitations of random Fourier features for dequantizing quantum machine learning](https://scirate.com/arxiv/2309.11647): we establish necessary and sufficient conditions under which RFF does indeed provide an efficient dequantization of variational quantum machine learning for regression. We build on these insights to make concrete suggestions for PQC architecture design, and to identify structures which are necessary for a regression problem to admit a potential quantum advantage via PQC based optimization. On a higher level, this work contributes to delineating the boundary between quantum and classical processes.\n",
        "\n",
        "* [Classical Surrogates for Quantum Learning Models](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.131.100803)"
      ],
      "metadata": {
        "id": "TBU-HI_ugksq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum statistical query model (QSQ)**\n",
        "  * e.g. quantum example oracle\n",
        "  * QSQ (Quantum statistical query model) is a model of quantum machine learning that allows us to ask queries about the distribution of a quantum state. In QSQ, the learner has access to a quantum oracle that can answer queries about the distribution of a quantum state, and the goal is to learn a hypothesis that predicts the output of the oracle with high accuracy.\n",
        "  * A quantum example oracle is a black box that takes a quantum state as input and gives a quantum state as output. The quantum example oracle is not accessible to the user, and the user only knows how to interact with it through a specific set of operations.\n",
        "  * The main difference between a quantum example oracle and a PAC learner is that a quantum example oracle provides the learner with quantum states, while a PAC learner provides the learner with labeled examples. Quantum states are more powerful than labeled examples (from PAC), because they can represent a superposition of multiple inputs and outputs. This means that a quantum example oracle can provide the learner with more information about the function being learned. ***As a result, quantum example oracles can be used to learn functions that are more difficult to learn with classical PAC learners.*** For example, it has been shown that DNF formulas can be learned efficiently with a quantum example oracle, but they are not known to be efficiently learnable with a classical PAC learner.\n",
        "  * Another example of a quantum oracle is the Deutsch-Jozsa algorithm. This algorithm takes a function f:{0,1}^n->{0,1} as input, and determines whether f is constant or balanced. A constant function is one that always outputs the same value, regardless of its input. A balanced function is one that outputs 1 half of the time and 0 half of the time. The Deutsch-Jozsa algorithm works by first creating a superposition of all possible inputs to f. It then applies the oracle to this superposition. If f is constant, then the oracle will not change the superposition. However, if f is balanced, then the oracle will flip the phase of half of the states in the superposition. Finally, the algorithm measures the superposition. If the measurement result is 0, then f is constant. If the measurement result is 1, then f is balanced.\n"
      ],
      "metadata": {
        "id": "yUEN_ECDmc0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tomography**\n",
        "  * **Quantum state tomography (QST)**:\n",
        "    * State tomography is an alternative to boolean functions in quantum computational learning.\n",
        "    * To solve shadow tomography, the goal is to find a quantum state σ that satisfies Tr(σEi) ≈ Tr(ρEi) for all i (the trace distance is almost zero, the states are identical). Further, one would like to minimize the number of copies of ρ, suggesting that σ should be no more informative than matching the above expectations.\n",
        "    * In state tomography, the complete state vector or density matrix of the quantum state is reconstructed. This requires measuring the state in a complete set of bases, which can be exponentially many bases for a large quantum state.\n",
        "  * **shadow tomography**:\n",
        "    * In shadow tomography, only a subset of the bases is measured. This allows the state to be reconstructed with fewer copies of the state, but the reconstructed state may not be as accurate as the state reconstructed using state tomography.\n",
        "    * The main difference between state tomography and shadow tomography is the number of copies of the quantum state that are needed to reconstruct the state.\n",
        "  * **alternate algorithm for shadow tomography**: Max-entropy principle and Matrix Multiplicative Weight Update."
      ],
      "metadata": {
        "id": "ojKgJkAHmabx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Other Learners**\n",
        "* [Communication complexity models](https://en.m.wikipedia.org/wiki/Communication_complexity)\n",
        "* The perceptron algorithm.\n",
        "* The ID3 algorithm.\n",
        "* The backpropagation algorithm"
      ],
      "metadata": {
        "id": "Fw0MNiKsmNqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Special: Backpropagation and Barren Plateaus (Overparametrization) in Quantum Machine Learning*"
      ],
      "metadata": {
        "id": "Az7EjhgzgTLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Special: Backpropagation and Barren Plateaus (Overparametrization) in Quantum Machine Learning**\n",
        "\n",
        "*Why can backpropagation not easily scale in quantum machine learning?*\n",
        "\n",
        "1. **Non-commutativity of operators**: Quantum operations, unlike classical ones, are represented by operators that generally do not commute, meaning the order in which they are applied matters. This non-commutativity makes the computation of gradients more complex than in the classical case.\n",
        "\n",
        "2. **Measurement**: In quantum mechanics, obtaining information about the state of a system involves measurement, which is a probabilistic process that collapses the state of the system. The inherent randomness of measurement makes the direct application of backpropagation problematic.\n",
        "\n",
        "3. **Complexity of quantum states**: Quantum states live in a complex vector space and can exist in a superposition of multiple states simultaneously, further complicating the process of backpropagation.\n",
        "\n",
        "4. **Barren plateaus**: In the context of variational quantum algorithms, it's been found that the cost function landscape often suffers from the problem of \"barren plateaus\", where the function is flat almost everywhere. This makes it difficult for gradient-based methods like backpropagation to find a direction to move in to improve the function.\n",
        "\n",
        "*Are Barren Plateaus a sign for Overparametrization and too high capacity of my quantum machine learning model?*\n",
        "\n",
        "* Yes, barren plateaus can be a sign of overparametrization and too high capacity of a quantum machine learning model. Overparametrization occurs when a model has more parameters than it needs to learn the task at hand. This can lead to the model fitting the training data too well, which can cause it to perform poorly on new data.\n",
        "\n",
        "* When a model is overparametrized, the cost function landscape can become very flat. This means that there are many different parameter settings that give the same or very similar cost values. As a result, the optimization algorithm can get stuck in a local minimum, where the cost function is not very low. This is what is known as a barren plateau.\n",
        "\n",
        "* There are a few things that can be done to mitigate the problem of barren plateaus:\n",
        "\n",
        "  * Reduce the number of parameters in the model. This can be done by simplifying the model architecture or by using regularization techniques.\n",
        "  \n",
        "  * Use a more robust optimization algorithm. Some optimization algorithms are more resistant to getting stuck in local minima than others.\n",
        "\n",
        "  * Use a more informative cost function. A more informative cost function can help the optimization algorithm find a better solution.\n",
        "\n",
        "* Here are some additional resources that you may find helpful:\n",
        "\n",
        "  * Avoiding Barren Plateaus in Variational Quantum Algorithms: https://arxiv.org/abs/2204.13751\n",
        "  * Barren Plateaus in Quantum Neural Network Training Landscapes: https://www.nature.com/articles/s41467-018-07090-4\n",
        "  * Solving 'barren plateaus' is the key to quantum machine learning: https://discover.lanl.gov/news/0319-barren-plateaus/\n",
        "\n",
        "*Techniques for improving gradient scaling and thus learning in quantum machine learning systems include:*\n",
        "\n",
        "1. **Variational Quantum Algorithms:** In the field of quantum machine learning, Variational Quantum Algorithms (VQAs) like the Variational Quantum Eigensolver (VQE) or Quantum Approximate Optimization Algorithm (QAOA) are commonly used. These algorithms employ a hybrid quantum-classical approach, which allows classical optimization techniques to be used in the learning process. This means classical techniques for managing gradient scaling, like batch normalization or gradient clipping, can still be applicable in this quantum setting.\n",
        "\n",
        "2. **Parameter Shift Rule:** The parameter-shift rule is a method for computing gradients in quantum circuits, which is particularly important for variational quantum algorithms. The rule ensures that for certain types of quantum gates (those that generate rotations), the gradient of the expectation value of a quantum circuit with respect to a parameter can be computed exactly, regardless of the number of qubits or the complexity of the circuit. This rule allows the derivative of a quantum circuit output with respect to its parameters to be computed in terms of circuit evaluations. Given a parameterized quantum gate (say, a rotation gate), the derivative of the expectation value of an observable with respect to the parameter can be computed as the difference between the expectation values of the observable for two slightly different values of the parameter. These \"shifted\" parameter values are typically chosen to be a small positive or negative shift from the original parameter value. The parameter-shift rule is powerful because it allows us to compute exact gradients using only additional evaluations of the quantum circuit, with no need for complex computations involving the inner workings of the quantum operations.\n",
        "\n",
        "3. **Adjoint method**: The adjoint method, also known as the reverse-mode differentiation, is a technique borrowed from classical automatic differentiation, generalized to the context of quantum circuits. It involves running the quantum circuit forward, storing the state at each step, and then running a modified version of the circuit backward to calculate the derivatives. This method is efficient in terms of the number of quantum operations required, especially for circuits with many parameters but a single output (as is common in quantum machine learning models). However, it requires the ability to run quantum operations in reverse, as well as the ability to store quantum states, which can be challenging to implement on near-term quantum devices.\n",
        "\n",
        "4. **Randomized Layerwise Training:** Another strategy suggested for training deep quantum circuits involves training one layer at a time with a random initialization for the rest of the circuit, a technique inspired by classical machine learning strategies. This approach can help to alleviate barren plateaus -- regions in the cost function landscape where the variance of the gradients vanishes exponentially with increasing system size.\n",
        "\n",
        "5. **Natural Gradient Descent:** There have been some initial studies into quantum natural gradient descent, which is an analogue to the classical natural gradient descent algorithm and is believed to be more robust to issues with gradient scaling.\n",
        "\n",
        "6. **Quantum-aware optimizers:**\n",
        "  * shot-frugal optimizers [51–54] can employ stochastic gradient descent while adapting the number of shots (or measurements)\n",
        "  * Quantum natural gradi- ent [55, 56] adjusts the step size according to the local geometry of the landscape (based on the quantum Fisher information metric).\n",
        "\n",
        "7. **New Research: Use unbounded objective function**\n",
        "\n",
        "  * Other barren plateaus also don't apply for unbounded objective function. Almost all of QML uses bounded operators.\n",
        "  * **KL divergence** in classical, would be quantum relativ entropy, but that's too hard to compute. **better: Maximal Quantum Rényi Divergence**\n",
        "  * compute with Extended swap test (Generalizes swap test and Hadamard test)\n",
        "  * Learning thermal states: Generative algorithm to thermal state learning,Access to LCU decomposition of the Hamiltonian\n",
        "  * Abstract [Quantum Generative Training Using Rényi Divergences](https://arxiv.org/abs/2106.09567): Quantum neural networks (QNNs) are a framework for creating quantum algorithms that promises to combine the speedups of quantum computation with the widespread successes of machine learning. A major challenge in QNN development is a concentration of measure phenomenon known as a barren plateau that leads to exponentially small gradients for a range of QNNs models.\n",
        "  * In this work, **we examine the assumptions that give rise to barren plateaus and show that an unbounded loss function can circumvent the existing no-go results**. We propose a training algorithm that minimizes the maximal **Renyi divergence** of order two and present techniques for gradient computation. We compute the closed form of the gradients for Unitary QNNs and Quantum Boltzmann Machines and **provide sufficient conditions for the absence of barren plateaus in these models**. We demonstrate our approach in two use cases: thermal state learning and Hamiltonian learning. In our numerical experiments, we observed rapid convergence of our training loss function and frequently archived a 99% average fidelity in fewer than 100 epochs.\n",
        "  * Video: [Maria Kieferova - Training quantum neural networks with an unbounded loss function - IPAM at UCLA](https://www.youtube.com/watch?v=01xvtDu94jM&list=WL&index=4&t=352s)\n",
        "\n",
        "8. **New Research: Algebraic solution to solve Barren Plateaus (overparametrization = too much capacity)**\n",
        "\n",
        "  * How can we measure if a Barren plateau (overparametrization) will occur before running the quantum neural network? - With Lie algebra! - **Overparamerization (too much capacity)** arises when the quantum Fischer information matrices (QFIM) simultaneously saturate their achievable rank. More parameter aren’t needed anymore.\n",
        "\n",
        "  * Link to Lie algebra: And the maximum rank of each QFIM is upper bounded by the dimension of the Lie algebra g. Lie Algebra: tells me where do I get when I start at a given state\n",
        "\n",
        "  * From: [QHack 2022: Marco Cerezo —Barren plateaus and overparametrization in quantum neural networks](https://www.youtube.com/watch?v=rErONNdHbjg)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1401.png)\n",
        "\n",
        "  * *Exponentiate Lie algebra to get lie groups:*\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1400.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1402.png)\n",
        "\n",
        "\n",
        "*What is backpropagation scaling?*\n",
        "\n",
        "\"Backpropagation scaling\" usually refers to techniques that manage the magnitudes of gradients during the process of backpropagation, which is used to train neural networks. Proper scaling is important because it can impact the speed and effectiveness of learning.\n",
        "\n",
        "Here are two common scaling issues that may arise during backpropagation:\n",
        "\n",
        "1. **Vanishing gradients:** When deep neural networks are trained, gradients of the loss function can become very small. As a result, weight updates during training become insignificant, and the network takes a very long time to learn, if it can learn at all. This problem is particularly common with activation functions like the sigmoid or hyperbolic tangent, which squish a large input space into a small output range.\n",
        "\n",
        "2. **Exploding gradients:** Conversely, gradients can also become very large, leading to large updates to the weights and causing the model to oscillate around the optimal solution, or even to diverge entirely. This is often a problem in recurrent neural networks (RNNs).\n",
        "\n",
        "Various techniques have been proposed to mitigate these issues:\n",
        "\n",
        "1. **Gradient clipping:** This is a common technique to prevent exploding gradients. If the norm of the gradient exceeds a certain threshold, we scale it back to prevent it from getting too large.\n",
        "\n",
        "2. **Weight initialization:** Properly initializing the weights can prevent gradients from vanishing or exploding too quickly. For example, Xavier/Glorot and He initialization are strategies that consider the sizes of the input and output layers.\n",
        "\n",
        "3. **Choice of activation function:** The choice of activation function can help alleviate the vanishing gradients problem. For example, ReLU (Rectified Linear Unit) and its variants (like Leaky ReLU and Parametric ReLU) are commonly used because they do not saturate for positive inputs.\n",
        "\n",
        "4. **Batch normalization:** This technique normalizes the activations of each layer to prevent the distribution of inputs to each layer from changing too much during training, which can help mitigate both vanishing and exploding gradients.\n",
        "\n",
        "5. **Use of optimizers:** Certain optimization algorithms like RMSProp, Adam, and Nadam can adaptively scale learning rates to mitigate both exploding and vanishing gradients.\n",
        "\n",
        "In summary, backpropagation scaling techniques are important to ensure that the magnitude of updates during training is appropriate and to prevent issues related to vanishing or exploding gradients.\n",
        "\n",
        "\n",
        "*Expectation Value and Backpropagation*\n",
        "\n",
        "The average value (expectation value) of the measurement result is given by the\n",
        "Born rule:\n",
        "\n",
        "> $\\langle B\\rangle=\\left\\langle\\psi\\left|U^{\\dagger}(\\theta) B U(\\theta)\\right| \\psi\\right\\rangle$\n",
        "\n",
        "Just linear algebra! Every step is a matrix-vector or matrix-matrix multiplication\n",
        "\n",
        "Expectation values depend continuously on the gate parameters\n",
        "\n",
        "*Backpropagating Through Quantum Circuits*\n",
        "\n",
        "However, as long as we don't \"zoom in\" to what is happening in the quantum circuit, backpropagation can treat the quantum circuit as a single indivisible function\n",
        "\n",
        "The expectation value of a quantum circuit is a differentiable function\n",
        "\n",
        "> $\n",
        "f(\\theta)=\\left\\langle\\psi\\left|U^{\\dagger}(\\theta) B U(\\theta)\\right| \\psi\\right\\rangle=\\langle B\\rangle$\n",
        "\n",
        "Running on hardware and using the parameter-shift rule, we can provide both ingredients needed by backpropagation\n",
        "\n",
        "> $\n",
        "\\left(\\langle B\\rangle, \\frac{\\partial}{\\partial \\theta}\\langle B\\rangle\\right)\n",
        "$\n",
        "\n",
        "[Automatic Differentiation of Quantum Circuits](https://youtu.be/McgBeSVIGus)\n",
        "\n",
        "[Variational Quantum Algorithms](https://youtu.be/YtepXvx5zdI)\n",
        "\n",
        "[Hybrid Quantum-Classical Machine Learning](https://youtu.be/t9ytqPTij7k)\n",
        "\n",
        "**Algebraic solution to solve Barren Plateaus (overparametrization = too much capacity)**\n",
        "\n",
        "\n",
        "* How can we measure if a Barren plateau (overparametrization) will occur before running the quantum neural network? - With Lie algebra! - **Overparamerization (too much capacity)** arises when the quantum Fischer information matrices (QFIM) simultaneously saturate their achievable rank. More parameter aren’t needed anymore.\n",
        "\n",
        "* Link to Lie algebra: And the maximum rank of each QFIM is upper bounded by the dimension of the Lie algebra g. Lie Algebra: tells me where do I get when I start at a given state\n",
        "\n",
        "* From: [QHack 2022: Marco Cerezo —Barren plateaus and overparametrization in quantum neural networks](https://www.youtube.com/watch?v=rErONNdHbjg)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1401.png)\n",
        "\n",
        "*Exponentiate Lie algebra to get lie groups:*\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1400.png)\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1402.png)"
      ],
      "metadata": {
        "id": "VXWcAsxVYr3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ***$\\hookrightarrow$ Model Complexity***"
      ],
      "metadata": {
        "id": "m_M1o-kVjMZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Jarrod McClean - The role of data, precomputation, and communication in a quantum learning landscape](https://youtu.be/dOUppTONVDM?t=2744)\n",
        "\n",
        "[Expressibility of Parametrized Quantum Circuits & Classification Accuracy of Quantum Neural Networks](https://www.youtube.com/watch?v=Igxr1HLhdrM&list=WL&index=6)\n",
        "\n",
        "[QHack 2022: Zoe Holmes —Expressibility & trainability: balancing the ingredients of an effective VQA](https://www.youtube.com/watch?v=RO3g7B0-IKA&list=WL&index=5&t=65s)\n",
        "\n",
        "[Google Random circuit sampling: \"Quantum Computational Supremacy\" lecture by Scott Aaronson](https://www.youtube.com/watch?v=XazjgK3yQB8&list=WL&index=4&t=3535s)\n",
        "\n",
        "[]()\n",
        "\n",
        "[]()"
      ],
      "metadata": {
        "id": "_wjdQ2k7TRkK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> How complex a model needs to be to accurately learn from data without overfitting? - Derive bounds on the generalization error of a learning algorithm (e.g. Inequality: bound probability of random variable deviating from its expected value / bounds probability of estimator deviating from its expected value by a certain amount = provide guarantees on accuracy of estimator).\n",
        "\n",
        "**Expressibility (Expressiveness or Representational Capacity)**:\n",
        "* Expressibility refers to the ability of a learning model or algorithm to represent a wide variety of functions or concepts. It's about the richness of the hypothesis space that the model can capture.\n",
        "* For example, a neural network with more layers and nodes has higher expressibility because it can represent more complex functions compared to a simpler network.\n",
        "* Expressibility is closely related to the concepts like VC dimension or Rademacher complexity, which measure the capacity of a model class to fit data."
      ],
      "metadata": {
        "id": "tyB6nQ3AXv8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In order to solve a specific problem, one has to find a model with sufficient capacity, but not too much, and an according sample size to the model?**\n",
        "\n",
        "\n",
        "Sufficient Capacity: The model should have enough capacity (or complexity) to capture the underlying patterns or relationships in the data. If the model's capacity is too low, it will underfit, meaning it cannot capture the complexity of the data.\n",
        "\n",
        "Avoiding Excess Capacity: On the other hand, if the model's capacity is too high, it risks overfitting, where it starts to learn the noise and random fluctuations in the training data as if they were meaningful patterns. This leads to poor generalization to new, unseen data."
      ],
      "metadata": {
        "id": "X2n0nVThRb_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Complexity I: Model Capacity / Power / Expressivity (for Generalization)**\n",
        "\n",
        "> Model complexity is the size or complexity of the function that an algorithm can learn.Bounding model complexity of learning algorithms: showing that the algorithm is unlikely to learn a function that is too complex, given a sufficient number of training samples. This helps us to prevent the algorithm from overfitting the training data. e.g. **Bounding the model complexity of neural networks**:  Concentration inequalities can be used to show that neural networks are unlikely to learn a function that is too complex, given a sufficient number of training samples and a suitable regularization scheme.\n",
        "\n",
        "* **Capacity** = **depth of functions** (for Generalization): complex functions (can be wide or narrow), also called model power or expressivity. Masure of how many possible hypotheses a learning algorithm can consider (e.g. number of parameters in ML model). Complex models can learn more complex functions, but also more likely to overfit training data and not generalize well to new data.\n",
        "\n",
        "  * (attention, double check this) It is important to distinguish between model capacity and expressivity. Capacity refers to the ability of a model to learn any function, while expressivity refers to the ability of a model to learn a specific class of functions. For example, a neural network with a large number of parameters may have high capacity, but it may not be expressive enough to learn a complex function such as the XOR function.\n",
        "\n",
        "* **Objective of Measuring Model Complexity: understanding how well model can generalize on dataset (prediction error)**\n",
        "  * No overfitting on training (high capacity networks, number of possible hypothesis not too small, but also not too large), not too high variance.\n",
        "  * **Determine bounds** on smallest possible variance, which is ultimately achievable precision, and on shattered (separated) points.\n",
        "  * Generalization (Prediction error) depends on both the training error as well as the complexity of the trained model. The prediction error is small only if training error is itself small and the **complexity of trained model is moderate** (i.e., sufficiently smaller than training data size).\n",
        "\n",
        "* Paper: [On the expressivity of embedding quantum kernels](https://arxiv.org/abs/2309.14419)\n",
        "\n",
        "*There is a relationship between Generalization and capacity (max capacity is not necessarily what we want):*\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1399.png)\n",
        "\n",
        "* [Neural network capacity](https://en.m.wikipedia.org/wiki/Artificial_neural_network#Capacity): A model's \"capacity\" property corresponds to its ability to model any given function. It is related to the amount of information that can be stored in the network and to the notion of complexity.\n",
        "\n",
        "* **Model capacity**: complexity of the patterns a model is capable of learning from the data. Is often associated with size or complexity of model — a model with more parameters (like a deep neural network) has a higher capacity than one with fewer parameters (like a simple linear regression).\n",
        "  * A higher capacity model is theoretically able to learn more complex relationships in the data, but this also opens up the risk of overfitting, where the model learns the noise or specific quirks of the training data instead of the general underlying patterns.\n",
        "\n",
        "* **Expressivity**: how well a model can approximate a wide variety of functions? A neural network with a higher number of layers and neurons would be considered more expressive than a network with fewer layers and neurons because it can theoretically approximate a greater variety of functions [Source](https://www.youtube.com/watch?v=ETxQNIR6dAg&t=684s).\n",
        "\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1602.png)\n",
        "\n",
        "**Metrics for Model Complexity (Measuring Bounds)**\n",
        "\n",
        "*Different measures (metrics) of model capacity and their usefulness (ED: effective dimension):*\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1644.png)\n",
        "\n",
        "*Model Complexity - Measure Metrics*\n",
        "* VC dimension\n",
        "* Rademacher complexity\n",
        "* Fisher-Rao norm, Fisher Information and Quantum Cramér-Rao Bound\n",
        "* Covering number\n",
        "* Fat-Shattering Dimension\n",
        "* Effective dimensions\n",
        "* Frobenius norm\n",
        "* Spectral norm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tZOQKo-v-PWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Complexity II: Model Expressibility (Trainability)**\n",
        "\n",
        "* **Expressibility** = **width of functions** (for trainability): wide array of functions (can be complex or shallow)\n",
        "\n",
        "* Expressibility of circuits: Learning an unknown unitary\n",
        "\n",
        "* **Expressibility & trainability is a tradeoff!!**\n",
        "\n",
        "* Expressibility generally refers to the ease with which a model can be trained to approximate a desired function.\n",
        "\n",
        "* Zoe Holmes: reduce expressibility to increase trainability. Find ansatz that fits the use case problem.\n",
        "\n",
        "* https://pennylane.ai/qml/demos/tutorial_haar_measure.html\n",
        "\n",
        "* Barren plateaus, and hence expressibility issues, are not so much in classical ML, because vanishing cost gradients are not so much of an issue in classical ML because we don‘t have precision limitations in the same way.  You don‘t have to evauluate your cost function using many many shots, or is so resource intensive to get gradients.\n",
        "* In quantum ML: you can use ideas from control theory to try to assess whether or not your ansatz is gonna be trainable or not in advance. Thats an important strategy.\n",
        "* The other approach: use symmetries of your problem / you gonna have to use physics to come up with whats a good ansatz. ZB: use VGQ for some system with various (particle number conserving) translational symmetries, you want to build all of those symmetries into your ansatz and hence reduce expressibility while capturing some of the solution space.\n",
        "\n",
        "* Maria schuld paper: how expressive are circuits? You can distribute circuits and how flexible are they? - identity gate maps to one point only. If you have a couple of more gates it maps to more points.\n",
        "\n",
        "https://arxiv.org/abs/1905.10876: Expressibility and entangling capability of parameterized quantum circuits for hybrid quantum-classical algorithms\n",
        "\n",
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1408.png)\n",
        "\n",
        "Is expressivity even important? (maria schuld) https://www.youtube.com/watch?v=8bfUMdj0-x4&t=1384s\n",
        "\n",
        "*Model Complexity in Deep Learning:*\n",
        "\n",
        "* **Expressive capacity**: model complexity may refer to capacity of deep models in expressing or approximating complicated distribution functions (seems to be **expressibility** = width, wide array of functions, complex or shallow)\n",
        "* **Effective complexity**: describes how complicated the distribution functions are with some parameterized deep models (seems to be **capacity** = depth, complex functions, wide or narrow)\n",
        "\n",
        "**There cases where expressibility is high and capacity is small and vice versa:**\n",
        "\n",
        "* You can have High expressibility, small capacity (shallow neural nets), but unlikely to have Low expressibility, high capacity.\n",
        "\n",
        "* **High expressibility, small capacity**: This could potentially occur in situations where a model has a wide range of different functions it can represent (high expressibility) but is limited in the complexity of those functions (small capacity). For example, a shallow neural network (only a few layers deep) can represent a wide variety of different functions, but it may struggle to accurately represent highly complex functions or patterns (like those present in high-dimensional data or complex tasks). This is because it lacks the depth necessary for creating intricate compositional representations.\n",
        "\n",
        "* **Low expressibility, high capacity**: This situation might be harder to come by, but one could imagine a scenario where a model has the potential to represent very complex functions (high capacity) but is restricted in the variety of functions it can actually express due to constraints on its parameters (low expressibility). An example could be a deep neural network with high capacity but with parameters constrained in such a way that it can only express a narrow range of functions. However, such a situation might be considered somewhat artificial.\n",
        "\n",
        "*Expressibility generally refers to the ease with which a model can be trained to approximate a desired function. Here some methods give you a more targeted approach to evaluating and measure model expressibility! It remains a nuanced topic with many factors at play:*\n",
        "\n",
        "1. **Training Convergence**: You can monitor the training convergence of the model, i.e., how quickly and reliably it reaches a minimum of the loss function during training.\n",
        "\n",
        "2. **Gradient-Based Metrics**: Examine the gradients during training, since the behavior of gradients (like vanishing or exploding gradients) can affect the expressibility of the model.\n",
        "\n",
        "3. **Loss Landscape Analysis**: Analyze the loss landscape of the model using techniques such as visualization of loss landscapes to understand the complexity and the potential difficulties in training the model.\n",
        "\n",
        "4. **Hessian-Based Analysis**: Use Hessian-based analysis to study the second-order properties of the loss function, which can provide insights into the local curvature of the loss landscape and potentially the expressibility of the model.\n",
        "\n",
        "5. **Optimization Trajectory**: Study the optimization trajectory of the model during training. Some models may have smoother, more predictable trajectories that suggest better expressibility.\n",
        "\n",
        "6. **Sensitivity to Initialization**: Investigate how the model's performance varies with different initialization strategies. A model that can train effectively from a wide range of initializations might be said to have good expressibility.\n",
        "\n",
        "7. **Sensitivity to Hyperparameters**: Analyze the sensitivity of the model to hyperparameter settings. If a model can only be trained effectively with a very narrow range of hyperparameter settings, it might have limited expressibility.\n",
        "\n",
        "8. **Generalization Gap**: Study the generalization gap, which is the difference between training error and test error. A smaller generalization gap might indicate better expressibility, as it suggests that the model is able to learn a more useful representation of the data.\n",
        "\n",
        "9. **Empirical Studies**: Conduct empirical studies where you train the model on a range of different tasks and datasets to see how easily it can adapt to different kinds of data and problem structures.\n",
        "\n",
        "10. **Computational Resources**: Evaluate the computational resources (time, memory) required to train the model. A model that requires less computational resources to reach a certain level of performance might be said to have better expressibility.\n"
      ],
      "metadata": {
        "id": "kuNW1Ap_Kzdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Myths Buster in study of complexity notions*"
      ],
      "metadata": {
        "id": "0md9DQ34gkax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Myths Buster in study of complexity notions**\n",
        "\n",
        "https://www.inference.vc/generalization-and-the-fisher-rao-norm-2/\n",
        "\n",
        "*Myth #1: Current theory is lacking because deep neural networks have too many parameters*\n",
        "\n",
        "* P. Bartlett, “The Sample Complexity of Pattern Classification with Neural Networks: The Size of the Weights is More Important than the Size of the Network,” 1998\n",
        "* Margin theory was developed to address this very problem for Boosting and NN (e.g. Koltchinskii & Panchenko ’02 and references therein)\n",
        "* Example: linear classifiers $\\left\\{x \\mapsto \\operatorname{sign}(\\langle w, x\\rangle):\\|w\\|_2 \\leq 1\\right\\}$ and assume margin. Then dimension of $w$ (num. of params in 1-layer NN) nevel appears in generalization bounds (and can be infinite). This observation already appears in the 60 's.\n",
        "* In Statistics, one often deals with infinite-dimensional models\n",
        "* Number of parameters is rarely the right notion of complexity (true, in classical statistics still the case for linear regression or simple models)\n",
        "* VC dimension is known to be a loose quantity (distribution-free, only an upper bound)\n",
        "* Our own (arguably incomplete) take on this problem:\n",
        "T. Liang, T. Poggio, J. Stokes, A.R. “Fisher-Rao Metric, Geometry, and Complexity of Neural Networks,” 2017.\n",
        "  * Fisher local norm as a common starting point for many measures of complexity currently studied in the literature (see work of Srebro’s group and Bartlett et al).\n",
        "  * Information Geometry suggests Natural Gradient as the optimization method. Appears to resolve ill-conditioned problems in Shalev-Shwartz et al ’17.\n",
        "\n",
        "*Myth #2: To prove good out-of-sample performance, we need to show uniform convergence (a la Vapnik) over some class*\n",
        "\n",
        "* The oldest counter-example: Cover and Hart, “Nearest neighbor pattern classification,” 1967.\n",
        "* Second (related) issue: uniform vs universal consistency.\n",
        "* **Uniform Consistency**: There exists a sequence $\\left\\{\\hat{y}_t\\right\\}_{t=1}^{\\infty}$ of estimators, such that for any $\\epsilon>0$, there exists $n_e$ such that for any distribution $P \\in \\mathcal{P}$ and $n \\geq n_e$, $\n",
        "\\mathbb{E} L\\left(\\widehat{y}_n\\right)-\\inf L(f) \\leq \\epsilon\n",
        "$\n",
        "* **Universal Consistency**: There exists a sequence $\\left\\{\\widehat{y}_t\\right\\}_{t=1}^{\\infty}$ of estimators, such that for any distribution $P \\in \\mathcal{P}$ and any $\\epsilon>0$, there exists $n_e$ such that for $n \\geq n_e(P)$, $\n",
        "\\mathbb{E} L\\left(\\widehat{y}_n\\right)-\\inf L(f) \\leq \\epsilon\n",
        "$\n",
        "* Importantly, can interpolate between the two notions using penalization. A few more approaches (e.g. use bracketing entropy)\n",
        "\n",
        "*Myth #3: Sample complexity of neural nets scales exponentially with depth*\n",
        "\n",
        "* A common pitfall of making conclusions based on (possibly loose) upper bounds. Mostly resolved: N. Golowich, A.R., O. Shamir, “Size-Independent Sample Complexity of Neural Networks,” 2017\n",
        "* From $2^{\\mathrm{d}}$ to $\\sqrt{\\mathrm{d}}$ dependence was simply a technical issue. From $\\sqrt{\\mathrm{d}}$ to $O(1)$ requires more work.\n",
        "\n",
        "*Myth #4: If we can fit any set of labels, then Rademacher complexity is too large and, hence, nothing useful can be concluded*\n",
        "\n",
        "* Related to Myth #2, but let’s illustrate with a slightly di↵erent technique. Bottom line: we can have a very large overall model, but performance depends on a **posteriori** complexity of the **obtained** solution.\n",
        "* Most trivial example: take a large $\\mathcal{F}=\\cup_k \\mathcal{F}_k$, where $\\mathcal{F}_k=\\left\\{f: \\operatorname{compl}_n(f) \\leq k\\right\\}$ and for simplicity assume $\\operatorname{compl}_n(f)$ is positive homogenous. Suppose (this is standard) we have that with high probability\n",
        "  * $\n",
        "\\forall f \\in \\mathcal{F}_1, \\quad \\mathbb{E f}-\\widehat{\\mathbb{E}} \\mathrm{f} \\lesssim \\widehat{\\mathscr{R}}\\left(\\mathcal{F}_1\\right)+\\ldots\n",
        "$\n",
        "* where $\\widehat{\\mathscr{R}}\\left(\\mathcal{F}_1\\right)$ is empirical Rademacher. Then with same probability\n",
        "  * $\n",
        "\\forall f \\in \\mathcal{F}, \\quad \\mathbb{E} f-\\widehat{\\mathbb{E}} f \\lesssim \\operatorname{compl}_n(f) \\cdot \\widehat{\\mathscr{R}}\\left(\\mathcal{F}_1\\right)+\\ldots\n",
        "$\n",
        "* Conclusion: an a posteriori data-dependent guarantee for all $\\mathrm{f}$ based on complexity of $f$, yet $\\widehat{\\mathscr{R}}(\\mathcal{F})$ never appears (huge or infinite). If complexity is not positive homogenous, use union bound instead.\n",
        "\n",
        "*Is there anything left to do? Yes, tons. Perhaps need to ask different questions*\n",
        "* What are the properties of solutions that optimization methods find in a nonconvex landscape? Is there “implicit regularization” that we can isolate? - a nice line of work by Srebro and co-authors\n",
        "* What are the salient features of the random landscape? Uniform deviations for gradients and Hessians? - nice work by Montanari and co-authors\n",
        "* How can one exploit randomness to make conclusions about optimization solutions? (e.g. see the SGLD work of Raginsky et al, as well as papers on escaping saddles)\n",
        "* What geometric notions can be associated to multi-layer neural nets? How can this geometry be exploited in optimization methods and be reflected in sample complexity?\n",
        "* Theoretical understanding of adversarial examples. etc."
      ],
      "metadata": {
        "id": "CobPNZxamooq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Model Complexity of classical deep learning*"
      ],
      "metadata": {
        "id": "jRi0tikbgikC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Model Complexity of classical deep learning*\n",
        "\n",
        "* the expressive power of a model is used to bound the generalization error\n",
        "* Vapnik-Chervoneniks (VC) dimension [26]. Besides, Rademacher complexity and Gaussian complexity [8, 12] are also used to mea- sure model complexity of logistic regression models\n",
        "* Comparing to VC dimension, Rademacher complexity takes data distribution into consideration and therefore reflects finer-grained model complexity.\n",
        "* suggest that model complexity of logistic regression models is related to the number of distinguishable distributions that can be rep- resented by the models.\n",
        "* Bulso et al. [21] define a complexity measure of logistic regression models based on the determinant of the Fisher Information matrix.\n",
        "* Spiegelhater et al. [93] define a model complexity measure by the number of effective parameters. Using the information theoretic argument, they show that this complexity measure can be estimated by the difference between the posterior mean of the deviance and the deviance at the posterior estimates of the parameters of interest, and is approximately the trace of the product of Fisher’s information [33] and the posterior covariance matrix.\n",
        "* Complexity measures are often model specific and complexity measures of different model frameworks cannot be compared\n",
        "* Expressibility: A notion to capture hypothesis space complexity is Rademacher complexity [12], which measures the degree to which a hypothesis space can fit random noise. Another notion is VC dimen- sion [26], which reflects the size of the largest set that can be shattered by the hypothesis space. Exploring expressive capacity helps to obtain the guarantee of learnability of deep models and derive generalization bounds\n",
        "* Page 11: The comparison of deep and shallow sum- product networks representing the same function indicates that, to represent the same functions, the number of neurons in a shallow network has to grow exponentially but only a linear growth is needed for deep networks.\n",
        "* Page 26: First, based on the piecewise linear property, Novak et al. [81] propose the Jacobian norm to measure the local sensitivity under the assumption that the input is perturbed within the same linear region. (Includes Frobenius norm)\n",
        "* To approach the generalization problem of deep learning models, Liang et al. [60] introduce a new notion of model complexity measure, the Fisher-Rao norm.\n",
        "* In statistical learning theory, expressive capacity (i.e., hypothesis space com- plexity) is used to bound generalization error [69]\n",
        "* Page 33: Based on these desiderata, Neyshabur et al. [76] investigate several complex- ity measures including norms [79], robustness [97], and sharpness [50]. They show that, these measures can meet some of the above requirements, but not all.\n",
        "* Novak et al. [81] define two complexity measures from the perspective of model sensitivity, and identify an empirical correlation between the complexity measures and model generalization capability. They show that operations that lead to poor generalization, such as full batch training, correspond to high sen- sitivity, and in turn imply high effective model complexity. Similarly, operations that lead to good generalization, such as data augmentation, correspond to low sensitivity, and thus imply low effective model complexity.\n",
        "* In other words, many different parameterizations may lead to the same prediction. Thus, the specific parameterization of deep models should not affect the generalization and the complexity measure. They show that the Fisher-Rao norm honors this invari- ance property and thus is able to explain the generalization capability of deep learning models.\n",
        "* On one hand, making predictions with high accuracy is the essential goal of learning a model [69]. A model is expected to be able to capture the underlying patterns hidden in the training data and achieve predictions of accuracy as high as possible. In order to represent a large amount of knowledge and obtain high accuracy, a model with a high expressive capacity, a large degree of freedom and a large training set is required [13]. To this extent, a model with more parameters and higher complexity is favored.\n",
        "    * On the other hand, an overly complex model may be difficult to train and may incur unnecessary resource consumption, such as storage, computation and time cost [72]. Unnecessary resource consumption should be avoided particularly in practical large scale applications [42]. To this extent, a simpler model with comparable accuracy is preferred than a more complicated one.\n",
        "* Can we obtain a lower bound of expressive capacity of deep learning models that are sufficient for a given task? Does a narrow layer limit the expressive capacity of a model even if the model itself has a large number of parameters?"
      ],
      "metadata": {
        "id": "TLrBzX9qghLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ***$\\hookrightarrow$ Sample and Query Complexity***"
      ],
      "metadata": {
        "id": "02eilyDPlFh8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [Sample Complexity](https://en.m.wikipedia.org/wiki/Sample_complexity): number of training examples that the most efficient learning algorithm needs to see in order to **learn a concept with a certain accuracy** (an arbitrarily small error of best possible function, with probability arbitrarily close to 1)\n",
        " - It's a measure of how data-efficient a learning algorithm is.\n",
        "  * A high sample complexity means that a large amount of data is needed to ensure good generalization.\n",
        "  * a learning algorithm with low sample complexity can achieve good performance with less data.\n",
        "\n",
        "* estimate how large a sample size is needed to ensure that the empirical average of a random variable is close to its true mean with high probability (especially relevant in scenarios like empirical risk minimization, where one seeks to minimize the discrepancy between the empirical risk (based on finite samples) and the true risk)\n",
        "\n",
        "* Bounding sample complexity:\n",
        "  * showing that output of learning algorithm is close to its expected value with high probability, given a sufficient number of training samples. Allows us to set a confidence bound on  accuracy of the algorithm, even if we have only seen a small number of training samples.\n",
        "  * e.g. **Bounding sample complexity of empirical risk minimization (ERM) or online learning**: (ERM=average loss on the training data). Concentration inequalities can show that ERM learns a function with a small generalization error with high probability, given a sufficient number of training samples.\n",
        "  * For only particular class of target functions (e.g. linear functions) sample complexity is finite and depends linearly on [VC dimension](https://en.m.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension) on class of target functions. Sample complexity of C is tightly determined by a combinatorial parameter called the VC dimension of C.\n",
        "\n",
        "* Factors that affect sample complexity of learning a target function:\n",
        "  * Size of hypothesis space: Large space = more samples\n",
        "  * Error tolerance (desired level of accuracy and confidence): Smaller error tolerance = more samples\n",
        "  * Noise: Higher noise = more samples\n",
        "  * Complexity of target function or concept to be learned: More complex target function = more samples\n",
        "\n",
        "* Difference:\n",
        "  * sample complexity focuses on the data requirements for learning,\n",
        "  * model complexity deals with the representational power of the model.\n",
        "\n",
        "* Trade-Offs:\n",
        "  * models with higher complexity (capacity) can represent more complex functions but may require more data (higher sample complexity) to generalize well and avoid overfitting.\n",
        "  * Conversely, simpler models might generalize better with less data but are limited in the complexity of functions they can learn."
      ],
      "metadata": {
        "id": "pA922WyYbUKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sample Complexity - Measure Metrics** (bounds and distances)\n",
        "\n",
        "* [Rademacher Complexity](https://en.m.wikipedia.org/wiki/Rademacher_complexity): upper bound on sample complexity = on learnability of function classes (deriving generalization bounds). Measures ability of functions in class to fit to random noise. [Rademacher Complexity PDF](https://www.cs.cmu.edu/~ninamf/ML11/lect1117.pdf). When the Rademacher complexity is small, it is possible to learn the hypothesis class H using [empirical risk minimization](https://en.m.wikipedia.org/wiki/Empirical_risk_minimization).\n",
        "\n",
        "* [Cauchy–Schwarz inequality](https://en.m.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality). Cauchy-Schwarz inequality used to bound sum of squared residuals (cost function for linear regression) by the sum of the squared predicted values and the sum of the squared actual values. Used in *A Survey of Quantum Learning Theory* page 11 to compute upper bounds of learning algorithm.\n",
        "\n",
        "* [Cramér–Rao bound](https://en.m.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound): lower bound (min value) on variance of an unbiased estimator (but cannot tell about probability of deviation) - this value is inverse of [Fisher information](https://de.m.wikipedia.org/wiki/Fisher-Information#Verwendung)(how much information data provides about parameters being estimated). Used to design estimators that are as efficient as possible.\n",
        "\n",
        "* Metric entropy\n",
        "\n",
        "* Covering number\n",
        "\n",
        "\n",
        "...\n",
        "\n",
        "* Haar measure: Quantum learning algorithm: define **average complexity** by sampling a unitary matrix from the Haar measure and then measuring sample complexity of the algorithm on the resulting quantum state. Average complexity is then the expected value of the sample complexity over all possible unitary matrices. Train machine learning models on quantum data: can be done by sampling a large number of random unitary operations and applying them to the data. The Haar measure ensures that all possible unitary operations have an equal chance of being sampled.\n",
        "* VC dimension, Rademacher complexity and Kullback Leibler divergence can all be used to measure the **worst-case complexity** (sample complexity of algorithm on worst possible quantum state)."
      ],
      "metadata": {
        "id": "eZZsreIaEoy2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**\"Up to constant factors\" in sample complexity**\n",
        "\n",
        "* two quantities are equal, with an error that is bounded by a constant (= error is always within a certain range, regardless of input, e.g. absolute value of error will never be greater than 1)\n",
        "\n",
        "* useful to make statements about performance or complexity of algorithms, without having to worry about the exact values of the constants (exact sample complexity of learning problem often difficult to determine)\n",
        "\n",
        "* If sample complexity of learning a concept is up to constant factors $c$, then any two learning algorithms that learn concept must use number of samples that is within a factor of $c$ of each other.\n",
        "\n",
        "* e.g. PAC learning model guarantees that any concept that can be PAC-learned can be learned with a sample complexity that is polynomial in the size of the hypothesis space and logarithmic in the inverse of the desired error rate. This means that the sample complexity is \"up to constant factors\" of the logarithm of the inverse of the error rate.\n",
        "\n"
      ],
      "metadata": {
        "id": "xOHRIRBzzqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query Complexity**\n",
        "\n",
        "* PAC and agnostic learning: sample complexities. Exact learning: query complexity.\n",
        "\n",
        "* QSQ: query to learn about quantum state of system (measure expectation value of observable, or extract information about entanglement of state)\n",
        "\n",
        "* Diagonal-QSQ is way of restricting types of QSQs that can be used to learn the output distributions of constant-depth circuits.\n",
        "\n",
        "  * only QSQs that can be expressed in terms of diagonal elements of density matrix of state can be used\n",
        "  \n",
        "  * How many QSQs are required to learn the output distributions of the circuits with a certain accuracy? - difficult to solve (no known general upper bounds on QSQ complexity, and best known lower bounds are exponential in number of qubits in circuits)\n",
        "\n",
        "  * Use QML to learn output distributions of these circuits with fewer QSQs.\n"
      ],
      "metadata": {
        "id": "Eh4FwtN5_Mh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <font color=\"blue\">*Distance Measures*"
      ],
      "metadata": {
        "id": "Cmqnes9brFPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Introduction*"
      ],
      "metadata": {
        "id": "LOnEwXajSzfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cramer rao bound amd Cauchy–Schwarz inequality, Frobeniusnorm:\n",
        "variance ideal for quantum Hilbert space?\n",
        "\n",
        "How much is a loss function concentrated around its mean (not partial derivative concentration)?\n",
        "\n",
        "\n",
        "**Currently: how to study Parametrized Quantum Circuits (PQCs)?**\n",
        "\n",
        "* Expressivity / Capacity\n",
        "* Trainability\n",
        "  * subset of computational complexity and circuit complexity?\n",
        "* Generalization > which model or algorithm to choose best?\n",
        "* Sample complexity\n",
        "\n",
        "**Generalization in Machine Learning:**\n",
        "\n",
        "* Generalization refers to the ability of an algorithm to **perform accurately on new, unseen data after being trained on a sample dataset**. The goal is to learn patterns that are not just specific to the training data but also applicable to new data.\n",
        "\n",
        "* Uniform Generalization Bounds: These bounds provide a measure of how well the learned model will generalize across all possible data distributions, not just the one it was trained on. They are called 'uniform' because they provide a guarantee that holds uniformly over a class of functions or models.\n",
        "\n",
        "* Role of Sample Size: One key aspect of these bounds is that they typically improve with an increase in the size of the training sample. As more data is used to train the model, we can be more confident that the model will generalize well.\n",
        "\n",
        "* Complexity of the Hypothesis Class: **The bounds are also influenced by the complexity of the hypothesis class** (the set of models being considered). More complex classes, such as those with a large number of parameters, typically have **looser bounds, meaning they need more data to ensure good generalization**.\n",
        "\n",
        "* Mathematical Formulation: **The bounds are often derived using tools from probability and statistics, such as concentration inequalities (like Hoeffding’s inequality or McDiarmid's inequality)**. These tools help quantify the likelihood that the observed performance of a model on a sample is close to its true performance on the entire population.\n",
        "\n",
        "* Practical Implication: In practical terms, **uniform generalization bounds help in understanding and choosing models and algorithms**. They provide a theoretical foundation for preferring certain models over others based on their generalization capabilities, given a finite amount of data."
      ],
      "metadata": {
        "id": "lWl0TKgLrsJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Besides model complexity, sample complexity and computational complexity, are there more dimension that need to be considered on computational learning theory?**\n",
        "\n",
        "Yes, besides model complexity, sample complexity, and computational complexity, there are several other dimensions and factors that are important in computational learning theory:\n",
        "\n",
        "1. **Algorithmic Stability**:\n",
        "    - This refers to how sensitive a learning algorithm is to small changes in the training set. Algorithms that are more stable are generally better at generalizing, as they don't overfit to the noise or specific details in the training data.\n",
        "\n",
        "2. **Noise Tolerance**:\n",
        "    - The ability of a learning algorithm to perform well in the presence of noise (errors or randomness in the training data) is crucial. This includes dealing with mislabeled data or data with measurement errors.\n",
        "\n",
        "3. **Robustness**:\n",
        "    - Robustness is the ability of the model to maintain performance when faced with input data that differs from the training data. This includes handling adversarial examples, where small, intentional changes to input data can mislead the model.\n",
        "\n",
        "4. **Learning Rate and Convergence**:\n",
        "    - This pertains to how quickly a learning algorithm converges to a good solution. Fast convergence is desirable for efficiency, but it's also important that the convergence leads to a solution that generalizes well.\n",
        "\n",
        "5. **Bias-Variance Tradeoff**:\n",
        "    - A fundamental concept in statistical learning, the bias-variance tradeoff involves balancing underfitting (bias) and overfitting (variance). It's about finding the right level of model complexity that neither oversimplifies (high bias) nor overcomplicates (high variance) the problem.\n",
        "\n",
        "6. **Data Distribution**:\n",
        "    - The nature of the data distribution, including how representative the training data is of the real-world scenarios the model will encounter, plays a crucial role in the effectiveness of learning.\n",
        "\n",
        "7. **Feature Representation**:\n",
        "    - The way data is represented or pre-processed can significantly impact the performance of a learning algorithm. Good feature representation can ease the learning process and improve generalization.\n",
        "\n",
        "8. **Scalability**:\n",
        "    - Scalability refers to how well a learning algorithm or model can handle increasing amounts of data or more complex problems. This is particularly important in big data applications.\n",
        "\n",
        "9. **Ethical and Social Considerations**:\n",
        "    - This includes considerations of fairness, privacy, and transparency. It's essential to ensure that learning algorithms do not perpetuate or exacerbate biases and are respectful of privacy and ethical norms.\n",
        "\n",
        "10. **Transferability and Adaptability**:\n",
        "    - This refers to the ability of a model to adapt to new tasks or transfer learned knowledge to different but related problems. It's a key aspect of research in areas like transfer learning and domain adaptation.\n",
        "\n",
        "11. **Interpretability and Explainability**:\n",
        "    - The ability to understand and interpret the decisions made by a model is increasingly important, especially for applications in sensitive areas like healthcare or finance.\n",
        "\n",
        "Each of these dimensions adds complexity to the design and evaluation of learning algorithms, and they are often interrelated. Balancing these factors is a key challenge in developing effective and responsible machine learning systems."
      ],
      "metadata": {
        "id": "3dgYVzt0a8lq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What are standard scientific methods to measure model complexity, sample complexity and computational complexity?**\n",
        "\n",
        "Measuring model complexity, sample complexity, and computational complexity in machine learning involves a blend of theoretical analysis and empirical evaluation. Each type of complexity has standard scientific methods associated with it:\n",
        "\n",
        "*1. Model Complexity*\n",
        "Model complexity refers to the ability of a model to fit a wide range of functions. It's often associated with the flexibility of the model to adapt to the underlying data structure.\n",
        "\n",
        "**Standard Methods to Measure:**\n",
        "- **VC Dimension**: For classification models, the Vapnik-Chervonenkis (VC) dimension is a theoretical measure of model capacity. It's the size of the largest set of points that the model can shatter.\n",
        "- **Number of Parameters**: In many models, such as neural networks, the number of trainable parameters is a direct measure of complexity.\n",
        "- **Model Depth and Architecture**: For neural networks, depth (number of layers) and architecture details (like types of layers and connections) indicate complexity.\n",
        "- **Information Criteria**: Metrics like AIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion) are used in statistical modeling to balance model fit and complexity.\n",
        "\n",
        "- Number of Parameters: One of the most common measures of model complexity is the number of parameters. This is a simple and intuitive measure, as it directly reflects the number of degrees of freedom in the model. However, it is not always the most informative measure, as it does not take into account the structure of the model or the relationships between its parameters.\n",
        "\n",
        "- Effective Number of Parameters: A more sophisticated measure of model complexity is the effective number of parameters. This measure takes into account the fact that some parameters may be more important than others, and it can be used to compare models with different numbers of parameters.\n",
        "\n",
        "- VC Dimension: The VC dimension is a theoretical measure of model complexity that is based on the concept of shattering. A shattered set of points is a set of points that can be perfectly classified by a hypothesis class in all possible ways. The VC dimension of a hypothesis class is the maximum size of a shattered set. A higher VC dimension indicates a more complex hypothesis class.\n",
        "\n",
        "- Kolmogorov Complexity: Kolmogorov complexity is a measure of the information content of an object. It is based on the idea that the complexity of an object is the shortest possible program that can generate it. Kolmogorov complexity can be used to measure the complexity of models, as well as the complexity of data.\n",
        "\n",
        "*2. Sample Complexity*\n",
        "Sample complexity relates to the amount of data required for a model to achieve a certain level of performance.\n",
        "\n",
        "**Standard Methods to Measure:**\n",
        "- **Empirical Evaluation**: Experimentally determining how model performance varies with different training set sizes. This often involves plotting learning curves.\n",
        "- **PAC Learning Framework**: Probably Approximately Correct (PAC) learning provides theoretical bounds on the number of samples needed for a model to learn a concept within a certain error margin and confidence level.\n",
        "- **Cross-validation**: Techniques like k-fold cross-validation can help assess how well a model with certain complexity performs with the available data.\n",
        "\n",
        "- Learning Curves: Learning curves are a simple and effective way to measure sample complexity. A learning curve is a plot of the training and generalization error of a model as a function of the number of training examples. A steeper learning curve indicates that the model is more sensitive to the number of training examples and therefore has higher sample complexity.\n",
        "\n",
        "- Error Bounds: Error bounds are a more theoretical way to measure sample complexity. Error bounds provide an upper bound on the generalization error of a model with a given level of confidence. A smaller error bound indicates lower sample complexity.\n",
        "\n",
        "- Rademacher Complexity: Rademacher complexity is a measure of the generalization error of a model that is based on the concept of Rademacher averages. Rademacher averages are a type of random average that is used to control for the randomness of the training data. A smaller Rademacher complexity indicates lower sample complexity.\n",
        "\n",
        "*3. Computational Complexity*\n",
        "Computational complexity is about the resources (time, memory) required to train or use a model.\n",
        "\n",
        "**Standard Methods to Measure:**\n",
        "- **Big O Notation**: Theoretical analysis of algorithms in terms of time and space complexity (e.g., O(n), O(n^2)) is standard.\n",
        "- **Time Profiling**: Empirically measuring the actual time taken to train models on datasets of varying sizes.\n",
        "- **Space Profiling**: Measuring the memory requirements of a model during training and inference.\n",
        "- **Algorithm Analysis**: Analyzing the specific steps of an algorithm to determine their computational requirements.\n",
        "\n",
        "- Time Complexity: Time complexity is a measure of the amount of time that an algorithm takes to run as a function of the input size. Time complexity is typically expressed using Big O notation, which provides an upper bound on the worst-case performance of the algorithm.\n",
        "\n",
        "- Space Complexity: Space complexity is a measure of the amount of memory that an algorithm requires to run as a function of the input size. Space complexity is also typically expressed using Big O notation.\n",
        "\n",
        "- Scalability: Scalability is a measure of how well an algorithm can handle increasing input sizes. An algorithm is said to be scalable if its time and space complexity grow sublinearly with the input size.\n",
        "\n",
        "*Integrating Theoretical and Empirical Approaches*\n",
        "In practice, a combination of these methods is often used. Theoretical measures provide a guideline or a framework, while empirical methods offer practical insights based on real-world data and computing environments. The choice of method depends on the specific model, the nature of the task, and the available resources. For example, in deep learning, empirical evaluation is heavily relied upon due to the complexity and non-linearity of the models, while in more traditional machine learning or statistical models, theoretical measures might be more prominently used."
      ],
      "metadata": {
        "id": "7FbmpALiSvmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Dimension</font> (VC, Fat-shattering, Pseudo, Effective, Hausdorff)*"
      ],
      "metadata": {
        "id": "ijtvzpIDxEzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dimensions**\n",
        "\n",
        "[Dimension](https://en.m.wikipedia.org/wiki/Dimension).Dimensionality measures are used to quantify the complexity of a set of points or a function class. They are often used in machine learning to bound the sample complexity of learning algorithms.\n",
        "* in mathematics, is a particular way of describing the size of an object (contrasting with measure and other, different, notions of size). Dimensionality measures are also used to study the relationships between different complexity classes. For example, it is known that the complexity class PSPACE is contained in the complexity class EXPTIME. This can be shown using the following theorem: Theorem: The metric entropy of any hypothesis class with VC dimension d is at most d. This theorem tells us that the complexity class PSPACE, which contains all problems that can be solved by a polynomial space Turing machine, is contained in the complexity class EXPTIME, which contains all problems that can be solved by an exponential time Turing machine. Dimensionality measures are a powerful tool for studying the complexity of computational problems. They can be used to bound the resource requirements of algorithms, and to study the relationships between different complexity classes.\n",
        "\n",
        "*Examples:*\n",
        "\n",
        "* [Effective dimension](https://en.m.wikipedia.org/wiki/Effective_dimension) is a modification of Hausdorff dimension and other fractal dimensions that places it in a computability theory setting. There are several variations (various notions of effective dimension) of which the most common is effective Hausdorff dimension.\n",
        "\n",
        "  * effective dimension is a modification of Hausdorff dimension and other fractal dimensions that places it in a computability theory setting\n",
        "\n",
        "  * to measure power / capacity of a model [Source](https://www.youtube.com/watch?v=fDIGmkq9xNE&t=2067s)\n",
        "\n",
        "  ![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1398.png)\n",
        "\n",
        "* [Hausdorff dimension](https://en.m.wikipedia.org/wiki/Hausdorff_dimension) generalizes the well-known integer dimensions assigned to points, lines, planes, etc. by allowing one to distinguish between objects of intermediate size between these integer-dimensional objects.\n",
        "\n",
        "* [Intrinsic dimension](https://en.m.wikipedia.org/wiki/Intrinsic_dimension): The intrinsic dimension of a set of points is the smallest number of parameters needed to represent the points accurately.\n",
        "\n",
        "* [Fractal dimension](https://en.m.wikipedia.org/wiki/Fractal_dimension) provides a rational statistical index of complexity detail in a pattern. A fractal pattern changes with the scale at which it is measured. It is also a measure of the space-filling capacity of a pattern, and it tells how a fractal scales differently, in a fractal (non-integer) dimension.\n",
        "\n",
        "* [Lebesgue covering dimension](https://en.m.wikipedia.org/wiki/Lebesgue_covering_dimension) or topological dimension of a topological space is one of several different ways of defining the dimension of the space in a topologically invariant way\n",
        "\n",
        "* [Krull dimension](https://en.m.wikipedia.org/wiki/Krull_dimension)\n",
        "\n",
        "* [Inductive dimension](https://en.m.wikipedia.org/wiki/Inductive_dimension)\n",
        "\n",
        "* [Minkowski–Bouligand dimension](https://en.m.wikipedia.org/wiki/Minkowski–Bouligand_dimension) also known as Minkowski dimension or box-counting dimension, is a way of determining the fractal dimension of a set S in a Euclidean space $\\mathbb {R} ^{n}$, or more generally in a metric space (X,d).\n",
        "\n",
        "* [Information dimension](https://en.m.wikipedia.org/wiki/Information_dimension) is a measure of the fractal dimension of a probability distribution. It characterizes the growth rate of the Shannon entropy given by successively finer discretizations of the space.\n",
        "\n",
        "  * In 2010, Wu and Verdú gave an operational characterization of [Rényi information dimension = Rényi entropy](https://en.m.wikipedia.org/wiki/Rényi_entropy) as the fundamental limit of almost lossless data compression for analog sources under various regularity constraints of the encoder/decoder.\n",
        "\n",
        "  * Enge Verbindung zwischen Entropy und Dimension measures.\n",
        "\n",
        "* [Correlation dimension](https://en.m.wikipedia.org/wiki/Correlation_dimension) is a measure of the dimensionality of the space occupied by a set of random points, often referred to as a type of fractal dimension.\n",
        "\n",
        "* [Packing dimension](https://en.m.wikipedia.org/wiki/Packing_dimension)\n",
        "\n",
        "* [Equilateral dimension](https://en.m.wikipedia.org/wiki/Equilateral_dimension)\n",
        "\n",
        "* [Dimensions of commutative algebra](https://en.m.wikipedia.org/wiki/Glossary_of_commutative_algebra#dimension), like Embedding dimension"
      ],
      "metadata": {
        "id": "DFFd1liCm28M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Vapnik-Chervonenkis, Pseudo- and Fat-Shattering Dimensions are three distinct notions of “dimension”. The phrase “dimension” is rather unfortunate, as the three “dimensions” have nothing to do with the dimension of a vector space, except in very special situations. Rather, these “dimensions” are combinatorial parameters that measure the “richness” of concept classes or function classes.*\n",
        "\n",
        "* [Vapnik–Chervonenkis dimension](https://en.m.wikipedia.org/wiki/Vapnik–Chervonenkis_dimension)\n",
        "  * It quantifies the expressive power or complexity of a hypothesis class in terms of its ability to \"shatter\" sets of points. It's a scalar value that provides insight into the capacity of a class of functions or models.\n",
        "  * A hypothesis class is said to \"shatter\" a set of points if, for every possible labeling of the points, there exists a hypothesis in the class that can perfectly classify those points according to that labeling. VC dimension is defined in terms of shattering.\n",
        "  * It is the most widely used complexity metric in PAC learning, and it has been used to prove a number of important theoretical results.\n",
        "  * However, the VC dimension is not a perfect metric for the complexity of a hypothesis class. For example, the VC dimension of the class of all linear classifiers is infinite, even though linear classifiers can be learned efficiently from a small number of training examples.\n",
        "  * In PAC learning: Let H be a hypothesis class with VC dimension d. Then, the sample complexity of PAC learning H is given by: $n >= O(d / ε^2 * ln(1/δ))$, where ε is the desired error tolerance and δ is the desired confidence level.\n",
        "  \n",
        "  * [*Bias-Variance Tradeoff*](https://en.m.wikipedia.org/wiki/Bias–variance_tradeoff): This is a key principle in statistical learning that helps to understand the tradeoff between model complexity and the risk of overfitting, which impacts the number of samples needed for learning.\n",
        "\n",
        "  * Higher VC-dimension of a class = more samples are required to learn that class. Bounds on sample complexity using VC-dimension are often given in the form, where d is the VC-dimension:\n",
        "\n",
        "  * $m \\geq \\frac{8}{\\epsilon} \\ln \\left(\\frac{4}{\\delta}\\right)+\\frac{4}{\\epsilon} d \\ln \\left(\\frac{2 e m}{d}\\right)$\n",
        "\n",
        "  * measure of the capacity: The more complex the hypothesis space, the more likely it is that the learning algorithm will overfit the training data and make errors on new data (-that was assumed for neural nets).\n",
        "\n",
        "  * The VC dimension can be used to choose a hypothesis space that is not too complex, so that the learning algorithm can generalize well to new data. sample complexity of C is tightly determined by a combinatorial parameter called the VC dimension of C. measure of the capacity of a hypothesis space, which is the set of all possible hypotheses that can be learned by a machine learning algorithm.\n",
        "\n",
        "  * A hypothesis space with a higher VC dimension can learn more complex functions, but it will also be more likely to overfit the training data. The VC Dimension can provide an **upper bound on the sample complexity in terms of the size of the hypothesis class**, the desired error rate, and the confidence level.\n",
        "\n",
        "  ![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1397.png)\n",
        "\n",
        "  * *Shatter points = separate points: how these functions can separate or \"shatter\" sets of points. If you can find large sets of points that can be arbitrarily labeled (i.e., \"shattered\") by functions in your class, then the class has high complexity. - Shattered:  A set of points is shattered by H if for every possible labeling of the points, there exists a hypothesis in H that agrees with that labeling.*\n",
        "\n",
        "  * One of the most fundamental results in learning theory is that the sample complexity of C is tightly determined by a combinatorial parameter called the VC dimension of C (Source: Optimal Quantum Sample Complexity of Learning Algorithms)\n",
        "\n",
        "  ![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1643.png)\n",
        "\n",
        "  * VC dimension is still a useful concept in machine learning. It can be used to understand the complexity of a neural network and to choose a neural network that is not too complex, so that it can generalize well to new data.\n",
        "\n",
        "  * Limitations of the VC dimension (VC dimension theorem would seem to imply that large neural networks would overfit very badly and never generalize well):\n",
        "    * The VC dimension is only a theoretical bound, and it is not always accurate in practice. The VC dimension theorem assumes that the training data is drawn from an i.i.d. (independent and identically distributed) distribution. However, in practice, the training data is often not i.i.d., and this can make the VC dimension theorem less accurate.\n",
        "    * The VC dimension does not take into account the complexity of the target function. The VC dimension is only a bound on the generalization error. It is possible for a neural network to have a large VC dimension and still generalize well, if the training data is large enough.\n",
        "    * The VC dimension does not take into account the optimization algorithm used to train the neural network. There are a number of techniques that can be used to prevent neural networks from overfitting, such as regularization and dropout. These techniques can help to reduce the complexity of the neural network and make it more likely to generalize well.\n",
        "\n",
        "  * https://www.bogotobogo.com/python/scikit-learn/scikit_machine_learning_VC_Dimension_Shatter.php\n",
        "\n",
        "  * Code example: https://www.geeksforgeeks.org/vapnik-chervonenkis-dimension/\n",
        "\n",
        "  * Video: https://youtu.be/puDzy2XmR5c?si=FTPneApRNiWQkJey\n",
        "\n",
        "  * VC dimension is a method to measure model complexity. It is a measure of the capacity of a hypothesis space, which is the set of all possible hypotheses that can be learned by a machine learning algorithm. A hypothesis space with a higher VC dimension can learn more complex functions, but it will also be more likely to overfit the training data.\n",
        "\n",
        "  * The VC Dimension can provide an upper bound on the sample complexity in terms of the size of the hypothesis class, the desired error rate, and the confidence level.\n",
        "\n",
        "  * In [Vapnik–Chervonenkis theory](https://en.m.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_theory), the [Vapnik–Chervonenkis (VC) dimension](v) is a **measure of the capacity (complexity, expressive power, richness, or flexibility)** of a set of functions that can be learned by a statistical binary classification algorithm.\n",
        "\n",
        "  * It is defined as the cardinality of the largest set of points that the algorithm can [shatter](https://en.m.wikipedia.org/wiki/Shattered_set), which means the algorithm can always learn a perfect classifier for any labeling of at least one configuration of those data points.\n",
        "\n",
        "  * Relationship:\tThe VC dimension can be used to derive bounds on the sample complexity.\tThe sample complexity can be used to estimate the VC dimension.\n",
        "\n",
        "  * The VC dimension of a set of functions can be used to bound the generalization error of a learning algorithm. The generalization error is the error that a learning algorithm makes on new data that it has not seen before. The VC dimension theorem states that the generalization error of a learning algorithm is bounded by the VC dimension of the hypothesis space divided by the number of training examples. In other words, **the more complex the hypothesis space, the more likely it is that the learning algorithm will overfit the training data and make errors on new data** (-that was assumed for neural nets). The VC dimension can be used to choose a hypothesis space that is not too complex, so that the learning algorithm can generalize well to new data.\n",
        "\n",
        "* [Sauer's Lemma (or Sauer–Shelah Lemma)](https://en.wikipedia.org/wiki/Sauer%E2%80%93Shelah_lemma): A combinatorial bound that relates the growth function to the VC dimension and the number of data points. It says that if a hypothesis class has a VC dimension \\( d \\) and does not shatter any set of \\( d+1 \\) points, then the number of dichotomies it can produce on any set of \\( n \\) points is bounded by the sum of binomial coefficients from \\( i = 0 \\) to \\( d \\).\n",
        "\n",
        "* [Natarajan dimension](https://en.m.wikipedia.org/wiki/Natarajan_dimension): An extension of VC dimension to multiclass classification problems.\n",
        "\n",
        "* **Fat-shattering dimension**:\n",
        "\n",
        "  * An extension of the VC dimension that considers the ability of a hypothesis class to shatter sets of points with margins. It's useful for analyzing algorithms that make use of margins, like Support Vector Machines. / [Fat-shattering dimension](https://mlweb.loria.fr/book/en/fatshattering.html) at a certain scale of a function class is defined as the maximal number of points that can be fat-shattered by this function class at that scale. It can be bounded for popular function classes such as for the set of linear functions.\n",
        "\n",
        "  * https://mathoverflow.net/questions/307201/vc-dimension-fat-shattering-dimension-and-other-complexity-measures-of-a-clas\n",
        "\n",
        "  * Covering Numbers and Fat-Shattering Dimension: measures of complexity of function classes that can be used to **derive upper bounds on sample complexity** (bounds on expressivity of class of CPTP maps (or unitaries) that a quantum machine learning model (QMLM) can implement in terms of number of trainable elements)\n",
        "\n",
        "  * **fat-shattering dimension and VC dimension (Vapnik-Chervonenkis dimension)** fat-shattering dimension is not an example of an inequality. It is a measure of the complexity of a function class. A function class with a small fat-shattering dimension is said to be easy to learn, while a function class with a large fat-shattering dimension is said to be difficult to learn.\n",
        "\n",
        "  * The fat-shattering dimension is a complexity measure used in statistical learning theory. It's one way of quantifying the **complexity or expressive power of a class of functions, and it's used to derive bounds on the generalization error** of a learning algorithm.\n",
        "\n",
        "  * The formal definition of the fat-shattering dimension is a bit technical, but here's the general idea: suppose you have a class of functions, and you want to understand how complex this class is. One way of doing this is to look at how these functions can separate or \"shatter\" sets of points. If you can find large sets of points that can be arbitrarily labeled (i.e., \"shattered\") by functions in your class, then the class has high complexity.\n",
        "\n",
        "  * **Now, for the fat-shattering dimension, you add an additional constraint: you require a certain margin (the \"fatness\") between points that are labeled differently**. The largest set of points that can be shattered with a given margin is used to define the fat-shattering dimension of the function class.\n",
        "\n",
        "  * The fat-shattering dimension is related to the VC dimension (Vapnik-Chervonenkis dimension), another complexity measure that is widely used in statistical learning theory. However, **while the VC dimension only considers exact separation of points, the fat-shattering dimension takes into account this idea of a margin, which makes it more suitable for dealing with \"noisy\" or non-separable data.**\n",
        "\n",
        "  * the concept of the fat-shattering dimension is often used in the analysis of machine learning algorithms, particularly those based on empirical risk minimization. It can help to understand the trade-off between the expressive power of a function class (which often corresponds to the complexity of a learning algorithm) and the ability of the algorithm to generalize well to unseen data.\n",
        "\n",
        "* **Pseudo-Dimension**: Similar in spirit to the VC dimension but adapted for real-valued function classes rather than binary classifiers. / [Pseudo-dimension](https://link.springer.com/chapter/10.1007/978-1-4471-3748-1_4), also Pollard dimension, is a generalization of the VC-dimension to real-valued functions. The fat-shattering dimension, unlike the Pseudo-dimension, is a “scale-sensitive” measure of richness.\n"
      ],
      "metadata": {
        "id": "yKc3PDS6bXwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Inequality (bound, complexity)</font> (Cramér–Rao, Trace , Cauchy-Schwarz, Rademacher, Hoeffding's)*"
      ],
      "metadata": {
        "id": "ThL-AmiaxI8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Concentration inequalities**](https://en.m.wikipedia.org/wiki/Concentration_inequality) = bounds probability of estimator deviating from its expected value by a certain amount = provide guarantees on accuracy of estimator. Inequalities above just bound magnitude of deviation, bound probability. Will a learning algorithm converge to correct hypothesis with high probability, even if data is noisy or incomplete? Concentration inequalities can be used to bound VC dimension of hypothesis space to design ML algorithms that are guaranteed to generalize well to new data. And in regularization (to control complexity of ML models): analyze effects of regularization on generalization performance of ML models. Concentration inequalities don't guarantee learning a function with small error, but provide high degree of confidence that algorithm is likely to learn a good function, given a sufficient number of training samples and a suitable regularization scheme.\n",
        "\n",
        "* Matrix concentration inequalities: use by Ewin tang for dequantization, see also: https://arxiv.org/abs/1501.01571 - An Introduction to Matrix Concentration Inequalities. Some common matrix concentration inequalities that might appear in Tang's work include:\n",
        "\n",
        "  * Matrix Bernstein Inequality: Provides bounds on the deviation of the sum of random matrices from its expectation. It has variants tailored to handling sums of matrices that aren't independent.\n",
        "  * Matrix Hoeffding Inequality: Generalizes Hoeffding's inequality (which is for sums of random variables) to the matrix setting.\n",
        "  * Matrix Chernoff Bound: Gives tail bounds on how much a random matrix might deviate from its mean.\n",
        "\n",
        "\n",
        "* [Markov's inequality](https://en.m.wikipedia.org/wiki/Markov%27s_inequality): simplest concentration inequality. Bounds probability that random variable deviates from its expected value by a certain amount = bounds probability of errors in statistical estimators, proves convergence of learning algorithms, analyzes performance of randomized algorithms.\n",
        "\n",
        "* [Hoeffding's inequality](https://en.m.wikipedia.org/wiki/Hoeffding%27s_inequality):\n",
        "  * We want to guarantee that a hypothesis with a small training error will have good accuracy on unseen examples, and one way to do so is with Hoeffding bounds. This characterizes the deviation between the true probability of some event and its observed frequency over m independent trails. [Source](https://www.cis.upenn.edu/~danroth/Teaching/CS446-17/LectureNotesNew/colt/main.pdf)\n",
        "  * states that probability that average of a number of independent and identically distributed random variables deviates from its expected value by more than a certain amount is exponentially small in number of random variables.\n",
        "  * average of n independent random variables deviates from its expected value by more than ε at most $2e^{(-2nε^2)}$ probability and decays exponentially with number of random variables -> Probability of deviation becomes very small as number of random variables increases. **This inequality bounds generalization error of a learning algorithm, regardless of the model complexity or the sample complexity. Can show that sample complexity of learning a linear regression model with a certain level of accuracy is proportional to logarithm of number of features.**  \n",
        "  * Hoeffding's inequality is a **special case of the Azuma–Hoeffding inequality and McDiarmid's inequality**. It is **similar to the Chernoff bound**, but tends to be less sharp, in particular when the variance of the random variables is small. It is **similar to, but incomparable with, one of Bernstein's inequalities**.\n",
        "  * Example: bound sample complexity of online learning algorithm (with perceptron):\n",
        "    * $X_1, X_2, ..., X_n$ be independent random variables with mean $\\mu$ and variance $\\sigma^2$.\n",
        "    * For any $\\delta > 0$, $P(\\bar{X} - \\mu > \\delta) \\leq \\exp(-\\delta^2 n / 2 \\sigma^2)$ where $\\bar{X}$ is average of $X_i$.\n",
        "    * $L_i$ be loss of Perceptron on $i$th training sample. Average loss of Perceptron on training data is: $\\bar{L} = \\frac{1}{n} \\sum_{i=1}^n L_i$.\n",
        "    * Objective: Use concentration inequality to show that average loss of Perceptron on training data is close to its expected value with high probability, given a sufficient number of training samples: $P(\\bar{L} - \\mu > \\delta) \\leq \\exp(-\\delta^2 n / 2 \\sigma^2)$ where $\\mu$ is expected loss of Perceptron on training data.\n",
        "    * With probability at least $1 - \\exp(-\\delta^2 n / 2 \\sigma^2)$, average loss of Perceptron on training data is within $\\delta$ of its expected value.\n",
        "    * Set $\\delta$ to be a small value, such as $0.01$, to ensure that average loss of Perceptron on training data is very close to its expected value with high probability.\n",
        "    * Hoeffdings inequality bounds sample complexity: $n \\geq \\frac{2 \\sigma^2 \\ln(1 / \\delta)}{\\delta^2}$ tells us that if we have $n$ training samples, then average loss of Perceptron on training data is within $\\delta$ of its expected value with probability at least $1 - \\exp(-\\delta^2 n / 2 \\sigma^2)$.\n",
        "\n",
        "* [Azuma's inequality](https://en.m.wikipedia.org/wiki/Azuma%27s_inequality)\n",
        "\n",
        "* [Chernoff bounds](https://en.m.wikipedia.org/wiki/Chernoff_bound): Bound probability of sum of independent random variables deviating from its expected value by more than a certain amount, even if the random variables are not identically distributed. Generalization of Hoeffding's inequality, used to bound tails of probability distributions.\n",
        "\n",
        "* [Bernstein's inequality](https://en.m.wikipedia.org/wiki/Bernstein_inequalities_(probability_theory)): generalization of Chernoff bounds. Bounds probability, even if the random variables are not identically distributed and have non-identical variances (used to bound tails of sub-Gaussian distributions).\n",
        "\n",
        "* [McDiarmid's inequality](https://en.m.wikipedia.org/wiki/McDiarmid%27s_inequality): bounds deviation between sampled value and expected value of certain functions (= functions that satisfy a bounded differences property, meaning that replacing a single argument to the function while leaving all other arguments unchanged cannot cause too large of a change in the value of the function) when they are evaluated on independent random variables.\n",
        "\n",
        "* [Bennett's inequality](https://en.m.wikipedia.org/wiki/Bennett%27s_inequality): provides an upper bound on the probability that the sum of independent random variables deviates from its expected value by more than any specified amount. **Can be used to: Bound the generalization error of learning algorithms.**\n",
        "\n",
        "* [(Bienaymé–) Chebyshev's inequality](https://en.m.wikipedia.org/wiki/Chebyshev%27s_inequality): provide upper bounds on the probability that a random variable deviates from its expected value by more than a certain amount. Chebyshev's inequality is particularly useful for bounding the deviations of random variables with finite mean and variance. One way to think about Chebyshev's inequality is that it provides a measure of how concentrated the probability distribution of a random variable is around its expected value. The more concentrated the probability distribution is, the lower the probability is that the random variable will deviate from its expected value by more than a certain amount. **Can be used to: Bound the probability of rare events**. Design confidence intervals for population parameters. Develop efficient algorithms for statistical testing.\n",
        "\n",
        "* [Vysochanskij–Petunin inequality](https://en.m.wikipedia.org/wiki/Vysochanskij%E2%80%93Petunin_inequality):  It is a refinement of Chebyshev's inequality that provides tighter bounds on the probability that a random variable deviates from its expected value by more than a certain amount, especially for random variables with unimodal distributions."
      ],
      "metadata": {
        "id": "2WMz6oFrnTD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[Inequality (complexities)](https://en.m.wikipedia.org/wiki/Inequality_(mathematics)): bound probability of random variable deviating from its expected value. Analyze reliability and stability of algorithm. Computational complexity: analysis of randomized algorithms to bound error probabilities.** See [Inequalities in information theory](https://en.m.wikipedia.org/wiki/Inequalities_in_information_theory), [Information geometry](https://en.m.wikipedia.org/wiki/Information_geometry), [Information projection](https://en.m.wikipedia.org/wiki/Information_projection), and [Confidence Interval](https://en.m.wikipedia.org/wiki/Confidence_interval).\n",
        "\n",
        "Evaluate performance of estimators: bounds on Prediction Errors, Sample Complexity, Model complexity, and Deviation of Estimators. By bounding error: ensure that model is not too far from optimal solution (Regularize models by bounding complexity of model: L1 norm to bound number of parameters, L2 norm to bound sum of squared parameters).\n",
        "\n",
        "* [Triangle inequality](https://en.m.wikipedia.org/wiki/Triangle_inequality). K-means clustering: cost function is sum of squared distances between data points and cluster centroids. Squared distances can be bounded by triangle inequality.\n",
        "\n",
        "* [Cramér–Rao bound](https://en.m.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound): lower bound (min value) on variance of an unbiased estimator (but cannot tell about probability of deviation) - this value is inverse of [Fisher information](https://de.m.wikipedia.org/wiki/Fisher-Information#Verwendung)(how much information data provides about parameters being estimated). Used to design estimators that are as efficient as possible.\n",
        "\n",
        "  * [*Quantum Cramér-Rao Bound*](https://en.m.wikipedia.org/wiki/Quantum_Cramér–Rao_bound)\n",
        "\n",
        "  * QFIM and Quantum Cramér-Rao Bound used in quantum metrology to **quantify ultimate limit to precision** that can be achieved in estimating parameters (CRB (derived from FIM) tells us smallest possible variance (or covariance in the multivariate case) that we can expect from an unbiased estimator. Fisher Information is a measure of how much information a random variable provides about an unknown parameter).\n",
        "\n",
        "  * Is an inequality: bound probability of random variable deviating from its expected value. Analyze reliability and stability of algorithm. Computational complexity: analysis of randomized algorithms to bound error probabilities.\n",
        "\n",
        "  * The Cramér-Rao bound (CRB) belongs to **model complexity** = Bounds on Precision of Estimator. It gives a measure of the best possible precision that can be achieved when estimating that parameter from a given set of data. The **quantum Cramér-Rao bound provides a limit on the precision with which these properties can be estimated, given the inherent uncertainties of quantum mechanics**.\n",
        "\n",
        "  * It provides a lower bound on the covariance matrix of any unbiased quantum estimator (The covariance matrix determines the uncertainty or precision of the estimated parameter). It characterizes the best possible precision that can be achieved in estimating a parameter of interest from quantum measurements.\n",
        "\n",
        "  * The quantum Cramér-Rao bound serves as a powerful tool for understanding the fundamental limits of precision in quantum state estimation (without consoidering noise, imperfections etc).\n",
        "\n",
        "  * The quantum Cramér-Rao bound is given by the inverse of the **Fisher information matrix**, which in the quantum case is calculated using the quantum state and the POVM (Positive Operator-Valued Measure) elements describing the measurements. It can provide insights into the optimal measurement strategies for estimating the parameters of a quantum state, and can help guide the design of quantum sensors and other quantum technologies.\n",
        "\n",
        "  * The basic formula for calculating the quantum Cramér-Rao bound (QCRB) for parameter estimation:\n",
        "\n",
        "  * $QCRB = Tr(F^{-1} M)$\n",
        "\n",
        "  * where:\n",
        "\n",
        "    - QCRB is the quantum Cramér-Rao bound, which provides a lower bound on the covariance matrix of any unbiased estimator.\n",
        "    - $F$ is the Fisher information matrix, which quantifies the amount of information provided by the measurements about the parameter of interest.\n",
        "    - $M$ is the symmetric, positive semidefinite matrix representing the measurement operators' influence on the parameter estimation.\n",
        "\n",
        "  * To calculate the QCRB, you'll need to obtain the Fisher information matrix (F) and the measurement matrix (M) for the chosen estimation strategy. The Fisher information matrix can be computed based on the measurement operators and the quantum state being measured.\n",
        "\n",
        "  * Cramér-Rao is a lower bound on the variance of any unbiased estimator of a parameter, given a fixed model. The CRB depends on the Fisher information, which is a measure of how much information the data provides about the parameter. A higher Fisher information means that the data is more informative about the parameter, and therefore the CRB is lower.\n",
        "\n",
        "  * In general, the CRB is a more fundamental concept than the sample complexity. It is used to understand the fundamental limits of parameter estimation, regardless of the amount of data available. The sample complexity, on the other hand, is more practical, as it tells us how much data we need to achieve a certain level of accuracy.\n",
        "\n",
        "  * In machine learning, the Cramér-Rao Bound (CRB) is often used as a tool for **understanding the fundamental limits of learning algorithms, particularly in the field of parameter estimation and model selection**. Here are some specific applications:\n",
        "\n",
        "    1. Variance Estimation: Similar to financial economics, the CRB provides a theoretical lower limit for the variance of an unbiased estimator. This can help understand how well a learning algorithm might perform in terms of parameter estimation, given a certain amount of data.\n",
        "\n",
        "    2. Model Complexity: The CRB can provide insights into how model complexity affects estimation accuracy. A model with too many parameters may have a higher CRB (i.e., higher variance for the best possible estimator), indicating that it could be more prone to overfitting.\n",
        "\n",
        "    3. Algorithm Evaluation: Researchers might use the CRB to evaluate and compare the performance of different learning algorithms. If an algorithm's performance is close to the CRB, it might be deemed near-optimal.\n",
        "\n",
        "    4. Designing Neural Networks: In the design of neural networks, the CRB can be used to understand the limit of what the network can learn from the data, which can help in making decisions about network architecture and training strategies.\n",
        "\n",
        "* [Trace_inequality](https://en.m.wikipedia.org/wiki/Trace_inequality) bounds the trace of a matrix by the sum of the traces of its eigenvalues. Trace inequality, also known as the triangle inequality for the trace distance, states that for any three quantum states ρ, σ, and τ, the following inequality holds:\n",
        "  * $δ(ρ, σ) + δ(σ, τ) ≥ δ(ρ, τ)$\n",
        "  * where δ(ρ, σ) is the trace distance between ρ and σ.\n",
        "  * Bounding the error of quantum learning algorithms: The trace inequality can be used to derive upper bounds on the error of quantum learning algorithms. This is useful for understanding the performance of quantum learning algorithms and for comparing them to classical learning algorithms.\n",
        "  *  The trace inequality can be used to derive bounds on the error of a wide variety of quantum learning algorithms, including algorithms for learning linear classifiers, support vector machines, and neural networks.\n",
        "  * It is important to note that the bounds derived using the trace inequality are often loose. This is because the trace inequality is a very general tool, and it does not take into account the specific structure of the quantum learning algorithm or the training data. However, the trace inequality can still be used to get a rough estimate of the error of a quantum learning algorithm.\n",
        "\n",
        "* [Bohnenblust-Hille inequality](https://en.m.wikipedia.org/wiki/Littlewood%27s_4/3_inequality):\n",
        "\n",
        "  * The Bohnenblust-Hille inequality says that the $\\ell^{\\frac{2 m}{m+1}}$-norm of the coefficients of an $m$-homogeneous polynomial $P$ on $\\mathbb{C}^n$ is bounded by $\\|P\\|_{\\infty}$ times a constant independent of $n$, where $\\|\\cdot\\|_{\\infty}$ denotes the supremum norm on the polydisc $\\mathbb{D}^n$. [Source](https://annals.math.princeton.edu/wp-content/uploads/annals-v174-n1-p13-s.pdf)\n",
        "\n",
        "\n",
        "* [Littlewood's 4/3 inequality](https://en.m.wikipedia.org/wiki/Littlewood%27s_4/3_inequality)\n",
        "\n",
        "  * is a norm inequality for multilinear forms and polynomials. It is used to study the behavior of random variables and multilinear forms. Can be used to derive concentration inequalities in some cases. For example, it can be used to prove that the coefficients of a random homogeneous polynomial are concentrated around their expected values. This can then be used to prove concentration inequalities for other random variables, such as the output of a neural network. Used in \"Learning to predict arbitrary quantum processes\".\n",
        "\n",
        "\n",
        "* [Golden–Thompson inequality](https://en.m.wikipedia.org/wiki/Golden%E2%80%93Thompson_inequality) bounds difference between logarithm of trace of a matrix and sum of logarithms of its eigenvalues. Used in 'A survey on the complexity of learning quantum states' page 17 - difference between real state and shadow tomography state)\n",
        "\n",
        "* [Cauchy–Schwarz inequality](https://en.m.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality). Cauchy-Schwarz inequality used to bound sum of squared residuals (cost function for linear regression) by the sum of the squared predicted values and the sum of the squared actual values. Used in *A Survey of Quantum Learning Theory* page 11 to compute upper bounds of learning algorithm.\n",
        "\n",
        "* [Chebyshev's inequality](https://en.m.wikipedia.org/wiki/Chebyshev%27s_inequality) bounds probability that a random variable deviates from its expected value by more than a certain amount (k standard deviations at most 1/k^2).\n",
        "\n",
        "* [Rademacher Complexity](https://en.m.wikipedia.org/wiki/Rademacher_complexity):\n",
        "  * upper bound on sample complexity = on learnability of function classes (deriving generalization bounds). Measures ability of functions in class to fit to random noise. [Rademacher Complexity PDF](https://www.cs.cmu.edu/~ninamf/ML11/lect1117.pdf).\n",
        "  * When the Rademacher complexity is small, it is possible to learn the hypothesis class H using [empirical risk minimization](https://en.m.wikipedia.org/wiki/Empirical_risk_minimization).\n",
        "\n",
        "* [Gaussian complexity](https://en.m.wikipedia.org/wiki/Rademacher_complexity#Gaussian_complexity):  similar complexity to Rademacher. Can be obtained from Rademacher using random variables $g_i$ instead of $\\sigma_i$, where $g_i$ are Gaussian i.i.d. random variables with zero-mean and variance 1, i.e. $g_i \\sim \\mathcal{N}(0,1)$. Gaussian and Rademacher are equivalent up to logarithmic factors.\n",
        "\n",
        "* [Fano's inequality](https://en.m.wikipedia.org/wiki/Fano%27s_inequality): is a lower bound on the average probability of error in a multiple hypothesis testing problem. It states that the average probability of error in a multiple hypothesis testing problem is at least as high as the entropy of the hypothesis distribution divided by the natural logarithm of two. It can be used to: Design efficient multiple hypothesis testing algorithms. Lower bound the generalization error of learning algorithms. Develop new algorithms for information compression and transmission. Fano's inequality is a powerful tool for analyzing the performance of multiple hypothesis testing algorithms and other machine learning algorithms.\n",
        "\n",
        "* [Data processing inequality](https://en.m.wikipedia.org/wiki/Data_processing_inequality): is a concept that states that the information content of a signal cannot be increased via a local physical operation. This can be expressed concisely as 'post-processing cannot increase information'. It is an inequality that relates the mutual information between two random variables before and after a data processing channel. It states that the mutual information between two random variables after a data processing channel cannot be greater than the mutual information between the two random variables before the channel. It can be used to: prove that certain learning problems are impossible to solve perfectly.\n",
        "Design efficient algorithms for information compression and transmission. It is a powerful tool for analyzing the flow of information through systems."
      ],
      "metadata": {
        "id": "r6LqFuIXrNmL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A norm inequality (like Bohnenblust-Hille inequalities) is an inequality that involves the norms of vectors and matrices. Norms are functions that measure the size of vectors and matrices. There are many different types of norms, but some of the most common include the Euclidean norm, the $p$-norm, and the Frobenius norm.\n",
        "\n",
        "Norm inequalities are useful in many different areas of mathematics, including functional analysis, numerical linear algebra, and machine learning. For example, norm inequalities can be used to prove bounds on the error of numerical algorithms, to design efficient machine learning algorithms, and to analyze the stability of differential equations.\n",
        "\n",
        "Here are some examples of norm inequalities:\n",
        "\n",
        "* **Triangle inequality:** $\\|x + y\\| \\leq \\|x\\| + \\|y\\|$ for all vectors $x$ and $y$.\n",
        "* **Cauchy-Schwarz inequality:** $\\|⟨x, y⟩\\| \\leq \\|x\\| \\|y\\|$ for all vectors $x$ and $y$.\n",
        "* **Hölder's inequality:** $\\left\\| \\sum_{i=1}^n a_i b_i \\right\\| \\leq \\left\\| \\sum_{i=1}^n |a_i|^p \\right\\|^{1/p} \\left\\| \\sum_{i=1}^n |b_i|^q \\right\\|^{1/q}$, where $p$ and $q$ are conjugate exponents (i.e., $1/p + 1/q = 1$).\n",
        "* **Submultiplicativity of the Frobenius norm:** $\\|AB\\|_F \\leq \\|A\\|_F \\|B\\|_F$ for all matrices $A$ and $B$.\n",
        "\n",
        "Norm inequalities can be used to prove many other important results in mathematics. For example, the triangle inequality can be used to prove the existence and uniqueness of solutions to differential equations. The Cauchy-Schwarz inequality can be used to prove the Bessel inequality, which is a fundamental result in Fourier analysis. Hölder's inequality can be used to prove the Minkowski inequality, which is another important result in functional analysis.\n",
        "\n",
        "Norm inequalities are a powerful tool in mathematics, and they have many applications in science and engineering.\n",
        "\n",
        "*Yes, the triangle inequality is a norm inequality. The triangle inequality states that the norm of the sum of two vectors is less than or equal to the sum of the norms of the two vectors. In other words, for any two vectors $x$ and $y$, we have:*\n",
        "\n",
        "```\n",
        "||x + y|| <= ||x|| + ||y||\n",
        "```\n",
        "\n",
        "This inequality holds for any norm, including the Euclidean norm, the $p$-norm, and the Frobenius norm.\n",
        "\n",
        "The triangle inequality is a fundamental property of norms, and it has many important consequences. For example, the triangle inequality can be used to prove the existence and uniqueness of solutions to differential equations, and it can also be used to design efficient machine learning algorithms.\n",
        "\n",
        "The triangle inequality is also related to the triangle inequality in Euclidean geometry. The triangle inequality in Euclidean geometry states that the sum of the lengths of any two sides of a triangle must be greater than or equal to the length of the third side. This inequality can be proven using the triangle inequality for norms.\n",
        "\n",
        "In conclusion, the triangle inequality is a norm inequality that has many important applications in mathematics, science, and engineering."
      ],
      "metadata": {
        "id": "6eeeLVg3nFxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what means that a generalization bound is uniform?**\n",
        "\n",
        "A generalization bound is said to be uniform if it holds for all hypotheses in a given hypothesis class, rather than just for a specific hypothesis. This is important because it allows us to make guarantees about the performance of our learning algorithm on any new data, regardless of the specific hypothesis that it learns.\n",
        "\n",
        "Uniform generalization bounds are typically derived using a technique called **Rademacher complexity**. Rademacher complexity is a measure of the complexity of a hypothesis class, and it can be used to bound the generalization error of any learning algorithm that uses that hypothesis class.\n",
        "\n",
        "Uniform generalization bounds are particularly useful for complex hypothesis classes, such as the class of all neural networks. These hypothesis classes have infinite VC-dimension, which makes it difficult to derive generalization bounds using traditional methods. However, uniform generalization bounds based on Rademacher complexity can be applied to any hypothesis class, regardless of its VC-dimension.\n",
        "\n",
        "Some examples of uniform generalization bounds include:\n",
        "\n",
        "* The generalization bound for uniformly stable learning algorithms\n",
        "* The generalization bound for overparameterized neural networks in kernel regimes\n",
        "\n",
        "Uniform generalization bounds are an important tool for understanding and analyzing the performance of machine learning algorithms. They allow us to make guarantees about the ability of our algorithms to generalize to new data, even when the hypothesis class is complex.\n",
        "\n",
        "Here is a simple analogy to help understand uniform generalization bounds:\n",
        "\n",
        "Imagine that you are trying to train a model to predict whether a given email is spam or not. You have a dataset of labeled emails, and you use this dataset to train a machine learning algorithm.\n",
        "\n",
        "Once the algorithm is trained, you want to be able to use it to predict the spam/ham label of any new email, even if that email is not in the training dataset.\n",
        "\n",
        "A uniform generalization bound tells you that the probability that your algorithm will make a mistake on any new email is less than a certain threshold. This threshold is independent of the specific email that you are trying to predict.\n",
        "\n",
        "In other words, a uniform generalization bound guarantees that your algorithm will generalize well to any new data, even if that data is very different from the training data."
      ],
      "metadata": {
        "id": "WLrjg16KskW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Norm</font> (Frobenius, Jacobian, Spectral, Trace)*"
      ],
      "metadata": {
        "id": "8SsJmnB0xNNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[Norm](https://de.wikipedia.org/wiki/Norm_(Mathematik)) measure size or length of vectors**. Compute error of model or regularize models. Analyze complexity of algorithms in terms of space or time. A norm-based measure of complexity in computational learning theory is a **measure that quantifies the difficulty of learning a function based on the norm of the function**. The norm of a function is a measure of the size or magnitude of the function.\n",
        "* Both the Frobenius norm and the spectral norm can be used to derive generalization bounds for machine learning algorithms. **Norm-based generalization bounds provide a strong theoretical guarantee on the performance of a machine learning algorithm on unseen data.**\n",
        "* Specific machine learning task require specific norm-based measure of complexity. All norm-based measures of complexity provide a useful way to quantify the difficulty of learning a function.\n",
        "* Norm kann von [Skalarprodukt](https://de.wikipedia.org/wiki/Skalarprodukt) abgeleitet werden (['Skalarproduktnorm'](https://de.m.wikipedia.org/wiki/Skalarproduktnorm)). In diesem Fall: norm of vector is square root of inner product of vector by itself. Complete space with an inner product is called a [Hilbert space](https://de.m.wikipedia.org/wiki/Hilbertraum).\n",
        "* In optimization: define objective function and constraints. Computer science: define complexity of algorithms.\n",
        "* Classical vs Quantum probability theory:\n",
        "  * classical probability theory: 1-Norm: ∑ pi = ∑ | p | = || p || 1 = 1\n",
        "  * quantum probabiliyt theory: 2-Norm: || | ψ > || ^2 = 1\n",
        "* Reeller Vektor für 1-, 2-, 3- und $\\infty$-Normen des Vektors $x=(3,-2,6)$:\n",
        "  * $\n",
        "\\begin{aligned}\n",
        "& \\|x\\|_1=|3|+|-2|+|6|=11 \\\\\n",
        "& \\|x\\|_2=\\sqrt{|3|^2+|-2|^2+|6|^2}=\\sqrt{49}=7 \\\\\n",
        "& \\|x\\|_{\\infty}=\\max \\{|3|,|-2|,|6|\\}=6\n",
        "\\end{aligned}\n",
        "$\n",
        "* Komplexer Vektor für 1-, 2-, 3- und $\\infty$-Normen des Vektors $x=(3-4 i,-2 i)$:\n",
        "  * $\n",
        "\\begin{aligned}\n",
        "& \\|x\\|_1=|3-4 i|+|-2 i|=5+2=7 \\\\\n",
        "& \\|x\\|_2=\\sqrt{|3-4 i|^2+|-2 i|^2}=\\sqrt{5^2+2^2}=\\sqrt{29} \\approx 5,385 \\\\\n",
        "& \\|x\\|_{\\infty}=\\max \\{|3-4 i|,|-2 i|\\}=\\max \\{5,2\\}=5\n",
        "\\end{aligned}$"
      ],
      "metadata": {
        "id": "n7MLTBvFGN7T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[*Normen auf endlichdimensionalen Vektorräumen*](https://de.m.wikipedia.org/wiki/Norm_(Mathematik)#Normen_auf_endlichdimensionalen_Vektorr%C3%A4umen)\n",
        "* [Zahlnorm](https://de.m.wikipedia.org/wiki/Norm_(Mathematik)#Zahlnormen): zB [Betragsnorm](https://de.m.wikipedia.org/wiki/Betragsfunktion)\n",
        "* [Vektornormen](https://de.m.wikipedia.org/wiki/Norm_(Mathematik)#Vektornormen):\n",
        "  * zB [$p$ -Normen](https://de.m.wikipedia.org/wiki/P-Norm) $\\|x\\|_{p}:=\\left(\\sum_{i=1}^{n}\\left|x_{i}\\right|^{p}\\right)^{1 / p}$.\n",
        "  * [Summennorm](https://de.m.wikipedia.org/wiki/Summennorm) ,\n",
        "  * Euklidische Norm und [Maximumsnorm](https://de.m.wikipedia.org/wiki/Maximumsnorm). L2 norm more robust to outliers than L1 norm.\n",
        "* [Matrixnorm](https://de.m.wikipedia.org/wiki/Matrixnorm):\n",
        "  * Matrix norm is a function that measures the size of a matrix. It must satisfy the following properties:\n",
        "    * ||A|| ≥ 0 for all matrices A.\n",
        "    * ||A|| = 0 if and only if A is the zero matrix.\n",
        "    * ||cA|| = |c| ||A|| for all scalars c and all matrices A.\n",
        "    * ||A + B|| ≤ ||A|| + ||B|| for all matrices A and B.\n",
        "  * **The trace norm is a matrix norm**, but it is not the only one. **Other examples of matrix norms include the Frobenius norm and the spectral norm**.\n",
        "  * [Natürliche Matrixnorm](https://de.m.wikipedia.org/wiki/Nat%C3%BCrliche_Matrixnorm): größtmöglicher Streckungsfaktor, der durch Matrix auf Vektor entsteht. [Spektralnorm](https://de.m.wikipedia.org/wiki/Spektralnorm): größtmöglicher Streckungsfaktor, der durch Matrix auf Vektor der Länge Eins entsteht = maximalen Singulärwert, [Singulärwertzerlegung](https://de.m.wikipedia.org/wiki/Singul%C3%A4rwertzerlegung)\n",
        "  * Various matrix norms provide different ways to quantify the size or complexity of matrices. While the Fisher Information Matrix is not a matrix norm, it's still a matrix, and depending upon the application, different matrix norms might be used to analyze its properties.\n",
        "* $\\hookrightarrow$ [Frobenius norm](https://de.m.wikipedia.org/wiki/Frobeniusnorm):\n",
        "  * special case of matrix norm. Frobenius norm of a matrix is the square root of the sum of the squares of all the elements of the matrix. Relatively easy to compute. Used in quantum state tomography (see *A Survey of Quantum Learning Theory* page 15. [interesting article](https://www.inference.vc/generalization-and-the-fisher-rao-norm-2/).\n",
        "  * E.g. Learn linear regression model from set of training data. One way: use ordinary least squares (OLS) algorithm (minimizes sum of squared residuals to find model). Frobenius norm: derive generalization bound for OLS algorithm that guarantees that probability of OLS algorithm making a large mistake on unseen data is small.\n",
        "* $\\hookrightarrow$ [Schatten p-Norm](https://en.m.wikipedia.org/wiki/Schatten_norm):\n",
        "  * The Schatten norm of the difference between the unitary matrices generated by the circuit and a target unitary operation can be used as a measure of the expressivity. Smaller values of the Schatten norm indicate higher expressivity. Useful measure of complexity for learning linear models and neural networks.\n",
        "  * Schatten norm is a class of matrix norms that includes the trace norm as a special case. The Schatten norm of order p, denoted by ||A||_p, is defined as the pth root of the sum of the pth powers of the singular values of A.\n",
        "* $\\hookrightarrow$ **Jacobian norm**\n",
        "  * is the maximum norm of the Jacobian matrix of a function. It is a measure of how the function changes with respect to its inputs.\n",
        "  * Jacobian norm is a useful tool for measuring the sensitivity of a function to its inputs and for designing robust control systems.\n",
        "  * The Jacobian matrix represents how changes in input affect changes in output in a vector-valued function. The Fisher Information matrix can sometimes be expressed in terms of derivatives (like the Jacobian), particularly when trying to understand how parameter changes influence the model's predictive distribution.\n",
        "* $\\hookrightarrow$ **Spectral norm**\n",
        "  * special case of matrix norm\n",
        "  * spectral morm of a matrix is the largest singular value of the matrix. Spectral norm is a more restrictive measure of complexity than the Frobenius norm, and more difficult to compute.\n",
        "  * This measures the largest singular value of a matrix. In the context of neural networks, it has been used to understand the smoothness of the loss landscape, which can be somewhat related to Fisher Information by providing insights into how parameters changes impact the output.\n",
        "  * Spectral norm is a useful tool for analyzing the stability of numerical algorithms and for studying the behavior of dynamical systems.\n",
        "  * The spectral norm of the Jacobian matrix of a function is an upper bound on the Jacobian norm of the function itself. This means that the spectral norm of the Jacobian matrix can be used to measure the maximum amount by which the function can change with respect to its inputs. Here is a simple example: Consider the following function: f(x) = x^2\n",
        "    * The Jacobian matrix of this function is simply the matrix [2x]. The spectral norm of the Jacobian matrix is 2x, and the Jacobian norm of the function is simply |2x|.\n",
        "    * If we set x = 1, then the spectral norm of the Jacobian matrix is 2, and the Jacobian norm of the function is also 2. However, if we set x = 10, then the spectral norm of the Jacobian matrix is 20, but the Jacobian norm of the function is still 2.\n",
        "    * This shows that the spectral norm of the Jacobian matrix is an upper bound on the Jacobian norm of the function itself.\n",
        "* $\\hookrightarrow$ [Trace norm (Nuclear norm)](https://en.m.wikipedia.org/wiki/Matrix_norm#Schatten_norms):\n",
        "  * It is sum of singular values of a matrix. Useful measure of complexity for learning linear models and neural networks. Special case of the Schatten norm, which is a class of matrix norms.\n",
        "  * Common distance measures in quantum information theory: here, \"distance measure\" is used in an informal sense, only three of the quantities introduced below are actual \"distances\" in the sense of a metric. First, and maybe most naturally, we can equip the set $\\mathcal{S}\\left(\\mathbb{C}^d\\right)$ with the (for convenience scaled) trace norm $I_i / 2$. This allows us to measure the difference between two quantum states $\\rho, \\sigma \\in$ $S\\left(\\mathbb{C}^d\\right)$ via the trace distance $\\left.\\left.\\|\\rho-\\sigma\\|_1 / 2=\\operatorname{tr} \\| \\rho-\\sigma\\right]\\right] / 2$. In fact, this distance is not only intuitive from a mathematical perspective, it also has an operational interpretation: The maximal success probability in distinghuishing $\\rho, \\sigma \\in \\mathcal{S}\\left(\\mathbb{C}^d\\right)$, assuming that either of the two is prepared with probability $1 / 2$, by performing a 2-outcome measurement on a single copy of the unknown state is given by $\\sup _{E \\in \\mathcal{E}(\\mathrm{C})} \\operatorname{tr}[E(\\rho-\\sigma)]+\\frac{1}{2}=\\frac{\\|\\rho-\\sigma\\|_1+1}{2}$ (see, e.g., $[17$, Chapter 9$]$ for a derivation).\n",
        "  * The trace distance is defined as half of the trace norm of the difference of the matrices\n",
        "  * The trace norm (also known as the nuclear norm) is a specific case of Schatten p-norm when p=1. It's the sum of singular values of a matrix. Sometimes, in the context of regularizing machine learning models, these norms are considered to constrain the learning capacity of the model. The trace of the Fisher Information Matrix can give a measure of the average sensitivity of the log-likelihood to parameter changes.\n",
        "* **Basis-path norm**: https://arxiv.org/abs/1809.07122\n"
      ],
      "metadata": {
        "id": "u_QCvV6brYZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[*Normen auf unendlichdimensionalen Vektorräumen*](https://de.m.wikipedia.org/wiki/Norm_(Mathematik)#Normen_auf_unendlichdimensionalen_Vektorräumen)\n",
        "* [Folgennormen](https://de.m.wikipedia.org/wiki/Norm_(Mathematik)#Folgennormen): $\\ell^{p}$ -Normen Verallgemeinerung der $p$ -Normen auf Folgenräume: $\\left\\|\\left(a_{n}\\right)\\right\\|_{\\ell^{p}}=\\left(\\sum_{n=1}^{\\infty}\\left|a_{n}\\right|^{p}\\right)^{1 / p}$. Mit Normen werden $\\ell$ - Räume zu vollständigen normierten Räumen.\n",
        "* [Supremumsnorm](https://de.m.wikipedia.org/wiki/Supremumsnorm): Für Grenzwert $p \\rightarrow \\infty$ ergibt sich Raum der beschränkten Folgen $\\ell^{\\infty}$\n",
        "* [Funktionennormen](https://de.m.wikipedia.org/wiki/Norm_(Mathematik)#Funktionennormen) im Funktionenraum, L-p-Raum.  $\\mathcal{L}^{p}$ -Normen definiert als $\\|f\\|_{\\mathcal{L}^{P}(\\Omega)}=\\left(\\int_{\\Omega}|f(x)|^{p} d x\\right)^{1 / p}$ (Summe durch Integral ersetzt).\n",
        "* [Diamond norm](https://en.m.wikipedia.org/wiki/Diamond_norm) (completely bounded trace norm) a measure defined between two quantum operations (two linear maps between operator spaces). Captures max difference between effects of two quantum operations.\n",
        "\n",
        "[*Normed Vector Spaces*](https://en.m.wikipedia.org/wiki/Normed_vector_space)\n",
        "* [L<sup>p</sup>-space](https://de.m.wikipedia.org/wiki/Lp-Raum) (Lebesgue Space) bestehen aus p-fach integrierbaren Funktionen. Für jede Zahl $0 < p \\leq \\infty$ ist $L^{p}$ -Raum definiert.\n",
        "* [Banach space](https://de.wikipedia.org/wiki/Banachraum): $\\mathbb{R}$<sup>n</sup> together with p-norm = vollständiger normierter Vektorraum (Lp-space over R^n). Viele Folgenräume $\\ell$ oder Funktionenräume $L$ sind unendlichdimensionale Banachräume.\n",
        "* [Hilbert space](https://de.wikipedia.org/wiki/Hilbertraum): Banachraum, dessen Norm durch Skalarprodukt induziert ist (p2-Norm, aber nicht p1 -> Prähilbertraum).\n",
        "* [Hardy space](https://de.m.wikipedia.org/wiki/Hardy-Raum): Untersucht man statt messbarer Funktionen nur holomorphe und harmonische Funktionen auf Integrierbarkeit im $L^{p}$-Raum\n",
        "* [F-space](https://en.m.wikipedia.org/wiki/F-space): for Lp-space 0 < p < 1. Admits complete translation-invariant metric with respect to which vector space operations are continuous.\n",
        "* [Fréchet space](https://en.m.wikipedia.org/wiki/Fr%C3%A9chet_space): locally convex F-spaces.\n",
        "* [Sobolev space](https://de.wikipedia.org/wiki/Sobolev-Raum): Funktionenraum von schwach differenzierbaren Funktionen. Variationsrechnung: zur Lösungstheorie partieller Differentialgleichungen"
      ],
      "metadata": {
        "id": "8WHLzF42GF6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[Inner Product](https://de.wikipedia.org/wiki/Skalarprodukt) (auch Dot Product / Scalar Product / Skalarprodukt) ordnet zwei Vektoren eine Zahl (Skalar) zu, die die Ähnlichkeit messen** (über Länge, Winkel von Vektoren, oder ob diese senkrecht zueinander stehen)\n",
        "  * Skalarprodukt zweier Vektoren: $\\vec{a} \\cdot \\vec{b}=|\\vec{a}||\\vec{b}| \\cos \\alpha(\\vec{a}, \\vec{b})$. Wenn $\\vec{a} \\cdot \\vec{b}= 0$, dann stehen orthogonal zueinander.\n",
        "  * [Dot product](https://en.m.wikipedia.org/wiki/Dot_product) or scalar product (special case): dot a ⋅ b.\n",
        "  * The [determinant](https://en.wikipedia.org/wiki/Determinant) is a scalar value that can be computed from the elements of a **square matrix** and encodes certain properties of the linear transformation described by the matrix. Geometrically can be viewed as volume scaling factor of linear transformation described by matrix.\n",
        "  * \"Inner Product of Functions\" says how similar two functions are (used in Fourier Transform): if they are orthogonal, then zero. if they are very similar, then they have a large inner product: $\\langle f(x), g(x)\\rangle=\\int_{a}^{b} f(x) g(x) d x$\n",
        "  * Take samples from functions - Up to infinity, you get integral (Riemann approximation of continuuos integral above): $\\langle f, g\\rangle=g^{\\top} {f}$ = $\\langle f, g \\rangle \\Delta x=\\sum_{k=1}^{n} f\\left(x_{n}\\right) g\\left(x_{n}\\right) \\Delta x$\n",
        "  * [Inner Product Space](https://en.m.wikipedia.org/wiki/Inner_product_space) (Prähilbertraum bzw. Skalarproduktraum) generalize Euclidean spaces (in which inner product is dot product = scalar product) to vector spaces of any (possibly infinite) dimension."
      ],
      "metadata": {
        "id": "FeFQyIqardUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Entropy</font> (Metric, Relative, Conditional, Cross)*"
      ],
      "metadata": {
        "id": "l-DiG5X3xTfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paper: [The Entropy-Based Quantum Metric](https://www.mdpi.com/1099-4300/16/7/3878)"
      ],
      "metadata": {
        "id": "VKof1_SSUMvp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[Entropy](https://en.m.wikipedia.org/wiki/Entropy_(information_theory) measures uncertainty or information content of random variable, randomness (of a quantum state). For feature selection, information retrieval, and anomaly detection, & analysis of informational complexity of algorithms, mMeasuring amount of information that can be stored in quantum system, determining security of quantum communication protocols**\n",
        "* [Shannon entropy](https://en.m.wikipedia.org/wiki/Entropy_(information_theory)): Measure of randomness, disorder, average unpredictability, expected value of information, complexity of dataset - Shannon entropy is a probabilistic measure of average unpredictability in data (stochastic random process).\n",
        "* [Von Neumann entropy](https://en.m.wikipedia.org/wiki/Von_Neumann_entropy): most commonly entropy function. Is a measure of the mixedness of a quantum state. It is defined as the von Neumann entropy of the density matrix of the state. Defined as Shannon entropy of eigenvalues of density matrix of quantum state (=probabilities of finding the system in the corresponding eigenstates). - Entanglement = von neumann entropy?\n",
        "  * The von Neumann entropy can be used to characterize the amount of information present in a quantum state. For a pure state, the von Neumann entropy is zero, indicating that the state is completely known. For a mixed state, the von Neumann entropy is greater than zero, indicating that the state is not fully known.\n",
        "  * The von Neumann entropy can also be used to quantify the amount of entanglement between two quantum systems. Entanglement is a non-local correlation between two quantum systems, such that the state of one system cannot be fully described without knowing the state of the other system. The von Neumann entropy of entanglement is defined as the difference between the von Neumann entropy of the joint system and the sum of the von Neumann entropies of the individual systems. A higher von Neumann entropy of entanglement indicates a stronger entanglement between the two systems.\n",
        "  * Example: Consider two qubits, A and B, which are entangled in the Bell state: $|Bell_{00}> = \\frac{1}{\\sqrt{2}} (|00> + |11>)$. The von Neumann entropy of this state is zero, indicating that it is a pure state. However, if we measure the state of qubit A, we will collapse the state of qubit B to either |0> or |1>, depending on the outcome of the measurement. This means that the state of qubit B is not fully known until we measure qubit A.The von Neumann entropy of entanglement between qubit A and qubit B is 1 bit, indicating that they are maximally entangled. This means that the correlation between the two qubits is as strong as possible.\n",
        "\n",
        "* [Gibbs entropy](https://en.m.wikipedia.org/wiki/Entropy_(statistical_thermodynamics)#Gibbs_entropy_formula): the Gibbs entropy expression of the statistical entropy is a discretized version of Shannon entropy. The von Neumann entropy formula is an extension of the Gibbs entropy formula to the quantum mechanical case.\n",
        "* [Tsallis divergence (entropy)](https://en.m.wikipedia.org/wiki/Tsallis_entropy): Generalization of Shannon entropy, allows for wider range of values / different degrees of non-linearity.\n",
        "* [Renyi entropy](https://en.m.wikipedia.org/wiki/R%C3%A9nyi_entropy): Generalization of Shannon entropy. It is defined as $S_\\alpha(\\rho) = \\frac{1}{1-\\alpha} \\log \\left( \\sum_i p_i^\\alpha \\right)$, where $p_i$ are the eigenvalues of the density matrix $\\rho$ and $\\alpha$ is a real number.\n",
        "  * [(Max) Quantum Rényi Divergence](https://de.m.wikipedia.org/wiki/R%C3%A9nyi-Entropie): KL divergence in classical, would be quantum relativ entropy, but too hard to compute. Better: Maximal Quantum Rényi Divergence. arxiv.org/abs/2106.09567 and [video](https://www.youtube.com/watch?v=01xvtDu94jM&list=WL&index=4&t=352s)\n",
        "\n",
        "* [Quantum relative entropy](https://en.m.wikipedia.org/wiki/Quantum_relative_entropy): Despite there being many other useful ways of determining distances between quantum states, we only discuss one more, namely the quantum relative entropy.\n",
        "  * The relative entropy H (P|Q) can, in some sense, be thought of as a measure of how much P and Q “resemble” each other. 72. Indeed, it takes its maximum value (i.e. 0) if and only if P = Q; it may become −∞ if P and Q have disjoint support, (i.e. when P (y)Q (y) = 0 for all y ∈ Y .)\n",
        "  * The quantum relative entropy between two quantum states $\\rho, \\sigma \\in \\mathcal{S}\\left(\\mathbb{C}^d\\right)$ that satisfy $\\operatorname{supp}(\\rho) \\cap \\operatorname{ker}(\\sigma)=\\emptyset$ is defined to be $D(\\rho \\| \\sigma):=\\operatorname{tr}[\\rho \\log (\\rho)]-\\operatorname{tr}[\\rho \\log (\\sigma)]$. Here, the logarithm is taken with base 2 . We can rewrite the relative entropy using the von Neumann entropy $S(\\rho)$, which is defined as $S(\\rho):=-\\operatorname{tr}[\\rho \\log (\\rho)]$.\n",
        "  * With this, the relative entropy becomes $D(\\rho \\| \\sigma)=-\\operatorname{tr}[\\rho \\log (\\sigma)]-S(\\rho)$. If $\\operatorname{supp}(\\rho) \\cap \\operatorname{ker}(\\sigma) \\neq \\emptyset$, then we define $D(\\rho \\| \\sigma):=+\\infty$. A useful result in quantum information is the non-negativity of the relative entropy, i.e., that $D(\\rho \\| \\sigma) \\geq 0$ holds for any two quantum states $\\rho, \\sigma \\in \\mathcal{S}\\left(\\mathbb{C}^d\\right)$. Moreover, for $\\rho, \\sigma \\in \\mathcal{S}\\left(\\mathbb{C}^d\\right), D(\\rho \\| \\sigma)=0$ implies $\\rho=\\sigma$ (see, e.g., [17, Theorem 11.7] for a proof).\n",
        "  * **However, the quantum relative entropy is neither symmetric nor does it satisfy a triangle inequality, so it does not define a metric**. Nevertheless, it is an important tool for comparing two quantum states. For example, when comparing a bipartite state $\\rho_{A B} \\in \\mathcal{S}\\left(\\mathbb{C}^{d_A} \\otimes \\mathbb{C}^{d_B}\\right)$ to $\\rho_A \\otimes \\rho_B$, the tensor product of its reduced density matrices, we obtain a measure for the correlation between the $A$ - and the $B$-system in the state $\\rho_{A B}$. This defines the quantum mutual information $I(A: B)_\\rho:=D\\left(\\rho_{A B} \\| \\rho_A \\otimes \\rho_B\\right)$.\n",
        "\n",
        "\n",
        "* [Kolmogov complexity](https://en.m.wikipedia.org/wiki/Kolmogorov_complexity): Measure randomness, disorder, or complexity in dataset - from algorithmic information theory to measure of computational resources needed to reproduce a piece of data, string etc. (length of shortest possible description of string, not computable, but gives absolute complexity of string independently of any specific probability distribution)\n",
        "* [Conditional entropy](https://en.m.wikipedia.org/wiki/Conditional_entropy): measures uncertainty of quantum state given knowledge of another quantum state. It is defined as $S(A|B) = S(\\rho_{AB}) - S(\\rho_B)$, where $\\rho_{AB}$ is the joint density matrix of the two quantum states, $\\rho_B$ is density matrix of second quantum state, and $S(\\rho)$ is entropy of density matrix $\\rho$.\n",
        "* Relative entropy: measures distinguishability between two quantum states. It is defined as $D(\\rho \\| \\sigma) = Tr (\\rho \\log \\rho) - Tr (\\rho \\log \\sigma)$, where $\\rho$ and $\\sigma$ are two quantum states.\n",
        "* [Metric entropy](https://en.m.wikipedia.org/wiki/Measure-preserving_dynamical_system#Measure-theoretic_entropy) measure of complexity of metric space. It is defined as the logarithm of the minimum number of open balls of radius δ needed to cover the space. Space with high metric entropy is more difficult to compress than a space with low metric entropy. Additionally, metric entropy can be used to estimate rate of convergence of certain algorithms. See [here](https://mathoverflow.net/questions/307201/vc-dimension-fat-shattering-dimension-and-other-complexity-measures-of-a-clas) metric entropy named under model complexity metrics\n",
        "* [Mutual information](https://en.m.wikipedia.org/wiki/Mutual_information) measures amount of information that one random variable X shares about another random variable Y. This information can be used to reduce amount of information required to describe X.\n",
        "* [Holevo's theorem](https://en.m.wikipedia.org/wiki/Holevo%27s_theorem) (Holevo's bound) upper limit on amount of classical information that can be extracted from quantum system: single qubit can exist in superposition of states with infinite amount of information, when we measure that qubit, we can extract at most 1 bit of classical information. Clear distinction between information capacity of quantum states and accessible information via measurements.\n",
        "* [Cross entropy](https://en.m.wikipedia.org/wiki/Cross_entropy) between two probability distributions over same underlying set of events measures average number of bits needed to identify an event drawn from set if a coding scheme used for set is optimized for an estimated probability distribution rather than true distribution. Cross-entropy will calculate a score that summarizes average difference between actual and predicted probability distributions for all classes. The score is minimized and a perfect cross-entropy value is 0.\n",
        "\n",
        "* [Binary entropy](https://en.m.wikipedia.org/wiki/Binary_entropy_function): is defined as the entropy of a Bernoulli process with probability p of one of two values"
      ],
      "metadata": {
        "id": "kGLHOLSRrQ8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Metrics</font> (Fisher information, Trace distance, Minkowski, Manhattan)*"
      ],
      "metadata": {
        "id": "oKvbzZ8cxOS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Metrics: generally used to define a distance between two points in a metric space. Häufig wird auch eine Metrik als [Distanzfunktion](https://de.m.wikipedia.org/wiki/Distanzfunktion). See [more](https://franknielsen.github.io/Divergence/index.html). Properties:**\n",
        "  1. Positive Definitheit (**positive definiteness**):\n",
        "    * $d(x, y) \\geq 0$ (**non-negativity**)\n",
        "    * $d(x, y)=0$ if and only if $x=y$ (Gleichheit gilt genau dann, wenn $x=y$, **identity of indiscernibles**) für alle $x, y \\in M$.\n",
        "  2. $d(x, y)=d(y, x)$ (**symmetry**)\n",
        "  3. $d(x, z) \\leq d(x, y)+d(y, z)$ (**Dreiecksungleichung / subadditivity / triangle inequality**) $\\forall x, y, z \\in M$\n",
        "  * Divergence fullfills property of positive definiteness (1). Distance (pseudometric) fullfills property of positive definiteness and symmetrie (1 + 2, but not 3 triangle inequality. Metrics and Norms fullfill property of positive definiteness, symmetrie and triangle inequality (1 + 2 + 3)."
      ],
      "metadata": {
        "id": "B8Sz3kzJn6VF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Aus Normen erzeugte Metriken:*\n",
        "* [Minkowski metrik / distance](https://en.m.wikipedia.org/wiki/Minkowski_distance) (L<sup>p</sup> Distances): aus einer $p$ -Norm abgeleitet (but p cannot be less than 1, because otherwise the triangle inequality does not hold). Wichtige Spezialfälle sind: Manhattan, Euclidean, Chebyshev.\n",
        "* [Manhattan-Metrik](https://de.m.wikipedia.org/wiki/Manhattan-Metrik) zu $p=1$,\n",
        "* [Euklidische Metrik (Euclidean distance)](https://en.m.wikipedia.org/wiki/Euclidean_distance) zu $p=2$. The Euclidean distance is often used in classification problems because it is a natural measure of similarity between two vectors.\n",
        "* [Maximum-Metrik (Chebyshev distance)](https://en.m.wikipedia.org/wiki/Chebyshev_distance) zu $p=\\infty$\n",
        "* der eindimensionale Raum der reellen oder komplexen Zahlen mit dem absoluten Betrag als Norm (mit beliebigem $p$ ) und der dadurch gegebenen **Betragsmetrik** $d(x, y)=|x-y|$\n",
        "* [Mahalanobis distance](https://de.m.wikipedia.org/wiki/Mahalanobis-Abstand) (see under 'Distances') is useful when dealing with variables measured in different scales (so the units of measure become standardized) and also, in order to avoid correlation issues between these variables.\n",
        "\n",
        "* [Fréchet-Metrik](https://de.m.wikipedia.org/wiki/Fréchet-Metrik) wird gelegentlich eine Metrik $d(x, y)=\\rho(x-y)$ bezeichnet, die von einer Funktion $\\rho$ induziert wird, welche die meisten Eigenschaften einer Norm besitzt, aber nicht homogen ist. Sie stellt eine Verbindung zwischen Metrik und Norm her.\n",
        "* [Cayley–Klein metric](https://en.m.wikipedia.org/wiki/Cayley%E2%80%93Klein_metric) is used in a variety of mathematical applications, including geometry, physics, and computer science. For example, it is used to define the distance between two points on the Poincaré disk, which is a model of the hyperbolic plane. It is an example of [Left- / right-/ bi-invariant Riemann metric](https://ncatlab.org/nlab/show/invariant+metric). Used in [The geometry of quantum computation](https://arxiv.org/abs/quant-ph/0701004)."
      ],
      "metadata": {
        "id": "IJBkzU6eFx1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Nicht aus Normen erzeugte Metriken:*\n",
        "* [Riemannsche Mannigfaltigkeit (Metrik)](https://en.m.wikipedia.org/wiki/Riemannian_manifold), zB  Die kürzesten Strecken zwischen unterschiedlichen Punkten (die sogenannten Geodäten) sind nicht zwingend Geradenstücke, sondern können gekrümmte Kurven sein. Die Winkelsumme von Dreiecken kann, im Gegensatz zur Ebene, auch größer (z. B. Kugel) oder kleiner (hyperbolische Räume) als 180° sein.\n",
        "* [Hausdorff-Metrik](https://de.m.wikipedia.org/wiki/Hausdorff-Metrik) misst den **Abstand zwischen Teilmengen, nicht Elementen, eines metrischen Raums**; man könnte sie als Metrik zweiten Grades bezeichnen, denn sie greift auf eine Metrik ersten Grades zwischen den Elementen des metrischen Raums zurück.\n",
        "* [Fisher information metric](https://en.m.wikipedia.org/wiki/Fisher_information_metric):\n",
        "  * also: Fisher-Rao norm: as a common starting point for many measures of complexity currently studied in the literature (see work of Srebro’s group and Bartlett et al). https://www.mit.edu/~rakhlin/papers/myths.pdf, Tengyuan Liang, Tomaso Poggio, Alexander Rakhlin, James Stokes (2017) Fisher-Rao Metric, Geometry, and Complexity of Neural Networks, https://arxiv.org/abs/1711.01530\n",
        "  * Fisher-Rao norm (or Fisher Information Metric) measures distance in the space of probability distributions, and it is defined in the context of information geometry. It is not a matrix norm per se\n",
        "  * The Fisher information metric is not a norm-induced metric. A norm-induced metric is a metric that can be defined from a norm on a vector space. The Fisher information metric is defined on a statistical manifold, which is a more general object than a vector space.\n",
        "  * To see why the Fisher information metric is not a norm-induced metric, consider the following. A norm-induced metric satisfies the triangle inequality, which states that the distance between two points is less than or equal to the sum of the distances between each point and a third point. However, the Fisher information metric does not satisfy the triangle inequality in general.\n",
        "  * For example, consider the statistical manifold of all Gaussian distributions with mean zero and variance one. The Fisher information metric on this manifold is given by the metric tensor $I^{-1}$, where $I$ is the Fisher information matrix. The Fisher information matrix for a Gaussian distribution with mean zero and variance one is given by $I = \\frac{1}{\\sigma^2}$, where $\\sigma$ is the standard deviation.\n",
        "  * Now, consider the following three points on this statistical manifold:\n",
        "    * $p_1$: The Gaussian distribution with mean zero and variance one.\n",
        "    * $p_2$: The Gaussian distribution with mean zero and variance two.\n",
        "    * $p_3$: The Gaussian distribution with mean zero and variance three.\n",
        "  * The Fisher information metric distances between these points are given by:\n",
        "    * $d(p_1, p_2) = \\sqrt{2}$\n",
        "    * $d(p_2, p_3) = \\sqrt{2}$\n",
        "    * $d(p_1, p_3) = \\sqrt{6}$\n",
        "  * We can see that the triangle inequality is not satisfied, since $\\sqrt{2} + \\sqrt{2} < \\sqrt{6}$. Therefore, the Fisher information metric is not a norm-induced metric.\n",
        "  * Although the Fisher information metric is not a norm-induced metric, it is still a useful metric for measuring the distance between points on a statistical manifold. It is often used in machine learning and statistics to quantify the amount of information that a set of data contains about a parameter.\n",
        "  * **The topic information geometry uses this to connect [Fisher information](https://en.m.wikipedia.org/wiki/Fisher_information) to differential geometry, and in that context, this metric is known as the Fisher information metric.**\n",
        "  * Fisher information is expected value of second derivative of log likelihood function. Fisher information measures how much the log likelihood function changes when the parameters of the distribution are changed (a measure of the sensitivity of the log likelihood function to changes in the parameters. The larger the Fisher information, the more sensitive the log likelihood function is to changes in the parameters).\n",
        "  * The Quantum Fisher Information Matrix (QFIM) is an extension of the concept of Fisher Information Matrix from classical statistics to quantum mechanics. It measures the amount of information that a quantum state carries about an unknown parameter. This parameter might be related to some aspect of the quantum state or a transformation applied to it.\n",
        "  * The Fisher Information Matrix (FIM) is a matrix whose entries are the expected values of the squared derivatives of the log-likelihood with respect to the parameters. The inverse of the FIM gives the Cramér-Rao Bound, which provides a lower limit on the covariance of any unbiased estimator. In other words, **the CRB (derived from the FIM) tells us the smallest possible variance (or covariance in the multivariate case) that we can expect from an unbiased estimator.**\n",
        "  * **Fisher Information is a measure of how much information a random variable provides about an unknown parameter**. The Fisher information is defined as the expected value of the squared derivative of the log-likelihood function with respect to the parameter.\n",
        "  * The Fisher information can be used to construct confidence intervals and hypothesis tests for the parameter. It can also be used to derive the asymptotic properties of maximum likelihood estimators.\n",
        "  * The Fisher information is a non-negative quantity. A random variable that provides no information about the parameter has a Fisher information of 0.\n",
        "  * Measure of redundancy. How much of model is active vs inactive.\n",
        "  * Fisher information: Sensitivity of my parameters to my model space --> measure of model capacity (?), see video from amira qhack 2022\n",
        "  * Fisher information is the expected value of the second derivative of the log likelihood function\n",
        "  * Given a parameterized quantum state ρ(θ), where θ is the parameter vector we are interested in, the QFIM is defined in terms of the symmetric logarithmic derivative (SLD), which is a Hermitian operator L(θ) that satisfies a particular equation related to the derivative of the state ρ(θ).\n",
        "  * The entries of the QFIM, denoted as H(θ), are given by:\n",
        "  * $H_ij(θ) = \\frac{1}{2} Tr [ρ(θ) {L_i(θ), L_j(θ)}]$\n",
        "  * where $L_i$ and $L_j$ are the SLDs corresponding to the parameters $θ_i$ and $θ_j$, respectively, and { , } denotes the anticommutator.\n",
        "  * Like the classical Fisher Information Matrix, the QFIM can be used to define a lower bound on the variance of an unbiased estimator for the parameters θ. This is the Quantum Cramér-Rao Bound.\n",
        "  * In practical terms, the QFIM and Quantum Cramér-Rao Bound are used in quantum metrology to quantify the ultimate limit to precision that can be achieved in estimating parameters, such as phase shifts or magnetic fields, based on quantum mechanical measurements.\n",
        "  * **Yes, the Fisher-Rao norm, or Fisher Information Metric**, is indeed a metric in the sense that it defines a distance function on the space of probability distributions. Specifically, it provides a way to measure the distance between different probability distributions in a manner that takes into account their geometrical structure.\n",
        "  * Mathematically, for a parametric family of probability distributions $\\( P_\\theta \\)$, the Fisher Information Metric $\\( g_{\\theta \\theta'} \\)$ is defined by taking the expectation of the outer product of the score (the gradient of the log-likelihood) with respect to the parameters $\\( \\theta \\)$ and $\\( \\theta' \\)$.\n",
        "  * $\\[ g_{\\theta \\theta'}(\\theta) = \\mathbb{E}\\left[ \\left( \\frac{\\partial \\log P_\\theta(X)}{\\partial \\theta} \\right) \\left( \\frac{\\partial \\log P_\\theta(X)}{\\partial \\theta'} \\right) \\right] \\]$\n",
        "  * Where the expectation is taken with respect to the distribution $\\( P_\\theta(X) \\)$.\n",
        "  * This matrix gives a Riemannian metric on the parameter space, defining a geometry that reflects how changes in parameters change the distributions. Consequently, it provides a natural distance measure between distributions (or models) that are nearby in parameter space.\n",
        "  * However, it's worth noting that while it's a \"metric\" in a geometrical sense, the Fisher Information Metric doesn’t satisfy all properties of a metric in the strict mathematical sense (like the triangle inequality). It does not measure \"distance\" in the conventional sense but quantifies the similarity or dissimilarity between statistical models or distributions based on their parametrizations. This concept and its implications are explored in the field of information geometry.\n",
        "* *what is a degenerate Fisher information matrix?*\n",
        "  * A degenerate Fisher information matrix is a Fisher information matrix that is not full rank. This means that there is at least one direction in which the Fisher information is zero. This can happen for a number of reasons, such as:\n",
        "    * When the model is overparameterized, meaning that there are more parameters than necessary to describe the data.\n",
        "    * When the parameters are not identifiable, meaning that there are multiple sets of parameters that can produce the same data.\n",
        "    * When the data is not informative enough to estimate all of the parameters.\n",
        "  * When the Fisher information matrix is degenerate, it means that there is some uncertainty in the estimation of the parameters that cannot be reduced by increasing the sample size. This is because the Fisher information matrix is a measure of the amount of information that the data contains about the parameters.\n",
        "  * Degenerate Fisher information matrices can be a problem in statistical inference, as they can lead to biased and inefficient estimates of the parameters. However, there are a number of ways to deal with degenerate Fisher information matrices, such as:\n",
        "    * Using regularization techniques to reduce the number of parameters in the model.\n",
        "    * Using constraints on the parameters to make them identifiable.\n",
        "    * Using Bayesian methods to estimate the parameters.\n",
        "  * It is important to note that a degenerate Fisher information matrix does not necessarily mean that the model is wrong. It is possible for a model to be correct even if the Fisher information matrix is degenerate. However, it is important to be aware of the potential problems that can arise from degenerate Fisher information matrices when interpreting the results of statistical analyses.\n",
        "  * Here are some examples of models that can have degenerate Fisher information matrices:\n",
        "    * A linear regression model with more predictors than observations.\n",
        "    * A logistic regression model with a constant predictor.\n",
        "    * A time series model with a seasonal component that is not identified.\n",
        "* [Trace distance](https://en.m.wikipedia.org/wiki/Trace_distance) is a **metric** on the space of density matrices and gives a measure of the distinguishability between two states. In quantum mechanics, the trace distance is used to measure the distinguishability between two quantum states. It is the quantum generalization of the Kolmogorov distance for classical probability distributions.\n",
        "  * The trace distance is defined as half of the [trace norm](https://en.m.wikipedia.org/wiki/Matrix_norm#Schatten_norms) of the difference of the matrices ${\\displaystyle T(\\rho ,\\sigma ):={\\frac {1}{2}}\\|\\rho -\\sigma \\|_{1}={\\frac {1}{2}}\\mathrm {Tr} \\left[{\\sqrt {(\\rho -\\sigma )^{\\dagger }(\\rho -\\sigma )}}\\right],}$\n",
        "  * Trace distance is a measure of the distinguishability between two quantum states. It is defined as half of the L1 norm of the difference between the density matrices of the two states:\n",
        "  * $δ(ρ, σ) = 1/2 ||ρ - σ||_1$\n",
        "  * where ||ρ - σ||_1 is the trace norm of ρ - σ.\n",
        "  * Trace distance is a metric on the space of density matrices, meaning that it satisfies the following properties:\n",
        "    * δ(ρ, σ) ≥ 0 for all ρ, σ\n",
        "    * δ(ρ, σ) = 0 if and only if ρ = σ\n",
        "    * δ(ρ, σ) = δ(σ, ρ)\n",
        "    * δ(ρ, τ) ≤ δ(ρ, σ) + δ(σ, τ) for all ρ, σ, τ\n",
        "  * The trace distance is a more general measure of distinguishability than the trace inequality. The trace inequality only states that the trace distance between two quantum states is at least as large as the sum of the trace distances between each state and a third state. The trace distance, on the other hand, can be used to measure the distinguishability between any two quantum states, regardless of whether there is a third state involved.\n",
        "  * Here is an example of how the trace distance can be used to measure the distinguishability between two quantum states: Suppose we have two quantum states ρ and σ that are represented by the following density matrices:\n",
        "    * $ρ = |0 > < 0| + | 1 > < 1|$\n",
        "    * $σ = | 0 > < 0| + 0.5 | 1 > <1|$\n",
        "  * The trace distance between ρ and σ can be calculated as follows:\n",
        "    * δ(ρ, σ) = 1/2 ||ρ - σ||_1\n",
        "    * = 1/2 ||(|0><0| + |1><1|) - (|0><0| + 0.5 |1><1|)||_1\n",
        "    * = 1/2 ||0.5 |1><1|)||_1\n",
        "    * = 1/2 * 0.5\n",
        "    * = 1/4\n",
        "  * This means that the two states ρ and σ are indistinguishable with a probability of 1/4.\n",
        "  * The trace distance is a powerful tool for analyzing quantum information processing protocols and for studying the effects of noise and decoherence on quantum systems. It is also used in quantum machine learning and quantum algorithms.\n",
        "  * the trace distance is a metric because:\n",
        "    * Non-negativity: The distance between two points is always non-negative.\n",
        "    * Identity: The distance between two identical points is zero.\n",
        "    * Symmetry: The distance between two points is the same as the distance between the points in the opposite order.\n",
        "    * Triangle inequality: The distance between two points is less than or equal to the sum of the distances between each point and a third point.\n",
        "* [Fubini–Study metric](https://en.m.wikipedia.org/wiki/Fubini–Study_metric): When extended to complex projective Hilbert space, the Fisher information metric becomes the Fubini–Study metric\n",
        "* [Bures metric](https://en.m.wikipedia.org/wiki/Bures_metric): when written in terms of mixed states, the Fisher information mettic is the quantum Bures metric. The Bures metric can be seen as the quantum equivalent of the Fisher information metric\n",
        "* [Französische Eisenbahnmetrik](https://de.m.wikipedia.org/wiki/Französische_Eisenbahnmetrik).\n",
        "* [Hamming-Abstand](https://de.m.wikipedia.org/wiki/Hamming-Abstand) Code space metric: gibt Unterschiedlichkeit von (gleich langen) Zeichenketten an (number of items that are different between two subsets).\n",
        "* [Levenshetin Distance](https://de.m.wikipedia.org/wiki/Levenshtein-Distanz) Extension of Hamming-Abstands. Die Levenshtein-Distanz kann als Sonderform der [Dynamic Time Warpening](https://de.m.wikipedia.org/wiki/Dynamic-Time-Warping) (DTW) betrachtet werden. Siehe auch [Lee distance](https://en.m.wikipedia.org/wiki/Lee_distance), [Jaro–Winkler distance](https://en.m.wikipedia.org/wiki/Jaro–Winkler_distance) & [Edit Distance](https://en.m.wikipedia.org/wiki/Edit_distance).\n",
        "* More [nicht aus Normen erzeugten Metriken](https://de.m.wikipedia.org/wiki/Metrischer_Raum#Nicht_durch_Normen_erzeugte_Metriken)"
      ],
      "metadata": {
        "id": "3HV9y-rvrhKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Measure</font> (Haar, Dirac, Radon, Hausdorff, Lebesgue)*"
      ],
      "metadata": {
        "id": "eLjOkdyQxLeb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Measures**\n",
        "\n",
        "A measure provides a description for how things are distributed in a mathematical set or space. From Video: [The Haar Measure | PennyLane Tutorial](https://www.youtube.com/watch?v=d4tdGeqcEZs&list=PLzgi0kRtN5sO8dkomgshjSGDabnjtjBiA&index=3)\n",
        "\n",
        "[Measure](https://de.m.wikipedia.org/wiki/Ma%C3%9F_(Mathematik)): Funktion, die Teilmengen einer Grundmenge Zahlen zuordnet, die als „Maß“ für die Größe dieser Mengen interpretiert werden können. In Stochastik werden Wahrscheinlichkeitsmaße verwendet, um zufälligen Ereignissen, die als Teilmengen eines Ergebnisraums aufgefasst werden, Wahrscheinlichkeiten zuzuordnen.\n",
        "\n",
        "  * See also [Geometric measure theory](https://en.m.wikipedia.org/wiki/Geometric_measure_theory) and [outer measure](https://en.m.wikipedia.org/wiki/Outer_measure).\n",
        "\n",
        "* [Lebesgue measure](https://en.m.wikipedia.org/wiki/Lebesgue_measure): is the standard way of assigning a measure to subsets of n-dimensional Euclidean space. For n = 1, 2, or 3, it coincides with the standard measure of length, area, or volume. In general, it is also called n-dimensional volume, n-volume, or simply volume.\n",
        "\n",
        "  * [Hausdorff measure](https://en.m.wikipedia.org/wiki/Hausdorff_measure) is a generalization of the traditional notions of area and volume to non-integer dimensions, specifically fractals and their Hausdorff dimensions. It is a type of outer measure that assigns number in [0,∞] to each set in $\\mathbb {R} ^{n}$ or, more generally, in any metric space.\n",
        "\n",
        "  * [Jordan measure](https://en.m.wikipedia.org/wiki/Jordan_measure) is an extension of the notion of size (length, area, volume) to shapes more complicated than, for example, a triangle, disk, or parallelepiped.\n",
        "\n",
        "* [Radon measure](https://en.m.wikipedia.org/wiki/Radon_measure)\n",
        "\n",
        "* [Wiener measure](https://en.wikipedia.org/wiki/Wiener_process) zur Beschreibung des Wiener-Prozesses (Brownsche Bewegung). It is the probability law on the space of continuous functions g, with g(0) = 0, induced by the Wiener process.\n",
        "\n",
        "* [Random measure](https://en.m.wikipedia.org/wiki/Random_measure) is a measure-valued random element, for example used in the theory of random processes, where they form many important point processes such as Poisson point processes and Cox processes.\n",
        "\n",
        "* [Vector measure](https://en.m.wikipedia.org/wiki/Vector_measure) eine Verallgemeinerung des Maßbegriffes dar: Das Maß ist nicht mehr reellwertig, sondern vektorwertig. Vektormaße werden unter anderem in der Funktionalanalysis benutzt (Spektralmaß).\n",
        "\n",
        "  * [Projection-valued measure (Spektralmaß)](https://en.m.wikipedia.org/wiki/Projection-valued_measure) ist eine Abbildung, die gewissen Teilmengen einer fest gewählten Menge orthogonale Projektionen eines Hilbertraums zuordnet. Spektralmaße werden verwendet, um Ergebnisse in der Spektraltheorie linearer Operatoren zu formulieren, wie z. B. den Spektralsatz für normale Operatoren.\n",
        "\n",
        "  * [Complex measure](https://en.m.wikipedia.org/wiki/Complex_measure)\n",
        "\n",
        "  * [Signed measure](https://en.m.wikipedia.org/wiki/Signed_measure)\n",
        "\n",
        "* [Moment measure](https://en.m.wikipedia.org/wiki/Moment_measure)\n",
        "\n",
        "* [Dirac measure](https://en.m.wikipedia.org/wiki/Dirac_measure) assigns a size to a set based solely on whether it contains a fixed element x or not. It is one way of formalizing the idea of the Dirac delta function.\n",
        "\n",
        "* [Discrete measure](https://en.m.wikipedia.org/wiki/Discrete_measure) is similar to the Dirac measure, except that it is concentrated at countably many points instead of a single point. More formally, a measure on the real line is called a discrete measure (in respect to the Lebesgue measure) if its support is at most a countable set.\n",
        "\n",
        "* [Poisson random measure](https://en.m.wikipedia.org/wiki/Poisson_random_measure) and [Poisson-type random measure](https://en.m.wikipedia.org/wiki/Poisson-type_random_measure)\n",
        "\n",
        "* [Haar measure](https://en.m.wikipedia.org/wiki/Haar_measure) assigns invariant volume (left- and right-invariant = (bi-)invariant measure). Generalization of Lebesgue measure. Sample unitary matrix uniformly at random according to Haar measure, and then apply it to another unitary matrix, the resulting unitary matrix will also be sampled uniformly at random according to Haar measure.\n",
        "  \n",
        "  * **Define expectation value of an observable = average value of the observable** over all possible quantum states. e.g. in QML: define <u>**average complexity**</u> by sampling a random unitary matrix (who represent quantum operations, like gates and channels) from Haar measure (= unitary matrix that is chosen with equal probability from all possible unitary matrices), **and then measuring sample complexity of algorithm on the resulting quantum state**. Average complexity is expected value of sample complexity over all possible unitary matrices. (*Train QML on quantum data: sampling large number of random unitary operations and applying them to data. Haar measure ensures that all possible unitary operations have an equal chance of being sampled.*)\n",
        "\n",
        "  * VC dimension, Rademacher complexity and Kullback Leibler divergence can all be used to measure the <u>**worst-case complexity**</u> (sample complexity of algorithm on worst possible quantum state).\n",
        "\n",
        "  * Sample unitary matrices according to Haar measure: Metropolis-Hastings algorithm iteratively proposes new unitary matrix and accepts or rejects proposal based on probability distribution (chosen that it converges to sampling from Haar measure)\n",
        "\n",
        "* Gibbs measure\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wUzfIQ8Ddoxj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Set Complexity</font> (Covering number, Maximal packing nets)*"
      ],
      "metadata": {
        "id": "V36uKfvAxRCm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set Complexity**\n",
        "\n",
        "* [Covering problems](https://en.m.wikipedia.org/wiki/Covering_problems)\n",
        "\n",
        "* [Covering number](https://en.m.wikipedia.org/wiki/Covering_number): smallest number of sets that can be used to cover a given set with a certain tolerance.\n",
        "  * Covering number of a set with respect to a metric quantifies how many balls of a specified radius are needed to cover the set. In learning theory, covering numbers can be used to analyze the complexity of function classes in certain metric spaces. [Covering number](https://en.m.wikipedia.org/wiki/Covering_number): helps in understanding the capacity of a hypothesis class, which can be crucial in understanding generalization errors and the learnability of a class. Specifically, it can provide bounds on the number of samples required to learn a target function to a desired accuracy. Covering numbers are from [Combinatorial (discrete) geometry](https://en.m.wikipedia.org/wiki/Discrete_geometry), like [Kissing number](https://en.m.wikipedia.org/wiki/Kissing_number) (Newton number or Contact number) and [Polygon number](https://en.m.wikipedia.org/wiki/Polygon_covering).\n",
        "  * Measure of the complexity of a set: Bound sample complexity of learning algorithms (meanwhile Lebesgue covering dimension is used to bound generalization error of learning algorithms. eg Covering number tells how many sets we need to cover unit circle, while Lebesgue covering dimension tells how many dimensions we need to represent unit circle). Covering number is more directly related to sample complexity and generalization error of learning algorithms.\n",
        "  * How can one calculate the covering number bounds for the space of pure output states of polynomial-size quantum circuits? **Lower bound** on covering number is number of pure states that can be represented by a polynomial-size quantum circuit: given by $2^{n_q}$, where $n_q$ is number of qubits in circuit. Lower bound is number of states that a polynomial-size quantum circuit can represent, and upper bound is number of states that any quantum circuit can represent.\n",
        "\n",
        "  * Covering numbers are a measure of the complexity of a set (in sample complexity). A set with a small covering number is said to be easy to cover, while a set with a large covering number is said to be difficult to cover\n",
        "\n",
        "  * Example: *we provide bounds on the expressivity of the class of CPTP maps (or unitaries) that a quantum machine learning model (QMLM) can implement in terms of the number of trainable elements used in the architecture. As a measure of expressivity, we choose covering numbers and metric entropies w.r.t. (the metric induced by) the diamond norm.* (from: Generalization in quantum machine learning from few training data)\n",
        "\n",
        "  * [The Most Important Concept in Topology and Analysis | Compactness](https://youtu.be/td7Nz9ATyWY)\n",
        "\n",
        "* [Kissing number](https://en.m.wikipedia.org/wiki/Kissing_number)\n",
        "\n",
        "* [Polygon covering](https://en.m.wikipedia.org/wiki/Polygon_covering)\n",
        "\n",
        "* [Spherical code](https://en.m.wikipedia.org/wiki/Spherical_code)\n",
        "\n",
        "* [Equilateral dimension](https://en.m.wikipedia.org/wiki/Equilateral_dimension)\n",
        "\n",
        "* [Packing problems](https://en.m.wikipedia.org/wiki/Packing_problems)\n",
        "\n",
        "  * **Maximal packing nets** - used in \"Information-theoretic bounds on quantum advantage in machine learning\". See (https://en.m.wikipedia.org/wiki/Close-packing_of_equal_spheres) and (https://en.m.wikipedia.org/wiki/Packing_density)\n",
        "  * \"measures the cardinality of a maximal packing net that depends on the input distribution\""
      ],
      "metadata": {
        "id": "w3xsatVa9aZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Divergence</font> (Kullback Leibler, Jensen-Shannon, Hellinger, Bregman, f, Bhattacharyya)*"
      ],
      "metadata": {
        "id": "hiezBxLBxVLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[Divergence](https://en.m.wikipedia.org/wiki/Divergence_(statistics)) is a (contrast) function which measure the difference between two probability distributions (statistical manifolds). Is a weaker notion than that of the distance (not symmetric, no triangle inequality).**\n",
        "\n",
        "* [Kullback Leibler](https://en.m.wikipedia.org/wiki/Kullback–Leibler_divergence) (relative entropy): measure of how one probability distribution (not only Gaussian) differs from a baseline distribution or amount of information lost when one distribution is converted to another. Equivalent to multi-class cross-entropy in multi-class classification, but used to approximate more complex function, e.g. autoencoder for learning a dense feature representation. Minimizing KL divergence (+ squared Euclidean distance) is main way to solve linear inverse problem, via principle of max entropy & least squares (logistic + linear regression). Used in clustering, feature selection (find features that minimize KL divergence between model's distribution and  true distribution when features are excluded), anomaly detection, GANs (similarity between real and generated data). Fisher information is expected value of second derivative of log likelihood function. KL divergence is quadratic form whose coefficients are given by elements of Fisher information matrix. FIM defines local curvature of KL divergence. Fisher information can be used to estimate the KL divergence between two distributions.\n",
        "  \n",
        "\n",
        "* [Jensen-Shannon divergence](https://en.m.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence): smoothed version of KLd = symmetrization of KL divergence and with finite values. Symmetric means that does not matter which distribution is source and which is target. More robust to noise than other measures of similarity like KLd. JSD is also non-parametric: does not make any assumptions about underlying distribution of data. Square root of Jensen–Shannon divergence is Jensen-Shannon distance. Used in dimensionality reduction, GAN, clustering, anomaly detection, novelty detection.\n",
        "\n",
        "* [Hellinger distance](https://en.m.wikipedia.org/wiki/Hellinger_distance) (closely related to Bhattacharyya) quantifies similarity between two probability distributions. Type of f-divergence. Hellinger distance is good choice when goal is to measure difference between the cumulative distribution functions of two distributions.\n",
        "\n",
        "* [f-Divergence](https://en.m.wikipedia.org/wiki/F-divergence): Probabilistic models are often trained by maximum likelihood, which corresponds to minimizing a specific f-divergence between model and data distribution.\n",
        "\n",
        "* [Bregman divergences](https://en.m.wikipedia.org/wiki/Bregman_divergence): calculate bi-tempered logistic loss, performing better than softmax function with noisy datasets. The Mahalanobis distance is an example of Bregman, and Squared (Euclidean) distance is a special case for Bregman.\n",
        "  \n",
        "* [Squared Euclidean distance](https://en.m.wikipedia.org/wiki/Euclidean_distance#Squared_Euclidean_distance): special case of Bregman (corresponding to function x<sup>2</sup>) for certain choice of generating function when generating convex function is quadratic - represents measure of divergence between two points in space. The cost function for K-means clustering is sum of squared distances between data points and cluster centroids. Squared distances are more sensitive to large errors than absolute distances.\n",
        "\n",
        "* [Bhattacharyya distance](https://en.m.wikipedia.org/wiki/Bhattacharyya_distance): determine relative closeness of two samples. Measure separability of classes in classification and more reliable than Mahalanobis when standard deviations of classes are same. When two classes have similar means but different standard deviations, Mahalanobis would tend to zero, whereas Bhattacharyya grows depending on difference between standard deviations.\n",
        "\n",
        "* Maximal Quantum Rényi Divergence: see under entropy"
      ],
      "metadata": {
        "id": "CdhvTHoqrUCS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Distances</font> (Wasserstein, Mahalanobis, Manhattan)*"
      ],
      "metadata": {
        "id": "IJCykPfwxdQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://en.m.wikipedia.org/wiki/Statistical_distance\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Total_variation_distance_of_probability_measures\n",
        "\n",
        "from: https://en.m.wikipedia.org/wiki/Trace_distance"
      ],
      "metadata": {
        "id": "KAgLEAgDJYCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[Distances](https://en.m.wikipedia.org/wiki/Distance), especially [Statistical distances](https://en.m.wikipedia.org/wiki/Statistical_distance): quantify separation between two elements. Can be defined on a wider variety of spaces than metrics and are often more interpretable than metrics. Distances can be more flexible than metrics: can be defined on a wider variety of spaces when data is not Euclidean (no natural notion of distance like in text, images, or graphs), data is noisy (more robust), or data is imbalanced. Is a weaker notion than that of the metric (there is no triangle inequality).**\n",
        "\n",
        "* [Manhattan distance (taxicab)](https://en.m.wikipedia.org/wiki/Taxicab_geometry): defined as sum of absolute values of the differences between the corresponding components of two vectors. The Manhattan distance is not symmetric, which means that the distance between two points is not the same as the distance between the reverse of the two points.\n",
        "* [Chebyshev distance](https://en.m.wikipedia.org/wiki/Chebyshev_distance): maximum absolute difference between corresponding components of two vectors. The Chebyshev distance is not symmetric, and it does not satisfy the triangle inequality.\n",
        "* [Jaccard distance](https://en.m.wikipedia.org/wiki/Jaccard_index): size of intersection of two sets divided by size of the union of the two sets. The Jaccard distance is not a metric because it does not satisfy the triangle inequality. The Jaccard distance is used for text classification tasks. It is defined as the size of the intersection of two sets divided by the size of the union of the two sets.\n",
        "* [Left- / right-/ bi-invariant Riemann metric](https://ncatlab.org/nlab/show/invariant+metric). Used in [The geometry of quantum computation](https://arxiv.org/abs/quant-ph/0701004). Example in discrete space: [Kendall tau distance](https://en.m.wikipedia.org/wiki/Kendall_tau_distance): is a measure of the similarity between two rankings of a set of objects. It is defined as the number of pairs of objects that are ranked in opposite order in the two rankings, divided by the total number of pairs of objects. The Kendall tau distance is not a metric because it does not satisfy the triangle inequality.\n",
        "* Lp-norm defined as the pth root of sum of the pth powers of the differences between the corresponding components of two vectors. The Lp norm is not a metric for p < 1.\n",
        "* [Wasserstein distance](https://en.m.wikipedia.org/wiki/Wasserstein_metric) (Earth Mover’s Distance): comparing probability distributions. The Wasserstein distance is not a metric for comparing vectors. Depending on the order parameter \\( p \\), it might not satisfy the triangle inequality property. When \\( p = 1 \\), it is a metric, but for other values of \\( p \\), it might not be. Is used for image segmentation tasks. It is defined as the minimum amount of work required to move one set of pixels to another set of pixels.  The Wasserstein distance is used where the data is represented as probability distributions. It is defined as the minimum cost of transporting one distribution to another.\n",
        "* Squared Euclidean distance is also a distance measure in a broader sense, as it quantifies the separation between two points in a Euclidean space. Squared Euclidean distance is also a divergence, specifically a special case of a Bregman divergence for a certain choice of generating function when the generating convex function is a quadratic function -  In this context, it represents a measure of divergence between two points in the space.\n",
        "* [Bhattacharyya distance](https://en.m.wikipedia.org/wiki/Bhattacharyya_distance)\n",
        "* [Mahalanobis distance](https://en.m.wikipedia.org/wiki/Mahalanobis_distance) is a measure of the distance between a point P and a distribution D, used in multivariate anomaly detection, classification on highly imbalanced datasets and one-class classification. If each of these axes is re-scaled to have unit variance, then the Mahalanobis distance corresponds to standard Euclidean distance in the transformed space. The Mahalanobis distance is thus unitless and scale-invariant, and takes into account the correlations of the data set. In statistics, the covariance matrix of the data is sometimes used to define a distance metric called Mahalanobis distance. The Mahalanobis distance does not satisfy the triangle inequality because it can be zero even if the two points are not the same. This can happen if the covariance matrix is singular. It is often used in multivariate anomaly detection, classification, and regression. [Mahalanobis distance](https://en.m.wikipedia.org/wiki/Mahalanobis_distance) is useful when dealing with variables measured in different scales (so the units of measure become standardized) and also, in order to avoid correlation issues between these variables.\n",
        "\n",
        "![sciences](https://raw.githubusercontent.com/deltorobarba/repo/master/mahalanobis.jpg)\n"
      ],
      "metadata": {
        "id": "OTsj83x7GbyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <font color=\"orange\">*Topological Invariants</font> (Homology Groups, Betti numbers, Characteristic classes)*"
      ],
      "metadata": {
        "id": "zXCXyX9DxfdE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploiting topological properties of the loss landscape of symmetry-machine-learning (in the data and problem) as a preprocessing step to reduce Barren plateaus - How do topological properties of the loss landscape vary in a QML algorithm that learns symmetries of data and problems\n",
        "https://pennylane.ai/qml/demos/tutorial_geometric_qml/"
      ],
      "metadata": {
        "id": "w_Y-pFySypvS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topological Invariants** (Distanz- und Ähnlichkeitsmaß um topologische Räumen / Objekte zu differenzieren)\n",
        "* **What is it used for?**: Similarity metrics for topology: A topological invariant is a property or characteristic of a space that remains unchanged under homeomorphisms, which are continuous transformations of the space that can be continuously undone. Topological invariants are used in:\n",
        "  * **Mathematics:** study properties of topological spaces and manifolds (Euler characteristic of surface to distinguish between different surfaces, such as spheres and tori)\n",
        "  * **Physics:** study the properties of quantum systems (Chern class of band insulator to determine whether the insulator is topological or not. also classify different types of insulators and superconductors)\n",
        "  * **Chemistry:** study properties of molecules and materials (winding number of a molecule to determine whether molecule is chiral or not. In materials science, to design new materials with desired properties, such as high strength and conductivity, or new drugs and catalysts)\n",
        "  * **Computer science:** study properties of algorithms and data structures ( genus of a graph to determine how difficult it is to color the graph)\n",
        "  * **Machine learning:** develop new machine learning algorithms more robust to noise and perturbations(TDA to extract features from data that are invariant to certain transformations)\n",
        "\n",
        "* **Topologische Räume:** Das einfachste Beispiel eines topologischen Raumes ist die Menge der reellen Zahlen. Dabei ist die Topologie, also das System der offenen Teilmengen so erklärt, dass wir eine Menge  Ω  C  R  offen nennen, wenn sie sich als Vereinigung von offenen Intervallen darstellen lässt. * [Separation Axioms](https://en.m.wikipedia.org/wiki/History_of_the_separation_axioms): Topologische Räume können klassifiziert werden nach Kolmogorov:\n",
        "  * Frechet Räume: sind Vektorräume von glatten Funktionen (unendlich oft differenzierbar, stetig). Diese Räume lassen sich zwar mit verschiedenen Normen ausstatten, sind aber bezüglich keiner Norm vollständig, also keine Banachräume. Man kann auf ihnen aber eine Topologie definieren, sodass viele Sätze, die in Banachräumen gelten, ihre Gültigkeit behalten.\n",
        "  * Uniforme Räume: erlauben es zwar nicht Abstände einzuführen, aber Begriffe wie gleichmäßige Stetigkeit, Cauchy-Folgen, Vollständigkeit und Vervollständigung zu definieren\n",
        "\n",
        "* **Basic topological invariants** (more \"Geometric\" or foundational / fundamental than the more algebraic invariants mentioned after)\n",
        "  * Connectedness: A space is connected if it cannot be divided into two disjoint non-empty open sets. This property is preserved under continuous maps, making it a topological invariant. There are several related notions as well, such as path-connectedness (there is a path connecting any two points in the space).\n",
        "  * Compactness: A space is compact if every open cover has a finite subcover. Like connectedness, this property is preserved under continuous functions, marking it as a topological invariant.\n",
        "\n",
        "* **Homotopy Invariants**\n",
        "These invariants are primarily concerned with the study of continuous deformations of topological spaces. Allows for classification of spaces based on their loop structures and offering a way to distinguish between different topological spaces\n",
        "  * **Fundamental Group (π₁)**, including the [fundamental group](https://en.m.wikipedia.org/wiki/Fundamental_group) (also known as the first homotopy group). It gives information about the loops in the space, essentially characterizing how one can loop around one point and come back to the same point.\n",
        "  * **Higher Homotopy Groups (π₂, π₃, ...)**: These groups generalize the concept of the fundamental group to higher dimensions, providing information about surfaces and higher-dimensional \"holes\" in a space.\n",
        "\n",
        "* **Homology and Cohomology**\n",
        "These invariants are associated with algebraic structures that help quantify various aspects of topological spaces.\n",
        "  * **Homology Groups** (including singular homology, simplicial homology, etc.)\n",
        "  * **Cohomology Groups** (including singular cohomology, sheaf cohomology, etc.)\n",
        "  * **Euler Characteristic** (can also be derived from homology)\n",
        "  * **Betti Numbers** (related to homology groups)\n",
        "\n",
        "* **[Characteristic class](https://en.m.wikipedia.org/wiki/Characteristic_class)**\n",
        "These are cohomology classes which help to study and classify fibred spaces and vector bundles (Higher dimensional invariants) are defined on vector bundles)\n",
        "  * [Chern classes](https://en.m.wikipedia.org/wiki/Chern_class) ( characteristic classes of complex vector bundles. To study complex geometry of manifolds.)\n",
        "  * [Chern Numbers](https://en.m.wikipedia.org/wiki/Chern_class#Chern_numbers) (they are associated with Chern classes, and give global information about the structure of a bundle)\n",
        "  * [Stiefel-Whitney classes](https://en.m.wikipedia.org/wiki/Stiefel%E2%80%93Whitney_class) (for real vector bundles, characteristic classes of principal bundles. Study the topology of manifolds)\n",
        "  * [Pontriagyn classes](https://en.m.wikipedia.org/wiki/Pontryagin_class) (characteristic classes of real vector bundles, particularly oriented ones. Study the real geometry of manifolds)\n",
        "  * [Segre classes](https://en.m.wikipedia.org/wiki/Segre_class): study of cones, a generalization of vector bundles (total Segre class is inverse to total Chern class, advantage of Segre class: it generalizes to more general cones, while Chern class does not)\n",
        "  * [Euler characteristic](https://en.m.wikipedia.org/wiki/Euler_characteristic) (a type of characteristic class associated with real vector bundles). It can be used to distinguish between orientable and non-orientable manifolds. It can distinguish between spheres and tori.\n",
        "  * Background: Characteristic classes are vector bundle invariants, while Betti numbers are defined on topological spaces.\n",
        "    * This means that **Betti numbers can only distinguish between topological spaces that are not homeomorphic, while characteristic classes can also distinguish between topological spaces that are homeomorphic but have different vector bundles**.\n",
        "    * For example, the sphere and the torus are homeomorphic, but they have different Euler classes. This means that the Betti numbers of the two spaces are the same, but they can be distinguished using characteristic classes.\n",
        "    * Characteristic classes can also be used to study the relationships between different manifolds and fiber bundles. For example, the Gysin homomorphism is a map between the cohomology groups of two manifolds that is defined using characteristic classes.\n",
        "    * Characteristic classes are global invariants, meaning that they do not change under local deformations of a manifold or fiber bundle. This makes them useful for classifying and differentiating topological spaces.\n",
        "\n",
        "* [Knot Invariants](https://en.m.wikipedia.org/wiki/Knot_invariant)\n",
        "These invariants are specific to the study of knots in three-dimensional space.\n",
        "  * [Jones Polynomial](https://de.m.wikipedia.org/wiki/Jones-Polynom)\n",
        "  * [Alexander Polynomial](https://de.m.wikipedia.org/wiki/Alexander-Polynom)\n",
        "  * [Winding Number](https://en.m.wikipedia.org/wiki/Winding_number)\n",
        "\n",
        "* **Differential Topology**\n",
        "These are invariants in the study of smooth manifolds and their properties.\n",
        "  * **De Rham Cohomology**\n",
        "  * **Differential Forms**\n",
        "\n",
        "* **Other Invariants Related to Manifold Geometry**\n",
        "  * **Genus** (related to the classification of surfaces)\n",
        "  * **Sectional Curvature**, **Ricci Curvature**, **Scalar Curvature** (these are invariants in Riemannian geometry, a field closely related to algebraic topology)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k_t6_qozAeTJ"
      }
    }
  ]
}