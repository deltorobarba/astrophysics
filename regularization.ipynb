{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "regularization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deltorobarba/machinelearning/blob/master/regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pa49bUnKyRgF"
      },
      "source": [
        "# Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebdu-Ydo47Gk",
        "colab_type": "text"
      },
      "source": [
        "*Author: Alexander Del Toro Barba*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTyMPxPtl588",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "* Regularization is a technique for preventing over-fitting by penalizing a model for having large weights\n",
        "* Weight regularization was borrowed from penalized regression models in statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlN8ilZEqQj7",
        "colab_type": "text"
      },
      "source": [
        "## L1 (Lasso)\n",
        "\n",
        "* Sum of the absolute weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZuDNlbKlWu4",
        "colab_type": "text"
      },
      "source": [
        "## L2 (Ridge)\n",
        "\n",
        "* Sum of the squared weights\n",
        "* The most common type of regularization is L2, also called simply “weight decay,” with values often on a logarithmic scale between 0 and 0.1, such as 0.1, 0.001, 0.0001, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ8UW9XnleoV",
        "colab_type": "text"
      },
      "source": [
        "## Elastic Net\n",
        "\n",
        "* Linear combination of L1 and L2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNJBr4ZHljUM",
        "colab_type": "text"
      },
      "source": [
        "## Lambda Value\n",
        "\n",
        "* Lambda is a regularization hyperparameter\n",
        "* Reasonable values of lambda range between 0 and 0.1\n",
        "* L2 weight regularization with very small regularization hyperparameters such as (e.g. 0.0005 or 5 x 10^−4) may be a good starting point"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H4crpOcoMlSe"
      },
      "source": [
        "# RNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRHu0whFdwoH",
        "colab_type": "text"
      },
      "source": [
        "## Import & Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc_Iu-7glx75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV-EingDXE_w",
        "colab_type": "text"
      },
      "source": [
        "## Choose Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnICMm4Dg1cf",
        "colab_type": "text"
      },
      "source": [
        "The Dense layer takes three regularizers, which all default to None. \n",
        "* kernel_regularizer: Regularizer function applied to the kernel weights matrix.\n",
        "* bias_regularizer: Regularizer function applied to the bias vector.\n",
        "* activity_regularizer: Regularizer function applied to the output of the layer (its \"activation\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb8hpJ37i5wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernel_regularizer=tf.keras.regularizers.l2(l=0.0005)\n",
        "bias_regularizer=None\n",
        "activity_regularizer=None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfVxKUnwXK8Z",
        "colab_type": "text"
      },
      "source": [
        "## Define Model & Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDEv6ZETl129",
        "colab_type": "code",
        "outputId": "8c26326c-c686-4ff3-87ca-7bee2a8e6b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu', \n",
        "                                kernel_regularizer=kernel_regularizer, \n",
        "                                bias_regularizer=bias_regularizer, \n",
        "                                activity_regularizer=activity_regularizer))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x=x_train, y=y_train, epochs=5, validation_data=(x_test, y_test))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 86us/sample - loss: 0.6831 - acc: 0.8137 - val_loss: 0.6109 - val_acc: 0.8162\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.5375 - acc: 0.8428 - val_loss: 0.5487 - val_acc: 0.8322\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.5099 - acc: 0.8490 - val_loss: 0.5410 - val_acc: 0.8361\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.4953 - acc: 0.8524 - val_loss: 0.4899 - val_acc: 0.8572\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4853 - acc: 0.8546 - val_loss: 0.5258 - val_acc: 0.8373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f41a9167048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}