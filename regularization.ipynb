{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regularization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deltorobarba/machinelearning/blob/master/regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjNmcYpFuFTY",
        "colab_type": "text"
      },
      "source": [
        "# **Regularization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYViK39mt7Nj",
        "colab_type": "code",
        "outputId": "9297d7ea-dccc-483c-bb27-6ed9a1abb124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlaD0R2A_Xm_",
        "colab_type": "text"
      },
      "source": [
        "## **Overfitting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kofQf1Yi_b6h",
        "colab_type": "text"
      },
      "source": [
        "* A fundamental problem in machine learning is the possibility of overfitting training data and carrying the noise of that data through to the test set, thereby providing inaccurate generalizations. Overfitting is when you have a complicated model that gives worse predictions than a simpler model.\n",
        "* Regularization is a technique for preventing a model from overfitting (e.g. preventing over-fitting by penalizing a model for having large weights)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEDOi0Mf_gkA",
        "colab_type": "text"
      },
      "source": [
        "**Regularization techniques against overfitting**\n",
        "\n",
        "* Add more data,\n",
        "* Vectornorm (L1, L2, Elastic Net) $^{1}$\n",
        "* Dropout, \n",
        "* Jitter (add noise),\n",
        "* Simpler model (reduce variance by taking into account fewer variables and parameters, thereby removing some of the noise in the training data), \n",
        "* Ensemble models, \n",
        "* Batch size (Small batches can oﬀer a regularizing eﬀect (Wilson and Martinez, 2003), perhaps due to the noise they add to the learning process) $^{2}$ \n",
        "* early stopping (this is not a formal regularization method, but can effectively limit overfitting). \n",
        "\n",
        "$^{1}$ *Traditional methods like cross-validation, stepwise regression to handle overfitting and perform feature selection work well with a small set of features but vectornorm regularization is a great alternative when dealing with a large set of features.*\n",
        "\n",
        "$^{2}$\n",
        "*Using a smaller batch size is like using some regularization to avoid converging to sharp minimizers. The gradients calculated with a small batch size are much more noisy than gradients calculated with large batch size, so it's easier for the model to escape from sharp minimizers, and thus leads to a better generalization. Generalization error is often best for a batch size of 1. Training with such a small batch size might require a small learning rate to maintain stability because of the high variance in the estimate of the gradient. The total runtime can be very high as a result of the need to make more steps, both because of the reduced learning rate and because it takes more steps to observe the entire training set.)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUp8zJmV_k6G",
        "colab_type": "text"
      },
      "source": [
        "**Overfitting: Variance-Bias-Tradeoff**\n",
        "\n",
        "Generally, we refer to this model as having a large variance and a small bias. That is, the model is sensitive to the specific examples, the statistical noise, in the training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_vXArve_o4V",
        "colab_type": "text"
      },
      "source": [
        "Source: [Regularization and Geometry](https://towardsdatascience.com/regularization-and-geometry-c69a2365de19) & [The Bias-Variance Tradeoff\n",
        "](https://towardsdatascience.com/the-bias-variance-tradeoff-8818f41e39e9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttcXa-1n_uOR",
        "colab_type": "text"
      },
      "source": [
        "**Benefits of regularization from a mathematical optimization point of view**\n",
        "\n",
        "* Machine learning is an optimization problem, where we try to minimize a cost function to find optimal values for our model's parameter. Some machine learning models, like neural networks, have non-convex cost functions. Stationary points in these cost functions are problematic because numerical optimization schemes (like gradient descent) can easily get stuck, leading to poor results.\n",
        "* Regularization can be used as a way of ‚convexifying‘ a non-convex cost function. The L2 regularizer, being an upward-facing convex function, can unflatten flat regions and curve up some stationary points without severely changing the minimum locations (e.g L2 regularized cost no longer has an issue with saddle points, as the region surrounding it has been curved upwards).\n",
        "* Regularization can also help with the optimization of convex machine learning problems, when is not invertible. For example the solution to the L2 regularized version of linear regression is given by is the regularization parameter, which can be set large enough so that becomes invertible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ-aw2an_xYB",
        "colab_type": "text"
      },
      "source": [
        "**Overfitting or Overtraining**\n",
        "\n",
        "* [Mehmet Suzen](https://www.linkedin.com/in/mehmetsuzen/): Regularisation does not prevent overfitting or even reduces. Regularisation originally developed for reducing ill-conditioning in inverse-problems. Regularisation, along with early-stopping, cross-validation and drop out, reduces and provides a reliable measure for generalisation error. Overfitting, on the other hand, is about the 'fit' , i.e., the model complexity. In deep nets, model complexity correlates with the full architecture and the activation functions. This is called 'overtraining' ([IEEE](https://ieeexplore.ieee.org/document/623200)).\n",
        "* Answer: if let it be, the learning process \"will tend to learn more and more complex functions as the number of iterations increases\". A model represented by a more complex function, thus having poor generalization, is an overfitting model. From the statement above, such a model can be prevented by stopping the learning early (among other techniques). Regularization is a process of applying those techniques. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHw6PP5XFgXo",
        "colab_type": "text"
      },
      "source": [
        "## **Vectornorm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5O1QrOXswPf",
        "colab_type": "text"
      },
      "source": [
        "Source: ['Getting started with Regression'](https://medium.com/@savannahar68/getting-started-with-regression-a39aca03b75f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75X3Z2teJNs-",
        "colab_type": "text"
      },
      "source": [
        "**Theoretical Foundation** \n",
        "\n",
        "Modify cost function J by adding 'preference' to certain parameter values:\n",
        "\n",
        "$J(\\underline{\\theta})=\\frac{1}{2}\\left(\\underline{y}-\\underline{\\theta} \\underline{X}^{T}\\right) \\cdot\\left(\\underline{y}-\\underline{\\theta} \\underline{X}^{T}\\right)^{T}+\\alpha \\theta \\theta^{T}$\n",
        "\n",
        "New solution (derive the same way) - problem is now well-posed for any degree:\n",
        "\n",
        "$\\underline{\\theta}=\\underline{y} \\underline{X}\\left(\\underline{X}^{T} \\underline{X}+\\alpha I\\right)^{-1}$\n",
        "\n",
        "* Shrinks parameters towards zero\n",
        "* Alpha large: we prefer small theta to small MSE\n",
        "* Regularization term is independent of the data: paying more attention reduces variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNJBr4ZHljUM",
        "colab_type": "text"
      },
      "source": [
        "**Lambda Value (λ)**\n",
        "\n",
        "* Lambda is a regularization hyperparameter\n",
        "* Reasonable values of lambda range between 0 and 0.1\n",
        "* L2 weight regularization with very small regularization hyperparameters such as (e.g. 0.0005 or 5 x 10^−4) may be a good starting point\n",
        "* Learn more: [Google Course: Regularization for Simplicity: Lambda](https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/lambda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlN8ilZEqQj7",
        "colab_type": "text"
      },
      "source": [
        "**L1 Regularization**\n",
        "\n",
        "<p>\n",
        "$\\sum_{i=1}^{n}\\left|u_{i}\\right|=\\sum_{i=1}^{n}\\left|y_{i}-b_{0}-b_{1} x_{i}\\right|$\n",
        "</p><br>\n",
        "\n",
        "\n",
        "$d_{1} \\equiv d_{\\mathrm{SAD}}:(x, y) \\mapsto\\|x-y\\|_{1}=\\sum_{i=1}^{n}\\left|x_{i}-y_{i}\\right|$\n",
        "\n",
        "* **Synonyms**: Lasso, Manhatten distance, least absolute deviations (LAD method), least absolute errors (LAE)\n",
        "* **Fun Fact**: L1 Regularization is analytical equivalent to Laplacean prior\n",
        "* **Summary**: Sum of the absolute weights. Gives sparse solutions, since it does not take all features. Lasso shrinks the less important feature’s coefficient to zero thus, removing some feature altogether. So, this works well for feature selection in case we have a huge number of features.\n",
        "* **Advantages**: less influenced by outliers (robust). Can shrink some coefficients to zero while lambda increases, performing variable selection. generates sparse feature vectors (Sparse: only very few entries in a matrix or vector is non-zero. L1-norm has property of producing many coefficients with zero values or very small values with few large coefficients). Sparse is sometimes good eg. in high dimensional classification problems. sparsity properties: calculation more computationally efficient.\n",
        "* **Disadvantages**: L1 regularization doesn’t easily work with all forms of training. gives a solution with more large residuals, and a lot of zeros in the solution.\n",
        "* **Use Cases**: if only a subset of features are correlated with the label, as in lasso model some coefficient can be shrunken to zero. very useful when you want to understand exactly which features are contributing to a decision. if you can ignore the ouliers in your dataset or you need them to be there. use L1 when constraints on feature extraction: easily avoid computing a lot of computationally expensive features  at the cost of some of the accuracy, since the L1-norm will give us a solution which has the weights for a large set of features set to zero (real-time detection or tracking of an object/face/material using a set of diverse handcrafted features with a large margin classifier like an SVM in a sliding window fashion - you'd probably want feature computation to be as fast as possible in this case).\n",
        "* **Bayesian**: L1 usually corresponds to setting a Laplacean prior: Some of the coefficients will shrink to zero: similar effect would be achieved in Bayesian linear regression using a Laplacian prior (strongly peaked at zero) on each of the beta coefficients.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHWJgeJqB4gy",
        "colab_type": "text"
      },
      "source": [
        "**Add L1 (Lasso) Penalty Term to Cost Function**\n",
        "\n",
        "$\\sum_{i=1}^{n}\\left(Y_{i}-\\sum_{j=1}^{p} X_{i j} \\beta_{j}\\right)^{2}+\\lambda \\sum_{j=1}^{p}\\left|\\beta_{j}\\right|$\n",
        "\n",
        "* Lasso Regression (Least Absolute Shrinkage and Selection Operator) adds “absolute value of magnitude” of coefficient as penalty term to the loss function.\n",
        "* If lambda is zero then we will get back OLS whereas very large value will make coefficients zero hence it will under-fit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZuDNlbKlWu4",
        "colab_type": "text"
      },
      "source": [
        "**L2 Regularization**\n",
        "\n",
        "<p>\n",
        "$\\sum_{i=1}^{n} u_{i}^{2}=\\sum_{i=1}^{n}\\left(y_{i}-b_{0}-b_{1} x_{i}\\right)^{2}$\n",
        "</p><br>\n",
        "\n",
        "* **Synonyms**: Weight Decay, Ridge Regression, KQ-Methode, kleinste Quadrate, [Tikhonov regularization](https://en.m.wikipedia.org/wiki/Tikhonov_regularization), Euclidean distance, least squares error (LSE)\n",
        "* **Fun Fact**: L2 Regularization is analytically equivalent to Gaussian prior\n",
        "* **Summary**: Sum of the squared weights. Is the most common type of regularization, also called simply “weight decay,” with values often on a logarithmic scale between 0 and 0.1, such as 0.1, 0.001, 0.0001, etc.\n",
        "* **Advantages**: Shrinks all the coefficient by the same proportions, but eliminates none. Leads to small distributed weights in neural networks. The L2 regularization heavily penalizes \"peaky\" weight vectors and prefers diffuse weight vectors. Empirically performs better than L1. The fit for L2 will be more precise than L1. Works with all forms of training. Smoother: fewer large residual values along with fewer very small residuals as well. L2-norm has analytical solution - allows the L2-norm solutions to be calculated computationally efficiently.\n",
        "* **Disadvantages**: Sensitive to outliers, since L2 wants all errors to be tiny and heavily penalizes anyone who doesn't obey. Computation heavy compared to the L1 norm. Doesn’t give you implicit feature selection.\n",
        "* **Use Cases**: Use ridge if all the features are correlated with the label, as the coefficients are never zero in ridge. \n",
        "* **Bayesian**: L2 similarly corresponds to Gaussian prior. As one moves away from zero, the probability for such a coefficient grows progressively smaller. The square loss penalty can be seen as putting a Gaussian prior on your weights.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYzCd1FUBnjV",
        "colab_type": "text"
      },
      "source": [
        "**Add L2 (Ridge) Penalty Term to Cost Function**\n",
        "\n",
        "$\\sum_{i=1}^{n}\\left(y_{i}-\\sum_{j=1}^{p} x_{i j} \\beta_{j}\\right)^{2}+\\lambda \\sum_{j=1}^{p} \\beta_{j}^{2}$\n",
        "\n",
        "* Ridge regression adds “squared magnitude” of coefficient as penalty term to the loss function.\n",
        "* If lambda is zero then you can imagine we get back OLS. However, if lambda is very large then it will add too much weight and it will lead to under-fitting. Having said that it’s important how lambda is chosen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ8UW9XnleoV",
        "colab_type": "text"
      },
      "source": [
        "**Elastic Net**\n",
        "\n",
        "* Method that linearly combines the L1 and L2 penalties of the lasso and ridge methods, at the \"only\" cost of introducing another hyperparameter to tune (see Hastie's paper on stanford.edu).\n",
        "* Overcome limitations of L1: in the \"large p, small n\" case (high-dimensional data with few examples), the LASSO selects at most n variables before it saturates. Also if there is a group of highly correlated variables, then the LASSO tends to select one variable from a group and ignore the others.\n",
        "* Solution in elastic net: add quadratic part to penalty (L2). quadratic penalty term makes the loss function strictly convex, and it therefore has a unique minimum.\n",
        "* Naive version of elastic net method finds an estimator in a two-stage procedure : first for each fixed λ2 it finds the ridge regression coefficients, and then does a LASSO type shrinkage. This kind of estimation incurs a double amount of shrinkage, which leads to increased bias and poor predictions. To improve the prediction performance, the authors rescale the coefficients of the naive version of elastic net by multiplying the estimated coefficients by (1+λ2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4foOVciWvULS",
        "colab_type": "text"
      },
      "source": [
        "**Special: Analytical Equivalence**\n",
        "\n",
        "Why is L2 Regularization is analytically equivalent to Gaussian prior?\n",
        "\n",
        "\n",
        "https://stats.stackexchange.com/questions/163388/why-is-the-l2-regularization-equivalent-to-gaussian-prior/163450#163450\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knt6wCob4xfj",
        "colab_type": "text"
      },
      "source": [
        "**Weight Regularization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvnac8AA41ac",
        "colab_type": "text"
      },
      "source": [
        "* Weight regularization was borrowed from penalized regression models in statistics. Neural networks learn a set of weights that best map inputs to outputs. \n",
        "* A network with large network weights can be a sign of an unstable network where small changes in the input can lead to large changes in the output. This can be a sign that the network has overfit the training dataset and will likely perform poorly when making predictions on new data. \n",
        "* A solution to this problem is to update the learning algorithm to encourage the network to keep the weights small. This is called weight regularization and it can be used as a general technique to reduce overfitting of the training dataset and improve the generalization of the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCXiItcr8fBF",
        "colab_type": "text"
      },
      "source": [
        "## **Dropout**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O51DzciO8gY4",
        "colab_type": "text"
      },
      "source": [
        "**What is it and how it works?**\n",
        "\n",
        "* Ziel: Overfitting vermeiden\n",
        "* Dropout forces a neural network to learn more robust features that are useful in conjunction with many different random subsets of the other neurons.\n",
        "* Dropout roughly doubles the number of iterations required to converge. However, training time for each epoch is less. With H hidden units, each of which can be dropped, we have 2^H possible models. In testing phase, the entire network is considered and each activation is reduced by a factor p.\n",
        "At test time the whole network is used (all units) but with scaled down weights. Mathematically this approximates ensemble averaging (using the geometric mean as average). Two papers that explain this much better are:\n",
        "* Hinton et al, [1207.0580] Improving neural networks by preventing co-adaptation of feature detectors, 2012 (probably the original paper on dropout)\n",
        "* Warde-Farley et al, [1312.6197] An empirical analysis of dropout in piecewise linear networks, 2014 (analyzes dropout specially for the case of using ReLU as activation function -arguably the most popular- , and checks the behavior of the geometric mean for ensemble averaging).\n",
        "* Andrew Ng: dropout is nothing more than an adaptive form of L2 regularization and that both methods have similar effects\n",
        "* The dropout will randomly mute some neurons in the neural network and we therefore have a sparse network which hugely decreases the possibility of overfitting. More importantly, the dropout will make the weights spread over the input features instead of focusing on some features. https://hackernoon.com/is-the-braess-paradox-related-to-dropout-in-neural-nets-270ecb97cdeb https://de.m.wikipedia.org/wiki/Dropout_(künstliches_neuronales_Netz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9kfZ8__8lq6",
        "colab_type": "text"
      },
      "source": [
        "**Is dropout outdated?**\n",
        "\n",
        "Neural Network:  Dropout\n",
        "\n",
        "https://medium.com/@bingobee01/a-review-of-dropout-as-applied-to-rnns-72e79ecd5b7b\n",
        "\n",
        "Don’t Use Dropout in Convolutional Networks\n",
        "https://towardsdatascience.com/dont-use-dropout-in-convolutional-networks-81486c823c16\n",
        "\n",
        "Instead you should insert batch normalization between your convolutions. This will regularize your model, as well as make your model more stable during training.\n",
        "\n",
        "First, dropout is generally less effective at regularizing convolutional layers: The reason? Since convolutional layers have few parameters, they need less regularization to begin with. Furthermore, because of the spatial relationships encoded in feature maps, activations can become highly correlated. This renders dropout ineffective. ([Source](https://www.reddit.com/r/MachineLearning/comments/5l3f1c/d_what_happened_to_dropout/))\n",
        "\n",
        "Second, what dropout is good at regularizing is becoming outdated: Large models like VGG16 included fully connected layers at the end of the network. For models like this, overfitting was combatted by including dropout between fully connected layers. Unfortunately, [recent architectures](https://arxiv.org/pdf/1512.03385.pdf) move away from this fully-connected block. By replacing dense layers with global average pooling, modern convnets have reduced model size while improving performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Zhb5RT8q-i",
        "colab_type": "text"
      },
      "source": [
        "**Use Dropout along with L1/L2 Regularization?**\n",
        "\n",
        "* You can, but it is still not clear whether using both at the same time acts synergistically or rather makes things more complicated for no net gain.\n",
        "* While ℓ 2 regularization is implemented with a clearly-defined penalty term, dropout requires a random process of “switching off” some units, which cannot be coherently expressed as a penalty term and therefore cannot be analyzed other than experimentally.\n",
        "* they both try to avoid the network’s over-reliance on spurious correlations, which are one of the consequences of overtraining that wreaks havoc with generalization. But more detailed research is necessary to determine whether and when they can “work together” or rather end up “fighting each other”. So far, it seems the results tend to vary in a case-by-case fashion. Using both can increase accuracy: https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf (Hinton paper 2014) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H4crpOcoMlSe"
      },
      "source": [
        "# **TensorFlow Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u151rKbBx8O",
        "colab_type": "text"
      },
      "source": [
        "**Load & Transform Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emC8moC8B0zF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6gKj7gjwQtw",
        "colab_type": "text"
      },
      "source": [
        "**Kernel Regularizer**\n",
        "\n",
        "*Regularizer function applied to the kernel weights matrix.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRsFyXXiwXYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernel_regularizer=tf.keras.regularizers.l1(l=0.0005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKn6U3WTwVRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernel_regularizer=tf.keras.regularizers.l2(l=0.0005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yVhv_57wbN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernel_regularizer=None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFJSTvHowfzn",
        "colab_type": "text"
      },
      "source": [
        "**Bias Regularizer**\n",
        "\n",
        "*Regularizer function applied to the bias vector*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7QXjYfzwsgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bias_regularizer=tf.keras.regularizers.l1(l=0.0005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHyBz0fwwvU_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bias_regularizer=tf.keras.regularizers.l2(l=0.0005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NrlNShswyvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bias_regularizer=None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDXotzf7wk4o",
        "colab_type": "text"
      },
      "source": [
        "**Activity Regularizer**\n",
        "\n",
        "*Regularizer function applied to the output of the layer (its \"activation\")*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO2jgyv5w30S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activity_regularizer=tf.keras.regularizers.l1(l=0.0005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXWwwJ5vw8HA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activity_regularizer=tf.keras.regularizers.l2(l=0.0005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFwslg_Bw_9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activity_regularizer=None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhvypXgZ_-44",
        "colab_type": "text"
      },
      "source": [
        "**Select Dropout Rate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkuqSCGXADpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout = 0.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtSoZCm6A8iN",
        "colab_type": "text"
      },
      "source": [
        "**Select Loss ([Cost Function](https://www.tensorflow.org/api_docs/python/tf/keras/losses/))**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2Ionbd8BCSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = 'sparse_categorical_crossentropy'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Deqvu9M1BZ4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTBTWNouBf4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = 'mae'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swQFNc3kCHqo",
        "colab_type": "text"
      },
      "source": [
        "**Select Activation function**\n",
        "\n",
        "* activation function als Dense parameter. \n",
        "* activation layer als eigener layer.\n",
        "* keras.activation = functions\n",
        "keras.layers = layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJwSFgUxCMus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = tf.keras.activations.tanh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU_dl5KjCQpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = tf.keras.activations.sigmoid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4bxye7mCTdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = tf.keras.layers.ReLU(max_value=None,\n",
        "                                 negative_slope=0,\n",
        "                                 threshold=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDYT0g12CWJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = tf.keras.layers.LeakyReLU(alpha=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCZw0RdMCZBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation = tf.keras.layers.Softmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHDipMKpCc_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Alternatively add default settings\n",
        "\n",
        "activation = 'relu'\n",
        "# activation = 'linear'\n",
        "# activation = 'sigmoid'\n",
        "# activation = 'tanh'\n",
        "# activation = 'softmax'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfVxKUnwXK8Z",
        "colab_type": "text"
      },
      "source": [
        "**Define Model & Run**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od2O5BqxEzRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install livelossplot --quiet\n",
        "from livelossplot import PlotLossesKerasTF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDEv6ZETl129",
        "colab_type": "code",
        "outputId": "b0592f06-8c5b-4dae-c196-8f63ed2faae4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu', \n",
        "                                kernel_regularizer=kernel_regularizer, \n",
        "                                bias_regularizer=bias_regularizer, \n",
        "                                activity_regularizer=activity_regularizer))\n",
        "model.add(tf.keras.layers.Dropout(dropout))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam', \n",
        "              loss=loss, \n",
        "              metrics=['accuracy'])\n",
        "model.fit(x=x_train, \n",
        "          y=y_train, \n",
        "          epochs=20, \n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[PlotLossesKerasTF()],\n",
        "          verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy\n",
            "\ttraining         \t (min:    0.095, max:    0.811, cur:    0.099)\n",
            "\tvalidation       \t (min:    0.030, max:    0.822, cur:    0.098)\n",
            "Loss\n",
            "\ttraining         \t (min:    0.804, max:    4.424, cur:    4.420)\n",
            "\tvalidation       \t (min:    0.766, max:    4.420, cur:    4.420)\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1875/1875 [==============================] - 8s 4ms/step - loss: 4.4201 - accuracy: 0.0992 - val_loss: 4.4201 - val_accuracy: 0.0978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0d88dd27b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    }
  ]
}