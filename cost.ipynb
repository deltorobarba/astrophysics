{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cost.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5jK34bCZV5L6",
        "gOhC8gWddYz_",
        "CXBpZ1M8zNi5",
        "oAf4sna4hQMg",
        "deNJWcC3hUSX",
        "jtmj4FOHq6ht",
        "ZrVKpOHIzWHG",
        "AmqQ5UuaFxPE",
        "MrnqfFqHXRuR",
        "VVJqZBKKTJcX",
        "zy6HK9uZG4NF",
        "MUL3Y97WG7n6",
        "M9V8uoymHN3M",
        "i7utPdOPHfya",
        "-bRPT7j2Hjpr",
        "bB89shlnkga3",
        "qPHAqSSzGRWu",
        "ZtrplweMXpx0",
        "zwF3TGA4HyGe",
        "iAuSM7rYi0nW",
        "TSRliOMMiHC-",
        "BmZFI8hdhy1u",
        "rYLc2b-qsm8N",
        "-59nC3Yih3Gm",
        "tvctBykzhmbB",
        "ZT8FPvZ3hi1N",
        "gVUgUeHIYPXm",
        "o2zuQpPO6vNn",
        "ceX3klubVpBn",
        "rCZf8vrBmGux",
        "N3jTMrMFRcgH",
        "LxKmU_MLUICH",
        "YfVxKUnwXK8Z"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deltorobarba/machinelearning/blob/master/cost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjNmcYpFuFTY"
      },
      "source": [
        "# **Cost (Loss) Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wxrDRida0pp",
        "outputId": "0187b2f2-187b-4d69-e997-7450fd330e49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install livelossplot --quiet\n",
        "from livelossplot import PlotLossesKerasTF\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jK34bCZV5L6"
      },
      "source": [
        "### **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOhC8gWddYz_"
      },
      "source": [
        "##### **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhfmrX5NyKmF"
      },
      "source": [
        "**Really good intro by Brandon Rohrer**: https://youtu.be/fr7dfyfB7mI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSldNKjE4BZa"
      },
      "source": [
        "Cost, loss, risk or error function\n",
        "\n",
        "Properties of ideal Cost functions:\n",
        "\n",
        "* smooth, \n",
        "* continuous, \n",
        "* symmetric (but i.e. Non-symmetric losses: e.g., for spam classification)\n",
        "* differentials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKwGKCZj3mhZ"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Loss_function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDL3lOvAnyOp"
      },
      "source": [
        "https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L9Rza0hlnNE"
      },
      "source": [
        "$\\min _{W}\\left\\{L(W):=\\frac{1}{m} \\sum_{i=1}^{m} \\ell\\left(W ; x_{i}, y_{i}\\right)+\\lambda r(W)\\right\\}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtSoZCm6A8iN"
      },
      "source": [
        "Complete list of [Loss / Cost Functions in TF](https://www.tensorflow.org/api_docs/python/tf/keras/losses/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOaMQSLdJk2u"
      },
      "source": [
        "https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0\n",
        "\n",
        "https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d\n",
        "\n",
        "https://stackoverflow.com/questions/45648351/what-is-difference-between-loss-function-and-rmse-in-machine-learning\n",
        "\n",
        "https://medium.com/@phuctrt/loss-functions-why-what-where-or-when-189815343d3f\n",
        "\n",
        "https://towardsdatascience.com/what-is-loss-function-1e2605aeb904\n",
        "\n",
        "https://datascience.stackexchange.com/questions/10188/why-do-cost-functions-use-the-square-error\n",
        "\n",
        "https://towardsdatascience.com/coding-deep-learning-for-beginners-linear-regression-part-2-cost-function-49545303d29f\n",
        "\n",
        "https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#kullback-leibler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkbfamvD4rHK"
      },
      "source": [
        "https://towardsdatascience.com/https-medium-com-chayankathuria-regression-why-mean-square-error-a8cad2a1c96f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQwg5vHW6Nuu"
      },
      "source": [
        "http://www.cs.cornell.edu/courses/cs4780/2015fa/web/lecturenotes/lecturenote10.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkEHOnK4ZwKY"
      },
      "source": [
        "**Overview: Similarity Learning & Distance Metric Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ozfgr776X5mk"
      },
      "source": [
        "* Ähnlichkeitsmaße werden für nominal oder ordinal skalierte Variablen genutzt\n",
        "\n",
        "* Distanzmaße werden für metrisch skalierte Variablen (d. h. für Intervall- und Verhältnisskala) genutzt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-LwPZQAWR1B"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Similarity_learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L23wfOaoYbkL"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erSCYUrvYFVx"
      },
      "source": [
        "https://cs.gmu.edu/~carlotta/teaching/CS775-s10/readings/LearningMetrics.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXUWzO4vWIuI"
      },
      "source": [
        "**Similarity learning** is closely related to distance metric learning. Metric learning is the task of learning a distance function over objects. A metric or distance function has to obey four axioms: non-negativity, identity of indiscernibles, symmetry and subadditivity (or the triangle inequality). **In practice, metric learning algorithms ignore the condition of identity of indiscernibles and learn a pseudo-metric.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5hje3wBYWv6"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Similarity_learning#Metric_learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIfdyn29WxlU"
      },
      "source": [
        "**Similarity Measure** In statistics and related fields, a similarity measure or similarity function is a real-valued function that quantifies the similarity between two objects.\n",
        "\n",
        "Although no single definition of a similarity measure exists, usually such measures are in some sense the inverse of distance metrics: they take on large values for similar objects and either zero or a negative value for very dissimilar objects.\n",
        "\n",
        "Cosine similarity is a commonly used similarity measure for real-valued vectors, used in (among other fields) information retrieval to score the similarity of documents in the vector space model. In machine learning, common kernel functions such as the RBF kernel can be viewed as similarity functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsjXQNXVW-QJ"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Similarity_measure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxEGxB4vXmU8"
      },
      "source": [
        "**Distance Metric Learning & Distance Measures**\n",
        "\n",
        "Distanzmaße werden für metrisch skalierte Variablen (d. h. für Intervall- und Verhältnisskala) genutzt.\n",
        "https://cs.gmu.edu/~carlotta/teaching/CS775-s10/readings/LearningMetrics.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXBpZ1M8zNi5"
      },
      "source": [
        "##### **Similarity Learning & Similarity Measures**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9rjjHRPe3Lc"
      },
      "source": [
        "*Ähnlichkeitsmaße werden für nominal oder ordinal skalierte Variablen genutzt*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxTnwP8u5YD2"
      },
      "source": [
        "**Overview**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdhCXyrkgLB0"
      },
      "source": [
        "In der Statistik, insbesondere der Multivariaten Statistik, interessiert man sich für die Messung der Ähnlichkeit zwischen verschiedenen Objekten und definiert dazu Ähnlichkeits- und Distanzmaße. **Es handelt sich dabei nicht um Maße im mathematischen Sinn**, der Begriff bezieht sich ausschließlich auf die Messung einer bestimmten Größe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez_pHYiXgPcu"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Ähnlichkeitsanalyse\n",
        "\n",
        "https://de.m.wikipedia.org/wiki/Distanzfunktion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu_3BJSrgnoi"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Distance_(graph_theory)\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAf4sna4hQMg"
      },
      "source": [
        "**Jaccard-Koeffizient**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYu5h2eLhR-N"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Jaccard-Koeffizient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deNJWcC3hUSX"
      },
      "source": [
        "**Yules Index**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGeN7197hXMA"
      },
      "source": [
        "Yules Index ist ein statistischer Messwert, der die Uniformität oder Diversität des Wortschatzes bestimmt. Er wurde vom schottischen Statistiker George Udny Yule entwickelt und misst die Wahrscheinlichkeit, mit der zwei zufällig ausgewählte Wörter eines Textes identisch sind – und zwar weitgehend unabhängig vom Umfang des Textes.Diesen Index hat Herdan aufgegriffen und weiterentwickelt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-YLY8Q4hZmk"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Yules_Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtmj4FOHq6ht"
      },
      "source": [
        "**Pearson Korrelationskoeffizient**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W0A6wTO22MZ"
      },
      "source": [
        "https://de.m.wikipedia.org/wiki/Korrelationskoeffizient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrVKpOHIzWHG"
      },
      "source": [
        "##### **Distance Metric Learning & Distance Measures (& Divergence)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au-5oyMJfCCd"
      },
      "source": [
        "*Distanzmaße werden für metrisch skalierte Variablen (d. h. für Intervall- und Verhältnisskala) genutzt.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UfyDobq5cXp"
      },
      "source": [
        "**Overview**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AepjAni7x_g9"
      },
      "source": [
        "**Exkurs**: [Distance measures](https://en.m.wikipedia.org/wiki/Distance_measures_(cosmology)) in cosmology are complicated by the [expansion of the universe](https://en.m.wikipedia.org/wiki/Expansion_of_the_universe), and by effects described by the [theory of relativity](https://en.m.wikipedia.org/wiki/Theory_of_relativity) such as [length contraction](https://en.m.wikipedia.org/wiki/Length_contraction) of moving objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfT-0QZZm8VW"
      },
      "source": [
        "**Properties of a Divergence, Distance & Metric**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HScpxU3gCkB"
      },
      "source": [
        "1. $d(x, y) \\geq 0 \\quad$ (**non-negativity**)\n",
        "\n",
        "2. $d(x, y)=0$ if and only if $x=y$ (**identity of indiscernibles**. Note that condition 1 and 2 together produce **positive definiteness**)\n",
        "\n",
        "3. $d(x, y)=d(y, x)$ (**symmetry**)\n",
        "\n",
        "4. $d(x, z) \\leq d(x, y)+d(y, z)$ (**subadditivity / triangle inequality**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGoqrlNKgEo8"
      },
      "source": [
        "* **Divergence** fullfills property of positive definiteness (1 + 2)\n",
        "\n",
        "* **Distance** fullfills property of positive definiteness and symmetrie (1 + 2+ 3)\n",
        "\n",
        "* **Metric** fullfills property of positive definiteness, symmetrie and triangle inequality (1 + 2 + 3 + 4)\n",
        "\n",
        "* Metric Space: Together with the set, a metric makes up a metric space.\n",
        "\n",
        "* (*Jede Norm induziert eine Metrik, aber nicht jede Metrik wird durch eine Norm induziert*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuiVX3avwKmS"
      },
      "source": [
        "**Distance function vs. Distance Metric**\n",
        "\n",
        "• Distance Metric:\n",
        "▫ Satisfy non-negativity, symmetry and triangle\n",
        "inequation\n",
        "\n",
        "• Distance Function:\n",
        "▫ May not satisfy one or more requirements for\n",
        "distance metric\n",
        "▫ More general than distance metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLWj7je0wMiG"
      },
      "source": [
        "https://www.cs.utexas.edu/~grauman/courses/spring2008/slides/Learning_distance_functions.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD8HZ1Q1giLt"
      },
      "source": [
        "**Divergence & 'Statistical Distance'**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqH4VD9zgjtm"
      },
      "source": [
        "In statistics and information geometry, divergence or a contrast function is a function which establishes the **\"distance\" of one probability distribution to the other** on a statistical manifold. In statistics, probability theory, and information theory, **a statistical distance** quantifies the distance between two statistical objects, which can be\n",
        "\n",
        "* two random variables, or \n",
        "* two probability distributions or \n",
        "* two samples, or \n",
        "* the distance can be between an individual sample point and a population or \n",
        "* a wider sample of points.\n",
        "\n",
        "A distance between populations can be interpreted as **measuring the distance between two probability distributions** and hence they are essentially measures of distances between probability measures. \n",
        "\n",
        "* Where statistical distance measures relate to the differences between random variables, these may have statistical dependence, and hence these distances are not directly related to measures of distances between probability measures. \n",
        "\n",
        "* Again, a measure of distance between random variables may **relate to the extent of dependence between them, rather than to their individual values.**\n",
        "\n",
        "**<u>Many statistical distances are not metrics</u>** (and some types are regerred to as divergence), because they lack one or more properties of proper metrics. For example, \n",
        "\n",
        "* [pseudometrics](https://en.m.wikipedia.org/wiki/Pseudometric_space) violate the \"positive definiteness\" (alternatively, \"identity of indescernibles\") property (1 & 2 above); \n",
        "\n",
        "* [quasimetrics](https://en.m.wikipedia.org/wiki/Metric_(mathematics)#Quasimetrics) violate the symmetry property (3); and semimetrics violate the triangle inequality (4). \n",
        "\n",
        "* Statistical distances that satisfy (1) and (2) are referred to as divergences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y2GffaHgpYZ"
      },
      "source": [
        "* In statistics and information geometry, there are many kinds of statistical distances, notably divergences, especially Bregman divergences and f-divergences. These include and generalize many of the notions of \"difference between two probability distributions\", and allow them to be studied geometrically, as statistical manifolds. \n",
        "\n",
        "* The **most elementary** is the **squared Euclidean distance**, which forms the basis of least squares; this is the most basic Bregman divergence (-> is this a metric then ???)\n",
        "\n",
        "* The **most important** in information theory is the relative entropy (**Kullback–Leibler divergence**), which allows one to analogously study maximum likelihood estimation geometrically; this is the most basic f-divergence, and is also a Bregman divergence (and is the only divergence that is both). \n",
        "\n",
        "* Statistical manifolds corresponding to Bregman divergences are flat manifolds in the corresponding geometry, allowing an analog of the Pythagorean theorem (which is traditionally true for squared Euclidean distance) to be used for linear inverse problems in inference by optimization theory.\n",
        "\n",
        "* Other important statistical distances include the Mahalanobis distance, the energy distance, and many others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_6VnI9tgsJe"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Information_geometry\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Statistical_distance\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Divergence_(statistics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15ok6ieBgYkv"
      },
      "source": [
        "**Exkurs: Meaning of 'no symmetry' in divergences**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFglF2QTgaEc"
      },
      "source": [
        "* The Kullback-Leibler divergence is not symmetric. Roughly speaking, it's because you should think of the two arguments of the KL divergence as different kinds of things: the first argument is empirical data, and the second argument is a model you're comparing the data to. \n",
        "\n",
        "* Take a bunch of independent random variables $X_{1}, \\ldots, X_{n}$ whose possible values lie in a finite set.\n",
        "\n",
        "* Say these variables are identically distributed, with $\\operatorname{Pr}\\left(X_{i}=x\\right)=p_{x}$. Let $F_{n, x}$ be the number of variables whose values are equal to $x$. The list $F_{n}$ is a random variable, often called the \"empirical frequency distribution\" of the $X_{i} .$ What does $F_{n}$ look like when $n$ is very large?\n",
        "\n",
        "* More specifically, let's try to estimate the probabilities of the possible values of $F_{n} .$ since the set of possible values is different for different $n$, take a sequence of frequency distributions $f_{1}, f_{2}, f_{3}, \\ldots$ approaching a fixed frequency distribution $f$. It turns out $^{* *}$ that\n",
        "\n",
        "> $\\lim _{n \\rightarrow \\infty} \\frac{1}{n} \\ln \\operatorname{Pr}\\left(F_{n}=f_{n}\\right)=-\\mathrm{KL}(f, p)$ \n",
        "\n",
        "* In other words, the Kullback-Leibler divergence of $f$ from $p$ lets you estimate the probability of getting an empirical frequency distribution close to $f$ from a large number of independent random variables with distribution $p$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEE5LAAygcf-"
      },
      "source": [
        "Excellent article \"Information Theory, Relative Entropy and Statistics,\" by [François Bavaud](https://link.springer.com/chapter/10.1007/978-3-642-00659-3_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1geLcP8Pgut9"
      },
      "source": [
        "List of Distances Types\n",
        "\n",
        "'braycurtis': hdbscan.dist_metrics.BrayCurtisDistance\n",
        "\n",
        "'canberra': hdbscan.dist_metrics.CanberraDistance\n",
        "\n",
        "'chebyshev': hdbscan.dist_metrics.ChebyshevDistance\n",
        "\n",
        "'cityblock': hdbscan.dist_metrics.ManhattanDistance\n",
        "\n",
        "'dice': hdbscan.dist_metrics.DiceDistance\n",
        "\n",
        "'euclidean': hdbscan.dist_metrics.EuclideanDistance\n",
        "\n",
        "'hamming': hdbscan.dist_metrics.HammingDistance\n",
        "\n",
        "'haversine': hdbscan.dist_metrics.HaversineDistance\n",
        "\n",
        "'infinity': hdbscan.dist_metrics.ChebyshevDistance\n",
        "\n",
        "'jaccard': hdbscan.dist_metrics.JaccardDistance\n",
        "\n",
        "'kulsinski': hdbscan.dist_metrics.KulsinskiDistance\n",
        "\n",
        "'l1': hdbscan.dist_metrics.ManhattanDistance\n",
        "\n",
        "'l2': hdbscan.dist_metrics.EuclideanDistance\n",
        "\n",
        "'mahalanobis': hdbscan.dist_metrics.MahalanobisDistance\n",
        "\n",
        "'manhattan': hdbscan.dist_metrics.ManhattanDistance\n",
        "\n",
        "'matching': hdbscan.dist_metrics.MatchingDistance\n",
        "\n",
        "'minkowski': hdbscan.dist_metrics.MinkowskiDistance\n",
        "\n",
        "'p': hdbscan.dist_metrics.MinkowskiDistance\n",
        "\n",
        "'pyfunc': hdbscan.dist_metrics.PyFuncDistance\n",
        "\n",
        "'rogerstanimoto': hdbscan.dist_metrics.RogersTanimotoDistance\n",
        "\n",
        "'russellrao': hdbscan.dist_metrics.RussellRaoDistance\n",
        "\n",
        "'seuclidean': hdbscan.dist_metrics.SEuclideanDistance\n",
        "\n",
        "'sokalmichener': hdbscan.dist_metrics.SokalMichenerDistance\n",
        "\n",
        "'sokalsneath': hdbscan.dist_metrics.SokalSneathDistance\n",
        "\n",
        "'wminkowski': hdbscan.dist_metrics.WMinkowskiDistance\n",
        "\n",
        "https://hdbscan.readthedocs.io/en/latest/basic_hdbscan.html\n",
        "\n",
        "https://reference.wolfram.com/language/guide/DistanceAndSimilarityMeasures.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmqQ5UuaFxPE"
      },
      "source": [
        "### **Regression & Forecasting** (mostly distance-based)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrnqfFqHXRuR"
      },
      "source": [
        "##### **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Tv81yCGpTRK"
      },
      "source": [
        "![xx](https://raw.githubusercontent.com/deltorobarba/machinelearning/master/regression_loss.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqK34fPyXYSR"
      },
      "source": [
        "Loss functions that belong to the category \"distance-based\" are primarily used in regression problems. They utilize the numeric difference between the predicted output and the true target as a proxy variable to quantify the quality of individual predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO5Zwg69Xagm"
      },
      "source": [
        "http://juliaml.github.io/LossFunctions.jl/stable/losses/distance/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay6hGBmgcGgw"
      },
      "source": [
        "**(Linear) Least Squares**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu_NEtLMdK0u"
      },
      "source": [
        "* Least Squares: Deren Parameter werden so bestimmt, dass die Summe der Abweichungsquadrate e der Beobachtungen y von den Werten der Funktion minimiert wird.\n",
        "\n",
        "* Da die Kleinste-Quadrate-Schätzung die Residuenquadratsumme minimiert, ist es dasjenige Schätzverfahren, welches das [Bestimmtheitsmaß](https://de.wikipedia.org/wiki/Bestimmtheitsmaß) maximiert.\n",
        "\n",
        "* Das Bestimmtheitsmaß der Regression, auch empirisches Bestimmtheitsmaß, ist eine dimensionslose Maßzahl die den Anteil der Variabilität in den Messwerten der abhängigen Variablen ausdrückt, der durch das lineare Modell „erklärt“ wird. Mithilfe dieser Definition können die Extremwerte für das Bestimmtheitsmaß aufgezeigt werden. Für das\n",
        "Bestimmtheitsmaß gilt, dass es umso năher am Wert 1 ist, je kleiner die Residuenquadratsumme ist. Es wird maximal gleich 1 wenn $\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}=0$ ist, also alle Residuen null sind. In diesem Fall ist die Anpassung an die Daten perfekt, was bedeutet, dass für jede Beobachtung $y_{i}=\\hat{y}_{i}$ ist.\n",
        "\n",
        "* [Least Squares](https://en.wikipedia.org/wiki/Least_squares) / [Methode der kleinsten Quadrate](https://de.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate) & [Linear Least Squares](https://en.wikipedia.org/wiki/Linear_least_squares)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpN5nnfyc3cD"
      },
      "source": [
        "**Gauss–Markov theorem (BLUE)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o91f4dHOc6Nh"
      },
      "source": [
        "*  states that the ordinary least squares (OLS) estimator has the lowest sampling variance within the class of linear unbiased estimators, **if the errors in the linear regression model are uncorrelated, have equal variances and expectation value of zero**.\n",
        "\n",
        "* stellt eine theoretische Rechtfertigung der Methode der kleinsten Quadrate dar\n",
        "\n",
        "* Der Satz besagt, dass in einem linearen Regressionsmodell, in dem die **Störgrößen (error term) einen Erwartungswert von null und eine konstante Varianz haben sowie unkorreliert sind** (Annahmen des klassischen linearen Regressionsmodells), der Kleinste-Quadrate-Schätzer – vorausgesetzt er existiert – ein bester linearer erwartungstreuer Schätzer ist (englisch Best Linear Unbiased Estimator, kurz: BLUE). \n",
        "\n",
        "* Hierbei bedeutet der „beste“, dass er – innerhalb der Klasse der linearen erwartungstreuen Schätzer – die „kleinste“ Kovarianzmatrix aufweist und somit minimalvariant ist. Die Störgrößen müssen nicht notwendigerweise normalverteilt sein. Sie müssen im Fall der verallgemeinerten Kleinste-Quadrate-Schätzung auch nicht unabhängig und identisch verteilt sein.\n",
        "\n",
        "The Gauss-Markov assumptions concern the set of error random variables, $\\varepsilon_{i}:$\n",
        "\n",
        "1. They have mean zero: $\\mathrm{E}\\left[\\varepsilon_{i}\\right]=0$ \n",
        "\n",
        "2. They are homoscedastic, that is all have the same finite variance: $\\operatorname{Var}\\left(\\varepsilon_{i}\\right)=\\sigma^{2}<\\infty$ for all $i$,\n",
        "3. Distinct error terms are uncorrelated: $\\operatorname{Cov}\\left(\\varepsilon_{i}, \\varepsilon_{j}\\right)=0, \\forall i \\neq j$.\n",
        "\n",
        "A linear estimator of $\\beta_{j}$ is a linear combination $\\widehat{\\beta}_{j}=c_{1 j} y_{1}+\\cdots+c_{n j} y_{n}$\n",
        "\n",
        "* The errors do not need to be normal, nor do they need to be independent and identically distributed (only uncorrelated with mean zero and homoscedastic with finite variance). \n",
        "\n",
        "* The requirement that the estimator be unbiased cannot be dropped, since biased estimators exist with lower variance. See, for example, the [James–Stein estimator](https://en.wikipedia.org/wiki/James–Stein_estimator) (which also drops linearity), [ridge regression(Tikhonov_regularization)](https://en.wikipedia.org/wiki/Tikhonov_regularization), or simply any [degenerate estimator](https://en.wikipedia.org/wiki/Degenerate_distribution).\n",
        "\n",
        "* https://en.wikipedia.org/wiki/Gauss–Markov_theorem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOS5wYbacIvh"
      },
      "source": [
        "**Ordinary Least Squares (OLS)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpMvpZWbbvZb"
      },
      "source": [
        "* Ordinary least squares is a type of linear least squares method for estimating the unknown parameters in a linear regression model.  \n",
        "\n",
        "* “Ordinary Least Squares” (OLS) method is used to find the best line intercept (b) and the slope (m). [in y = mx + b, m is the slope and b the intercept]\n",
        "\n",
        "\n",
        "> $m=\\frac{\\sum\\left(x_{i}-\\bar{x}\\right)\\left(y_{i}-\\bar{y}\\right)}{\\sum\\left(x_{i}-\\bar{x}\\right)^{2}}$\n",
        "\n",
        "> $b=\\bar{y}-m * \\bar{x}$\n",
        "\n",
        "* In other words → with OLS Linear Regression the goal is to find the line (or hyperplane) that minimizes the vertical offsets. We define the best-fitting line as the line that minimizes the sum of squared errors (SSE) or mean squared error (MSE) between our target variable (y) and our predicted output over all samples i in our dataset of size n.\n",
        "\n",
        "* OLS chooses the parameters of a linear function of a set of explanatory variables by the principle of least squares: minimizing the sum of the squares of the differences between the observed dependent variable (values of the variable being observed) in the given dataset and those predicted by the linear function\n",
        "\n",
        "* The OLS method minimizes the sum of squared residuals, and leads to a [closed-form expression](https://en.wikipedia.org/wiki/Closed-form_expression) for the estimated value of the unknown parameter vector β.\n",
        "\n",
        "* It is important to point out though that OLS method will work for a univariate dataset (ie., single independent variables and single dependent variables). Multivariate dataset contains a single independent variables set and multiple dependent variables sets, requiring a machine learning algorithm called “Gradient Descent”.\n",
        "\n",
        "* [Wiki](https://en.wikipedia.org/wiki/Ordinary_least_squares) & [Medium](https://medium.com/@jorgesleonel/linear-regression-307937441a8b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPkDdIB-cNzm"
      },
      "source": [
        "**Weighted Least Squares (WLS)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lnnftv7dCZi"
      },
      "source": [
        "* are used when heteroscedasticity is present in the error terms of the model.\n",
        "* https://en.wikipedia.org/wiki/Weighted_least_squares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXEOjvoPcTWG"
      },
      "source": [
        "**Generalized Least Squares (GLS)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdLHRcoPc_2m"
      },
      "source": [
        "* is an extension of the OLS method, that **allows efficient estimation of β when either heteroscedasticity, or correlations, or both are present among the error terms of the model**, as long as the form of heteroscedasticity and correlation is known independently of the data. \n",
        "\n",
        "* To handle heteroscedasticity when the error terms are uncorrelated with each other, GLS minimizes a weighted analogue to the sum of squared residuals from OLS regression, where the weight for the ith case is inversely proportional to var(εi). This special case of GLS is called \"weighted least squares\". \n",
        "\n",
        "* https://en.wikipedia.org/wiki/Generalized_least_squares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVJqZBKKTJcX"
      },
      "source": [
        "##### **SE, SAE & SSE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSGJLSQ_TbBo"
      },
      "source": [
        "**Sum of Errors (SE)** the difference in the predicted value and the actual value.\n",
        "\n",
        "$\\mathbf{L}=\\Sigma(\\hat{Y}-Y)$\n",
        "\n",
        "Errors terms cancel each other out. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzYBf5MKTvi-"
      },
      "source": [
        "**Sum of Absolute Errors (SAE)** takes the absolute values of the errors for all iterations.\n",
        "\n",
        "$\\mathbf{L}=\\Sigma (|\\hat{Y}-Y|)$\n",
        "\n",
        "This loss function is not differentiable at 0. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jN34GYcUXz9"
      },
      "source": [
        "**Sum of Squared Errors (SSE)** is differentiable at all points and gives non-negative errors. But you could argue that why cannot we go for higher orders like 4th order or so. Then what if we consider to take 4th order loss function, which would look like:\n",
        "\n",
        "$\\mathbf{L}=\\left[\\Sigma(\\hat{Y}-Y)^{2}\\right]$\n",
        "\n",
        "The gradient of the loss function will vanish at minima & maxima. And the error will grow with the sample size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1r2VOUPXMmq"
      },
      "source": [
        "![xxx](https://raw.githubusercontent.com/deltorobarba/machinelearning/master/sumoferrors.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IzwoGPnZRbx"
      },
      "source": [
        "* Minimizing Sum of Squared Errors / SSE ([wiki](https://de.m.wikipedia.org/wiki/Residuenquadratsumme) and [medium](https://medium.com/@dustinstansbury/cutting-your-losses-loss-functions-the-sum-of-squared-errors-loss-4c467d52a511)).  We can think of the SSE loss as the (unscaled) variance of the model errors. \n",
        "* Therefore **minimizing the SEE loss is equivalent to minimizing the variance of the model residuals**. For this reason, the sum of squares loss is often referred to as the Residual Sum of Squares error (RSS) for linear models. We can think of minimizing the SSE loss as maximizing the covariance between the real outputs and those predicted by the model.\n",
        "* Ideal when distribution of residuals in normal: the [Gauss-Markov theorem](https://en.wikipedia.org/wiki/Gauss–Markov_theorem) states that if errors of a linear function are distributed Normally about the mean of the line, then the LSS solution gives the [best unbiased estimator](https://en.wikipedia.org/wiki/Bias_of_an_estimator) for the parameters .\n",
        "* Problem: Because each error is squared, any outliers in the dataset can dominate the parameter estimation process. For this reason, the LSS loss is said to lack robustness. Therefore preprocessing of the the dataset (i.e. removing or thresholding outlier values) may be necessary when using the LSS loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy6HK9uZG4NF"
      },
      "source": [
        "##### **MSE (L2) & RMSE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhwL39dIoAR5"
      },
      "source": [
        "**Squared Euclidean Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mHVqq2toEeh"
      },
      "source": [
        "* Squared Euclidean distance is of central importance in estimating parameters of statistical models, where it is used in the method of least squares, a standard approach to regression analysis. \n",
        "\n",
        "* The corresponding loss function is the squared error loss (SEL), and places progressively greater weight on larger errors. The corresponding risk function (expected loss) is mean squared error (MSE).\n",
        "\n",
        "* **Squared Euclidean distance is not a metric**, as it does not satisfy the triangle inequality. However, **it is a more general notion of distance, namely a divergence** (specifically a Bregman divergence), and can be used as a statistical distance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjoet-ldoMGv"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Euclidean_distance#Squared_Euclidean_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avYjKTJLgym1"
      },
      "source": [
        "![bb](https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/3d-function-2.svg/566px-3d-function-2.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzQChHhag2sJ"
      },
      "source": [
        "*A paraboloid, the graph of squared Euclidean distance from the origin*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l37ol-1xg6yd"
      },
      "source": [
        "![bb](https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/3d-function-5.svg/566px-3d-function-5.svg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbkxPutkg_cF"
      },
      "source": [
        "*A cone, the graph of Euclidean distance from the origin in the plane*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH6KPYDJfgjs"
      },
      "source": [
        "**Mean Squared Error**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a9PTm_aGIaH"
      },
      "source": [
        "loss = 'mse'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roP8IXhWVyqD"
      },
      "source": [
        "$\\mathrm{MSE}={\\frac{1}{n} \\sum_{j=1}^{n}\\left(y_{j}-\\hat{y}_{j}\\right)^{2}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlQ3pcb3JrHK"
      },
      "source": [
        "* Mean Squared Error (L2 or Quadratic Loss). Error decreases as we increase our sample data as the distribution of our data becomes more and more narrower (referring to normal distribution). The more data we have, the less is the error.\n",
        "* Can range from 0 to ∞ and are indifferent to the direction of errors. It is  negatively-oriented scores, which means lower values are better. It is always non – negative and values close to zero are better. The MSE is the second moment of the error (about the origin) and thus incorporates both the variance of the estimator and its bias.\n",
        "* Problem: Sensitive to outliers and the order of loss is more than that of the data. As my data is of order 1 and the loss function, MSE has an order of 2 (squared). So we cannot directly correlate data with the error. \n",
        "* [Wikipedia](https://de.m.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wutQa1GTppX9",
        "outputId": "9815f758-caab-4428-f857-d6548773fc0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# MSE loss function\n",
        "def mse_loss(y_pred, y_true):\n",
        "    squared_error = (y_pred - y_true) ** 2\n",
        "    sum_squared_error = np.sum(squared_error)\n",
        "    loss = sum_squared_error / y_true.size\n",
        "    return loss\n",
        "    \n",
        "# Plotting\n",
        "x_vals = np.arange(-20, 20, 0.01)\n",
        "y_vals = np.square(x_vals)\n",
        "\n",
        "sns.set(rc={'figure.figsize':(10, 5), \"lines.linewidth\": 1.0})\n",
        "# plt.plot(x_vals, y_vals, \"blue\")\n",
        "plt.plot(x_vals, y_vals)\n",
        "plt.grid(True, which=\"major\")\n",
        "plt.axhline(y=0, color='red', linestyle='--', linewidth=1.0)\n",
        "plt.axvline(x=0, color='red', linestyle='--', linewidth=1.0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRmCUqgTgkLt"
      },
      "source": [
        "def mse(predictions, targets):\n",
        "    # Retrieving number of samples in dataset\n",
        "    samples_num = len(predictions)\n",
        "    \n",
        "    # Summing square differences between predicted and expected values\n",
        "    accumulated_error = 0.0\n",
        "    for prediction, target in zip(predictions, targets):\n",
        "        accumulated_error += (prediction - target)**2\n",
        "        \n",
        "    # Calculating mean and dividing by 2\n",
        "    mae_error = (1.0 / (2*samples_num)) * accumulated_error\n",
        "    \n",
        "    return mae_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bYdhcdnwE66"
      },
      "source": [
        "def MSE(y_predicted, y):\n",
        "  squared_error = (y_predicted - y) ** 2\n",
        "  sum_squared_error = np.sum(squared_error)\n",
        "  mse = sum_squared_error / y.size\n",
        "  return(mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iztigyeof0qt"
      },
      "source": [
        "**Mean Squared Logarithmic Error (MSLR)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVndjV5xf5tY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0fMbvjdf57W"
      },
      "source": [
        "* Mean Squared Logarithmic Error\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/losses/MeanSquaredLogarithmicError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1FZ-FjIfW1T"
      },
      "source": [
        "**RMSE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cE7mWb3fYeP"
      },
      "source": [
        "tf.keras.metrics.RootMeanSquaredError(\n",
        "    name='root_mean_squared_error', dtype=None\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGKvemXQTxrG"
      },
      "source": [
        "$\\mathrm{RMSE}=\\sqrt{\\frac{1}{n} \\sum_{j=1}^{n}\\left(y_{j}-\\hat{y}_{j}\\right)^{2}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7DiXtVUfZv3"
      },
      "source": [
        "* Root-Mean-Square Error is the distance, on average, of a data point from the fitted line, measured along a vertical line.\n",
        "* The **RMSE is directly interpretable in terms of measurement units**, and so is a better measure of goodness of fit than a correlation coefficient. One can compare the RMSE to observed variation in measurements of a typical point. The two should be similar for a reasonable fit. Metric can range from 0 to ∞ and are indifferent to the direction of errors. It is  negatively-oriented scores, which means lower values are better.\n",
        "* Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE should be more useful when large errors are particularly undesirable\n",
        "* https://www.sciencedirect.com/science/article/pii/S096014811831231X\n",
        "* The **RMSE is more appropriate to represent model performance than the MAE when the error distribution is expected to be Gaussian**.\n",
        "https://www.geosci-model-dev-discuss.net/7/C473/2014/gmdd-7-C473-2014-supplement.pdf\n",
        "* When both metrics are calculated, the MAE tends to be much smaller than the RMSE because the RMSE penalizes large errors while the MAE gives the same weight to all errors.\n",
        "* They summarized that the **RMSE tends to become increasingly larger than the MAE** (but not necessarily in a monotonic fashion) as the distribution of error magnitudes becomes more variable. The RMSE tends to 1 grow larger than the MAE with n2 since its lower limit is fixed at the MAE and its upper 11 limit (n2 · MAE) increases with n2 .\n",
        "* [Wiki](https://en.m.wikipedia.org/wiki/Root-mean-square_deviation) & [Keras](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/RootMeanSquaredError)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taoM__MVSAbf"
      },
      "source": [
        "**RMSLE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHCT13-gSDAw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZUhp1-tSJXq"
      },
      "source": [
        "* Abzüge für Fehler nach der relativen Größe statt des absoluten Werts vornehmen. Das ist besonders hilfreich, wenn sowohl die vorhergesagten als auch die tatsächlichen Werte sehr groß werden können. Nicht gültig für eine Zielspalte mit negativen Werten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrujRpndSDa7"
      },
      "source": [
        "**RMSPE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27unxIPOSE7D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUL3Y97WG7n6"
      },
      "source": [
        "##### **MAE (L1) & MAPE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTBTWNouBf4e"
      },
      "source": [
        "loss = 'mae'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0l6NTY_T00L"
      },
      "source": [
        "$\\mathrm{MAE}=\\frac{1}{n} \\sum_{j=1}^{n}\\left|y_{j}-\\hat{y}_{j}\\right|$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RPbrLn8qpqc",
        "outputId": "d8db94a2-27f8-440c-fd0e-ab1c52d56883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# MAE loss function\n",
        "def mae_loss(y_pred, y_true):\n",
        "    abs_error = np.abs(y_pred - y_true)\n",
        "    sum_abs_error = np.sum(abs_error)\n",
        "    loss = sum_abs_error / y_true.size\n",
        "    return loss\n",
        "    \n",
        "# Plotting\n",
        "x_vals = np.arange(-100, 100, 0.01)\n",
        "y_vals = np.abs(x_vals)\n",
        "\n",
        "sns.set(rc={'figure.figsize':(10, 5), \"lines.linewidth\": 1.0})\n",
        "plt.plot(x_vals, y_vals)\n",
        "plt.grid(True, which=\"major\")\n",
        "plt.axhline(y=0, color='red', linestyle='--', linewidth=1.0)\n",
        "plt.axvline(x=0, color='red', linestyle='--', linewidth=1.0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGmm_005WT6H"
      },
      "source": [
        "*If the absolute value is not taken (the signs of the errors are not removed), the average error becomes the Mean Bias Error (MBE) and is usually intended to measure average model bias. MBE can convey useful information, but should be interpreted cautiously because positive and negative errors will cancel out.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwewFlH5dtSO"
      },
      "source": [
        "* Mean Absolute Error (L1 Loss)\n",
        "* Computes the mean of absolute difference between labels and predictions\n",
        "* measures the average magnitude of the errors in a set of predictions, without considering their direction. It’s the average over the test sample of the absolute differences between prediction and actual observation where all individual differences have equal weight.\n",
        "* On some regression problems, the **distribution of the target variable may be mostly Gaussian, but may have outliers**, e.g. large or small values far from the mean value. The Mean Absolute Error, or MAE, loss is an appropriate loss function in this case as it is more robust to outliers. It is calculated as the average of the absolute difference between the actual and predicted values.\n",
        "* Metric can range from 0 to ∞ and are indifferent to the direction of errors. It is  negatively-oriented scores, which means lower values are better.\n",
        "* Extremwerte als Ausreißer mit geringerem Einfluss auf das Modell ansehen: MAE loss is useful if the training data is corrupted with outliers (i.e. we erroneously receive unrealistically huge negative/positive values in our training environment, but not our testing environment).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZlsXjjYguS_"
      },
      "source": [
        "def mae(predictions, targets):\n",
        "    # Retrieving number of samples in dataset\n",
        "    samples_num = len(predictions)\n",
        "    \n",
        "    # Summing absolute differences between predicted and expected values\n",
        "    accumulated_error = 0.0\n",
        "    for prediction, target in zip(predictions, targets):\n",
        "        accumulated_error += np.abs(prediction - target)\n",
        "        \n",
        "    # Calculating mean\n",
        "    mae_error = (1.0 / samples_num) * accumulated_error\n",
        "    \n",
        "    return mae_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by0MnQ9bN0LH"
      },
      "source": [
        "**MSE vs MSE**\n",
        "\n",
        "One big problem in using MAE loss (for neural nets especially) is that its gradient is the same throughout, which means the gradient will be large even for small loss values. This isn’t good for learning. To fix this, we can use dynamic learning rate which decreases as we move closer to the minima. MSE behaves nicely in this case and will converge even with a fixed learning rate. The gradient of MSE loss is high for larger loss values and decreases as loss approaches 0, making it more precise at the end of training (see figure below.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daG9qEDxOCyo"
      },
      "source": [
        "![xx](https://raw.githubusercontent.com/deltorobarba/machinelearning/master/mae_vs_mse.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNncxKvrUZ3k"
      },
      "source": [
        "**Mean Absolute Percentage Error (MAPE)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0besM03eqMI"
      },
      "source": [
        "tf.keras.losses.MAPE(\n",
        "    y_true, y_pred\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC70VH4ftWSU"
      },
      "source": [
        "$\\mathrm{M}=\\frac{1}{n} \\sum_{t=1}^{n}\\left|\\frac{A_{t}-F_{t}}{A_{t}}\\right|$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCaQs6DTevbo"
      },
      "source": [
        "* The mean absolute percentage error (MAPE) is a statistical measure of **how accurate a forecast** system is. \n",
        "\n",
        "* It measures this accuracy as a percentage, and can be calculated as the average absolute percent error for each time period minus actual values divided by actual values. Where At is the actual value and Ft is the forecast value.\n",
        "\n",
        "* The mean absolute percentage error (MAPE) is the most common measure used to forecast error, and works best if there are no extremes to the data (and no zeros).\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Mean_absolute_percentage_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8-r2TGwefJj"
      },
      "source": [
        "**Symmetric Mean Absolute Percentage Error (sMAPE)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfBnOe2TejxO"
      },
      "source": [
        "# Import Keras backend\n",
        "import keras.backend as K\n",
        "\n",
        "# Define SMAPE loss function\n",
        "def customLoss(true,predicted):\n",
        "    epsilon = 0.1\n",
        "    summ = K.maximum(K.abs(true) + K.abs(predicted) + epsilon, 0.5 + epsilon)\n",
        "    smape = K.abs(predicted - true) / summ * 2.0\n",
        "    return smape\n",
        "\n",
        "# https://medium.com/@mlguy/adding-custom-loss-and-optimizer-in-keras-e255764e1b7d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxNt8Ap4wuYc"
      },
      "source": [
        "There are 3 different definitions of sMAPE. 2 of them are below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phIyFqeIufVm"
      },
      "source": [
        "$\\operatorname{SMAPE}=\\frac{100 \\%}{n} \\sum_{t=1}^{n} \\frac{\\left|F_{t}-A_{t}\\right|}{\\left(\\left|A_{t}\\right|+\\left|F_{t}\\right|\\right) / 2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trnmeQ--ezQl"
      },
      "source": [
        "* Symmetric mean absolute percentage error (SMAPE or sMAPE) is an accuracy measure based on percentage (or relative) errors. \n",
        "\n",
        "* At is the actual value and Ft is the forecast value\n",
        "\n",
        "* The absolute difference between At and Ft is divided by half the sum of absolute values of the actual value At and the forecast value Ft. The value of this calculation is summed for every fitted point t and divided again by the number of fitted points n.\n",
        "\n",
        "* Armstrong's original definition is as follows:\n",
        "\n",
        "$\\mathrm{SMAPE (old)}=\\frac{1}{n} \\sum_{t=1}^{n} \\frac{\\left|F_{t}-A_{t}\\right|}{\\left(A_{t}+F_{t}\\right) / 2}$\n",
        "\n",
        "* The problem is that it can be negative (if ${\\displaystyle A_{t}+F_{t}<0}$) or even undefined (if ${\\displaystyle A_{t}+F_{t}=0}$). Therefore the currently accepted version of SMAPE assumes the absolute values in the denominator.\n",
        "\n",
        "* In contrast to the mean absolute percentage error, SMAPE has both a lower bound and an upper bound. Indeed, the formula above provides a result between 0% and 200%. However a percentage error between 0% and 100% is much easier to interpret. That is the reason why the formula below is often used in practice (i.e. no factor 0.5 in denominator)\n",
        "\n",
        "* One supposed problem with SMAPE is that it is not symmetric since over- and under-forecasts are not treated equally. This is illustrated by the following example by applying the second SMAPE formula:\n",
        "\n",
        "  * Over-forecasting: At = 100 and Ft = 110 give SMAPE = 4.76%\n",
        "\n",
        "  * Under-forecasting: At = 100 and Ft = 90 give SMAPE = 5.26%.\n",
        "\n",
        "* [Wiki](https://en.m.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error) & [Wiki2](https://wiki2.org/en/Symmetric_mean_absolute_percentage_error) & [other](https://www.brightworkresearch.com/the-problem-with-using-smape-for-forecast-error-measurement/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29IIXN87yRoG"
      },
      "source": [
        "**Mean absolute scaled error (MASE)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O8_TzRzyWQy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imOQ42osyYZk"
      },
      "source": [
        "* mean absolute scaled error (MASE) is a measure of the accuracy of forecasts.\n",
        "\n",
        "*  It is the mean absolute error of the forecast values, divided by the mean absolute error of the in-sample one-step naive forecast. It was proposed in 2005.\n",
        "\n",
        "* The mean absolute scaled error has the following desirable propertie: [Wiki](https://en.wikipedia.org/wiki/Mean_absolute_scaled_error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9V8uoymHN3M"
      },
      "source": [
        "##### **Huber**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78swAUdn5ftf"
      },
      "source": [
        "loss = tf.keras.losses.Huber(delta=10.0, name='huber_loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhS0rF_24E-C"
      },
      "source": [
        "TLDR: will better find a minimum than L1, but less exposed to outliers than L2. However one has to tune the hyperparameter delta. The larger (3+), the more it is L2, the smaller (1), the more it is L1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGqUQWVHzd2E"
      },
      "source": [
        "![huber](https://raw.githubusercontent.com/deltorobarba/machinelearning/master/huberloss.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yXcWmMUzv8G"
      },
      "source": [
        "* For target = 0, the loss increases when the error increases. However, the speed with which it increases depends on this 𝛿 value. In fact, Grover (2019) writes about this as follows: Huber loss approaches MAE when 𝛿 ~ 0 and MSE when 𝛿 ~ ∞ (large numbers.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NonIaG1MOoo6"
      },
      "source": [
        "![xx](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Huber_loss.svg/320px-Huber_loss.svg.png)\n",
        "\n",
        "*Huber loss (green, \n",
        "δ\n",
        "=\n",
        "1) and squared error loss (blue) as a function of \n",
        "y\n",
        "−\n",
        "f\n",
        "(\n",
        "x\n",
        ")*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbvRBSBjQLJC"
      },
      "source": [
        "$L_{\\delta}(y, f(x))=\\left\\{\\begin{array}{ll}\n",
        "\\frac{1}{2}(y-f(x))^{2} & \\text { for }|y-f(x)| \\leq \\delta \\\\\n",
        "\\delta|y-f(x)|-\\frac{1}{2} \\delta^{2} & \\text { otherwise }\n",
        "\\end{array}\\right.$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLnk6D7kz6MR"
      },
      "source": [
        "When you compare this statement with the benefits and disbenefits of both the MAE and the MSE, you’ll gain some insights about how to adapt this delta parameter:\n",
        "\n",
        "* **If your dataset contains large outliers**, it’s likely that your model will not be able to predict them correctly at once. In fact, it might take quite some time for it to recognize these, if it can do so at all. This results in large errors between predicted values and actual targets, because they’re outliers. Since MSE squares errors, large outliers will distort your loss value significantly. If outliers are present, you likely don’t want to use MSE. Huber loss will still be useful, but you’ll have to use small values for 𝛿.\n",
        "\n",
        "* If it does not contain many outliers, it’s likely that it will generate quite accurate predictions from the start – or at least, from some epochs after starting the training process. In this case, you may observe that the errors are very small overall. Then, one can argue, it may be worthwhile to let the largest small errors contribute more significantly to the error than the smaller ones. In this case, MSE is actually useful; hence, with Huber loss, you’ll likely want to use quite large values for 𝛿.\n",
        "\n",
        "* If you don’t know, you can always start somewhere in between – for example, in the plot above, 𝛿 = 1 represented MAE quite accurately, while 𝛿 = 3 tends to go towards MSE already. What if you used 𝛿 = 1.5 instead? You may benefit from both worlds.\n",
        "\n",
        "https://www.machinecurve.com/index.php/2019/10/12/using-huber-loss-in-keras/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU6KtzGg34eN"
      },
      "source": [
        "The biggest problem with using MAE to train neural networks is the constant large gradient, which may cause the minimum point to be missed when the gradient descent is about to end. For MSE, the gradient will decrease as the loss decreases, making the result more accurate.\n",
        "\n",
        "In this case, Huber loss is very useful. It will fall near the minimum value due to the decreasing gradient. It is more robust to outliers than MSE. Therefore, Huber loss combines the advantages of MSE and MAE. However, the problem with Huber loss is that we may need to constantly adjust the hyperparameters\n",
        "\n",
        "https://www.programmersought.com/article/86974383768/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3_rXmIerEhD",
        "outputId": "b7a3251b-c5e8-47b2-cc92-aec522600bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "# Huber loss function\n",
        "def huber_loss(y_pred, y, delta=1.0):\n",
        "    huber_mse = 0.5*(y-y_pred)**2\n",
        "    huber_mae = delta * (np.abs(y - y_pred) - 0.5 * delta)\n",
        "    return np.where(np.abs(y - y_pred) <= delta, huber_mse, huber_mae)\n",
        "    \n",
        "# Plotting\n",
        "x_vals = np.arange(-65, 65, 0.01)\n",
        "\n",
        "# Hyperparameter\n",
        "delta = 1.5\n",
        "\n",
        "# Formula\n",
        "huber_mse = 0.5*np.square(x_vals)\n",
        "huber_mae = delta * (np.abs(x_vals) - 0.5 * delta)\n",
        "y_vals = np.where(np.abs(x_vals) <= delta, huber_mse, huber_mae)\n",
        "\n",
        "sns.set(rc={'figure.figsize':(10, 5), \"lines.linewidth\": 1.0})\n",
        "plt.plot(x_vals, y_vals)\n",
        "plt.axhline(y=0, color='red', linestyle='--', linewidth=1.0)\n",
        "plt.axvline(x=0, color='red', linestyle='--', linewidth=1.0)\n",
        "plt.grid(True, which=\"major\")\n",
        "plt.show()\n",
        "\n",
        "# https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u-W2FmUOZAC"
      },
      "source": [
        "* Huber Loss (Smooth Mean Absolute Error)\n",
        "\n",
        "* The Huber loss **combines the best properties of MSE and MAE** (Mean Absolute Error). It is quadratic for smaller errors and is linear otherwise (and similarly for its gradient). It is identified by its delta parameter.\n",
        "\n",
        "* It's **less sensitive to outliers** in data than the squared error loss. It’s **also differentiable at 0**. It’s basically absolute error, which becomes quadratic when error is small.  How small that error has to be to make it quadratic depends on a hyperparameter 𝛿. \n",
        "\n",
        "* Once differentiable.\n",
        "\n",
        "* **Huber loss approaches MSE when 𝛿 ~ 0 and MAE when 𝛿 ~ ∞**\n",
        "\n",
        "* The choice of delta is critical because it determines what you’re willing to consider as an outlier. Residuals larger than delta are minimized with L1 (which is less sensitive to large outliers), while residuals smaller than delta are minimized “appropriately” with L2.\n",
        "\n",
        "* One big problem with using MAE for training of neural nets is its constantly large gradient, which can lead to missing minima at the end of training using gradient descent. For MSE, gradient decreases as the loss gets close to its minima, making it more precise.\n",
        "Huber loss can be really helpful in such cases, as it curves around the minima which decreases the gradient. And it’s more robust to outliers than MSE. Therefore, **it combines good properties from both MSE and MAE**. \n",
        "\n",
        "* However, the problem with Huber loss is that we might need to train hyperparameter delta which is an iterative process.\n",
        "\n",
        "* [Wiki](https://en.m.wikipedia.org/wiki/Huber_loss) * [TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/losses/Huber)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7utPdOPHfya"
      },
      "source": [
        "##### **Log-Cosh**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-duKUH6p4kD-"
      },
      "source": [
        "TLDR: Similar to MAE, will not be affected by outliers. Log-Cosh has all the points of Huber loss, and no need to set hyperparameters. Compared with Huber, Log-Cosh derivation is more complicated, requires more computation, and is not used much in deep learning. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4txMn1YnHjXc"
      },
      "source": [
        "loss = tf.keras.losses.LogCosh()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUYfXn-xLED_"
      },
      "source": [
        "* Log-cosh is another function used in regression tasks that’s smoother than L2 (is smoothed towards large errors (presumably caused by outliers) so that the final error score isn’t impacted thoroughly.)\n",
        "* Log-cosh is the logarithm of the hyperbolic cosine of the prediction error. “Log-cosh is the logarithm of the hyperbolic cosine of the prediction error.” (Grover, 2019). Oops, that’s not intuitive but nevertheless quite important – this is the maths behind Logcosh loss:\n",
        "\n",
        "> $\\log \\cosh (t)=\\sum_{p \\in P} \\log (\\cosh (p-t))$\n",
        "\n",
        "* Similar to Huber Loss, but twice differentiable everywhere\n",
        "* [Wiki Hyperbolic Functions](https://en.m.wikipedia.org/wiki/Hyperbolic_functions), [TF Class](https://www.tensorflow.org/api_docs/python/tf/keras/losses/LogCosh), [Machinecurve](https://www.machinecurve.com/index.php/2019/10/23/how-to-use-logcosh-with-keras/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCIfX2d12UxJ"
      },
      "source": [
        "![logcosh](https://raw.githubusercontent.com/deltorobarba/machinelearning/master/logcosh.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl2bx-Q843c_"
      },
      "source": [
        "However, Log-Cosh is second-order differentiable everywhere, which is still very useful in some machine learning models. For example, XGBoost uses Newton's method to find the best advantage. Newton's method requires solving the second derivative (Hessian). Therefore, for machine learning frameworks such as XGBoost, the second order of the loss function is differentiable. But the Log-cosh loss is not perfect, and there are still some problems. For example, if the error is large, the first step and Hessian will become fixed, which leads to the lack of split points in XGBoost.\n",
        "\n",
        "https://www.programmersought.com/article/86974383768/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bRPT7j2Hjpr"
      },
      "source": [
        "##### **Quantile**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgCQiqB46fK5"
      },
      "source": [
        "TLDR: for Heteroskedastizität, i.e. for risk management when variance changes. Quantile Loss, you can set different quantiles to control the proportion of overestimation and underestimation in loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gNvk2yzHko8"
      },
      "source": [
        "loss = tfa.losses.PinballLoss(tau=.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klWHgHHm4_R4"
      },
      "source": [
        "The usual regression algorithm is to fit the expected or median training data, and the quantile loss function can be used to fit different quantiles of training data by giving different quantiles. As shown below\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iabSraKQ5LY6"
      },
      "source": [
        "![sdd](https://raw.githubusercontent.com/deltorobarba/machinelearning/master/quantileloss.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1iavs6u5Q84"
      },
      "source": [
        "Set different quantiles to fit different straight lines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WY_2hBO58EU"
      },
      "source": [
        "This function is a piecewise functio., γ is the quantile coefficient. y is the true value, f(x) is the predicted value. According to the size of the predicted value and the true value, there are two cases to consider. \n",
        "\n",
        "y>f(x) For overestimation, the predicted value is greater than the true value; \n",
        "\n",
        "y<f(x) to underestimate, the predicted value is smaller than the real value.\n",
        "\n",
        "Use different pass coefficients to control the weight of overestimation and underestimation in the entire loss value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql_nd2Cr5yud"
      },
      "source": [
        "Especially when γ=0.5 When the quantile loss degenerates into the mean absolute error MAE, **MAE can also be regarded as a special case of quantile loss-median loss**. The picture below is taken with different median points [0.25,0.5,0.7] Obtaining different quantile loss function curves can also be seen as MAE at 0.5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FZwvyGy5q51"
      },
      "source": [
        "![fgfgf](https://raw.githubusercontent.com/deltorobarba/machinelearning/master/quantileloss2.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A23UY_EtKCYA"
      },
      "source": [
        "![xx](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/Pinball_Loss_Function.svg/320px-Pinball_Loss_Function.svg.png)\n",
        "\n",
        "*Pinball-Verlustfunktion mit \n",
        "τ\n",
        "=0,9. Für \n",
        "ε\n",
        "<\n",
        "0 beträgt der Fehler \n",
        "−\n",
        "0\n",
        ",\n",
        "1\n",
        "ε, für \n",
        "ε\n",
        "≥\n",
        "0 beträgt er \n",
        "0\n",
        ",\n",
        "9\n",
        "ε.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V61VVogsIIED"
      },
      "source": [
        "* Quantile Loss (Pinball Loss)\n",
        "* estimates conditional “quantile” of a response variable given certain values of predictor variables\n",
        "* is an extension of MAE (**when quantile is 50th percentile, it’s MAE**)\n",
        "* Im Gegensatz zur Kleinste-Quadrate-Schätzung, die den Erwartungswert der Zielgröße schätzt, ist die Quantilsregression dazu geeignet, ihre Quantile zu schätzen.\n",
        "* Fitting models for many percentiles, you can estimate the entire conditional distribution. Often, the answers to important questions are found by modeling percentiles in the tails of the distribution. For that reason **quantile regression provides critical insights in financial risk management & fraud detection**. \n",
        "* [Wikipedia](https://de.m.wikipedia.org/wiki/Quantilsregression), [TF Class](https://www.tensorflow.org/addons/api_docs/python/tfa/losses/PinballLoss) & [TF Function](https://www.tensorflow.org/addons/api_docs/python/tfa/losses/pinball_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1zREy6LgiWc"
      },
      "source": [
        "https://www.evergreeninnovations.co/blog-quantile-loss-function-for-machine-learning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT0gbfKEf9MY"
      },
      "source": [
        "* project where predictions were subject to high uncertainty. The client required for their decision to be driven by both the predicted machine learning output and a measure of the potential prediction error. The quantile regression loss function solves this and similar problems by replacing a single value prediction by prediction intervals.\n",
        "\n",
        "* The quantile regression loss function is applied to predict quantiles. A quantile is the value below which a fraction of observations in a group falls. For example, a prediction for quantile 0.9 should over-predict 90% of the times.\n",
        "\n",
        "* For q equal to 0.5, under-prediction and over-prediction will be penalized by the same factor, and the median is obtained. The larger the value of q, the more over-predictions are penalized compared to under-predictions. For q equal to 0.75, over-predictions will be penalized by a factor of 0.75, and under-predictions by a factor of 0.25. The model will then try to avoid over-predictions approximately three times as hard as under-predictions, and the 0.75 quantile will be obtained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB89shlnkga3"
      },
      "source": [
        "##### **Poisson Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IDu5bC_kiIb"
      },
      "source": [
        "tf.keras.losses.poisson(\n",
        "    y_true, y_pred\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5cdiNmhxV5l"
      },
      "source": [
        "https://towardsdatascience.com/the-poisson-distribution-103abfddc312"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhGj5O9-qbci"
      },
      "source": [
        "https://towardsdatascience.com/the-poisson-distribution-and-poisson-process-explained-4e2cb17d459"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ci4FK976jCoT"
      },
      "source": [
        "https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/poisson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXCzt1erjaOS"
      },
      "source": [
        "https://openacttexts.github.io/Loss-Data-Analytics/C-RiskClass.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPHAqSSzGRWu"
      },
      "source": [
        "### **Classification** (mostly entropy-/ divergence-based or margin-based)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtrplweMXpx0"
      },
      "source": [
        "##### **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lLdD3qajuJd"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Loss_functions_for_classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRN26mFZhiS-"
      },
      "source": [
        "https://www.machinecurve.com/index.php/2019/10/04/about-loss-and-loss-functions/#loss-functions-for-classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLQNVZmphglM"
      },
      "source": [
        "https://arxiv.org/pdf/1702.05659.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jSsGU3piR_I"
      },
      "source": [
        "http://cs229.stanford.edu/extra-notes/loss-functions.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwF3TGA4HyGe"
      },
      "source": [
        "##### **Cross-Entropy-based**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37P_46NIZDH1"
      },
      "source": [
        "**Cross Entropy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JJVQSAzHzfe"
      },
      "source": [
        "* the cross entropy between two probability distributions p and q **over the same underlying set of events** measures the average number of bits needed to identify an event drawn from the set if a coding scheme used for the set is optimized for an estimated probability distribution q, rather than the true distribution p."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEHec9phH1hb"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Cross_entropy\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Cross-entropy_method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28ekAmVTH5lJ"
      },
      "source": [
        "Conditional Entropy the conditional entropy (or equivocation)\n",
        "quantifies the amount of information needed to describe the outcome of a random variable $Y$ given that the value of another\n",
        "random variable $X$ is known. Here, information is measured in shannons, nats, or hartleys. The entropy of $Y$ conditioned on $X$ is written as $\\mathrm{H}(Y \\mid X)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1gLjoOpH7Tb"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Conditional_entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29AcuGJjH9yd"
      },
      "source": [
        "Joint Entropy: In information theory, joint entropy is a measure of the uncertainty associated with a set of variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai0GeirSIDkx"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Joint_entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jieM-rKQjf_L"
      },
      "source": [
        "**Binary Cross-Entropy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-On4dPTgUuR"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41gq-BjVfuem"
      },
      "source": [
        "https://towardsdatascience.com/log-loss-function-math-explained-5b83cd8d9c83"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G6KVcH-ji6L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7lTRcsl1uNt"
      },
      "source": [
        "$-(y \\log (p)+(1-y) \\log (1-p))$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYYl1AFf0_rv"
      },
      "source": [
        "* Cross-Entropy or Log-Loss (Logistic Loss/ negative log-likelihood) \n",
        "\n",
        "* It measures the performance of a classification model whose output is a probability value between 0 and 1. Cross-entropy loss increases as the predicted probability diverges from the actual label. \n",
        "\n",
        "* So predicting a probability of .012 when the actual observation label is 1 would be bad and result in a high loss value.  A perfect model would have a log loss of 0.\n",
        "\n",
        "* Cross-entropy and log loss are slightly different depending on context, but in machine learning when calculating error rates between 0 and 1 they resolve to the same thing. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeUnraN74y0_"
      },
      "source": [
        "* Cross-entropy is the default loss function to use for binary classification problems.\n",
        "\n",
        "* It is intended for use with binary classification where the target values are in the set {0, 1}.\n",
        "\n",
        "* Mathematically, it is the preferred loss function under the inference framework of maximum likelihood. It is the loss function to be evaluated first and only changed if you have a good reason.\n",
        "\n",
        "* Cross-entropy will calculate a score that summarizes the average difference between the actual and predicted probability distributions for predicting class 1. The score is minimized and a perfect cross-entropy value is 0.\n",
        "\n",
        "* The function requires that the output layer is configured with a single node and a ‘sigmoid‘ activation in order to predict the probability for class 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9_FrV4ZjMIx"
      },
      "source": [
        "**Sparse Categorical Cross-Entropy (Multiclass)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Deqvu9M1BZ4n"
      },
      "source": [
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2Ionbd8BCSM"
      },
      "source": [
        "loss = 'sparse_categorical_crossentropy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nwGwb-f6d_t"
      },
      "source": [
        "* Cross-entropy is the default loss function to use for multi-class classification problems.\n",
        "\n",
        "* In this case, it is intended for use with multi-class classification where the target values are in the set {0, 1, 3, …, n}, where each class is assigned a unique integer value.\n",
        "\n",
        "* Mathematically, it is the preferred loss function under the inference framework of maximum likelihood. It is the loss function to be evaluated first and only changed if you have a good reason.\n",
        "\n",
        "* Cross-entropy will calculate a score that summarizes the average difference between the actual and predicted probability distributions for all classes in the problem. The score is minimized and a perfect cross-entropy value is 0.\n",
        "\n",
        "* A possible cause of frustration when using cross-entropy with classification problems with a large number of labels is the one hot encoding process.\n",
        "\n",
        "* For example, predicting words in a vocabulary may have tens or hundreds of thousands of categories, one for each label. This can mean that the target element of each training example may require a one hot encoded vector with tens or hundreds of thousands of zero values, requiring significant memory.\n",
        "\n",
        "* Sparse cross-entropy addresses this by performing the same cross-entropy calculation of error, without requiring that the target variable be one hot encoded prior to training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAuSM7rYi0nW"
      },
      "source": [
        "##### **Divergence-based**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQBmBQ-tb6de"
      },
      "source": [
        "**Kullback-Leibler Divergence (Multiclass)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks4_vx_wFci9"
      },
      "source": [
        "loss = tf.keras.losses.KLDivergence(name='kl_divergence')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuF2ySph674M"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Kullback–Leibler_divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srlCKVTyVtB-"
      },
      "source": [
        "* Kullback Leibler Divergence, or KL Divergence for short, is a measure of how one probability distribution differs from a baseline distribution. \n",
        "\n",
        "* A KL divergence loss of 0 suggests the distributions are identical. In practice, the behavior of KL Divergence is very similar to cross-entropy. It calculates how much information is lost (in terms of bits) if the predicted probability distribution is used to approximate the desired target probability distribution. \n",
        "\n",
        "* As such, the KL divergence loss function is more commonly used when using models that learn to **approximate a more complex function than simply multi-class classification**, such as in the case of an autoencoder used for learning a dense feature representation under a model that must reconstruct the original input. In this case, KL divergence loss would be preferred. \n",
        "\n",
        "* Nevertheless, it can be used for **multi-class classification, in which case it is functionally equivalent to multi-class cross-entropy**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dPKg9bY61dp"
      },
      "source": [
        "* Kullback Leibler Divergence, or KL Divergence for short, is a measure of how one probability distribution differs from a baseline distribution.\n",
        "\n",
        "* A KL divergence loss of 0 suggests the distributions are identical. In practice, the behavior of KL Divergence is very similar to cross-entropy. It calculates how much information is lost (in terms of bits) if the predicted probability distribution is used to approximate the desired target probability distribution.\n",
        "\n",
        "* As such, the KL divergence loss function is more commonly used when using models that learn to approximate a more complex function than simply multi-class classification, such as in the case of an autoencoder used for learning a dense feature representation under a model that must reconstruct the original input. In this case, KL divergence loss would be preferred. Nevertheless, it can be used for multi-class classification, in which case it is functionally equivalent to multi-class cross-entropy.\n",
        "\n",
        "* [TF doc](https://www.tensorflow.org/api_docs/python/tf/keras/losses/KLDivergence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OWsTyvziEce"
      },
      "source": [
        "The only divergence that is both an f-divergence and a Bregman divergence is the Kullback–Leibler divergence\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Kullback–Leibler_divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYkeCV6pdHEI"
      },
      "source": [
        "Use for example as **loss function in variational autoencoder**\n",
        "\n",
        "https://www.kaggle.com/debanga/statistical-distances\n",
        "\n",
        "https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InmmPaXEHSoz"
      },
      "source": [
        "* the Kullback–Leibler divergence (also called relative entropy) is a measure of how one probability distribution is different from a second, reference probability distribution.\n",
        "\n",
        "* Applications include characterizing the relative (Shannon) entropy in information systems, randomness in continuous time-series, and information gain when comparing statistical models of inference. \n",
        "\n",
        "* In contrast to variation of information, **it is a distribution-wise asymmetric measure** and thus **does not qualify as a statistical metric of spread** - it also does not satisfy the triangle inequality.\n",
        "\n",
        "* In the simple case, a Kullback–Leibler divergence of 0 indicates that the two distributions in question are identical. In simplified terms, it is a measure of surprise, with diverse applications such as applied statistics, fluid mechanics, neuroscience and machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSRliOMMiHC-"
      },
      "source": [
        "**Jensen–Shannon divergence**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj-KEamza3xD"
      },
      "source": [
        "* It is based on the Kullback–Leibler divergence, with some notable (and useful) differences, including that it is symmetric and it always has a finite value. The square root of the Jensen–Shannon divergence is a metric often referred to as Jensen-Shannon distance\n",
        "* use in GAN's for example (Goodfellow, Ian J.; Pouget-Abadie, Jean; Mirza, Mehdi; Xu, Bing; Warde-Farley, David; Ozair, Sherjil; Courville, Aaron; Bengio, Yoshua (2014). Generative Adversarial Networks. NIPS. arXiv:1406.2661. Bibcode:2014arXiv1406.2661G)\n",
        "* https://en.m.wikipedia.org/wiki/Generative_adversarial_network\n",
        "* https://en.m.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmZFI8hdhy1u"
      },
      "source": [
        "**f-Divergence**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvHKWuyic7Fn"
      },
      "source": [
        "* Probabilistic models are often trained by maxi- mum likelihood, which corresponds to minimiz- ing a specific f-divergence between the model and data distribution. \n",
        "\n",
        "* In light of recent suc- cesses in training Generative Adversarial Networks, alternative non-likelihood training crite- ria have been proposed.\n",
        "\n",
        "https://arxiv.org/pdf/1907.11891.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHB9e-5seJRf"
      },
      "source": [
        "https://arxiv.org/pdf/1905.12888.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9smhem9wh0x8"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/F-divergence\n",
        "\n",
        "The Hellinger distance is a type of f-divergence\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Hellinger_distance\n",
        "\n",
        "https://www.mis.mpg.de/fileadmin/pdf/geoasp_2008_petz.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYLc2b-qsm8N"
      },
      "source": [
        "**Hellinger Distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEGZl1OtyhBy"
      },
      "source": [
        "*  the Hellinger distance (closely related to, although different from, the Bhattacharyya distance) is used to **quantify the similarity between two probability distributions**. \n",
        "\n",
        "* **It is a type of f-divergence.**\n",
        "\n",
        "* (?) ist vielleicht sogar eine metric weil es triangle inequality erfüllt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owVHpnpSywyW"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Hellinger_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-59nC3Yih3Gm"
      },
      "source": [
        "**Bregman Divergence**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbZKOiCwf6Jw"
      },
      "source": [
        "In machine learning, Bregman divergences are used to calculate the bi-tempered logistic loss, performing better than the softmax function with noisy datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXaFiel6h7Fl"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Bregman_divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnDfoUM_h5VG"
      },
      "source": [
        "The squared Euclidean divergence is a Bregman divergence (corresponding to the function x<sup>2</sup>, but not an f-divergence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eD4Qwu7eOOm"
      },
      "source": [
        "COST-SENSITIVE CLASSIFICATION BASED ON\n",
        "BREGMAN DIVERGENCES: https://core.ac.uk/download/pdf/29402554.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vvhq-zZ2h9Ae"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Euclidean_distance#Squared_Euclidean_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvctBykzhmbB"
      },
      "source": [
        "**Mahalanobis distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-TZ_CmyyVV-"
      },
      "source": [
        "* The Mahalanobis distance is a measure of the distance between a point P and a distribution D\n",
        "\n",
        "* If each of these axes is re-scaled to have unit variance, then the Mahalanobis distance corresponds to standard Euclidean distance in the transformed space. The Mahalanobis distance is thus unitless and scale-invariant, and takes into account the correlations of the data set.\n",
        "\n",
        "* In statistics, the covariance matrix of the data is sometimes used to define a distance metric called Mahalanobis distance.\n",
        "\n",
        "* Bregman divergence: **the Mahalanobis distance is an example of a Bregman divergence**\n",
        "\n",
        "* **Bhattacharyya distance related, for measuring similarity between data sets (and not between a point and a data set** - Mahalanobis distance is a particular case of the Bhattacharyya distance when the standard deviations of the two classes are the same.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guFweB6AhoJs"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Mahalanobis_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYZzNeN0mJJ2"
      },
      "source": [
        "* Mahalanobis distance is an effective multivariate distance metric that measures the distance between a point and a distribution. \n",
        "\n",
        "* It is an extremely useful metric having, excellent applications **in multivariate anomaly detection, classification on highly imbalanced datasets and one-class classification**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCC_7jqmo0rN"
      },
      "source": [
        "![alternativer Text](https://raw.githubusercontent.com/deltorobarba/machinelearning/master/mahalanobis.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAydAR1XqBN_"
      },
      "source": [
        "* If the dimensions (columns in your dataset) are correlated to one another, which is typically the case in real-world datasets, the Euclidean distance between a point and the center of the points (distribution) can give little or misleading information about how close a point really is to the cluster.\n",
        "\n",
        "* The two points above are equally distant (Euclidean) from the center. But only one of them (blue) is actually more close to the cluster, even though, technically the Euclidean distance between the two points are equal.\n",
        "\n",
        "* This is because, Euclidean distance is a distance between two points only. It does not consider how the rest of the points in the dataset vary. So, it cannot be used to really judge how close a point actually is to a distribution of points.\n",
        "\n",
        "* **What we need here is a more robust distance metric that is an accurate representation of how distant a point is from a distribution.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdi3fJK7pK-O"
      },
      "source": [
        "So computationally, how is Mahalanobis distance different from Euclidean distance?\n",
        "\n",
        "1. It transforms the columns into uncorrelated variables\n",
        "2. Scale the columns to make their variance equal to 1\n",
        "3. Finally, it calculates the Euclidean distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzlk1JzZmQRz"
      },
      "source": [
        "https://www.machinelearningplus.com/statistics/mahalanobis-distance/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40Jv2Z1mmUFw"
      },
      "source": [
        "The Mahalanobis distance has the following properties:\n",
        "\n",
        "* It accounts for the fact that the variances in each direction are different.\n",
        "\n",
        "* It accounts for the covariance between variables.\n",
        "\n",
        "* It reduces to the familiar Euclidean distance for uncorrelated variables with unit variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0Hwd5cNpl_c"
      },
      "source": [
        "Distance in standard units\n",
        "\n",
        "In statistics, we sometimes measure \"nearness\" or \"farness\" in terms of the scale of the data. **Often \"scale\" means \"standard deviation.\"** For univariate data, we say that an observation that is one standard deviation from the mean is closer to the mean than an observation that is three standard deviations away. (You can also specify the distance between two observations by specifying how many standard deviations apart they are.)\n",
        "\n",
        "**For many distributions, such as the normal distribution, this choice of scale also makes a statement about probability**. Specifically, it is more likely to observe an observation that is about one standard deviation from the mean than it is to observe one that is several standard deviations away. Why? Because the probability density function is higher near the mean and nearly zero as you move many standard deviations away.\n",
        "\n",
        "**For normally distributed data, you can specify the distance from the mean by computing the so-called z-score**. For a value x, the z-score of x is the quantity z = (x-μ)/σ, where μ is the population mean and σ is the population standard deviation. This is a dimensionless quantity that you can interpret as the number of standard deviations that x is from the mean.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIjjqmwLmY0F"
      },
      "source": [
        "https://blogs.sas.com/content/iml/2012/02/15/what-is-mahalanobis-distance.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT8FPvZ3hi1N"
      },
      "source": [
        "**Bhattacharyya distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1YoJ42mx-xb"
      },
      "source": [
        "* In statistics, the Bhattacharyya distance measures the similarity of two probability distributions. It is closely related to the Bhattacharyya coefficient which is a measure of the amount of overlap between two statistical samples or populations. \n",
        "\n",
        "* The coefficient can be used to determine the relative closeness of the two samples being considered. It is used to measure the separability of classes in classification and it is considered to be more reliable than the Mahalanobis distance, as the ***Mahalanobis distance is a particular case of the Bhattacharyya distance** when the standard deviations of the two classes are the same. \n",
        "\n",
        "* Consequently, when two classes have similar means but different standard deviations, the Mahalanobis distance would tend to zero, whereas the Bhattacharyya distance grows depending on the difference between the standard deviations.\n",
        "\n",
        "* under certain conditions does not obey the triangle inequality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AVM3T1Dhkld"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Bhattacharyya_distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVUgUeHIYPXm"
      },
      "source": [
        "##### **Margin-based**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwTvtFI9YWAE"
      },
      "source": [
        "Margin-based loss functions are particularly useful for binary classification. In contrast to the distance-based losses, these do not care about the difference between true target and prediction. Instead they penalize predictions based on how well they agree with the sign of the target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0eYJwywYX4z"
      },
      "source": [
        "http://juliaml.github.io/LossFunctions.jl/stable/losses/margin/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7Fs8xDgjqGa"
      },
      "source": [
        "**Exponential Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbZJydo4jr_v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KMGvau7juCt"
      },
      "source": [
        "**Hinge Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oYZzEwfjwRc",
        "outputId": "e4110e4c-e80f-45aa-eb11-e87735aeb223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "tf.keras.losses.hinge(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-b1fbf841e29e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhinge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVtO_rWx8Bj_"
      },
      "source": [
        "[TF](https://www.tensorflow.org/api_docs/python/tf/keras/losses/hinge)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63gn-fNY5OQd"
      },
      "source": [
        "**Squared Hinge Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tESv9TFj5QpZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx3yMKCj5YYI"
      },
      "source": [
        "* The hinge loss function has many extensions, often the subject of investigation with SVM models.\n",
        "\n",
        "* A popular extension is called the squared hinge loss that simply calculates the square of the score hinge loss. It has the effect of smoothing the surface of the error function and making it numerically easier to work with.\n",
        "\n",
        "* If using a hinge loss does result in better performance on a given binary classification problem, is likely that a squared hinge loss may be appropriate.\n",
        "\n",
        "* As with using the hinge loss function, the target variable must be modified to have values in the set {-1, 1}."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDjzTk8x3Nxb"
      },
      "source": [
        "[Wiki](https://en.m.wikipedia.org/wiki/Loss_functions_for_classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gTrY2o6kbEm"
      },
      "source": [
        "**Square Loss (also margin-based??)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3Ce2C-1kj4N"
      },
      "source": [
        "* While more commonly used in regression, the square loss function can be re-written as a function  and utilized for classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn6BwbJdkf54"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Loss_functions_for_classification#Square_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2zuQpPO6vNn"
      },
      "source": [
        "### **Metric (Similarity) Learning**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceX3klubVpBn"
      },
      "source": [
        "##### **Similarity Learning vs Regression & Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48QuuE2UVrrO"
      },
      "source": [
        "Similarity learning is an area of supervised machine learning in artificial intelligence. It is closely related to regression and classification, but the goal is to learn a similarity function that measures how similar or related two objects are. It has applications in ranking, in recommendation systems, visual identity tracking, face verification, and speaker verification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv_gjC1HVtlk"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Similarity_learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-lWqu51M0MO"
      },
      "source": [
        "**Classification vs Metric Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTEXXuH_NCJf"
      },
      "source": [
        "* **Classification is a “Closed-set” task**. can't add new labels without complete retraining.  The model here is trying to learn separable features in this case — i.e. features, that would allow to assign a label from a predefined set to a given image. The model is trying to find a hyperplane, a rule that separates given classes in space.\n",
        "\n",
        "* **Metric Learning** is a “Open-set” task. This one means that we do indeed have some predefined set of labels for training, but the model can be applied to any unseen data and it should generalize. In this case the model is trying to solve a metric-learning problem: to learn some sort of similarity metric, and for that it needs to extract discriminative features — features that can be used to distinguish between different people on any two (or more) images. The model is trying not to separate images with a hyperplane, but rather reorganize the input space, pull the similar images together in some form of a cluster while pushing dissimilar images away. \n",
        "\n",
        "* This is somewhat reminiscent of clustering problem in Unsupervised Learning — and indeed you can use a model trained on a metric-learning task to create a distance matrix for new data, and than run algorithms like DBSCAN on it to, e.g., cluster images of people’s faces, where each cluster would correspond to a new person."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC_Q8HIXlT2V"
      },
      "source": [
        "https://medium.com/@maksym.bekuzarov/losses-explained-contrastive-loss-f8f57fe32246"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCZf8vrBmGux"
      },
      "source": [
        "##### **Ranking, Contrastive & Triplet Loss**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRYzIeHwXR45"
      },
      "source": [
        "**Ranking & Learning to Rank**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJiItIotXUp0"
      },
      "source": [
        "Ranking.. (triplet loss mit similarity learning wird im ranking verwendet, weil es ordinal ist im ggs zu distance learning..)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-r_KVeIXXKk"
      },
      "source": [
        "https://en.m.wikipedia.org/wiki/Ranking_(information_retrieval)\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Learning_to_rank\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Ranking\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Information_retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y7Wj16jWj6C"
      },
      "source": [
        "**Contrastive Loss**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuSkp4jpN8iT"
      },
      "source": [
        "* Contrastive loss was first introduced in 2005 by Yann Le Cunn et al. in this paper and its original application was in Dimensionality Reduction. Now, if you recall, the general goal of a Dimensionality reduction algorithm can be formulated like this:\n",
        "\n",
        "> Given a sample (a data point) — a D-dimensional vector, transform this sample into a d-dimensional vector, where d ≪ D, while preserving as much information as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcC6lbUMPXwy"
      },
      "source": [
        "* The difference is that Cross-entropy loss is a classification loss which operates on class probabilities produced by the network independently for each sample, and Contrastive loss is a metric learning loss, which operates on the data points produced by network and their positions relative to each other. \n",
        "\n",
        "* This is also part of the reason a **cross-entropy loss is not usually used for metric learning tasks** like Face Verification — it doesn’t impose any constraints on the distribution on the model’s inner representation of the given data — i.e. the model can learn any features regardless of whether similar data points would be located closely to each other or not after the transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EKxhx0vPgn-"
      },
      "source": [
        "* for each class/group of similar points (in case of Face Recognition task it would be all the photos of the same person) the **maximum intra-class distance is smaller than the minimum inter-class distance.** \n",
        "* It operates on pairs of embeddings received from the model and on the ground-truth similarity flag — a Boolean label, specifying whether these two samples are “similar” or “dissimilar”. So the input must be not one, but 2 images.\n",
        "* It penalizes “similar” samples for being far from each other in terms of Euclidean distance (although other distance metrics could be used).\n",
        "* “Dissimilar” samples are penalized by being to close to each other, but in a somewhat different way — Contrastive Loss introduces the concept of “margin” — a minimal distance that dissimilar points need to keep. So it penalizes dissimilar samples for beings closer than the given margin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDA3ZuNqWh16"
      },
      "source": [
        "**Triplet Loss**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hU6TokIWgm2"
      },
      "source": [
        "Triplet Loss (a loss function for machine learning algorithms) is often used for learning similarity for the purpose of learning embeddings, like word embeddings and even thought vectors, and metric learning.\n",
        "https://en.m.wikipedia.org/wiki/Triplet_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoLTTPqSSmeZ"
      },
      "source": [
        "**Terms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h90FJ46fSlgQ"
      },
      "source": [
        "Ranking Losses are essentialy the ones explained above, and are used in many different aplications with the same formulation or minor variations. However, different names are used for them, which can be confusing. Here I explain why those names are used.\n",
        "\n",
        "* Ranking loss: This name comes from the information retrieval field, where we want to train models to rank items in an specific order.\n",
        "* Margin Loss: This name comes from the fact that these losses use a margin to compare samples representations distances.\n",
        "* Contrastive Loss: Contrastive refers to the fact that these losses are computed contrasting two or more data points representations. This name is often used for * Pairwise Ranking Loss, but I’ve never seen using it in a setup with triplets.\n",
        "* Triplet Loss: Often used as loss name when triplet training pairs are employed.\n",
        "* Hinge loss: Also known as max-margin objective. It’s used for training SVMs for classification. It has a similar formulation in the sense that it optimizes until a margin. That’s why this name is sometimes used for Ranking Losses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OynXAgWS3PJ"
      },
      "source": [
        "**Pairwise Ranking Loss**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo7ymLUtS5N8"
      },
      "source": [
        "dd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF-hJBn3S7Ox"
      },
      "source": [
        "**Triplet Ranking Loss**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLY6Gz-IS-E0"
      },
      "source": [
        "ddd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AXn5dd9uVrH"
      },
      "source": [
        "https://gombru.github.io/2019/04/03/ranking_loss/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3jTMrMFRcgH"
      },
      "source": [
        "##### **Architectures: Siamese Nets or Triplet Nets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJXjlJ_NTHte"
      },
      "source": [
        "Siamese and triplet nets are training setups where Pairwise Ranking Loss and Triplet Ranking Loss are used. But those losses can be also used in other setups. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60dIC1URTml5"
      },
      "source": [
        "**Siamese Nets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy98MKUKTkO4"
      },
      "source": [
        "Are built by two identical CNNs with shared weights (both CNNs have the same weights). Each one of these nets processes an image and produces a representation. Those representations are compared and a distance between them is computed. Then, a Pairwise Ranking Loss is used to train the network, such that the distance between representations produced by similar images is small, and the distance between representations of dis-similar images is big."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQlkcsi6TsO3"
      },
      "source": [
        "**Triplet Nets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMpc0YQCTuod"
      },
      "source": [
        "The idea is similar to a siamese net, but a triplet net has three branches (three CNNs with shared weights). The model is trained by simultaneously giving a positive and a negative image to the corresponding anchor image, and using a Triplet Ranking Loss. That lets the net learn better which images are similar and different to the anchor image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCZVN7B_TL1i"
      },
      "source": [
        "**Example: Ranking Loss for Multi-Modal Retrieval**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTURi0iPTrre"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxKmU_MLUICH"
      },
      "source": [
        "##### **Loss Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cicxm5OuUKbo"
      },
      "source": [
        "[PyTorch] CosineEmbeddingLoss. It’s a Pairwise Ranking Loss that uses cosine distance as the distance metric. Inputs are the features of the pair elements, the label indicating if it’s a positive or a negative pair, and the margin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhywPFnNUMy1"
      },
      "source": [
        "[PyTorch] MarginRankingLoss. Similar to the former, but uses euclidian distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWICWkZXUOp8"
      },
      "source": [
        "[PyTorch] TripletMarginLoss. A Triplet Ranking Loss using euclidian distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGofcArVURUB"
      },
      "source": [
        "[TensorFlow] contrastive_loss. Pairwise Ranking Loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxXiIet9UTaN"
      },
      "source": [
        "[TensorFlow] triplet_semihard_loss. Triplet loss with semi-hard negative mining."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfVxKUnwXK8Z"
      },
      "source": [
        "### **Define Model & Run**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKomy6Y9c18A",
        "outputId": "d66a05bc-91df-4627-996a-bd27b03007c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "# Load & Prepare Data\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Define Model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu')) \n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer='adam', \n",
        "              loss=loss, \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "model.fit(x=x_train, \n",
        "          y=y_train, \n",
        "          epochs=5, \n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[PlotLossesKerasTF()],\n",
        "          verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy\n",
            "\ttraining         \t (min:    0.700, max:    0.846, cur:    0.846)\n",
            "\tvalidation       \t (min:    0.724, max:    0.841, cur:    0.839)\n",
            "Loss\n",
            "\ttraining         \t (min:    1.615, max:    1.763, cur:    1.615)\n",
            "\tvalidation       \t (min:    1.619, max:    1.736, cur:    1.623)\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1875/1875 [==============================] - 8s 4ms/step - loss: 1.6150 - accuracy: 0.8457 - val_loss: 1.6226 - val_accuracy: 0.8389\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fefdc3a1e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    }
  ]
}