{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "optimizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deltorobarba/machinelearning/blob/master/optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pa49bUnKyRgF"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebdu-Ydo47Gk",
        "colab_type": "text"
      },
      "source": [
        "*Author: Alexander Del Toro Barba*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOEi6BGsJnlE",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "\n",
        "* why optimizer\n",
        "* what is it doing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZvzO_jXqJ2j",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## SGD (Stochastic Gradient Descent)\n",
        "\n",
        "* [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) documentation\n",
        "* Nesterov algorithm based on [this paper](http://jmlr.org/proceedings/papers/v28/sutskever13.pdf)\n",
        "\n",
        "**Characteristics**\n",
        "* SGD is a stochastic approximation of the gradient descent optimization and iterative method for minimizing an objective function that is written as a sum of differentiable functions. All other optimizers are called „adaptive“, because they have momentum.\n",
        "* A compromise between computing the true gradient and the gradient at a single example is to compute the gradient against more than one training example (called a \"mini-batch\") at each step. This can perform significantly better than \"true\" stochastic gradient descent described, because the code can make use of vectorization libraries rather than computing each step separately. It may also result in smoother convergence, as the gradient computed at each step uses more training examples.\n",
        "* The convergence of stochastic gradient descent has been analyzed using the theories of convex minimization and of stochastic approximation. Briefly, when the learning rates decrease with an appropriate rate, and subject to relatively mild assumptions, stochastic gradient descent converges almost surely to a global minimum when the objective function is convex or pseudoconvex, and otherwise converges almost surely to a local minimum.[3][4] This is in fact a consequence of the Robbins-Siegmund theorem.\n",
        "* SGD suffers from 2 problems: (i) being hesitant at steep slopes, and (ii) having same learning rate for all parameters.\n",
        "\n",
        "**Formula**\n",
        "\n",
        "$\\theta=\\theta-\\eta \\cdot \\nabla_{\\theta} J\\left(\\theta ; x^{(i)} ; y^{(i)}\\right)$\n",
        "\n",
        "* Stochastic gradient descent (SGD) in contrast performs a parameter update for each training example $x^{(i)}$ and label $y^{(i)}$\n",
        "* Batch gradient descent performs redundant computations for large datasets, as it recomputes gradients for similar examples before each parameter update. SGD does away with this redundancy by performing one update at a time. It is therefore usually much faster and can also be used to learn online. \n",
        "* SGD performs frequent updates with a high variance that cause the objective function to fluctuate heavily.\n",
        "\n",
        "**SGD Optimizer Components**\n",
        "\n",
        "* **learning_rate**: float hyperparameter >= 0. Learning rate.\n",
        "* **momentum**: float hyperparameter >= 0 that accelerates SGD in the relevant direction and dampens oscillations.\n",
        "* **nesterov**: boolean. Whether to apply Nesterov momentum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6NoCAuaFx7J",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## SGD with Momentum\n",
        "\n",
        "**Characteristics**\n",
        "* The update vector consists of another term which has the previous update vector (weighted by γ). This helps it to move faster downhill — like a ball.\n",
        "* The momentum term γ is usually set to 0.9 or a similar value.\n",
        "\n",
        "**Formula**\n",
        "\n",
        "$\\begin{aligned}\n",
        "v_{t} &=\\gamma v_{t-1}+\\eta \\nabla_{\\theta} J(\\theta) \\\\\n",
        "\\theta &=\\theta-v_{t}\n",
        "\\end{aligned}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS_xflXQEu0y",
        "colab_type": "text"
      },
      "source": [
        "![Momentum](https://raw.githubusercontent.com/deltorobarba/repo/master/momentum.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeNhjjFCE2Ed",
        "colab_type": "text"
      },
      "source": [
        "Source: [An overview of gradient descent optimization\n",
        "algorithms](https://arxiv.org/pdf/1609.04747.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPyc7_d2F9DL",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## SGD with NAG (Nesterov Accelerated Gradient)\n",
        "\n",
        "**Characteristics**\n",
        "* In Momentum optimizer, the ball may go past the minima due to too much momentum, so we want to have a look-ahead term. \n",
        "* In NAG, we take gradient of future position instead of current position.\n",
        "\n",
        "**Formula**\n",
        "\n",
        "$\\begin{aligned}\n",
        "v_{t} &=\\gamma v_{t-1}+\\eta \\nabla_{\\theta} J\\left(\\theta-\\gamma v_{t-1}\\right) \\\\\n",
        "\\theta &=\\theta-v_{t}\n",
        "\\end{aligned}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mjwq2sSddqEa",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Adam (Adaptive Moment Estimation)\n",
        "\n",
        "* [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) documentation\n",
        "* Algorithm based on the paper ['Adam: A Method for Stochastic Optimization' by Kingma et al., 2014,](https://arxiv.org/abs/1412.6980)\n",
        "\n",
        "**Characteristics**\n",
        "* Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments. The method is computationally efficient, has little memory requirement, invariant to diagonal rescaling of gradients, and is well suited for problems that are large in terms of data/parameters.\n",
        "* Adam can be looked at as a combination of RMSprop and Stochastic Gradient Descent with momentum. It uses the squared gradients to scale the learning rate like RMSprop and it takes advantage of momentum by using moving average of the gradient instead of gradient itself like SGD with momentum.\n",
        "\n",
        "**Formula**\n",
        "\n",
        "$\\theta_{t+1}=\\theta_{t}-\\frac{\\eta}{\\sqrt{\\hat{v}_{t}+\\epsilon}} \\hat{m}_{t}$\n",
        "\n",
        "* Adam combines RMSProp with Momentum. So, in addition to using the decaying average of past squared gradients for parameter-specific learning rate, it uses a decaying average of past gradients in place of the current gradient (similar to Momentum).\n",
        "* The ^ terms are actually bias-corrected averages to ensure that the values are not biased towards 0.\n",
        "\n",
        "**Adam Optimizer Components**\n",
        "\n",
        "* **learning_rate**: A Tensor or a floating point value. The learning rate.\n",
        "* **beta_1**: A float value or a constant float tensor. The exponential decay rate for the 1st moment estimates.\n",
        "* **beta_2**: A float value or a constant float tensor. The exponential decay rate for the 2nd moment estimates.\n",
        "* **epsilon**: A small constant for numerical stability. This epsilon is \"epsilon hat\" in the Kingma and Ba paper (in the formula just before Section 2.1), not the epsilon in Algorithm 1 of the paper.\n",
        "* **amsgrad**: boolean. Whether to apply AMSGrad variant of this algorithm from the paper \"On the Convergence of Adam and beyond\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex9Z4S0gKm6_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Nadam (Nesterov Adaptive Moment Estimation)\n",
        "\n",
        "* [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Nadam) documentation\n",
        "* Algorithm based on the paper ['Incorporating Nesterov Momentum into Adam' by Dozat, T., 2015](http://cs229.stanford.edu/proj2015/054_report.pdf)\n",
        "\n",
        "**Characteristics**\n",
        "* Nadam is Adam with Nesterov momentum\n",
        "\n",
        "**Nadam Optimizer Components**\n",
        "* learning_rate: A Tensor or a floating point value. The learning rate.\n",
        "* beta_1: A float value or a constant float tensor. The exponential decay rate for the 1st moment estimates.\n",
        "* beta_2: A float value or a constant float tensor. The exponential decay rate for the 2nd moment estimates.\n",
        "* epsilon: A small constant for numerical stability. This epsilon is \"epsilon hat\" in the Kingma and Ba paper (in the formula just before Section 2.1), not the epsilon in Algorithm 1 of the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWK8KSUTqV3O",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## RMSprop\n",
        "\n",
        "* [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop) documentation\n",
        "* RMSprop is an unpublished optimization algorithm designed for neural networks, first proposed by Geoff Hinton in lecture 6 of the online course “Neural Networks for Machine Learning”\n",
        "\n",
        "**Characteristics**\n",
        "* RMSPro: works well in non-stationary settings. RMSProp with momentum is the method most closely related to Adam. Main differences: RMSProp rescales gradient and then applies momentum, Adam first applies momentum (moving average) and then rescales. RMSProp lacks bias correction, often leading to large stepsizes in early stages of run (especially when β2 is close to 1)\n",
        "* maintain a moving (discounted) average of the square of gradients\n",
        "divide gradient by the root of this average\n",
        "* This implementation of RMSprop uses plain momentum, not Nesterov momentum.\n",
        "* The centered version additionally maintains a moving average of the gradients, and uses that average to estimate the variance\n",
        "\n",
        "**Formula**\n",
        "\n",
        "$E\\left[g^{2}\\right]_{t}=\\gamma E\\left[g^{2}\\right]_{t-1}+(1-\\gamma) g_{t}^{2}$\n",
        "\n",
        "* In Adagrad, since we keep adding all gradients, gradients become vanishingly small after some time. So in RMSProp, the idea is to add them in a decaying fashion as shown in the formula. \n",
        "* Now replace G_t in the denominator of Adagrad equation by this new term. Due to this, the gradients are no more vanishing.\n",
        "\n",
        "**RMSprop Optimizer Components**\n",
        "* **learning_rate**: A Tensor or a floating point value. The learning rate.\n",
        "* **rho**: Discounting factor for the history/coming gradient\n",
        "* **momentum**: A scalar tensor.\n",
        "* **epsilon**: Small value to avoid zero denominator.\n",
        "* **centered**: If True, gradients are normalized by the estimated variance of the gradient; if False, by the uncentered second moment. Setting this to True may help with training, but is slightly more expensive in terms of computation and memory. Defaults to False."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlN8ilZEqQj7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## FTRL (Follow The (Proximally) Regularized Leader)\n",
        "\n",
        "* Algorithm based on [this paper](https://www.eecs.tufts.edu/~dsculley/papers/ad-click-prediction.pdf)\n",
        "* [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Ftrl) documentation\n",
        "\n",
        "**Characteristics**\n",
        "* kkk\n",
        "\n",
        "**Ftrl Optimizer Components**\n",
        "\n",
        "* learning_rate: A float value or a constant float Tensor.\n",
        "learning_rate_power: A float value, must be less or equal to zero. Controls how the learning rate decreases during training. Use zero for a fixed learning rate.\n",
        "* initial_accumulator_value: The starting value for accumulators. Only zero or positive values are allowed.\n",
        "* l1_regularization_strength: A float value, must be greater than or equal to zero.\n",
        "* l2_regularization_strength: A float value, must be greater than or equal to zero.\n",
        "* l2_shrinkage_regularization_strength: A float value, must be greater than or equal to zero. This differs from L2 above in that the L2 above is a stabilization penalty, whereas this L2 shrinkage is a magnitude penalty. The FTRL formulation can be written as: w_{t+1} = argminw(\\hat{g}{1:t}w + L1||w||_1 + L2||w||_2^2), where \\hat{g} = g + (2L2_shrinkagew), and g is the gradient of the loss function w.r.t. the weights w. Specifically, in the absence of L1 regularization, it is equivalent to the following update rule: w_{t+1} = w_t - lr_t / (1 + 2L2lr_t) * g_t - 2L2_shrinkagelr_t / (1 + 2L2lr_t) * w_t where lr_t is the learning rate at t. When input is sparse shrinkage will only happen on the active weights.\\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-oQ1xbVqSGF",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Adagrad\n",
        "\n",
        "**Characteristics**\n",
        "* Instead of a common learning rate for all parameters, we want to have separate learning rate for each. So Adagrad keeps sum of squares of parameter-wise gradients and modifies individual learning rates using this. As a result, parameters occuring more often have smaller gradients.\n",
        "* works well with sparse gradients\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGxXk0wJWOsJ",
        "colab_type": "text"
      },
      "source": [
        "## Which Optimizer to use?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi99ddgpWMXh",
        "colab_type": "text"
      },
      "source": [
        "* So, which optimizer should you now use? If your input data is sparse, then you likely achieve the best results using one of the adaptive learning-rate methods. An additional benefit is that you won't need to tune the learning rate but likely achieve the best results with the default value.\n",
        "* In summary, RMSprop is an extension of Adagrad that deals with its radically diminishing learning rates. It is identical to Adadelta, except that Adadelta uses the RMS of parameter updates in the numinator update rule. Adam, finally, adds bias-correction and momentum to RMSprop. Insofar, RMSprop, Adadelta, and Adam are very similar algorithms that do well in similar circumstances. Kingma et al. [15] show that its bias-correction helps Adam slightly outperform RMSprop towards the end of optimization as gradients become sparser. Insofar, Adam might be the best overall choice.\n",
        "* Interestingly, many recent papers use vanilla SGD without momentum and a simple learning rate annealing schedule. As has been shown, SGD usually achieves to find a minimum, but it might take significantly longer than with some of the optimizers, is much more reliant on a robust initialization and annealing schedule, and may get stuck in saddle points rather than local minima. Consequently, if you care about fast convergence and train a deep or complex neural network, you should choose one of the adaptive learning rate methods.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y28QYb52WuoQ",
        "colab_type": "text"
      },
      "source": [
        "## Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYX8H74HWv_X",
        "colab_type": "text"
      },
      "source": [
        "* Few days ago, an interesting paper titled The Marginal Value of Adaptive Gradient Methods in Machine Learning (https://arxiv.org/abs/1705.08292) from UC Berkeley came out. In this paper, the authors compare adaptive optimizer (Adam, RMSprop and AdaGrad) with SGD, observing that SGD has better generalization than adaptive optimizers.\n",
        "* “We observe that the solutions found by adaptive methods generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.”\n",
        "* I was astounded by their finding since I never used SGD before and consider it as an outdated optimizer with slower convergence than Adam or RMSprop. Am I totally wrong from the very beginning?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG9r3v39XviC",
        "colab_type": "text"
      },
      "source": [
        "![Optimizer](https://raw.githubusercontent.com/deltorobarba/repo/master/optimizer_4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8eTV9RTI6_F",
        "colab_type": "text"
      },
      "source": [
        "https://medium.com/vitalify-asia/whats-up-with-deep-learning-optimizers-since-adam-5c1d862b9db0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H4crpOcoMlSe"
      },
      "source": [
        "# RNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRHu0whFdwoH",
        "colab_type": "text"
      },
      "source": [
        "## Import & Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHmKZX1K4Jrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Niyell7b3bLz",
        "colab_type": "code",
        "outputId": "4f7c5402-611a-45ba-e08f-ddab9f79cc69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYk9nB0c3fJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV-EingDXE_w",
        "colab_type": "text"
      },
      "source": [
        "## Select Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EooYutp0TVBc",
        "colab_type": "text"
      },
      "source": [
        "**Stochastic Gradient Descent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cfe8rEabMrM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, \n",
        "                                    momentum=0.9, \n",
        "                                    nesterov=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnTBaUyVTbcg",
        "colab_type": "text"
      },
      "source": [
        "**Adam Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHylB2SbMn0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, \n",
        "                                     beta_1=0.9, \n",
        "                                     beta_2=0.999, \n",
        "                                     epsilon=1e-07, \n",
        "                                     amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXT4wrybTfRK",
        "colab_type": "text"
      },
      "source": [
        "**Nadam Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFjCzKZiMuCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01, \n",
        "                                      beta_1=0.9, \n",
        "                                      beta_2=0.999, \n",
        "                                      epsilon=1e-07)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekLbKmVOTifx",
        "colab_type": "text"
      },
      "source": [
        "**RMSprop Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk7bZFtwMwd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001, \n",
        "                                        rho=0.9, \n",
        "                                        momentum=0.0, \n",
        "                                        epsilon=1e-07, \n",
        "                                        centered=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbt-r8QCqeOo",
        "colab_type": "text"
      },
      "source": [
        "**FTRL Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m2Llr7TqG9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Ftrl(learning_rate=0.001, \n",
        "                                     learning_rate_power=-0.5, \n",
        "                                     initial_accumulator_value=0.1, \n",
        "                                     l1_regularization_strength=0.0, \n",
        "                                     l2_regularization_strength=0.0, \n",
        "                                     name='Ftrl', \n",
        "                                     l2_shrinkage_regularization_strength=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOT2fRFUILXH",
        "colab_type": "text"
      },
      "source": [
        "**Adadelta**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF2msqBiIOa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adadelta(learning_rate=0.001, \n",
        "                                        rho=0.9, \n",
        "                                        epsilon=1e-07)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQZjdaG9Ia7j",
        "colab_type": "text"
      },
      "source": [
        "**Adagrad**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aSa_ZToIcVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.001, \n",
        "                                        initial_accumulator_value=0.1,\n",
        "                                        epsilon=1e-07)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM5ohmheIvUj",
        "colab_type": "text"
      },
      "source": [
        "**Adamax**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNPKxOn8Iw79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adamax(learning_rate=0.01, \n",
        "                                     beta_1=0.9, \n",
        "                                     beta_2=0.999, \n",
        "                                     epsilon=1e-07)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfVxKUnwXK8Z",
        "colab_type": "text"
      },
      "source": [
        "## Define Model & Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDEv6ZETl129",
        "colab_type": "code",
        "outputId": "2602a1ca-124b-4112-adef-38a0d06d6832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x=x_train, y=y_train, epochs=5, validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.6103 - acc: 0.7857 - val_loss: 0.5376 - val_acc: 0.8173\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.5112 - acc: 0.8193 - val_loss: 0.4692 - val_acc: 0.8383\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.4951 - acc: 0.8260 - val_loss: 0.4896 - val_acc: 0.8238\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.4846 - acc: 0.8280 - val_loss: 0.4755 - val_acc: 0.8289\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.4831 - acc: 0.8293 - val_loss: 0.4601 - val_acc: 0.8452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9fe1a8d438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    }
  ]
}