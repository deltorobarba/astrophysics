{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "optimizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deltorobarba/machinelearning/blob/master/optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pa49bUnKyRgF"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebdu-Ydo47Gk",
        "colab_type": "text"
      },
      "source": [
        "*Author: Alexander Del Toro Barba*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZvzO_jXqJ2j",
        "colab_type": "text"
      },
      "source": [
        "## Stochastic Gradient Descent\n",
        "\n",
        "* Stochastic GD. Middle training cost.\n",
        "* known as incremental gradient descent, is a stochastic approximation of the gradient descent optimization and iterative method for minimizing an objective function that is written as a sum of differentiable functions. In other words, SGD tries to find minima or maxima by iteration.\n",
        "* https://en.m.wikipedia.org/wiki/Stochastic_gradient_descent\n",
        "* https://www.kdnuggets.com/2017/04/simple-understand-gradient-descent-algorithm.html\n",
        "* All other optimizer are called „adaptive“, because it has momentum\n",
        "* A compromise between computing the true gradient and the gradient at a single example is to compute the gradient against more than one training example (called a \"mini-batch\") at each step. This can perform significantly better than \"true\" stochastic gradient descent described, because the code can make use of vectorization libraries rather than computing each step separately. It may also result in smoother convergence, as the gradient computed at each step uses more training examples.\n",
        "* The convergence of stochastic gradient descent has been analyzed using the theories of convex minimization and of stochastic approximation. Briefly, when the learning rates decrease with an appropriate rate, and subject to relatively mild assumptions, stochastic gradient descent converges almost surely to a global minimum when the objective function is convex or pseudoconvex, and otherwise converges almost surely to a local minimum.[3][4] This is in fact a consequence of the Robbins-Siegmund theorem.\n",
        "\n",
        "**SGD Optimizer Components**\n",
        "\n",
        "* learning_rate: float hyperparameter >= 0. Learning rate.\n",
        "* momentum: float hyperparameter >= 0 that accelerates SGD in the relevant direction and dampens oscillations.\n",
        "* nesterov: boolean. Whether to apply Nesterov momentum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mjwq2sSddqEa",
        "colab_type": "text"
      },
      "source": [
        "## Adam\n",
        "\n",
        "* Adam is essentially RMSprop with momentum\n",
        "\n",
        "https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c\n",
        "\n",
        "https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
        "\n",
        "* https://engmrk.com/adam-optimization-algorithm/\n",
        "Adaptive Moment Estimation. \n",
        "* replacement optimization algorithm for stochastic gradient descent for training deep learning models. \n",
        "* Adam optimizer has momentum, that is, it doesn't just follow the instantaneous gradient, but it keeps track of the direction it was going before with a sort of velocity. This way, if you start going back and forth because of the gradient than the momentum will force you to go slower in this direction. This helps a lot! \n",
        "* Adam has a few more tweeks other than momentum that make it the prefered deep learning optimizer. (Which one?)\n",
        "* Combine the advantages of: AdaGrad and RMSProp -> Maintain exponential moving averages of gradient and its square\n",
        "* learning rate (typical choice: 0.001)\n",
        "* Low training cost.\n",
        "* The tf.train.AdamOptimizer uses Kingma and Ba's Adam algorithm to control the learning rate. Adam offers several advantages over the simple tf.train.GradientDescentOptimizer. Foremost is that it uses moving averages of the parameters (momentum); Bengio discusses the reasons for why this is beneficial in Section 3.1.1 of this paper. Simply put, this enables Adam to use a larger effective step size, and the algorithm will converge to this step size without fine tuning.\n",
        "* The main down side of the algorithm is that Adam requires more computation to be performed for each parameter in each training step (to maintain the moving averages and variance, and calculate the scaled gradient); and more state to be retained for each parameter (approximately tripling the size of the model to store the average and variance for each parameter). A simple tf.train.GradientDescentOptimizer could equally be used in your MLP, but would require more hyperparameter tuning before it would converge as quickly.\n",
        "* Learning rate decay? - ADAM updates any parameter with an individual learning rate. This means that every parameter in the network have a specific learning rate associated. But the single learning rate for parameter is computed using lambda (the initial learning rate) as upper limit. This means that every single learning rate can vary from 0 (no update) to lambda (maximum update). The learning rates adapt themselves during train steps.\n",
        "* The theory is that Adam already handles learning rate optimization (check reference) : \"We propose Adam, a method for efficient stochastic optimization that only requires first-order gradients with little memory requirement. The method computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients; the name Adam is derived from adaptive moment estimation.\"\n",
        "* the reason why most people don't use learning rate decay with Adam is that the algorithm itself does a learning rate decay in the following way\n",
        "t <- t + 1\n",
        "lr_t <- learning_rate * sqrt(1 - beta2^t) / (1 - beta1^t)\n",
        "where t0 is initial timestep and lr_t is the new learning rate used\n",
        "\n",
        "**Adam Optimizer Components**\n",
        "\n",
        "* learning_rate: A Tensor or a floating point value. The learning rate.\n",
        "* beta_1: A float value or a constant float tensor. The exponential decay rate for the 1st moment estimates.\n",
        "* beta_2: A float value or a constant float tensor. The exponential decay rate for the 2nd moment estimates.\n",
        "* epsilon: A small constant for numerical stability. This epsilon is \"epsilon hat\" in the Kingma and Ba paper (in the formula just before Section 2.1), not the epsilon in Algorithm 1 of the paper.\n",
        "* amsgrad: boolean. Whether to apply AMSGrad variant of this algorithm from the paper \"On the Convergence of Adam and beyond\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex9Z4S0gKm6_",
        "colab_type": "text"
      },
      "source": [
        "## Nadam\n",
        "\n",
        "* Nadam is Adam with Nesterov momentum\n",
        "\n",
        "**Nadam Optimizer Components**\n",
        "* learning_rate: A Tensor or a floating point value. The learning rate.\n",
        "* beta_1: A float value or a constant float tensor. The exponential decay rate for the 1st moment estimates.\n",
        "* beta_2: A float value or a constant float tensor. The exponential decay rate for the 2nd moment estimates.\n",
        "* epsilon: A small constant for numerical stability. This epsilon is \"epsilon hat\" in the Kingma and Ba paper (in the formula just before Section 2.1), not the epsilon in Algorithm 1 of the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWK8KSUTqV3O",
        "colab_type": "text"
      },
      "source": [
        "## RMSprop\n",
        "\n",
        "* RMSPro: works well in non-stationary settings. RMSProp with momentum is the method most closely related to Adam. Main differences: RMSProp rescales gradient and then applies momentum, Adam first applies momentum (moving average) and then rescales. RMSProp lacks bias correction, often leading to large stepsizes in early stages of run (especially when β2 is close to 1)\n",
        "* maintain a moving (discounted) average of the square of gradients\n",
        "divide gradient by the root of this average\n",
        "* This implementation of RMSprop uses plain momentum, not Nesterov momentum.\n",
        "* The centered version additionally maintains a moving average of the gradients, and uses that average to estimate the variance:\n",
        "\n",
        "**RMSprop Optimizer Components**\n",
        "* learning_rate: A Tensor or a floating point value. The learning rate.\n",
        "* rho: Discounting factor for the history/coming gradient\n",
        "* momentum: A scalar tensor.\n",
        "epsilon: Small value to avoid zero denominator.\n",
        "* centered: If True, gradients are normalized by the estimated variance of the gradient; if False, by the uncentered second moment. Setting this to True may help with training, but is slightly more expensive in terms of computation and memory. Defaults to False."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlN8ilZEqQj7",
        "colab_type": "text"
      },
      "source": [
        "## Adadelta\n",
        "\n",
        "* xxx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-oQ1xbVqSGF",
        "colab_type": "text"
      },
      "source": [
        "## Adagrad\n",
        "\n",
        "* works well with sparse gradients\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l9Ba7gqWWxH",
        "colab_type": "text"
      },
      "source": [
        "* http://ruder.io/optimizing-gradient-descent/index.html\n",
        "* [tf.keras Optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGxXk0wJWOsJ",
        "colab_type": "text"
      },
      "source": [
        "## Which Optimizer to use?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi99ddgpWMXh",
        "colab_type": "text"
      },
      "source": [
        "* So, which optimizer should you now use? If your input data is sparse, then you likely achieve the best results using one of the adaptive learning-rate methods. An additional benefit is that you won't need to tune the learning rate but likely achieve the best results with the default value.\n",
        "* In summary, RMSprop is an extension of Adagrad that deals with its radically diminishing learning rates. It is identical to Adadelta, except that Adadelta uses the RMS of parameter updates in the numinator update rule. Adam, finally, adds bias-correction and momentum to RMSprop. Insofar, RMSprop, Adadelta, and Adam are very similar algorithms that do well in similar circumstances. Kingma et al. [15] show that its bias-correction helps Adam slightly outperform RMSprop towards the end of optimization as gradients become sparser. Insofar, Adam might be the best overall choice.\n",
        "* Interestingly, many recent papers use vanilla SGD without momentum and a simple learning rate annealing schedule. As has been shown, SGD usually achieves to find a minimum, but it might take significantly longer than with some of the optimizers, is much more reliant on a robust initialization and annealing schedule, and may get stuck in saddle points rather than local minima. Consequently, if you care about fast convergence and train a deep or complex neural network, you should choose one of the adaptive learning rate methods.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y28QYb52WuoQ",
        "colab_type": "text"
      },
      "source": [
        "## Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYX8H74HWv_X",
        "colab_type": "text"
      },
      "source": [
        "* Few days ago, an interesting paper titled The Marginal Value of Adaptive Gradient Methods in Machine Learning (https://arxiv.org/abs/1705.08292) from UC Berkeley came out. In this paper, the authors compare adaptive optimizer (Adam, RMSprop and AdaGrad) with SGD, observing that SGD has better generalization than adaptive optimizers.\n",
        "* “We observe that the solutions found by adaptive methods generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.”\n",
        "* I was astounded by their finding since I never used SGD before and consider it as an outdated optimizer with slower convergence than Adam or RMSprop. Am I totally wrong from the very beginning?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG9r3v39XviC",
        "colab_type": "text"
      },
      "source": [
        "![Optimizer](https://raw.githubusercontent.com/deltorobarba/repo/master/optimizer_4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8eTV9RTI6_F",
        "colab_type": "text"
      },
      "source": [
        "https://medium.com/vitalify-asia/whats-up-with-deep-learning-optimizers-since-adam-5c1d862b9db0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H4crpOcoMlSe"
      },
      "source": [
        "# RNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRHu0whFdwoH",
        "colab_type": "text"
      },
      "source": [
        "## Import & Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHmKZX1K4Jrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Niyell7b3bLz",
        "colab_type": "code",
        "outputId": "ced765cd-f765-4e10-b491-e71f19482b62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYk9nB0c3fJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV-EingDXE_w",
        "colab_type": "text"
      },
      "source": [
        "## Choose Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cfe8rEabMrM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, \n",
        "                                    momentum=0.9, \n",
        "                                    nesterov=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHylB2SbMn0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, \n",
        "                                     beta_1=0.9, \n",
        "                                     beta_2=0.999, \n",
        "                                     epsilon=1e-07, \n",
        "                                     amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFjCzKZiMuCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01, \n",
        "                                      beta_1=0.9, \n",
        "                                      beta_2=0.999, \n",
        "                                      epsilon=1e-07)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk7bZFtwMwd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001, \n",
        "                                        rho=0.9, \n",
        "                                        momentum=0.0, \n",
        "                                        epsilon=1e-07, \n",
        "                                        centered=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZnWO2GwMzyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimizer = 'adamax'\n",
        "# optimizer = 'adadelta'\n",
        "# optimizer = 'adagrad'\n",
        "# optimizer = 'ftrl'\n",
        "# optimizer = 'optimizer'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfVxKUnwXK8Z",
        "colab_type": "text"
      },
      "source": [
        "## Define Model & Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDEv6ZETl129",
        "colab_type": "code",
        "outputId": "eb68e86e-73aa-42e3-91d4-c64cd29ad67b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x=x_train, y=y_train, epochs=5, validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 87us/sample - loss: 0.6522 - accuracy: 0.7717 - val_loss: 0.5269 - val_accuracy: 0.8197\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.5533 - accuracy: 0.8030 - val_loss: 0.4872 - val_accuracy: 0.8355\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.5461 - accuracy: 0.8083 - val_loss: 0.4763 - val_accuracy: 0.8297\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.5256 - accuracy: 0.8111 - val_loss: 0.5072 - val_accuracy: 0.8292\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.5185 - accuracy: 0.8167 - val_loss: 0.4655 - val_accuracy: 0.8390\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb1d003cc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}