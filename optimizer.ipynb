{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "optimizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deltorobarba/machinelearning/blob/master/optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pa49bUnKyRgF"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebdu-Ydo47Gk",
        "colab_type": "text"
      },
      "source": [
        "*Author: Alexander Del Toro Barba*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZvzO_jXqJ2j",
        "colab_type": "text"
      },
      "source": [
        "## Stochastic Gradient Descent\n",
        "\n",
        "* Stochastic GD. Middle training cost.\n",
        "* known as incremental gradient descent, is a stochastic approximation of the gradient descent optimization and iterative method for minimizing an objective function that is written as a sum of differentiable functions. In other words, SGD tries to find minima or maxima by iteration.\n",
        "* https://en.m.wikipedia.org/wiki/Stochastic_gradient_descent\n",
        "* https://www.kdnuggets.com/2017/04/simple-understand-gradient-descent-algorithm.html\n",
        "* All other optimizer are called „adaptive“, because it has momentum\n",
        "* A compromise between computing the true gradient and the gradient at a single example is to compute the gradient against more than one training example (called a \"mini-batch\") at each step. This can perform significantly better than \"true\" stochastic gradient descent described, because the code can make use of vectorization libraries rather than computing each step separately. It may also result in smoother convergence, as the gradient computed at each step uses more training examples.\n",
        "* The convergence of stochastic gradient descent has been analyzed using the theories of convex minimization and of stochastic approximation. Briefly, when the learning rates decrease with an appropriate rate, and subject to relatively mild assumptions, stochastic gradient descent converges almost surely to a global minimum when the objective function is convex or pseudoconvex, and otherwise converges almost surely to a local minimum.[3][4] This is in fact a consequence of the Robbins-Siegmund theorem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mjwq2sSddqEa",
        "colab_type": "text"
      },
      "source": [
        "## Adam\n",
        "\n",
        "https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c\n",
        "\n",
        "https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
        "\n",
        "* https://engmrk.com/adam-optimization-algorithm/\n",
        "Adaptive Moment Estimation. \n",
        "* replacement optimization algorithm for stochastic gradient descent for training deep learning models. \n",
        "* Adam optimizer has momentum, that is, it doesn't just follow the instantaneous gradient, but it keeps track of the direction it was going before with a sort of velocity. This way, if you start going back and forth because of the gradient than the momentum will force you to go slower in this direction. This helps a lot! \n",
        "* Adam has a few more tweeks other than momentum that make it the prefered deep learning optimizer. (Which one?)\n",
        "* Combine the advantages of: AdaGrad and RMSProp -> Maintain exponential moving averages of gradient and its square\n",
        "* learning rate (typical choice: 0.001)\n",
        "* Low training cost.\n",
        "* The tf.train.AdamOptimizer uses Kingma and Ba's Adam algorithm to control the learning rate. Adam offers several advantages over the simple tf.train.GradientDescentOptimizer. Foremost is that it uses moving averages of the parameters (momentum); Bengio discusses the reasons for why this is beneficial in Section 3.1.1 of this paper. Simply put, this enables Adam to use a larger effective step size, and the algorithm will converge to this step size without fine tuning.\n",
        "* The main down side of the algorithm is that Adam requires more computation to be performed for each parameter in each training step (to maintain the moving averages and variance, and calculate the scaled gradient); and more state to be retained for each parameter (approximately tripling the size of the model to store the average and variance for each parameter). A simple tf.train.GradientDescentOptimizer could equally be used in your MLP, but would require more hyperparameter tuning before it would converge as quickly.\n",
        "* Learning rate decay? - ADAM updates any parameter with an individual learning rate. This means that every parameter in the network have a specific learning rate associated. But the single learning rate for parameter is computed using lambda (the initial learning rate) as upper limit. This means that every single learning rate can vary from 0 (no update) to lambda (maximum update). The learning rates adapt themselves during train steps.\n",
        "* The theory is that Adam already handles learning rate optimization (check reference) : \"We propose Adam, a method for efficient stochastic optimization that only requires first-order gradients with little memory requirement. The method computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients; the name Adam is derived from adaptive moment estimation.\"\n",
        "* the reason why most people don't use learning rate decay with Adam is that the algorithm itself does a learning rate decay in the following way\n",
        "t <- t + 1\n",
        "lr_t <- learning_rate * sqrt(1 - beta2^t) / (1 - beta1^t)\n",
        "where t0 is initial timestep and lr_t is the new learning rate used\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlN8ilZEqQj7",
        "colab_type": "text"
      },
      "source": [
        "## Adadelta\n",
        "\n",
        "* xxx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-oQ1xbVqSGF",
        "colab_type": "text"
      },
      "source": [
        "## Adagrad\n",
        "\n",
        "* works well with sparse gradients\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWK8KSUTqV3O",
        "colab_type": "text"
      },
      "source": [
        "## RMSprop\n",
        "\n",
        "* RMSPro: works well in non-stationary settings. RMSProp with momentum is the method most closely related to Adam. Main differences: RMSProp rescales gradient and then applies momentum, Adam first applies momentum (moving average) and then rescales. RMSProp lacks bias correction, often leading to large stepsizes in early stages of run (especially when β2 is close to 1).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCeV8-8qWSn5",
        "colab_type": "text"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLmUVAOaWZT7",
        "colab_type": "text"
      },
      "source": [
        "## List of Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l9Ba7gqWWxH",
        "colab_type": "text"
      },
      "source": [
        "* http://ruder.io/optimizing-gradient-descent/index.html\n",
        "* [tf.keras Optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGxXk0wJWOsJ",
        "colab_type": "text"
      },
      "source": [
        "## Which Optimizer to use?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi99ddgpWMXh",
        "colab_type": "text"
      },
      "source": [
        "* So, which optimizer should you now use? If your input data is sparse, then you likely achieve the best results using one of the adaptive learning-rate methods. An additional benefit is that you won't need to tune the learning rate but likely achieve the best results with the default value.\n",
        "* In summary, RMSprop is an extension of Adagrad that deals with its radically diminishing learning rates. It is identical to Adadelta, except that Adadelta uses the RMS of parameter updates in the numinator update rule. Adam, finally, adds bias-correction and momentum to RMSprop. Insofar, RMSprop, Adadelta, and Adam are very similar algorithms that do well in similar circumstances. Kingma et al. [15] show that its bias-correction helps Adam slightly outperform RMSprop towards the end of optimization as gradients become sparser. Insofar, Adam might be the best overall choice.\n",
        "* Interestingly, many recent papers use vanilla SGD without momentum and a simple learning rate annealing schedule. As has been shown, SGD usually achieves to find a minimum, but it might take significantly longer than with some of the optimizers, is much more reliant on a robust initialization and annealing schedule, and may get stuck in saddle points rather than local minima. Consequently, if you care about fast convergence and train a deep or complex neural network, you should choose one of the adaptive learning rate methods.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y28QYb52WuoQ",
        "colab_type": "text"
      },
      "source": [
        "## Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYX8H74HWv_X",
        "colab_type": "text"
      },
      "source": [
        "* Few days ago, an interesting paper titled The Marginal Value of Adaptive Gradient Methods in Machine Learning (https://arxiv.org/abs/1705.08292) from UC Berkeley came out. In this paper, the authors compare adaptive optimizer (Adam, RMSprop and AdaGrad) with SGD, observing that SGD has better generalization than adaptive optimizers.\n",
        "* “We observe that the solutions found by adaptive methods generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.”\n",
        "* I was astounded by their finding since I never used SGD before and consider it as an outdated optimizer with slower convergence than Adam or RMSprop. Am I totally wrong from the very beginning?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG9r3v39XviC",
        "colab_type": "text"
      },
      "source": [
        "![Optimizer](https://raw.githubusercontent.com/deltorobarba/repo/master/optimizer_4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H4crpOcoMlSe"
      },
      "source": [
        "# RNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRHu0whFdwoH",
        "colab_type": "text"
      },
      "source": [
        "## Import & Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc_Iu-7glx75",
        "colab_type": "code",
        "outputId": "19f98698-bb60-4de7-8fd6-38fb042a462e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV-EingDXE_w",
        "colab_type": "text"
      },
      "source": [
        "## Choose Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oy4a71ZnFg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = 'adam'\n",
        "# optimizer = 'adamax'\n",
        "# optimizer = 'adadelta'\n",
        "# optimizer = 'adagrad'\n",
        "# optimizer = 'ftrl'\n",
        "# optimizer = 'nadam'\n",
        "# optimizer = 'optimizer'\n",
        "# optimizer = 'RMSprop'\n",
        "# optimizer = 'sgd'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfVxKUnwXK8Z",
        "colab_type": "text"
      },
      "source": [
        "## Define Model & Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDEv6ZETl129",
        "colab_type": "code",
        "outputId": "737a7482-ba58-4104-85aa-7b88bb59ddc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x=x_train, y=y_train, epochs=5, validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.4969 - acc: 0.8216 - val_loss: 0.4565 - val_acc: 0.8350\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.3846 - acc: 0.8594 - val_loss: 0.4048 - val_acc: 0.8480\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.3531 - acc: 0.8712 - val_loss: 0.3753 - val_acc: 0.8634\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.3302 - acc: 0.8786 - val_loss: 0.3996 - val_acc: 0.8560\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3127 - acc: 0.8853 - val_loss: 0.3537 - val_acc: 0.8744\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa72565d1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    }
  ]
}